title,language,original,stars
NetBSD/src,None,"NetBSD
NetBSD is a free, fast, secure, and highly portable Unix-like Open
Source operating system.  It is available for a wide range of
platforms, from large-scale servers
and powerful desktop systems to handheld and embedded devices.
Building
You can cross-build NetBSD from most UNIX-like operating systems.
To build for amd64 (x86_64), in the src directory:
./build.sh -U -u -j4 -m amd64 -O ~/obj release

Additional build information available in the BUILDING file.
Binaries

Daily builds
Releases

Testing
On a running NetBSD system:
cd /usr/tests; atf-run | atf-report

Troubleshooting

Send bugs and patches via web form.
Subscribe to the mailing lists.
The netbsd-users list is a good choice for many problems; watch current-users if you follow the bleeding edge of NetBSD-current.
Join the community IRC channel #netbsd @ freenode.

Latest sources
To fetch the main CVS repository:
cvs -d anoncvs@anoncvs.NetBSD.org:/cvsroot checkout -P src

To work in the Git mirror, which is updated every few hours from CVS:
git clone https://github.com/NetBSD/src.git

Additional Links

The NetBSD Guide
NetBSD manual pages
NetBSD Cross-Reference

",157
morozov-group/magento2-similar-products,PHP,"magento2-similar-products

Magento 2 Similarity extension which provides connectivity with Similarity Engine.
Demo store

Automated Upsells for every product Demo | Production
Visually Similar products for specified product /catalogsearch/advanced/result/?similar=PRODUCT_ID
Visually Similar products within same category category.html?similar=PRODUCT_ID Demo
CMS Widget to put similar products any where for specified PRODUCT_ID.
(Near future) Category filling assistant, for some special events or campaigns.

Installation
Simple installation via composer.
compose require morozov-group/magento2-similar-products

Go to configuration enter your email, and we'll take care of everything else.
You will receive email once we are ready to serve similar products recommendations.
Then you can proceed with customizations.
Contributions and new ideas
You are welcome to post tickets and pull requests.
",5
u-simon/springCloudDemo,Java,"springCloudDemo
",2
AMReX-Codes/amrex,C++,"
License
AMReX Copyright (c) 2017, The Regents of the University of California,
through Lawrence Berkeley National Laboratory and the Alliance for
Sustainable Energy, LLC., through National Renewable Energy Laboratory
(subject to receipt of any required approvals from the U.S. Dept. of
Energy).  All rights reserved.
If you have questions about your rights to use or distribute this
software, please contact Berkeley Lab's Innovation & Partnerships
Office at IPO@lbl.gov.
NOTICE.  This Software was developed under funding from the
U.S. Department of Energy and the U.S. Government consequently retains
certain rights. As such, the U.S. Government has been granted for
itself and others acting on its behalf a paid-up, nonexclusive,
irrevocable, worldwide license in the Software to reproduce,
distribute copies to the public, prepare derivative works, and perform
publicly and display publicly, and to permit other to do so.
License for AMReX can be found at LICENSE.
Development Model
Development generally follows the following ideas:


New features are committed to the development branch.
Nightly regression testing is used to ensure that no answers
change (or if they do, that the changes were expected).
If a change is critical, we can cherry-pick the commit from
development to master.


Bug fixes, questions and contributions of new features are welcome!


Bugs should be reported through GitHub issues


We suggest asking questions through GitHub issues as well


Any contributions of new features that have the potential
to change answers should be done via pull requests.
A pull request should be generated from your fork of
amrex and target the development branch.
If there are a number of small commits making up the PR, we may
wish to squash commits upon merge to have a clean history.
Please ensure that your PR title and first post are descriptive,
since these will be used for a squashed commit message.
Please note the following:
If you choose to make contributions to the code
then you hereby grant a non-exclusive, royalty-free perpetual license
to install, use, modify, prepare derivative works,
incorporate into other computer software,
distribute, and sublicense such enhancements or derivative works
thereof, in binary and source code form.




On the first workday of each month, we perform a merge of
development into master.  For this merge to take place, we
need to be passing the regression tests.
To accommodate this need, we close the merge window into
development a few days before the merge day.  While the merge
window is closed, only bug fixes should be pushed into
development.  Once the merge from development -> master is
done, the merge window reopens.


Core Developers
People who make a number of substantive contributions will be named
""core developers"" of AMReX.  The criteria for becoming a core
developer are flexible, but generally involve one of the following:


100 non-trivial commits to amrex/Src/ and/or


addition of a new algorithm / module  and/or


substantial input into the code design process or testing


If a core developer is inactive for multiple years, we may reassess their
status as a core developer.
The current list of core developers is: Ann Almgren (LBNL), Vince Beckner, John Bell (LBNL), Johannes Blaschke (LBNL), Cy Chan (LBNL), Marcus Day (LBNL), Brian Friesen (NERSC), Kevin Gott (NERSC), Daniel Graves (LBNL), Max Katz (NVIDIA), Andrew Myers (LBNL), Tan Nguyen (LBNL), Andrew Nonaka (LBNL), Michele Rosso (LBNL), Sam Williams (LBNL), Weiqun Zhang (LBNL), Michael Zingale (Stonybrook University).
",130
joeynmt/joeynmt,Python,"Â   Joey NMT

Goal and Purpose
Joey NMT framework is developed for educational purposes.
It aims to be a clean and minimalistic code base to help novices
pursuing the understanding of the following questions.

How to implement classic NMT architectures (RNN and Transformer) in PyTorch?
What are the building blocks of these architectures and how do they interact?
How to modify these blocks (e.g. deeper, wider, ...)?
How to modify the training procedure (e.g. add a regularizer)?

In contrast to other NMT frameworks, we will not aim for
state-of-the-art results or speed through engineering or training tricks
since this often goes in hand with an increase in code complexity
and a decrease in readability.
However, Joey NMT re-implements baselines from major publications.
Contributors
Joey NMT is developed by Joost Bastings (University of Amsterdam) and Julia Kreutzer (Heidelberg University).
Features
We aim to implement the following features (aka the minimalist toolkit of NMT):

Recurrent Encoder-Decoder with GRUs or LSTMs
Transformer Encoder-Decoder
Attention Types: MLP, Dot, Multi-Head, Bilinear
Word-, BPE- and character-based input handling
BLEU, ChrF evaluation
Beam search with length penalty and greedy decoding
Customizable initialization
Attention visualization
Learning curve plotting

[Work in progress: Transformer, Multi-Head and Dot still missing.]
Coding
In order to keep the code clean and readable, we make use of:

Style checks: pylint with (mostly) PEP8 conventions, see .pylintrc.
Typing: Every function has documented input types.
Docstrings: Every function, class and module has docstrings describing their purpose and usage.
Unittests: Every module has unit tests, defined in test/unit/.
Travis CI runs the tests and pylint on every push to ensure the repository stays clean.

Installation
Joey NMT is built on PyTorch and torchtext for Python >= 3.5.

Clone this repository:
git clone https://github.com/joeynmt/joeynmt.git
Install the requirements:
cd joeynmt
pip3 install -r requirements.txt (you might want to add --user for a local installation).
Install joeynmt:
python3 setup.py install
Run the unit tests:
python3 -m unittest

Usage
For details, follow the tutorial in the docs.
Data Preparation
Parallel Data
For training a translation model, you need parallel data, i.e. a collection of source sentences and reference translations that are aligned sentence-by-sentence and stored in two files,
such that each line in the reference file is the translation of the same line in the source file.
Pre-processing
Before training a model on it, parallel data is most commonly filtered by length ratio, tokenized and true- or lowercased.
The Moses toolkit provides a set of useful scripts for this purpose.
In addition, you might want to build the NMT model not on the basis of words, but rather sub-words or characters (the level in JoeyNMT configurations).
Currently, JoeyNMT supports the byte-pair-encodings (BPE) format by subword-nmt.
Configuration
Experiments are specified in configuration files, in simple YAML format. You can find examples in the configs directory.
small.yaml contains a detailed explanation of configuration options.
Most importantly, the configuration contains the description of the model architecture (e.g. number of hidden units in the encoder RNN),
paths to the training, development and test data, and the training hyperparameters (learning rate, validation frequency etc.).
Training
Start
For training, run
python3 -m joeynmt train configs/small.yaml.
This will train a model on the training data specified in the config (here: small.yaml),
validate on validation data,
and store model parameters, vocabularies, validation outputs and a small number of attention plots in the model_dir (also specified in config).
Note that pre-processing like tokenization or BPE-ing is not included in training, but has to be done manually before.
Tip: Be careful not to overwrite models, set overwrite: False in the model configuration.
Validations
The validations.txt file in the model directory reports the validation results at every validation point.
Models are saved whenever a new best validation score is reached, in batch_no.ckpt, where batch_no is the number of batches the model has been trained on so far.
best.ckpt links to the checkpoint that has so far achieved the best validation score.
Visualization
JoeyNMT uses TensorboardX to visualize training and validation curves and attention matrices during training.
Launch Tensorboard with tensorboard --logdir model_dir/tensorboard (or python -m tensorboard.main ...) and then open the url (default: localhost:6006) with a browser.
For a stand-alone plot, run python3 scripts/plot_validation.py model_dir --plot_values bleu PPL --output_path my_plot.pdf to plot curves of validation BLEU and PPL.
CPU vs. GPU
For training on a GPU, set use_cuda in the config file to True. This requires the installation of required CUDA libraries.
Translating
There's 3 options for testing what the model has learned.
Whatever data you feed the model for translating, make sure it is properly pre-processed, just as you pre-processed the training data, e.g. tokenized and split into subwords (if working with BPEs).
1. Test Set Evaluation
For testing and evaluating on your parallel test/dev set, run
python3 -m joeynmt test configs/small.yaml --output_path out.
This will generate translations for validation and test set (as specified in the configuration) in out.[dev|test]
with the latest/best model in the model_dir (or a specific checkpoint set with load_model).
It will also evaluate the outputs with eval_metric.
If --output_path is not specified, it will not store the translation, and only do the evaluation and print the results.
2. File Translation
In order to translate the contents of a file not contained in the configuration (here my_input.txt), simply run
python3 -m joeynmt translate configs/small.yaml < my_input.txt > out.
The translations will be written to stdout or alternatively--output_path if specified.
3. Interactive
If you just want try a few examples, run
python3 -m joeynmt translate configs/small.yaml
and you'll be prompted to type input sentences that JoeyNMT will then translate with the model specified in the configuration.
Documentation and Tutorial
The docs include an overview of the NMT implementation, a walk-through tutorial for building, training, tuning, testing and inspecting an NMT system, the API documentation and FAQs.
Benchmarks
Benchmarks on small models trained on GPU/CPU on standard data sets are reported here.

IWSLT15 En-Vi, word-based
IWSLT14 De-En, 32000 joint BPE, word-based
WMT17 En-De and Lv-En, 32000 joint BPE

IWSLT English-Vietnamese
We compare against Tensorflow NMT on the IWSLT15 En-Vi data set as preprocessed by Stanford.
You can download the data with scripts/get_iwslt15_envi.sh, and then use configs/iwslt_envi_luong.yaml to replicate the experiment.



Systems
tst2012 (dev)
test2013 (test)




TF NMT (greedy)
23.2
25.5


TF NMT (beam=10)
23.8
26.1


Joey NMT (greedy)
23.2
25.8


Joey NMT (beam=10, alpha=1.0)
23.8
26.5


(Luong & Manning, 2015)
-
23.3



We also compare against xnmt which uses different hyperparameters, so we use a different configuration for Joey NMT too: configs/iwslt_envi_xnmt.yaml.



Systems
tst2012 (dev)
test2013 (test)




xnmt (beam=5)
25.0
27.3


Joey NMT (greedy)
24.6
27.4


Joey NMT (beam=5, alpha=1.0)
24.9
27.7



IWSLT  German-English
We compare against the baseline scores reported in (Wiseman & Rush, 2016) (W&R),
(Bahdanau et al., 2017) (B17) with tokenized, lowercased BLEU (using sacrebleu).
áºe compare a word-based model of the same size and vocabulary as in W&R and B17.
The script to obtain and pre-process the data is the one published with W&R.
Use configs/iwslt_deen_bahdanau.yaml for training the model.
On a K40-GPU word-level training took <1h, beam search decoding for both dev and test <2min.



Systems
level
dev
test
#params




W&R (greedy)
word
-
22.53



W&R (beam=10)
word
-
23.87



B17 (greedy)
word
-
25.82



B17 (beam=10)
word
-
27.56



Joey NMT (greedy)
word
28.41
26.68
22.05M


Joey NMT (beam=10, alpha=1.0)
word
28.96
27.03
22.05M



On CPU (use_cuda: False):
(approx 8-10x slower: 8h for training, beam search decoding for both dev and test 19min, greedy decoding 5min)



Systems
level
dev
test
#params




Joey NMT (greedy)
word
28.35
26.46
22.05M


Joey NMT (beam=10, alpha=1.0)
word
28.85
27.06
22.05M



In addition, we compare to a BPE-based GRU model with 32k (Groundhog style).
Use scripts/get_iwslt14_bpe.sh to pre-process the data and configs/iwslt14_deen_bpe.yaml to train the model.
This model is available for download here.



Systems
level
dev
test
#params




Joey NMT (greedy)
bpe
27.57

60.69M


Joey NMT (beam=5, alpha=1.0)
bpe
28.55
27.34
60.69M



WMT 17 English-German and Latvian-English
We compare against the results for recurrent BPE-based models that were reported in the Sockeye paper.
We only consider the Groundhog setting here, where toolkits are used out-of-the-box for creating a Groundhog-like model (1 layer, LSTMs, MLP attention).
The data is pre-processed as described in the paper (code).
Postprocessing is done with Moses' detokenizer, evaluation with sacrebleu.
Note that the scores reported for other models might not reflect the current state of the code, but the state at the time of the Sockeye evaluation.
Please also consider the difference in number of parameters despite ""the same"" setup: our models are the smallest in numbers of parameters.
English-German
Groundhog setting: configs/wmt_ende_default.yaml  with encoder rnn=500, lr=0.0003, init_hidden=""bridge"".



Systems
level
dev
test
#params




Sockeye (beam=5)
bpe
-
23.18
87.83M


OpenNMT-Py (beam=5)
bpe
-
18.66
87.62M


Joey NMT (beam=5)
bpe
24.33
23.45
86.37M



The Joey NMT model was trained for 4 days (14 epochs).
Latvian-English
Groundhog setting: configs/wmt_lven_default.yaml with encoder rnn=500, lr=0.0003, init_hidden=""bridge"".



Systems
level
dev
test
#params




Sockeye (beam=5)
bpe
-
14.40
?


OpenNMT-Py (beam=5)
bpe
-
9.98
?


Joey NMT (beam=5)
bpe
12.09
8.75
64.52M



Contributing
Since this codebase is supposed to stay clean and minimalistic, contributions addressing the following are welcome:

Code correctness
Code cleanliness
Documentation quality
Speed or memory improvements
resolving issues

Code extending the functionalities beyond the basics will most likely not end up in the master branch, but we're curions to learn what you used Joey for.
Use-cases and Projects
Here we'll collect projects and repositories that are based on Joey. If you used Joey for a project, publication or built some code on top of it, let us know and we'll link it here.
Projects:

TBD

Contact
Please leave an issue if you have questions or issues with the code.
For general questions, email us at joeynmt <at> gmail.com.
Naming
Joeys are infant marsupials.
",46
JingningShi/MtreeRing,R,"MtreeRing
Authors: Jingning Shi, Wei Xiang
License: GPL3






MtreeRing is a tool for automatically measuring tree-ring width using image processing techniques.
Installation
Install the stable version from CRAN
install.packages(""MtreeRing"")
or the development version from GitHub
# install.packages(""devtools"")
devtools::install_github(""JingningShi/MtreeRing"")
Ring-width measurement
1. Read an image
library(MtreeRing)
## Read and plot a tree ring image
img.name <- system.file(""001.png"", package = ""MtreeRing"")
t1 <- ring_read(img = img.name, dpi = 1200, plot = TRUE)
ring_read supports commonly used image formats, including png, tiff, jpg and bmp.
2. Detect ring borders
After plotting the image, the automatic detection of ring borders can be performed using three alternative methods: (1) watershed algorithm; (2) Canny edge detector; (3) a linear detection algorithm from R package measuRing.
## Split a long core sample into 2 pieces to
## get better display performance and use the
## watershed algorithm to detect ring borders:
t2 <- ring_detect(ring.data = t1, seg = 2, method = 'watershed')

Figure 1. The automatic detection of ring borders
3. Calculate ring-width series
If all ring borders are correctly identified, you can generate a ring-width series in data frame format. Use write.rwl to export the ring-width series to an rwl file.
rw.df <- ring_calculate(ring.data = t2, seriesID = ""940220"")
library(dplR) # A dendrochronological analysis package
fn <- tempfile(fileext="".rwl"")
write.rwl(rwl.df = rw.df, fname = fn, format = ""tucson"")
Shiny application
If you are not familiar with R and its command line interface, the shiny-based app is a good alternative.
MtreeRing::ring_app_launch()
This command allows to run a Shiny-based application within the system's default web browser. The app provides a beginner-friendly graphical interface and supports more flexible mouse-based interactions.
The dashboard has three components: a header, sidebar and body, like this

A workflow for the Shiny app can be found in the package vignette. Most steps are demonstrated with a gif to make the workflow more understandable.
vignette('app-MtreeRing')
Ring width correction
If an increment borer is used to extract samples, it is well known that the auger sometimes fails to traverse the pith of the sampled tree but passes through one side of the pith at a certain distance. Tangent lines of rings close to the pith are therefore not perpendicular to the horizontal path, which may lead to considerable errors in ring widths.
Under such conditions, you can create two paths by setting the argument incline = TRUE, or by ticking the checkbox ""Inclined tree rings"". See this example.

The line segment connecting two dots on the same ring should match the tangent of a tree ring border. The corrected ring width is estimated from the distance between adjacent rings and orientation of ring borders.
Code of conduct
Please note that the 'MtreeRing' project is released with a Contributor Code of Conduct. By contributing to this project, you agree to abide by its terms.
",2
yongzhuo/nlp_xiaojiang,Python,"nlp_xiaojiang
AugmentText
- åè¯ï¼æææ¯è¾å¥½ï¼
- EDAï¼åä¹è¯æ¿æ¢ãæå¥ãäº¤æ¢åå é¤ï¼ï¼ææè¿è¡ï¼
- HMM-markoï¼è´¨éè¾å·®ï¼
- syntaxï¼ä¾å­å¥æ³ãå¥æ³ãè¯­æ³ä¹¦ï¼ï¼ç®åå¥è¿å¯ï¼
- seq2seqï¼æ·±åº¦å­¦ä¹ åä¹å¥çæï¼ææä¸çæ³ï¼seq2seqä»£ç å¤§é½æ¯ [https://github.com/qhduan/just_another_seq2seq] çï¼ææä¸çæ³ï¼

ChatBot
- æ£ç´¢å¼ChatBot
    - åESé£æ ·ç´æ¥æ£ç´¢(å¦ä½¿ç¨fuzzywuzzy)ï¼åªè½å­é¢å¹é
    - æé å¥åéï¼æ£ç´¢é®ç­åºï¼è½å¤æ£ç´¢æåä¹è¯çå¥å­
- çæå¼ChatBotï¼todoï¼
    - seq2seq
    - GAN

ClassificationText
- bert+bi-lstm(keras) approach 0.78~0.79% acc of Weizhong Bank Intelligent Customer Service Question Matching Competition

FeatureProject
- bertå¥åéãææ¬ç¸ä¼¼åº¦
    - bert/extract_keras_bert_feature.py:æåbertå¥åéç¹å¾
    - bert/tet_bert_keras_sim.py:æµè¯bertå¥åécosinç¸ä¼¼åº¦
- normalization_utilæçæ¯æ°æ®å½ä¸å
    - 0-1å½ä¸åå¤ç
    - åå¼å½ä¸å
    - sigå½ä¸åå¤ç
- sim featureï¼MLï¼
    - distance_text_or_vec:åç§è®¡ç®ææ¬ãåéè·ç¦»ç­
    - distance_vec_TS_SSï¼TS_SSè®¡ç®è¯åéè·ç¦»
    - cut_td_idfï¼å°å°é»é¸¡è¯­æågossipç»å
    - sentence_sim_featureï¼è®¡ç®ä¸¤ä¸ªææ¬çç¸ä¼¼åº¦æèè·ç¦»ï¼ä¾å¦qqï¼é®é¢åé®é¢ï¼ï¼æèqaï¼é®é¢åç­æ¡ï¼

run(å¯ä»¥å¨win10ä¸,pycharmä¸è¿è¡)

1.åå»ºtf-idfæä»¶ç­ï¼è¿è¡2éè¦åè·1ï¼:
python cut_td_idf.py
2.è®¡ç®ä¸¤ä¸ªå¥å­é´çåç§ç¸ä¼¼åº¦ï¼åè®¡ç®ä¸ä¸ªé¢å®ä¹çï¼ç¶åå¯è¾å¥èªå®ä¹çï¼åè·1ï¼:
python sentence_sim_feature.py
3.chatbot_1è·èµ·æ¥(fuzzyæ£ç´¢-æ²¡)ï¼ç¬ç«ï¼ï¼
python chatbot_fuzzy.py
4.chatbot_2è·èµ·æ¥(å¥åéæ£ç´¢-è¯)ï¼ç¬ç«ï¼ï¼
python chatbot_sentence_vec_by_word.py
5.chatbot_3è·èµ·æ¥(å¥åéæ£ç´¢-å­)ï¼ç¬ç«ï¼ï¼
python chatbot_sentence_vec_by_char.py
6.æ°æ®å¢å¼ºï¼eda)ï¼                     python enhance_eda.py
7.æ°æ®å¢å¼ºï¼markoï¼:                   python enhance_marko.py
8.æ°æ®å¢å¼ºï¼translate_accountï¼:       python translate_tencent_secret.py
9.æ°æ®å¢å¼ºï¼translate_toolsï¼:         python translate_translate.py
10.æ°æ®å¢å¼ºï¼translate_webï¼:          python translate_google.py
11.æ°æ®å¢å¼ºï¼augment_seq2seqï¼:        åè· python extract_char_webank.pyçææ°æ®ï¼
åè· python train_char_anti.py
ç¶åè· python predict_char_anti.py
12.ç¹å¾è®¡ç®(bert)ï¼æåç¹å¾ãè®¡ç®ç¸ä¼¼åº¦ï¼:
run extract_keras_bert_feature.py run tet_bert_keras_sim.py

Data
- chinese_L-12_H-768_A-12ï¼è°·æ­é¢è®­ç»å¥½çæ¨¡åï¼
   githubé¡¹ç®ä¸­åªæ¯ä¸ä¼ é¨åæ°æ®ï¼éè¦çåå¾é¾æ¥: https://pan.baidu.com/s/1I3vydhmFEQ9nuPG2fDou8Q æåç : rket
   è§£ååå°±å¯ä»¥å¦
- chinese_vector
    githubé¡¹ç®ä¸­åªæ¯ä¸ä¼ é¨åæ°æ®ï¼éè¦çåå¾é¾æ¥: https://pan.baidu.com/s/1I3vydhmFEQ9nuPG2fDou8Q æåç : rket
    - æªåçé¨åword2vecè®­ç»è¯åéï¼èªå·±éè¦ä¸è½½å¨æææä¼å¥½ï¼
    - w2v_model_wiki_char.vecãw2v_model_wiki_word.vecé½åªæé¨å
- corpus
    githubé¡¹ç®ä¸­åªæ¯ä¸ä¼ é¨åæ°æ®ï¼éè¦çåå¾é¾æ¥: https://pan.baidu.com/s/1I3vydhmFEQ9nuPG2fDou8Q æåç : rket
    - webank(trainãdevãtest)
    - å°é»é¸¡ågossipé®ç­é¢æï¼æ°æ®æ²¡æ¸æ´ï¼,chicken_and_gossip.txt
    - å¾®ä¼é¶è¡åæ¯ä»å®ææ¬ç¸ä¼¼åº¦ç«èµæ°æ®ï¼ sim_webank.csv
- sentence_vec_encode_char
    - 1.txtï¼å­åéçæçå100000å¥åéï¼
- sentence_vec_encode_word
    - 1.txtï¼è¯åéçæçå100000å¥åéï¼
- tf_idfï¼chicken_and_gossip.txtçæçtf-idfï¼

requestments.txt
- python_Levenshtei
    - è°ç¨Levenshteinï¼æçpythonæ¯3.6ï¼
    - æå¼å¶æºæä»¶: https://www.lfd.uci.edu/~gohlke/pythonlibs/
    - æ¥æ¾python_Levenshtein-0.12.0-cp36-cp36m-win_amd64.whlä¸è½½å³å¯
- pyemd
- pyhanlp
    - ä¸å¥½ä¾èµJPype1-0.6.3-cp36-cp36m-win_amd64.whl

åè/æè°¢

eda_chineseï¼https://github.com/zhanlaoban/eda_nlp_for_Chinese
ä¸»è°å®¾æåå¨ï¼https://github.com/hankcs/MainPartExtractor
HMMçæå¥å­ï¼https://github.com/takeToDreamLand/SentenceGenerate_byMarkov
åä¹è¯ç­ï¼https://github.com/fighting41love/funNLP/tree/master/data/
å°çç¿»è¯ï¼http://www.niutrans.com/index.html

å¶ä»èµæ

bert(keras):https://github.com/CyberZHG/keras-bert
NLPæ°æ®å¢å¼ºæ±æ»:https://github.com/quincyliang/nlp-data-augmentation
ç¥ä¹NLPæ°æ®å¢å¼ºè¯é¢:https://www.zhihu.com/question/305256736/answer/550873100
chatbot_seq2seq_seqGanï¼æ¯è¾å¥½ç¨ï¼ï¼https://github.com/qhduan/just_another_seq2seq
èªå·±å¨æåèå¤©æºå¨äººæç¨: https://github.com/warmheartli/ChatBotCourse

",19
alexherbo2/site,JavaScript,"Site
Configuration | Theme | Builds | Contributing

Personal web site built with Hugo.

",2
opengeospatial/geotiff,HTML,"geotiff
The key folder where the asciidoc specification is developed is GeoTIFF_Standard cf. https://github.com/opengeospatial/geotiff/tree/master/GeoTIFF_Standard/standard
Other files of interest are:

geotiff_standard.html
geotiff_standard.pdf

Other folders are just for traceability, capturing the works done between 2014 and 2018.
",6
dawoudt/JustWatchAPI,Python,"JustWatchAPI

JustWatch.com Python 3 API
Install
python3 -m pip install JustWatch
How To
search for an item
from justwatch import JustWatch

just_watch = JustWatch(country='US')

results = just_watch.search_for_item(query='the matrix')
or search for combination of genres
just_watch = JustWatch(genres=['act', 'scf', 'hrr'])

results_by_genres = just_watch.search_for_item()
or maybe search by provider
just_watch = JustWatch()

results_by_providers = just_watch.search_for_item(providers=['nfx', 'stn'])
or possibly a combination of the above
just_watch = JustWatch()

results_by_multiple = just_watch.search_for_item(
    providers=['nfx', 'stn'], 
    content_types=['movie'], 
    monetization_types=['free'])
get list of genres and codes
just_watch = JustWatch(country='GB')
genre_details = just_watch.get_genres()

get list of providers for a country
just_watch = JustWatch(country='DE')
provider_details = just_watch.get_providers()

get further details on a movie or tv program
Based on title id found in previous search
just_watch = JustWatch(country='GB')
megamind = just_watch.get_title(title_id=103561)
dark = just_watch.get_title(title_id=55668, content_type='show')

You can query for title IDs
just_watch = JustWatch(country='GB')
the_matrix = just_watch.get_title_id(query='the matrix')

{'The Matrix': 10, 'The Matrix Revisited': 30701, ...}

get further defails on a specific season of a tv program
season_id can be found in the response from get_title of a tv program
just_watch = JustWatch(country='GB')
hannibal_season2 = just_watch.get_season(season_id=20236)

get country specific certification details
just_watch = JustWatch(country='GB')
certs = just_watch.get_certifications()

content_type can be specified but (for GB at least) setting to 'show' gives less detail than the default of 'movie'
get cinema details
Setting ""monetization_types"" to ""cinema"" and possibly setting nationwide_cinema_releases_only = True will return a list of potential showings.
just_watch = JustWatch(country='GB')
cinema_showings = just_watch.search_for_item(monetization_types='cinema')

Then based on title_id obtained from that search
cinema_times = just_watch.get_cinema_times(title_id=this_title_id,
                                           date='2018-03-24',
                                           latitude=51.5287718,
                                           longitude=-0.2416809,
                                           radius=20000)
This will return details of all the showings in the area.  Details of all the cinemas in the area can be obtained by a call to get_cinema_details().  This takes the same latitutde, longitude and radius parameters as get_cinema_times(), and if a call has already been made they'll be reused.
local_cinemas = just_watch.get_cinema_details()
You can then join the data from the two calls by joining 'cinema_id' from get_cinema_times() with 'id' from get_cinema_details()
get upcoming cinema details
Call get_upcoming_cinema() with number of weeks forward or back and whether you only require national releases
showings_last_week = just_watch.get_upcoming_cinema(weeks_offset=-1, nationwide_cinema_releases_only=True)
showings_three_weeks = just_watch.get_upcoming_cinema(weeks_offset=3, nationwide_cinema_releases_only=False)
Note: Default country is AU
Read api_payload.txt for more information
Contributions
Contributions are welcome!
Please write unit tests for any new functionality :)
",70
apple/swift-source-compat-suite,Python,"Swift Source Compatibility Suite
Source compatibility is a strong goal for future Swift releases. To aid in this
goal, a community owned source compatibility test suite serves to regression
test changes to the compiler against a (gradually increasing) corpus of Swift
source code. Projects added to this test suite are periodically built against
the latest development versions of Swift as part of Swift's continuous
integration system, allowing Swift compiler developers to
understand the compatibility impact their changes have on real-world Swift
projects.
Current List of Projects
The current list of projects can be viewed on Swift.org.
Adding Projects
The Swift source compatibility test suite is community driven, meaning that open
source Swift project owners are encouraged to submit their projects that meet
the acceptance criteria for inclusion in the test suite. Projects added to the
suite serve as general source compatibility tests and are afforded greater
protection against unintentional source breakage in future Swift releases.
Acceptance Criteria
To be accepted into the Swift source compatibility test suite, a project must:

Target Linux, macOS, or iOS/tvOS/watchOS device
Be an Xcode or Swift Package Manager project (Carthage and CocoaPods are currently unsupported but are being explored to be supported in the future)
Support building on either Linux or macOS
Be contained in a publicly accessible git repository
Maintain a project branch that builds against Swift 3.0 compatibility mode
and passes any unit tests
Have maintainers who will commit to resolve issues in a timely manner
Be compatible with the latest GM/Beta versions of Xcode and swiftpm
Add value not already included in the suite
Be licensed with one of the following permissive licenses:

BSD
MIT
Apache License, version 2.0
Eclipse Public License
Mozilla Public License (MPL) 1.1
MPL 2.0
CDDL



Note: Linux compatibility testing in continuous integration is not available
yet, but Linux projects are being accepted now.
Adding a Project
To add a project meeting the acceptance criteria to the suite, perform the
following steps:

Ensure the project builds successfully at a chosen commit against
Swift 3.0 GM
Create a pull request against the source compatibility suite
repository,
modifying projects.json to include a reference to the project being added
to the test suite.

The project index is a JSON file that contains a list of repositories containing
Xcode and/or Swift Package Manager target actions.
To add a new Swift Package Manager project, use the following template:
{
  ""repository"": ""Git"",
  ""url"": ""https://github.com/example/project.git"",
  ""path"": ""project"",
  ""branch"": ""master"",
  ""maintainer"": ""email@example.com"",
  ""compatibility"": [
    {
      ""version"": ""3.0"",
      ""commit"": ""195cd8cde2bb717242b3081f9c367ccd0a2f0121""
    }
  ],
  ""platforms"": [
    ""Darwin""
  ],
  ""actions"": [
    {
      ""action"": ""BuildSwiftPackage"",
      ""configuration"": ""release""
    },
    {
      ""action"": ""TestSwiftPackage""
    }
  ]
}
The compatibility field contains a list of version dictionaries, each
containing a Swift version and a commit. Commits are checked out before
building a project in the associated Swift version compatibility mode. The
Swift version is the earliest version of Swift known to compile the project at
the given commit. The goal is to have multiple commits at different points in a
project's history that are compatible with all supported Swift version
compatibility modes.
The platforms field specifies the platforms that can be used to build the
project. Linux and Darwin can currently be specified.
If tests aren't supported, remove the test action entry.
To add a new Swift Xcode workspace, use the following template:
{
  ""repository"": ""Git"",
  ""url"": ""https://github.com/example/project.git"",
  ""path"": ""project"",
  ""branch"": ""master"",
  ""maintainer"": ""email@example.com"",
  ""compatibility"": [
    {
      ""version"": ""3.0"",
      ""commit"": ""195cd8cde2bb717242b3081f9c367ccd0a2f0121""
    }
  ],
  ""platforms"": [
    ""Darwin""
  ],
  ""actions"": [
    {
      ""action"": ""BuildXcodeWorkspaceScheme"",
      ""workspace"": ""project.xcworkspace"",
      ""scheme"": ""project OSX"",
      ""destination"": ""platform=macOS"",
      ""configuration"": ""Release""
    },
    {
      ""action"": ""BuildXcodeWorkspaceScheme"",
      ""workspace"": ""project.xcworkspace"",
      ""scheme"": ""project iOS"",
      ""destination"": ""generic/platform=iOS"",
      ""configuration"": ""Release""
    },
    {
      ""action"": ""BuildXcodeWorkspaceScheme"",
      ""workspace"": ""project.xcworkspace"",
      ""scheme"": ""project tvOS"",
      ""destination"": ""generic/platform=tvOS"",
      ""configuration"": ""Release""
    },
    {
      ""action"": ""BuildXcodeWorkspaceScheme"",
      ""workspace"": ""project.xcworkspace"",
      ""scheme"": ""project watchOS"",
      ""destination"": ""generic/platform=watchOS"",
      ""configuration"": ""Release""
    },
    {
      ""action"": ""TestXcodeWorkspaceScheme"",
      ""workspace"": ""project.xcworkspace"",
      ""scheme"": ""project OSX"",
      ""destination"": ""platform=macOS""
    },
    {
      ""action"": ""TestXcodeWorkspaceScheme"",
      ""workspace"": ""project.xcworkspace"",
      ""scheme"": ""project iOS"",
      ""destination"": ""platform=iOS Simulator,name=iPhone 7""
    },
    {
      ""action"": ""TestXcodeWorkspaceScheme"",
      ""workspace"": ""project.xcworkspace"",
      ""scheme"": ""project tvOS"",
      ""destination"": ""platform=tvOS Simulator,name=Apple TV 1080p""
    }
  ]
}
To add a new Swift Xcode project, use the following template:
{
  ""repository"": ""Git"",
  ""url"": ""https://github.com/example/project.git"",
  ""path"": ""project"",
  ""branch"": ""master"",
  ""maintainer"": ""email@example.com"",
  ""compatibility"": [
    {
      ""version"": ""3.0"",
      ""commit"": ""195cd8cde2bb717242b3081f9c367ccd0a2f0121""
    }
  ],
  ""platforms"": [
    ""Darwin""
  ],
  ""actions"": [
    {
      ""action"": ""BuildXcodeProjectTarget"",
      ""project"": ""project.xcodeproj"",
      ""target"": ""project"",
      ""destination"": ""generic/platform=iOS"",
      ""configuration"": ""Release""
    }
  ]
}
After adding a new project to the index, ensure it builds successfully at the
pinned commits against the specified versions of Swift. In the examples,
the commits are specified as being compatible with Swift 3.0, which is included
in Xcode 8.0.
# Select Xcode 8.0 GM
sudo xcode-select -s /Applications/Xcode.app
# Build project at pinned commit against selected Xcode
./project_precommit_check project-path-field --earliest-compatible-swift-version 3.0
On Linux, you can build against the Swift 3.0 release toolchain:
curl -O https://swift.org/builds/swift-3.0-release/ubuntu1510/swift-3.0-RELEASE/swift-3.0-RELEASE-ubuntu15.10.tar.gz
tar xzvf swift-3.0-RELEASE-ubuntu15.10.tar.gz
./project_precommit_check project-path-field --earliest-compatible-swift-version 3.0 --swiftc swift-3.0-RELEASE-ubuntu15.10/usr/bin/swiftc
Maintaining Projects
In the event that Swift introduces a change that breaks source compatibility
with a project (e.g., a compiler bug fix that fixes wrong behavior in the
compiler), project maintainers are expected to update their projects and submit
a new pull request with the updated commit hash within two weeks of being
notified. Otherwise, unmaintained projects may be removed from the project
index.
Pull Request Testing
Pull request testing against the Swift source compatibility suite can be
executed by commenting with @swift-ci Please test source compatibility in a
Swift pull request.
Building Projects
To build all projects against a specified Swift compiler locally, use the
runner.py utility as shown below.
./runner.py --swift-branch master --projects projects.json --include-actions 'action.startswith(""Build"")' --swiftc path/to/swiftc
Use the --include-repos flag to build a specific project.
./runner.py --swift-branch master --projects projects.json --include-actions 'action.startswith(""Build"")' --include-repos 'path == ""Alamofire""' --swiftc path/to/swiftc
By default, build output is redirected to per-action .log files in the current
working directory. To change this behavior to output build results to standard
out, use the --verbose flag.
Marking actions as expected failures
When an action is expected to fail for an extended period of time, it's
important to mark the action as an expected failure to make new failures more
visible.
To mark an action as an expected failure, add an xfail entry for the correct
Swift version and branch to the failing actions, associating each with a link
to a JIRA reporting the relevant failure. The following is an example of an
action that's XFAIL'd when building against Swift master branch in 3.0
compatibility mode.
{
  ""repository"": ""Git"",
  ""url"": ""https://github.com/example/project.git"",
  ""path"": ""project"",
  ""branch"": ""master"",
  ""maintainer"": ""email@example.com"",
  ""compatibility"": [
    {
      ""version"": ""3.0"",
      ""commit"": ""195cd8cde2bb717242b3081f9c367ccd0a2f0121""
    }
  ],
  ""platforms"": [
    ""Darwin""
  ],
  ""actions"": [
    {
      ""action"": ""BuildXcodeProjectTarget"",
      ""project"": ""project.xcodeproj"",
      ""target"": ""project"",
      ""destination"": ""generic/platform=iOS"",
      ""configuration"": ""Release"",
      ""xfail"": {
        ""compatibility"": {
          ""3.0"": {
            ""branch"": {
              ""master"": ""https://bugs.swift.org/browse/SR-9999""
            }
          }
        }
      }
    }
  ]
}
Additional Swift branches and versions can be added to XFAIL different
configurations.
",197
MaksimRudnev/LittleHelpers,R,"LittleHelpers
Continuously updated collection of little helpers (tm) that facilitates my life in analyzing data (mostly comparative datasets) with R.
Use devtools::install_github(""maksimrudnev/LittleHelpers"") to install.
Overview

Multilevel helpers
Multigroup helpers
Tools for labelled data and Rstudio viewer
Pipe helpers
Values, Schwartz, ESS
Miscellaneous

Multilevel helpers
Explore multilevel data:

cor_within prints and plots individual correlations within each group.
cor_between computes means and shows group-level correlation between two variables.
scatter_means_ci Computes means by group and plots on scatterplot against each other (shows country-level correlations).
graph_means_ci Plots means by group.
stacked_bar Computes proportions cross-table and plots them in a nice way, returns ggplot object, so any further +theme(), +scale_x(), etc. codes can be added.

Recode multilevel data:

aggr_and_merge helps to create group-level variables from individual-level variables and merge them back to the data.frame on the go.
grand_center Quick grand-mean centering.
group_center Quick group-mean centering.

Summarize and visualize multilevel regressions:

good_table Large function that creates customizable coefficients tables using multiple lmer models; outputs in Rstudio viewer.
potential_interactions Exploratory. If you have no idea what cross-level interactions to look for. Computes pairwise tests of all the possible interactions in the lmer() model, or simply shows correlations between random effects and group-level variables.
random_interaction Plots cross-level interactions for lmer()-fitted models. Customizable. Can automatically choose real moderator values close to mean+-(2)SD.
random_plot Plots random effects from lmer()-fitted models.

Compute extra stats for multilevel regressions:

explained_variance.merMod Computes psudo-R-square for two-level regressions fitted with lmer().
vif_mer Compute variance inflation factor for multilevel regressions fitted with lmer().

Multigroup helpers


lavTestScore_clean Wrapper around lavaan::lavTestScore(), merging parameter labels with parameters and groups names and adding stars. Useful when you decide with between-group contraints might be relaxed.


mgcfa_diagnose Print comprehensible output to diagnose problems with MGCFA models.


mi_test Series of measurement invariance tests, analoigous to semTools::measurementInvariance().


See also Measurement invariance explorer - Shiny App


Pipe helpers
Branching/ramifying pipes
Imagine you need to create a list with means, correlations, and regression results. And you like to do it in one single pipe. In general, it is not possible, and you'll have to start a second pipe, probably doing some redundant computations.
Three little functions that allow for branching pipes. It is against Hadley's idea, as pipes are in principle linear, and in general I agree, but sometimes it would be comfy to ramify pipes away. It overcomes native magrittr %T>% by allowing more than one step after cutting the pipe.

ramify Saves current result into temporary object .buf and identifies a point in the pipe where branching will happen. Argument is an id of a ramification.
branch Starts a new branch from the ramify point. (branch(1) can be omitted, as ramify creates the first branch. Second argument is a family of branches, or parent branch. By default it uses the last parent branch created by the last used ramify.
harvest Returns contents of all the branches as a list.

Example that allows it:
data.frame(a=1:5, b=1/(1+exp(6:10)) ) %>%
  ramify(1) %>%
    branch(1) %>% colMeans %>% 
    branch(2) %>% lm(a ~ b, .) %>% broom::tidy(.) %>% 
    branch(3) %>% cor %>%
      ramify(2) %>%
        branch(1) %>% round(2) %>%
        branch(2) %>% psych::fisherz(.) %>%
      harvest(2) %>%
  harvest

Save'n'go & Append'n'go
savengo is ridiculously  simple but very useful function that saves objects from a middle of your pipe and passes the same object to further elements of the pipe. It allows more efficient debugging and less confusing code, in which you don't have to interrupt your pipe every time you need to save an output.
Its sister function appendngo appends an intermediary product to an existing list or a vector.
By analogy, one can create whatever storing function they need.
## Example 1
#Saves intermediary result as an object called intermediate.result

final.result <- dt %>% dplyr::filter(score<.5) %>%
                        savengo(""intermediate.result"") %>% 
                        dplyr::filter(estimated<0)
  
## Example 2
#Saves intermediary result as a first element of existing list myExistingList

final.result <- dt %>% dplyr::filter(score<.5) %>%
                        appendngo(myExistingList, after=0) %>% 
                        dplyr::filter(estimated<0)

Tools for labelled data and Rstudio viewer
Know the labels:

label_book Creates a codebook for data.frames with labels.

Make use of labels:

cor_table Prints ready-to-publish correlation tables with significance stars.
crosstab Simple cross-tabulation with labels.

Get rid of labels:

drop_labs Drops labels if you don't need them.
untibble Get rid of tibble and get clean data.frame.
lab_to_fac Converts labelled variables to factors.

Make use of Rstudio viewer:

df_to_viewer Puts any data.frame to RStudio viewer. Also works with models and anything that can be passed through stargazer.

Values, Schwartz, ESS

values list of value labels.
download_ess Download European Social Survey data
schwartz_circle Draw Schwartz circle and more with three simple functions: add_circle, add_radius, and add_label.
ess_values Computes 2, 4, or 10 value indices as they are measured in ESS.

Miscellaneous

reverse Recodes variable in reverse order. Works with labels.
replace_by_table Useful for recoding when matching tables are alsready specified in a table. Particularly useful for translation.
mean_se_lower_upper Simply mean, SE, upper and lower 95% CI.
verb Simply prints its arguments.
rename Renames variables in data.frame without bullshittery.
theme_mr Clean theme for ggplot.

News

plef

",3
alexherbo2/configuration.chrome,JavaScript,"Chrome â Configuration

Completed extension for a Dead simple Kakoune support for Chrome.

Installation
make
Open chrome://extensions in your browser, enable Developer mode then Load unpacked to select the extension directory.

",3
ryanelandt/PressureFieldContact.jl,Julia,"PressureFieldContact.jl



This module implements the elastic foundation-themed contact model for rigid body dynamics described in this short video.
This paper describes the method in greater detail.
UNDER CONSTRUCTION: See the latest documentation for installation instructions, a quick-start guide and summary of how the different pieces of this method work.
Summary
The surface of bodies are represented with a triangular mesh.
The compliant portion of bodies is represented with a tetrahedral mesh.
The easiest way to get started is to run the boxes.jl example in the test directory.
More examples will come soon.
Friction Models
This package can model friction using either a regularized Coulomb friction model or a bristle friction model.
A regularized Coulomb friction model is simple at the cost of allowing creep (i.e. a block will slide down a ramp irrespective of slope).
The bristle friction model adds extra state variables that model deformation.
This friction model allows objects to have zero tangential velocity even when applied tangential forces are not zero.
Try both to see which is best for your application.
",2
Genivia/ugrep,C++,"ugrep: universal grep
Offers powerful pre-defined search patterns and quick options to selectively
search source code files efficiently in large directory trees.
ugrep uses RE/flex for
high-performance regex matching, which is 100 times faster than the GNU C
POSIX.2 regex library used by GNU grep and 10 times faster than PCRE2 and RE2.
Because RE/flex is a streaming regex matcher, ugrep scans files more
efficiently with options like -o, permitting pattern matches that span
multiple lines instead of searching per line as with other grep utilities.
ugrep makes it easy to search source code.  It is the only grep tool that
allows you to define negative patterns to ""zap"" parts in files you want to
skip.  This removes many false positives.  For example to find exact matches of
main in C/C++ source code while skipping strings and comments that may have a
match with main in them:
ugrep -r -o -tc,c++ -n -w 'main' -f patterns/c/zap_strings -f patterns/c/zap_comments myprojects

where -r is recursive search, -o for multi-line matches (since strings and
comments may span multiple lines), -tc,c++ searches C and C++ source code
files only, -n shows line numbers in the output, -w matches exact words
(for example, mainly won't be matched), the -f options specify two
pre-defined patterns to match and ignore strings and comments in the input.
ugrep searches source code files by file name extension and other criteria
using option -t so specify the type of files to search recursively in a
directory tree with option -r, e.g. -r -tc++.
ugrep includes a growing database of
patterns with common
search patterns to use with option -f.  So you don't need to memorize complex
regex patterns for common search criteria.  Environment variable GREP_PATH
can be set to point to your own directory with patterns that option -f uses
to read your pattern files.
ugrep offers options that are compatible with the
GNU grep and BSD grep
utilities, and can be used as a more powerful replacement of these.
ugrep matches Unicode patterns.  The regular expression syntax is POSIX ERE
compliant, extended with Unicode character classes, lazy quantifiers, and
negative patterns to skip unwanted pattern matches to produce more precise
results.
ugrep searches UTF-encoded input when UTF BOM
(byte order mark) are present
and ASCII and UTF-8 when no UTF BOM is present.  Option --file-format permits
many other file formats to be searched, such as ISO-8859-1, EBCDIC, and code
pages 437, 850, 858, 1250 to 1258.
ugrep regex patterns are converted to
DFAs for fast
matching.  Rare and pathelogical cases are known to exist that may increase the
initial running time for DFA construction.  The resulting DFAs still yield
significant speedups to search large files.
ugrep is portable and compiles with MSVC++ to run on Windows.
ugrep is free BSD-3 source
code and does not include any GNU or BSD grep open source code or algorithms.
ugrep is built entirely on the RE/flex open source library and Rich Salz'
free and open wildmat source code for glob matching with options --include
and --exclude.
ugrep is evolving and more features will be added.  You can help!  We love
your feedback (issues) and contributions (pull requests) â¤ï¸
Speed
Initial performance results look promising.  For example, searching for all
matches of syntactically-valid variants of #include ""..."" in the directory
tree from the Qt 5.9.2 root, restricted to .h, .hpp, and .cpp files only:
time egrep -r -o '#[ \t]*include[ \t]+""[^""]+""' --include='*.h' --include='*.hpp' --include='*.cpp' . >& /dev/null
3.630u 0.274s 0:03.90 100.0%    0+0k 0+0io 0pf+0w

time ugrep -r -o '#[ \t]*include[ \t]+""[^""]+""' -Oh,hpp,cpp . >& /dev/null
0.837u 0.185s 0:01.02 99.0%     0+0k 0+0io 0pf+0w

Unoptimized, ugrep is already 3 times faster than BSD egrep (ugrep was
compiled with clang 9.0.0 -O2, and this test was run on a 2.9 GHz Intel Core
i7, 16 GB 2133 MHz LPDDR3 machine).
Dependencies
https://github.com/Genivia/RE-flex
Installation
First install RE/flex from https://github.com/Genivia/RE-flex then download
ugrep from https://github.com/Genivia/ugrep and execute:
$ ./configure; make

This builds ugrep in the src directory.  You can tell which version it is
with:
$ src/ugrep -V
ugrep 1.1.0 x86_64-apple-darwin16.7.0

Optionally, install the ugrep utility and the ugrep manual page:
$ sudo make install
$ ugrep -V
ugrep 1.1.0 x86_64-apple-darwin16.7.0

Examples
Searching source code
To search for the identifier main as a word (-w) recursively (-r) in
directory myproject, showing the matching line (-n) and column (-k)
numbers next to the lines matched:
ugrep -r -n -k -w 'main' myproject

But this search query also finds main in strings and comment blocks.  With
ugrep we can use ""negative patterns"" of the form (?^...) to ignore
unwanted matches in C/C++ quoted strings and comment blocks.  Because strings
and comment blocks may span multiple lines, we should use -o:
ugrep -r -o -nkw 'main' '(?^""(\\.|\\\r?\n|[^\\\n""])*""|//.*|/\*([^*]|(\*+[^*/]))*\*+\/)' myproject

This is a lot of work to type in correctly!  If you are like me, I'm lazy and
don't want to spend time fiddling with regex patterns when I am working on
something more important.  There is an easier way by using ugrep's
pre-defined patterns (-f):
ugrep -r -o -nkw 'main' -f patterns/c/zap_strings -f patterns/c/zap_comments myproject

This query also searches through other files than C/C++ source code, like
READMEs, Makefiles, and so on.  So let's refine this query by selecting C/C++
files only using option -tc,c++:
ugrep -r -o -tc,c++ -nkw 'main' -f patterns/c/zap_strings -f patterns/c/zap_comments myproject

As another example, we may want to search for word FIXME in C/C++ comment
blocks.  To do so we can first select the comment blocks with ugrep's
pre-defined c/comments pattern AND THEN select lines with FIXME using a
pipe:
ugrep -r -o -tc,c++ -nk -f patterns/c/comments myproject | ugrep -w 'FIXME'

Filtering results this way with pipes is generally easier than using AND-OR
logic that some search tools use.  This approach follows the Unix spirit to
keep utilities simple and use them in combination for more complex tasks.
Say we want to produce a sorted list of all identifiers found in Java source
code while skipping strings and comments:
ugrep -r -o -tjava -f patterns/java/names -f patterns/java/zap_strings -f patterns/java/zap_comments myproject | sort -u

This matches Java Unicode identifiers using the regex
\p{JavaIdentifierStart}\p{JavaIdentifierPart}* defined in
patterns/java/names.
With traditional grep and grep-like tools it takes great effort to recursively
search for the C/C++ source file that defines function qsort, requiring
something like this:
ugrep -r --include='*.c' --include='*.cpp' '^([ \t]*[[:word:]:*&]+)+[ \t]+qsort[ \t]*\([^;\n]+$' myproject

Fortunately, with ugrep we can simply select all function definitions in
files with extension .c or .cpp by using option -Oc,cpp and by using a
pre-defined pattern function_defs to produce all function definitions.  Then
we select the one we want:
ugrep -r -o -Oc,cpp -nk -f patterns/c/function_defs myproject | ugrep 'qsort'

Note that we could have used -tc,c++ to select C/C++ files, but this also
includes header files when we want to only search .c and .cpp files.  To
display the list of file name extensions searched for all available options for
-t use:
ugrep -tlist

We can also skip files and directories from being searched that are defined in
.gitignore.  To do so we use --exclude-from to specify a file with files
and directories (declared as glob patterns) to ignore:
ugrep -r -tc++ --color --exclude-from='.gitignore' -f patterns/c++/defines .

While searching C++ files (-tc++) in the current directory (.)for #define
lines (-f patterns/c++/defines), this query skips file config.h and other
files and directories declared in .gitignore.
To highlight matches when pushed through a chain of pipes we should use
--color=always:
ugrep -r -tc++ --color=always --exclude-from='.gitignore' -f patterns/c++/defines . | ugrep -w 'Foo.*'

To list all files in a GitHub project directory that are not ignored by
.gitignore:
ugrep -r -l '' --exclude-from='.gitignore' .

Where -l (files with matches) lists the files specified in .gitignore
matched by the empty pattern '', which is typically used to match any
non-empty file (as per POSIX.1 compliance).
Note that the complement of --exclude is not --include, so we cannot
reliably list the files that are ignored with --include-from='.gitignore'.
Only files explicitly specified with --include and directories explicitly
specified with --include-dir are visited.  The --include-from from lists
globs that are considered both files and directories to add to --include and
--include-dir, respectively.  This means that when a directory or directory
path is not explicitly listed in this file then it will not be visited using
--include-from.
Using Unicode
To display lines with Unicode words in places.txt:
ugrep '\w+' places.txt

To produce a sorted list of all ASCII words in places.txt:
ugrep '[[:word:]]+' places.txt

To display all lines containing laughing face emojis in birthday.txt:
ugrep '[ð-ð]' birthday.txt

Likewise, we can use the following for the same results:
ugrep '[\x{1F600}-\x{1F60F}]' birthday.txt

To display lines containing the names GÃ¶del (or Goedel), Escher, or Bach:
ugrep 'G(Ã¶|oe)del|Escher|Bach' GEB.txt wiki.txt

To display lines that do not contain the names GÃ¶del (or Goedel), Escher, or
Bach we use option -v (invert match):
ugrep -v 'G(Ã¶|oe)del|Escher|Bach' GEB.txt wiki.txt

To count the number of lines containing the names GÃ¶del (or Goedel), Escher, or
Bach we use option -c:
ugrep -c 'G(Ã¶|oe)del|Escher|Bach' GEB.txt wiki.txt

To count the total number of occurrences of the names GÃ¶del (or Goedel),
Escher, or Bach we use options -c and -g (don't group matches on the same
line):
ugrep -c -g 'G(Ã¶|oe)del|Escher|Bach' GEB.txt wiki.txt

To check if myfile contains any non-ASCII Unicode characters we use pattern
[^[:ascii:]] (not ASCII) and option -q (quick) that only sets the ugrep
exit status to 0 (success) or 1 (failure):
ugrep -q '[^[:ascii:]]' myfile && echo ""contains Unicode""

To check if a file has any invalid Unicode characters:
ugrep -q '[^\p{Unicode}--[\xFFFD]]' myfile && echo ""contains invalid Unicode""

In this example we included the Unicode code point U+FFFD as an error for
illustrative purposes, because it is often used to flag invalid UTF encodings.
To search for lorem in lower or upper case (option -i case insensitive) in
a UTF-16 file (with UTF-16 BOM), while color-highlighting the matches:
ugrep --color -i -w 'lorem' utf16lorem.txt

When utf16lorem.txt has no UTF-16 BOM we can specify UTF-16 file encoding:
ugrep --file-format=UTF-16 -i -w 'lorem' utf16lorem.txt

Man page
UGREP(1)                         User Commands                        UGREP(1)



NAME
       ugrep -- universal file pattern searcher

SYNOPSIS
       ugrep [OPTIONS] [-A NUM] [-B NUM] [-C[NUM]] [PATTERN] [-e PATTERN]
             [-f FILE] [--file-type=TYPES] [--file-format=ENCODING]
             [--colour[=WHEN]|--color[=WHEN]] [--label[=LABEL]] [FILE ...]

DESCRIPTION
       The  ugrep utility searches any given input files, selecting lines that
       match one or more patterns.  By default, a  pattern  matches  an  input
       line  if  the  regular expression (RE) in the pattern matches the input
       line without its trailing newline.  An empty expression  matches  every
       line.   Each  input  line  that matches at least one of the patterns is
       written to the standard output.

       The ugrep utility normalizes Unicode input, so ugrep  can  be  used  to
       search  for  Unicode  patterns  in text files encoded in UTF-8, UTF-16,
       UTF-32 by detecting UTF BOM in the input.  When no UTF BOM is detected,
       ugrep  searches  for  Unicode  patterns  in UTF-8 input, which includes
       ASCII input.  ugrep searches input files encoded in ISO-8859-1, EBCDIC,
       CP-437,  CP-850, CP-858, CP-1250 to CP-1258 when the file encoding for-
       mat is specified with option --file-format.

       The following options are available:

       -A NUM, --after-context=NUM
              Print NUM  lines  of  trailing  context  after  matching  lines.
              Places a --group-separator between contiguous groups of matches.
              See also the -B and -C options.

       -B NUM, --before-context=NUM
              Print NUM  lines  of  leading  context  before  matching  lines.
              Places a --group-separator between contiguous groups of matches.
              See also the -A and -C options.

       -b, --byte-offset
              The offset in bytes of a matched line is displayed in  front  of
              the respective matched line.  With option -g displays the offset
              in bytes of each pattern matched.

       -C[NUM], --context[=NUM]
              Print NUM lines of leading and trailing context surrounding each
              match.  The default is 2 and is equivalent to -A 2 -B 2.  Places
              a --group-separator between contiguous groups of matches.  Note:
              no  whitespace may be given between the option and its argument.

       -c, --count
              Only a count of selected lines is written  to  standard  output.
              When used with option -g, counts the number of patterns matched.
              With option -v, counts the number of non-matching lines.

       --colour[=WHEN], --color[=WHEN]
              Mark up the matching text with  the  expression  stored  in  the
              GREP_COLOR  or  GREP_COLORS  environment variable.  The possible
              values of WHEN can be `never', `always' or `auto'.

       -D ACTION, --devices=ACTION
              If an input file is a device, FIFO  or  socket,  use  ACTION  to
              process  it.   By  default,  ACTION  is `read', which means that
              devices are read just as if they were ordinary files.  If ACTION
              is `skip', devices are silently skipped.

       -d ACTION, --directories=ACTION
              If  an  input file is a directory, use ACTION to process it.  By
              default, ACTION is `read', i.e., read  directories  just  as  if
              they  were  ordinary  files.  If ACTION is `skip', silently skip
              directories.  If ACTION is `recurse', read all files under  each
              directory,  recursively,  following  symbolic links only if they
              are on the command line.  This is equivalent to the  -r  option.
              If  ACTION  is  `dereference-recurse', read all files under each
              directory,  recursively,  following  symbolic  links.   This  is
              equivalent to the -R option.

       -E, --extended-regexp
              Interpret  patterns as extended regular expressions (EREs). This
              is the default.

       -e PATTERN, --regexp=PATTERN
              Specify a PATTERN used during the search of the input: an  input
              line  is  selected  if it matches any of the specified patterns.
              This option is most useful when multiple -e options are used  to
              specify  multiple  patterns,  when  a pattern begins with a dash
              (`-'), or to specify a pattern after option -f.

       --exclude=GLOB
              Skip files whose name matches GLOB (using wildcard matching).  A
              glob  can  use  *,  ?,  and [...] as wildcards, and \ to quote a
              wildcard or backslash character literally.  If GLOB contains  /,
              full  pathnames  are  matched.  Otherwise basenames are matched.
              Note that --exclude patterns take priority over  --include  pat-
              terns.  This option may be repeated.

       --exclude-dir=GLOB
              Exclude  directories  whose  name  matches  GLOB  from recursive
              searches.  If GLOB contains /, full pathnames are matched.  Oth-
              erwise  basenames are matched.  Note that --exclude-dir patterns
              take priority over --include-dir patterns.  This option  may  be
              repeated.

       --exclude-from=FILE
              Read  the  globs  from FILE and skip files and directories whose
              name matches one or more globs (as if specified by --exclude and
              --exclude-dir).   Lines  starting  with a `#' and empty lines in
              FILE ignored. This option may be repeated.

       -F, --fixed-strings
              Interpret pattern as a set of fixed strings, separated  by  new-
              lines,  any  of  which  is  to be matched.  This forces ugrep to
              behave as fgrep but less efficiently.

       -f FILE, --file=FILE
              Read one or more newline-separated patterns  from  FILE.   Empty
              pattern  lines  in  the file are not processed.  Options -F, -w,
              and -x do not apply to FILE patterns.  If FILE does  not  exist,
              uses the GREP_PATH environment variable to attempt to open FILE.
              This option may be repeated.

       -G, --basic-regexp
              Interpret pattern as a  basic  regular  expression  (i.e.  force
              ugrep to behave as traditional grep).

       -g, --no-group
              Do  not  group  pattern  matches  on the same line.  Display the
              matched line again for each additional pattern match, using  `+'
              as the field separator for each additional line.

       --group-separator=SEP
              Use SEP as a group separator for context options -A, -B, and -C.
              By default SEP is a double hyphen (`--').

       -H, --with-filename
              Always print the  filename  with  output  lines.   This  is  the
              default when there is more than one file to search.

       -h, --no-filename
              Never print filenames with output lines.

       --help Print a help message.

       -i, --ignore-case
              Perform   case   insensitive   matching.   This  option  applies
              case-insensitive matching of ASCII characters in the input.   By
              default, ugrep is case sensitive.

       --include=GLOB
              Search only files whose name matches GLOB (using wildcard match-
              ing).  A glob can use *, ?, and [...] as  wildcards,  and  \  to
              quote a wildcard or backslash character literally.  If GLOB con-
              tains /, file pathnames are matched.  Otherwise  file  basenames
              are  matched.   Note  that --exclude patterns take priority over
              --include patterns.  This option may be repeated.

       --include-dir=GLOB
              Only directories whose name matches GLOB are included in  recur-
              sive  searches.  If GLOB contains /, full pathnames are matched.
              Otherwise basenames are matched.  Note that  --exclude-dir  pat-
              terns  take  priority  over --include-dir patterns.  This option
              may be repeated.

       --include-from=FILE
              Read the globs from FILE and search only files  and  directories
              whose  name  matches  one  or  more  globs  (as  if specified by
              --include and --include-dir).  Lines starting  with  a  `#'  and
              empty lines in FILE are ignored.  This option may be repeated.

       -k, --column-number
              The  column number of a matched pattern is displayed in front of
              the respective matched line, starting at  column  1.   Tabs  are
              expanded when columns are counted.

       -L, --files-without-match
              Only  the names of files not containing selected lines are writ-
              ten to standard output.  Pathnames  are  listed  once  per  file
              searched.   If  the  standard  input  is  searched,  the  string
              ``(standard input)'' is written.

       -l, --files-with-matches
              Only the names of files containing selected lines are written to
              standard  output.   ugrep  will only search a file until a match
              has been found,  making  searches  potentially  less  expensive.
              Pathnames  are  listed  once per file searched.  If the standard
              input is searched, the string ``(standard input)'' is written.

       --label[=LABEL]
              Displays the LABEL value when input is read from standard  input
              where a file name would normally be printed in the output.  This
              option applies to options -H, -L, and -l.

       --line-buffered
              Force output to be line buffered.  By default,  output  is  line
              buffered  when  standard output is a terminal and block buffered
              otherwise.

       -m NUM, --max-count=NUM
              Stop reading the input after NUM matches.

       -N, --only-line-number
              The line number of the match in the file is output without  dis-
              playing  the  match.   The line number counter is reset for each
              file processed.

       -n, --line-number
              Each output line is preceded by its relative line number in  the
              file,  starting at line 1.  The line number counter is reset for
              each file processed.

       --no-group-separator
              Removes the group separator line from  the  output  for  context
              options -A, -B, and -C.

       -O EXTENSIONS, --file-extensions=EXTENSIONS
              Search only files whose file name extensions match the specified
              comma-separated list of file name EXTENSIONS.   This  option  is
              the same as specifying --include='*.ext' for each extension name
              `ext' in the EXTENSIONS list.  This option may be repeated.

       -o, --only-matching
              Prints only the matching part of the lines.   Allows  a  pattern
              match  to  span  multiple  lines.   Line  numbers for multi-line
              matches are displayed with option -n, using  `|'  as  the  field
              separator for each additional line matched by the pattern.  Con-
              text options -A, -B, and -C are disabled.

       -P, --perl-regexp
              Interpret PATTERN as a Perl regular expression.  This feature is
              not yet available.

       -p, --no-dereference
              If -R is specified, no symbolic links are followed.  This is the
              default.

       -q, --quiet, --silent
              Quiet mode: suppress normal output.  ugrep will  only  search  a
              file  until  a match has been found, making searches potentially
              less expensive.  Allows a pattern match to span multiple  lines.

       -R, --dereference-recursive
              Recursively  read  all  files  under each directory.  Follow all
              symbolic links, unlike -r.

       -r, --recursive
              Recursively read all files under each directory, following  sym-
              bolic links only if they are on the command line.

       -S, --dereference
              If  -R  is  specified,  all  symbolic  links  are followed.  The
              default is not to follow symbolic links.

       -s, --no-messages
              Silent mode.  Nonexistent and unreadable files are ignored (i.e.
              their error messages are suppressed).

       -T, --initial-tab
              Add  a  tab space to separate the file name, line number, column
              number, and byte offset with the matched line.

       -t TYPES, --file-type=TYPES
              Search only files of TYPES, which is a comma-separated  list  of
              file  types.   Each  file  type is associated with a set of file
              name extensions to search.  This option may  be  repeated.   The
              possible  values  of  type  can  be  (use  -t  list to display a
              detailed list): `actionscript',  `ada',  `asm',  `asp',  `aspx',
              `autoconf',  `automake',  `awk', `basic', `batch', `bison', `c',
              `c++', `clojure',  `csharp',  `css',  `csv',  `dart',  `delphi',
              `elixir',   `erlang',   `fortran',  `go',  `groovy',  `haskell',
              `html', `jade', `java', `javascript',  `json',  `jsp',  `julia',
              `kotlin',  `less', `lex', `lisp', `lua', `m4', `make', `matlab',
              `objc', `objcpp', `ocaml', `parrot',  `pascal',  `perl',  `php',
              `prolog',   `python',   `R',  `rst',  `ruby',  `rust',  `scala',
              `scheme', `shell', `smalltalk', `sql',  `swift',  `tcl',  `tex',
              `text',  `tt',  `typescript',  `verilog',  `vhdl', `vim', `xml',
              `yacc', `yaml'

       --tabs=NUM
              Set the tab size to NUM to expand tabs for option -k.  The value
              of NUM may be 1, 2, 4, or 8.

       -V, --version
              Display version information and exit.

       -v, --invert-match
              Selected  lines are those not matching any of the specified pat-
              terns.

       -w, --word-regexp
              The pattern or -e patterns are searched for as  a  word  (as  if
              surrounded by `\<' and `\>').

       -X, --free-space
              Spacing (blanks and tabs) in regular expressions are ignored.

       -x, --line-regexp
              Only  input lines selected against the entire pattern or -e pat-
              terns are considered to be matching lines (as if surrounded by ^
              and $).

       -Y ENCODING, --file-format=ENCODING
              The  input file format.  The possible values of ENCODING can be:
              `binary', `ISO-8859-1', `ASCII',  `EBCDIC',  `UTF-8',  `UTF-16',
              `UTF-16BE',   `UTF-16LE',   `UTF-32',   `UTF-32BE',  `UTF-32LE',
              `CP437',  `CP850',  `CP1250',  `CP1251',   `CP1252',   `CP1253',
              `CP1254', `CP1255', `CP1256', `CP1257', `CP1258'

       -y     Equivalent to -i.  Obsoleted.

       -Z, --null
              Prints a zero-byte after the file name.

       -z SEP, --separator=SEP
              Use  SEP as field separator between file name, line number, col-
              umn number, byte offset, and the matched line.  The default is a
              colon (`:').

       The  regular expression pattern syntax is an extended form of the POSIX
       ERE syntax.  For an overview of the syntax see README.md or visit:

              https://github.com/Genivia/ugrep

       Note that `.' matches any non-newline character.   Matching  a  newline
       character  is  not possible in line-buffered mode.  Pattern matches may
       span multiple lines in block-buffered mode, which is enabled by one  of
       the options -c, -o, or -q (unless combined with option -v).

       If  no  file arguments are specified, or if `-' is specified, the stan-
       dard input is used.

EXIT STATUS
       The ugrep utility exits with one of the following values:

       0      One or more lines were selected.

       1      No lines were selected.

       >1     An error occurred.

GLOBBING
       Globbing is used by options --include,  --include-dir,  --include-from,
       --exclude,  --exclude-dir,  --exclude-from to match pathnames and base-
       names.  Globbing supports gitignore syntax and the corresponding match-
       ing  rules.  When a glob contains a path separator `/', the pathname is
       matched.  Otherwise the basename of a file  or  directory  is  matched.
       For   example,  *.h  matches  foo.h  and  bar/foo.h.   bar/*.h  matches
       bar/foo.h but not foo.h and not bar/bar/foo.h.  Use a  leading  `/'  to
       force /*.h to match foo.h but not bar/foo.h.

       Syntax:

       **/    Matches zero or more directories.

       /**    When at the end of a glob, matches everything after the /.

       *      Matches anything except a /.

       /      When  used at the begin of a glob, matches if pathname has no /.

       ?      Matches any character except a /.

       [a-z]  Matches one character in the selected range of characters.

       [^a-z] Matches one character not in the selected range of characters.

       [!a-z] Matches one character not in the selected range of characters.

       \?     Matches a ? (or any character after the backslash).

       Examples:


       **/a   Matches a, x/a, x/y/a,       but not b, x/b.

       a/**/b Matches a/b, a/x/b, a/x/y/b, but not x/a/b, a/b/x

       a/**   Matches a/x, a/y, a/x/y,     but not b/x

       a/*/b  Matches a/x/b, a/y/b,        but not a/x/y/b

       /a     Matches a,                   but not x/a

       /*     Matches a, b,                but not x/a, x/b

       a?b    Matches axb, ayb,            but not a, b, ab

       a[xy]b Matches axb, ayb             but not a, b, azb

       a[a-z]b
              Matches aab, abb, acb, azb,  but not a, b, a3b, aAb, aZb

       a[^xy]b
              Matches aab, abb, acb, azb,  but not a, b, axb, ayb

       a[^a-z]b
              Matches a3b, aAb, aZb        but not a, b, aab, abb, acb, azb

       Lines in the --exclude-from and --include-from files are  ignored  when
       empty  or  start  with  a `#'.  The prefix `!' to a glob in such a file
       negates the pattern match, i.e.  matching  files  are  excluded  except
       files  matching the globs prefixed with `!' in the --exclude-from file.

ENVIRONMENT
       GREP_PATH
              May be used to specify a file path to pattern files.   The  file
              path  is used by option -f to open a pattern file, when the file
              specified with option -f cannot be opened.

       GREP_COLOR
              May be used to specify ANSI SGR parameters to highlight  matches
              when  option --color is used, e.g. 1;35;40 shows pattern matches
              in bold magenta text on a black background.

       GREP_COLORS
              May be used to specify ANSI SGR parameters to highlight  matches
              and  other attributes when option --color is used.  Its value is
              a colon-separated list of ANSI SGR parameters that  defaults  to
              mt=1;31:sl=:cx=:fn=35:ln=32:cn=32:bn=32:se=36.   The  mt=,  ms=,
              and  mc=  capabilities  of  GREP_COLORS   have   priority   over
              GREP_COLOR.

GREP_COLORS
       sl=    SGR substring for selected lines.

       cx=    SGR substring for context lines.

       rv     Swaps the sl= and cx= capabilities when -v is specified.

       mt=    SGR substring for matching text in any matching line.

       ms=    SGR  substring  for  matching text in a selected line.  The sub-
              string mt= by default.

       mc=    SGR substring for matching text in a  context  line.   The  sub-
              string mt= by default.

       fn=    SGR substring for file names.

       ln=    SGR substring for line numbers.

       cn=    SGR substring for column numbers.

       bn=    SGR substring for byte offsets.

       se=    SGR substring for separators.

EXAMPLES
       To find all occurrences of the word `patricia' in a file:

              $ ugrep -w 'patricia' myfile

       To  count the number of lines containing the word `patricia' or `Patri-
       cia` in a file:

              $ ugrep -cw '[Pp]atricia' myfile

       To count the total number of times the word  `patricia'  or  `Patricia`
       occur in a file:

              $ ugrep -cgw '[Pp]atricia' myfile

       To list all Unicode words in a file:

              $ ugrep -o '\w+' myfile

       To list all ASCII words in a file:

              $ ugrep -o '[[:word:]]+' myfile

       To  list  all  laughing  face  emojis  (Unicode  code points U+1F600 to
       U+1F60F) in a file:

              $ ugrep -o '[\x{1F600}-\x{1F60F}]' myfile

       To check if a file contains any non-ASCII (i.e. Unicode) characters:

              $ ugrep -q '[^[:ascii:]]' myfile && echo ""contains Unicode""

       To list all C/C++ comments in a file displaying their line  and  column
       numbers using options -n and -k, and option -o that allows for matching
       patterns across multiple lines:

              $ ugrep -nko -e '//.*' -e '/\*([^*]|(\*+[^*/]))*\*+\/' myfile

       The same search, but using pre-defined patterns:

              $ ugrep -nko -f patterns/c_comments myfile

       To list the lines that need fixing in a C/C++ source  file  by  looking
       for  the word FIXME while skipping any FIXME in quoted strings by using
       a negative pattern `(?^X)' to ignore quoted strings:

              $ ugrep -no -e 'FIXME' -e '(?^""(\\.|\\\r?\n|[^\\\n""])*"")' myfile

BUGS
       Report bugs at:

              https://github.com/Genivia/ugrep/issues


LICENSE
       ugrep  is  released under the BSD-3 license.  All parts of the software
       have reasonable copyright terms permitting free  redistribution.   This
       includes the ability to reuse all or parts of the ugrep source tree.

SEE ALSO
       grep(1).



ugrep 1.1.0                      May 11, 2019                         UGREP(1)

ugrep versus other ""greps""

ugrep supports ""negative patterns"" to skip parts of the input that should
not be matched, such as skipping strings and comments when searching for
identifiers in source code.
When one or more of the options -q (quiet), -o (only matching), -N
(only line number), -l (file with match), or -L (files without match) is
used, ugrep performs an even faster streaming-based search of the input
file instead of reading the input line-by-line as other grep tools do.  This
allows matching patterns that include newlines (\n), i.e. a match can span
multiple lines.  This is not possible with other grep-like tools.
New option -k, --column-number with ugrep to display the column
number, taking tab spacing into account by expanding tabs, as specified by
option --tabs.
New option -g, --no-group to not group matches per line.  This option
displays a matched input line again for each additional pattern match.  This
option is particularly useful with option -c to report the total number of
pattern matches per file instead of the number of lines matched per file.
When option -b is used with option -o or with option -g, ugrep
displays the exact byte offset of the pattern match instead of the byte
offset of the start of the matched line as grep reports.  Reporting exact
byte offsets is now possible with grep.
ugrep regular expression patterns are more expressive than GNU grep and
BSD grep and support Unicode pattern matching, see further below.  Extended
regular expression syntax is the default (i.e.  option -E, as egrep).
ugrep always assumes UTF-8 locale to support Unicode, e.g.
LANG=en_US.UTF-8, wheras grep is locale-sensitive.
BSD grep (e.g. on Mac OS X) has bugs and limitations that ugrep fixes,
e.g.  options -r versus -R, support for GREP_COLORS, and more.

For future updates

Skip hidden files and directories, e.g. dot files and Windows hidden files.
However, skipping dot files and directories can already be done with
--exclude='.*' and --exclude-dir='.*', respectively.  Windows hidden
files are defined by their attributes returned by GetFileAttributesA.
Pattern ^$ does not match empty lines, because RE/flex find() does not
permit empty matches.  This can be fixed in RE/flex, but requires some work
and testing to avoid infinite find() loops on an empty match that does not
advance the input cursor.
Back-references are not supported.  This will likely not be supported soon
with the RE/flex library.  We could use Boost.Regex for this (using RE/flex
BoostMatcher class), which is faster than PCRE2 but slower than RE/flex
Matcher class.  With Boost.Regex we can also support Perl-like matching
as an option.
There are reported cases where lazy quantifiers misbehave when used in
negative patterns, so it is best to avoid them unless the patterns are
simple.
Not locale-sensitive, e.g. LC_COLLATE currently has no effect.

Pattern syntax
A pattern is an extended set of regular expressions, with nested sub-expression
patterns Ï and Ï:



Pattern
Matches




x
matches the character x, where x is not a special character


.
matches any single character except newline (unless in dotall mode)


\.
matches . (dot), special characters are escaped with a backslash


\n
matches a newline, others are \a (BEL), \b (BS), \t (HT), \v (VT), \f (FF), and \r (CR)


\0
matches the NUL character


\cX
matches the control character X mod 32 (e.g. \cA is \x01)


\0177
matches an 8-bit character with octal value 177


\x7f
matches an 8-bit character with hexadecimal value 7f


\x{3B1}
matches Unicode character U+03B1, i.e. Î±


\u{3B1}
matches Unicode character U+03B1, i.e. Î±


\p{C}
matches a character in category C


\Q...\E
matches the quoted content between \Q and \E literally


[abc]
matches one of a, b, or c


[0-9]
matches a digit 0 to 9


[^0-9]
matches any character except a digit


Ï?
matches Ï zero or one time (optional)


Ï*
matches Ï zero or more times (repetition)


Ï+
matches Ï one or more times (repetition)


Ï{2,5}
matches Ï two to five times (repetition)


Ï{2,}
matches Ï at least two times (repetition)


Ï{2}
matches Ï exactly two times (repetition)


Ï??
matches Ï zero or once as needed (lazy optional)


Ï*?
matches Ï a minimum number of times as needed (lazy repetition)


Ï+?
matches Ï a minimum number of times at least once as needed (lazy repetition)


Ï{2,5}?
matches Ï two to five times as needed (lazy repetition)


Ï{2,}?
matches Ï at least two times or more as needed (lazy repetition)


ÏÏ
matches Ï then matches Ï (concatenation)


Ïâ®Ï
matches Ï or matches Ï (alternation)


(Ï)
matches Ï as a group


(?:Ï)
matches Ï as a group without capture


(?=Ï)
matches Ï without consuming it, i.e. lookahead (top-level Ï, not for sub-patterns Ï)


(?^Ï)
matches Ï and ignore it to continue matching (top-level Ï, not for sub-patterns Ï)


^Ï
matches Ï at the start of input or start of a line (top-level Ï, not for sub-patterns Ï)


Ï$
matches Ï at the end of input or end of a line (top-level Ï, not for sub-patterns Ï)


\AÏ
matches Ï at the start of input (requires option -o) (top-level Ï, not for sub-patterns Ï)


Ï\z
matches Ï at the end of input (requires option -o) (top-level Ï, not for sub-patterns Ï)


\bÏ
matches Ï starting at a word boundary (top-level Ï, not for sub-patterns Ï)


Ï\b
matches Ï ending at a word boundary (top-level Ï, not for sub-patterns Ï)


\BÏ
matches Ï starting at a non-word boundary (top-level Ï, not for sub-patterns Ï)


Ï\B
matches Ï ending at a non-word boundary (note: top-level regex pattern only)


\<Ï
matches Ï that starts a word (top-level Ï, not for sub-patterns Ï)


\>Ï
matches Ï that starts a non-word (top-level Ï, not for sub-patterns Ï)


Ï\<
matches Ï that ends a non-word (top-level Ï, not for sub-patterns Ï)


Ï\>
matches Ï that ends a word (top-level Ï, not for sub-patterns Ï)


\i
matches an indent


\j
matches a dedent


(?i:Ï)
matches Ï ignoring case


(?s:Ï)
. (dot) in Ï matches newline


(?x:Ï)
ignore all whitespace and comments in Ï


(?#:X)
all of X is skipped as a comment



The order of precedence for composing larger patterns from sub-patterns is as
follows, from high to low precedence:

Characters, character classes (bracket expressions), escapes, quotation
Grouping (Ï), (?:Ï), (?=Ï), and inline modifiers (?imsux:Ï)
Quantifiers ?, *, +, {n,m}
Concatenation ÏÏ
Anchoring ^, $, \<, \>, \b, \B, \A, \z
Alternation Ï|Ï
Global modifiers (?imsux)Ï

POSIX and Unicode character classes
Character classes in bracket lists represent sets of characters.  Sets can be
inverted, subtracted, intersected, and merged:



Pattern
Matches




[a-zA-Z]
matches a letter


[^a-zA-Z]
matches a non-letter (character class inversion)


[a-zââ[aeiou]]
matches a consonant (character class subtraction)


[a-z&&[^aeiou]]
matches a consonant (character class intersection)


[a-zâ®â®[A-Z]]
matches a letter (character class union)



Bracket lists cannot be empty, so [] and [^] are invalid.  In fact, the
first character after the bracket is always part of the list.  So [][] is a
list that matches a ] and a [, [^][] is a list that matches anything but
] and [, and [-^] is a list that matches a - and a ^.
POSIX and Unicode character categories



POSIX form
POSIX category
Matches




[:ascii:]
\p{ASCII}
matches any ASCII character


[:space:]
\p{Space}
matches a white space character [ \t\n\v\f\r]


[:xdigit:]
\p{Xdigit}
matches a hex digit [0-9A-Fa-f]


[:cntrl:]
\p{Cntrl}
matches a control character [\x00-\0x1f\x7f]


[:print:]
\p{Print}
matches a printable character [\x20-\x7e]


[:alnum:]
\p{Alnum}
matches a alphanumeric character [0-9A-Za-z]


[:alpha:]
\p{Alpha}
matches a letter [A-Za-z]


[:blank:]
\p{Blank}, \h
matches a blank [ \t]


[:digit:]
\p{Digit}, \d
matches a digit [0-9]


[:graph:]
\p{Graph}
matches a visible character [\x21-\x7e]


[:lower:]

matches a lower case letter [a-z]


[:punct:]
\p{Punct}
matches a punctuation character [\x21-\x2f\x3a-\x40\x5b-\x60\x7b-\x7e]


[:upper:]

matches an upper case letter [A-Z]


[:word:]

matches a word character [0-9A-Za-z_]


[:^blank:]
\H
matches a non-blank character [^ \t]


[:^digit:]
\D
matches a non-digit [^0-9]



The POSIX form can only be used in bracket lists, for example
[[:lower:][:digit:]] matches an ASCII lower case letter or a digit.
You can also use the capitalized \P{C} form that has the same meaning as
\p{^C}, which matches any character except characters in the class C.
For example, \P{ASCII} is the same as \p{^ASCII} which is the same as
[^[:ascii:]].  A word of caution: because POSIX character categories only
cover ASCII, [[:^ascii]] is empty and invalid to use.  By contrast,
[^[:ascii]] is a Unicode character class that excludes the ASCII character
category.



Unicode category
Matches




.
matches any single Unicode character except newline


\X
matches any ISO-8859-1 or Unicode character


\R
matches a Unicode line break


\s, \p{Zs}
matches a white space character with Unicode sub-propert Zs


\l, \p{Ll}
matches a lower case letter with Unicode sub-property Ll


\u, \p{Lu}
matches an upper case letter with Unicode sub-property Lu


\w, \p{Word}
matches a Unicode word character with property L, Nd, or Pc


\p{Unicode}
matches any Unicode character (U+0000 to U+10FFFF minus U+D800 to U+DFFF)


\p{ASCII}
matches an ASCII character U+0000 to U+007F)


\p{Non_ASCII_Unicode}
matches a non-ASCII character U+0080 to U+10FFFF minus U+D800 to U+DFFF)


\p{Letter}
matches a character with Unicode property Letter


\p{Mark}
matches a character with Unicode property Mark


\p{Separator}
matches a character with Unicode property Separator


\p{Symbol}
matches a character with Unicode property Symbol


\p{Number}
matches a character with Unicode property Number


\p{Punctuation}
matches a character with Unicode property Punctuation


\p{Other}
matches a character with Unicode property Other


\p{Lowercase_Letter}, \p{Ll}
matches a character with Unicode sub-property Ll


\p{Uppercase_Letter}, \p{Lu}
matches a character with Unicode sub-property Lu


\p{Titlecase_Letter}, \p{Lt}
matches a character with Unicode sub-property Lt


\p{Modifier_Letter}, \p{Lm}
matches a character with Unicode sub-property Lm


\p{Other_Letter}, \p{Lo}
matches a character with Unicode sub-property Lo


\p{Non_Spacing_Mark}, \p{Mn}
matches a character with Unicode sub-property Mn


\p{Spacing_Combining_Mark}, \p{Mc}
matches a character with Unicode sub-property Mc


\p{Enclosing_Mark}, \p{Me}
matches a character with Unicode sub-property Me


\p{Space_Separator}, \p{Zs}
matches a character with Unicode sub-property Zs


\p{Line_Separator}, \p{Zl}
matches a character with Unicode sub-property Zl


\p{Paragraph_Separator}, \p{Zp}
matches a character with Unicode sub-property Zp


\p{Math_Symbol}, \p{Sm}
matches a character with Unicode sub-property Sm


\p{Currency_Symbol}, \p{Sc}
matches a character with Unicode sub-property Sc


\p{Modifier_Symbol}, \p{Sk}
matches a character with Unicode sub-property Sk


\p{Other_Symbol}, \p{So}
matches a character with Unicode sub-property So


\p{Decimal_Digit_Number}, \p{Nd}
matches a character with Unicode sub-property Nd


\p{Letter_Number}, \p{Nl}
matches a character with Unicode sub-property Nl


\p{Other_Number}, \p{No}
matches a character with Unicode sub-property No


\p{Dash_Punctuation}, \p{Pd}
matches a character with Unicode sub-property Pd


\p{Open_Punctuation}, \p{Ps}
matches a character with Unicode sub-property Ps


\p{Close_Punctuation}, \p{Pe}
matches a character with Unicode sub-property Pe


\p{Initial_Punctuation}, \p{Pi}
matches a character with Unicode sub-property Pi


\p{Final_Punctuation}, \p{Pf}
matches a character with Unicode sub-property Pf


\p{Connector_Punctuation}, \p{Pc}
matches a character with Unicode sub-property Pc


\p{Other_Punctuation}, \p{Po}
matches a character with Unicode sub-property Po


\p{Control}, \p{Cc}
matches a character with Unicode sub-property Cc


\p{Format}, \p{Cf}
matches a character with Unicode sub-property Cf


\p{UnicodeIdentifierStart}
matches a character in the Unicode IdentifierStart class


\p{UnicodeIdentifierPart}
matches a character in the Unicode IdentifierPart class


\p{IdentifierIgnorable}
matches a character in the IdentifierIgnorable class


\p{JavaIdentifierStart}
matches a character in the Java IdentifierStart class


\p{JavaIdentifierPart}
matches a character in the Java IdentifierPart class


\p{CsIdentifierStart}
matches a character in the C# IdentifierStart class


\p{CsIdentifierPart}
matches a character in the C# IdentifierPart class


\p{PythonIdentifierStart}
matches a character in the Python IdentifierStart class


\p{PythonIdentifierPart}
matches a character in the Python IdentifierPart class



To specify a Unicode block as a category use \p{IsBlockName} with a Unicode
BlockName.
To specify a Unicode language script, use \p{Language} with a Unicode
Language.
Unicode language script character classes differ from the Unicode blocks that
have a similar name.  For example, the \p{Greek} class represents Greek and
Coptic letters and differs from the Unicode block \p{IsGreek} that spans a
specific Unicode block of Greek and Coptic characters only, which also includes
unassigned characters.
",4
gochain-io/web3,Go,"Web3
Simple command line tool for interacting with web3 enabled blockchains - GoChain, Ethereum, etc.
This repository also exports the backing golang package web3.

Install web3
Quick one line install:
curl -LSs https://raw.githubusercontent.com/gochain-io/web3/master/install.sh | sh
Install Docker (optional) - While not required for all commands, many of the developer commands require Docker so we recommend installing it.
More options
Quickstart
If you just plan to read from the blockchain, you do not need any GO tokens and you do not need to set your PRIVATE_KEY. If you plan to deploy contracts or write anything to the blockchain, you'll need tokens and you'll need to set your PRIVATE_KEY for the account that has those tokens.
Pick a network to use
a) Run a local node
Run this command to start a local node. It will print 10 addresses with keys upon starting that you can use to deploy and interact.
web3 start
export WEB3_NETWORK=localhost
b) Use the GoChain testnet
export WEB3_NETWORK=testnet
To do any write operations, get yourself some GO testnet tokens so you can deploy and interact with your contract.
c) Use the GoChain mainnet or another web3 network
export WEB3_NETWORK=gochain
You'll need mainnet GO for this which you can buy on various exchanges.
You can also point this to other web3 based networks such as Ethereum. Ethereum is supported by default and you
can use one of the following: ethereum or ropsten.
Set Private Key (optional)
Required if you plan to deploy or write transactions.
export WEB3_PRIVATE_KEY=0x...
Deploy a contract
Copy contracts/hello.sol into your current directory.
Then:
web3 contract build hello.sol
web3 contract deploy Hello.bin
This will return a contract address, copy it and use below.
Read from a contract
Let's call a read function (which is free):
web3 contract call --address 0xCONTRACT_ADDRESS --abi Hello.abi --function hello
That should return: [Hello World].
Write to a contract
Now let's change the name:
web3 contract call --address 0xCONTRACT_ADDRESS --abi Hello.abi --function setName ""Johnny""
And call the hello function again to see if the name changed:
web3 contract call --address 0xCONTRACT_ADDRESS --abi Hello.abi --function hello
Now it should return [Hello Johnny]
ð¥
Troubleshooting
If it doesn't return Hello Johnny, you can check the logs and receipt with:
web3 rc TX_HASH
Testing
To automate testing using web3 CLI, enable the JSON format flag with --format json. This will
return easily parseable results for your tests. Eg:
web3 --format json contract call --address 0xCONTRACT_ADDRESS --abi Hello.abi --function hello
And you'll get a JSON response like this:
{
  ""response"": [
    ""Hello"",
    ""World""
  ]
}
Deploying an Upgradeable Contract
The web3 tool comes with built-in support for deploying contracts that can be
upgraded later. To deploy an upgradeable contract, simply specify the
--upgradeable flag while deploying. From our Hello example above:
web3 contract deploy --upgradeable Hello.bin
This will return the contract address. Let's set the contract address environment variable so you can use it throughout the rest of this
tutorial (alternatively you can pass in the --address CONTRACT_ADDRESS flag on all the commands).
export WEB3_ADDRESS=0xCONTRACT_ADDRESS
Internally, deploying an upgradeable contract will actually deploy two separate contracts:

Your original Hello contract.
A proxy contract for redirecting calls and storage.

The returned contract address is the address of your proxy. To see the contract
address that your proxy is pointing to, you can use the target command in
the CLI:
web3 contract target
One caveat to using upgradeable contracts is that their constructors will not
execute. To get around this, we will have to initialize our contract with an
initial call to setName:
web3 contract call --abi Hello.abi --function setName ""World""
Now we can interact with our upgradeable contract just like a normal contract:
web3 contract call --abi Hello.abi --function hello
# returns: [Hello World]
Alright, so we have a working contract. Let's upgrade it!
Upgrading the contract
We can now deploy a different contract (without the upgradeable flag) and
redirect our upgradeable contract to point to that new contract.
Copy contracts/goodbye.sol into your current directory
and build and deploy it:
web3 contract build goodbye.sol
web3 contract deploy Goodbye.bin
Using the new Goodbye contract address, we can upgrade our previous contract
using the contract upgrade command:
web3 contract upgrade --to 0xGOODBYE_CONTRACT_ADDRESS
We can see that our proxy contract now points to this new contract by
calling the hello function again:
web3 contract call --abi Hello.abi --function hello
# returns: [Goodbye World]
Note that contracts can only be upgraded by the account that created them.
Pausing and resuming a contract
Upgradeable contracts also include the ability to pause & resume execution.
This can be useful if you discover a bug in your contract and you wish to cease
operation until you can upgrade to a fixed version.
Pausing a contract is simple:
web3 contract pause
Wait a minute for the transaction to go through, then try to use the contract again and it will fail:
web3 contract call --abi Hello.abi --function hello
# returns: ERROR: Cannot call the contract: abi: unmarshalling empty output
Contracts can be upgraded while they are paused. To execute any other contract functions, you
will need to first resume operation:
web3 contract resume
List of available commands
Global parameters
$NETWORK as env variable or -network as command parameter - the name of the network. Available networks are:

gochain (default)
testnet
ethereum
ropsten
localhost

$RPC_URL as env variable or -rpc-url as command parameter - The network RPC URL (ie http://localhost:8545)
-verbose as command parameter - Verbose logging
Show information about a block
web3 block BLOCK_ID
Parameters:

BLOCK_ID - id of a block (omit for latest)

Show information about a transaction
web3 transaction TX_HASH
Parameters:

TX_HASH - hash of a transaction

Show information about an address
web3 transaction ADDRESS_HASH
Parameters:

ADDRESS_HASH - hash of the address

Build a smart contract
web3 contract build FILENAME.sol --solc-version SOLC_VERSION
Parameters:

FILENAME - the name of the .sol file, eg: hello.sol
SOLC_VERSION - the version of the solc compiler

Deploy a smart contract to a network
web3 contract deploy FILENAME.bin
Parameters:

FILENAME - the name of the .bin
$WEB3_PRIVATE_KEY as env variable or -private-key as command parameter - the private key of the wallet

Call a function of a deployed contract
web3 contract call --amount AMOUNT --address CONTRACT_ADDRESS --abi CONTRACT_ABI_FILE --function FUNCTION_NAME FUNCTION_PARAMETERS
or using bundled abi files
web3 contract call --amount AMOUNT --address CONTRACT_ADDRESS --abi erc20|erc721 --function FUNCTION_NAME FUNCTION_PARAMETERS
Parameters:

CONTRACT_ADDRESS - the address of the deployed contract
CONTRACT_ABI_FILE - the abi file of the deployed contract (take into account that there are some bundled abi files like erc20 and erc721 so you could use them without downloading or compiling them)
FUNCTION_NAME - the name of the function you want to call
FUNCTION_PARAMETERS - the list of the function parameters
AMOUNT - amount of wei to be send with transaction (require only for paid transact functions)
$WEB3_PRIVATE_KEY as env variable or -private-key as command parameter - the private key of the wallet

List functions in an ABI
web3 contract list --abi CONTRACT_ABI_FILE
Parameters:

CONTRACT_ABI_FILE - the abi file of the compiled contract

Transfer amount to the address
web3 send --to RECIPIENT_ADDRESS AMOUNT
Parameters:

RECIPIENT_ADDRESS - the address of the recepient
AMOUNT - the amount that should be send in the transaction ie - 1go (allowed units: go,eth,nanogo,gwei,attogo,wei)

Generate common contracts - ERC20, ERC721, etc
web3 generate contract [erc20/erc721] --name ""TEST Tokens"" --symbol ""TEST""
See web3 generate contract --help for more information.
Generate ABI bindings
web3 generate code --abi CONTRACT_ABI_FILE --out OUT_FILENAME --lang [go|objc|java] --pkg PGK_NAME
See web3 generate code --help for more information.
Parameters:

CONTRACT_ABI_FILE - the abi file of the compiled contract
OUT_FILENAME - the output file
PGK_NAME - package name

More installation options
Install a specific version
You can use the script to install a specific version:
curl -LSs https://raw.githubusercontent.com/gochain-io/web3/master/install.sh | sh -s v0.0.9
Install using the Go language
go install github.com/gochain-io/web3/cmd/web3
Build from source
Clone this repo:
git clone https://github.com/gochain-io/web3
cd web3
make build
./web3 help
",12
gochain-io/web3,Go,"Web3
Simple command line tool for interacting with web3 enabled blockchains - GoChain, Ethereum, etc.
This repository also exports the backing golang package web3.

Install web3
Quick one line install:
curl -LSs https://raw.githubusercontent.com/gochain-io/web3/master/install.sh | sh
Install Docker (optional) - While not required for all commands, many of the developer commands require Docker so we recommend installing it.
More options
Quickstart
If you just plan to read from the blockchain, you do not need any GO tokens and you do not need to set your PRIVATE_KEY. If you plan to deploy contracts or write anything to the blockchain, you'll need tokens and you'll need to set your PRIVATE_KEY for the account that has those tokens.
Pick a network to use
a) Run a local node
Run this command to start a local node. It will print 10 addresses with keys upon starting that you can use to deploy and interact.
web3 start
export WEB3_NETWORK=localhost
b) Use the GoChain testnet
export WEB3_NETWORK=testnet
To do any write operations, get yourself some GO testnet tokens so you can deploy and interact with your contract.
c) Use the GoChain mainnet or another web3 network
export WEB3_NETWORK=gochain
You'll need mainnet GO for this which you can buy on various exchanges.
You can also point this to other web3 based networks such as Ethereum. Ethereum is supported by default and you
can use one of the following: ethereum or ropsten.
Set Private Key (optional)
Required if you plan to deploy or write transactions.
export WEB3_PRIVATE_KEY=0x...
Deploy a contract
Copy contracts/hello.sol into your current directory.
Then:
web3 contract build hello.sol
web3 contract deploy Hello.bin
This will return a contract address, copy it and use below.
Read from a contract
Let's call a read function (which is free):
web3 contract call --address 0xCONTRACT_ADDRESS --abi Hello.abi --function hello
That should return: [Hello World].
Write to a contract
Now let's change the name:
web3 contract call --address 0xCONTRACT_ADDRESS --abi Hello.abi --function setName ""Johnny""
And call the hello function again to see if the name changed:
web3 contract call --address 0xCONTRACT_ADDRESS --abi Hello.abi --function hello
Now it should return [Hello Johnny]
ð¥
Troubleshooting
If it doesn't return Hello Johnny, you can check the logs and receipt with:
web3 rc TX_HASH
Testing
To automate testing using web3 CLI, enable the JSON format flag with --format json. This will
return easily parseable results for your tests. Eg:
web3 --format json contract call --address 0xCONTRACT_ADDRESS --abi Hello.abi --function hello
And you'll get a JSON response like this:
{
  ""response"": [
    ""Hello"",
    ""World""
  ]
}
Deploying an Upgradeable Contract
The web3 tool comes with built-in support for deploying contracts that can be
upgraded later. To deploy an upgradeable contract, simply specify the
--upgradeable flag while deploying. From our Hello example above:
web3 contract deploy --upgradeable Hello.bin
This will return the contract address. Let's set the contract address environment variable so you can use it throughout the rest of this
tutorial (alternatively you can pass in the --address CONTRACT_ADDRESS flag on all the commands).
export WEB3_ADDRESS=0xCONTRACT_ADDRESS
Internally, deploying an upgradeable contract will actually deploy two separate contracts:

Your original Hello contract.
A proxy contract for redirecting calls and storage.

The returned contract address is the address of your proxy. To see the contract
address that your proxy is pointing to, you can use the target command in
the CLI:
web3 contract target
One caveat to using upgradeable contracts is that their constructors will not
execute. To get around this, we will have to initialize our contract with an
initial call to setName:
web3 contract call --abi Hello.abi --function setName ""World""
Now we can interact with our upgradeable contract just like a normal contract:
web3 contract call --abi Hello.abi --function hello
# returns: [Hello World]
Alright, so we have a working contract. Let's upgrade it!
Upgrading the contract
We can now deploy a different contract (without the upgradeable flag) and
redirect our upgradeable contract to point to that new contract.
Copy contracts/goodbye.sol into your current directory
and build and deploy it:
web3 contract build goodbye.sol
web3 contract deploy Goodbye.bin
Using the new Goodbye contract address, we can upgrade our previous contract
using the contract upgrade command:
web3 contract upgrade --to 0xGOODBYE_CONTRACT_ADDRESS
We can see that our proxy contract now points to this new contract by
calling the hello function again:
web3 contract call --abi Hello.abi --function hello
# returns: [Goodbye World]
Note that contracts can only be upgraded by the account that created them.
Pausing and resuming a contract
Upgradeable contracts also include the ability to pause & resume execution.
This can be useful if you discover a bug in your contract and you wish to cease
operation until you can upgrade to a fixed version.
Pausing a contract is simple:
web3 contract pause
Wait a minute for the transaction to go through, then try to use the contract again and it will fail:
web3 contract call --abi Hello.abi --function hello
# returns: ERROR: Cannot call the contract: abi: unmarshalling empty output
Contracts can be upgraded while they are paused. To execute any other contract functions, you
will need to first resume operation:
web3 contract resume
List of available commands
Global parameters
$NETWORK as env variable or -network as command parameter - the name of the network. Available networks are:

gochain (default)
testnet
ethereum
ropsten
localhost

$RPC_URL as env variable or -rpc-url as command parameter - The network RPC URL (ie http://localhost:8545)
-verbose as command parameter - Verbose logging
Show information about a block
web3 block BLOCK_ID
Parameters:

BLOCK_ID - id of a block (omit for latest)

Show information about a transaction
web3 transaction TX_HASH
Parameters:

TX_HASH - hash of a transaction

Show information about an address
web3 transaction ADDRESS_HASH
Parameters:

ADDRESS_HASH - hash of the address

Build a smart contract
web3 contract build FILENAME.sol --solc-version SOLC_VERSION
Parameters:

FILENAME - the name of the .sol file, eg: hello.sol
SOLC_VERSION - the version of the solc compiler

Deploy a smart contract to a network
web3 contract deploy FILENAME.bin
Parameters:

FILENAME - the name of the .bin
$WEB3_PRIVATE_KEY as env variable or -private-key as command parameter - the private key of the wallet

Call a function of a deployed contract
web3 contract call --amount AMOUNT --address CONTRACT_ADDRESS --abi CONTRACT_ABI_FILE --function FUNCTION_NAME FUNCTION_PARAMETERS
or using bundled abi files
web3 contract call --amount AMOUNT --address CONTRACT_ADDRESS --abi erc20|erc721 --function FUNCTION_NAME FUNCTION_PARAMETERS
Parameters:

CONTRACT_ADDRESS - the address of the deployed contract
CONTRACT_ABI_FILE - the abi file of the deployed contract (take into account that there are some bundled abi files like erc20 and erc721 so you could use them without downloading or compiling them)
FUNCTION_NAME - the name of the function you want to call
FUNCTION_PARAMETERS - the list of the function parameters
AMOUNT - amount of wei to be send with transaction (require only for paid transact functions)
$WEB3_PRIVATE_KEY as env variable or -private-key as command parameter - the private key of the wallet

List functions in an ABI
web3 contract list --abi CONTRACT_ABI_FILE
Parameters:

CONTRACT_ABI_FILE - the abi file of the compiled contract

Transfer amount to the address
web3 send --to RECIPIENT_ADDRESS AMOUNT
Parameters:

RECIPIENT_ADDRESS - the address of the recepient
AMOUNT - the amount that should be send in the transaction ie - 1go (allowed units: go,eth,nanogo,gwei,attogo,wei)

Generate common contracts - ERC20, ERC721, etc
web3 generate contract [erc20/erc721] --name ""TEST Tokens"" --symbol ""TEST""
See web3 generate contract --help for more information.
Generate ABI bindings
web3 generate code --abi CONTRACT_ABI_FILE --out OUT_FILENAME --lang [go|objc|java] --pkg PGK_NAME
See web3 generate code --help for more information.
Parameters:

CONTRACT_ABI_FILE - the abi file of the compiled contract
OUT_FILENAME - the output file
PGK_NAME - package name

More installation options
Install a specific version
You can use the script to install a specific version:
curl -LSs https://raw.githubusercontent.com/gochain-io/web3/master/install.sh | sh -s v0.0.9
Install using the Go language
go install github.com/gochain-io/web3/cmd/web3
Build from source
Clone this repo:
git clone https://github.com/gochain-io/web3
cd web3
make build
./web3 help
",12
NetBSD/src,None,"NetBSD
NetBSD is a free, fast, secure, and highly portable Unix-like Open
Source operating system.  It is available for a wide range of
platforms, from large-scale servers
and powerful desktop systems to handheld and embedded devices.
Building
You can cross-build NetBSD from most UNIX-like operating systems.
To build for amd64 (x86_64), in the src directory:
./build.sh -U -u -j4 -m amd64 -O ~/obj release

Additional build information available in the BUILDING file.
Binaries

Daily builds
Releases

Testing
On a running NetBSD system:
cd /usr/tests; atf-run | atf-report

Troubleshooting

Send bugs and patches via web form.
Subscribe to the mailing lists.
The netbsd-users list is a good choice for many problems; watch current-users if you follow the bleeding edge of NetBSD-current.
Join the community IRC channel #netbsd @ freenode.

Latest sources
To fetch the main CVS repository:
cvs -d anoncvs@anoncvs.NetBSD.org:/cvsroot checkout -P src

To work in the Git mirror, which is updated every few hours from CVS:
git clone https://github.com/NetBSD/src.git

Additional Links

The NetBSD Guide
NetBSD manual pages
NetBSD Cross-Reference

",157
morozov-group/magento2-similar-products,PHP,"magento2-similar-products

Magento 2 Similarity extension which provides connectivity with Similarity Engine.
Demo store

Automated Upsells for every product Demo | Production
Visually Similar products for specified product /catalogsearch/advanced/result/?similar=PRODUCT_ID
Visually Similar products within same category category.html?similar=PRODUCT_ID Demo
CMS Widget to put similar products any where for specified PRODUCT_ID.
(Near future) Category filling assistant, for some special events or campaigns.

Installation
Simple installation via composer.
compose require morozov-group/magento2-similar-products

Go to configuration enter your email, and we'll take care of everything else.
You will receive email once we are ready to serve similar products recommendations.
Then you can proceed with customizations.
Contributions and new ideas
You are welcome to post tickets and pull requests.
",5
u-simon/springCloudDemo,Java,"springCloudDemo
",2
AMReX-Codes/amrex,C++,"
License
AMReX Copyright (c) 2017, The Regents of the University of California,
through Lawrence Berkeley National Laboratory and the Alliance for
Sustainable Energy, LLC., through National Renewable Energy Laboratory
(subject to receipt of any required approvals from the U.S. Dept. of
Energy).  All rights reserved.
If you have questions about your rights to use or distribute this
software, please contact Berkeley Lab's Innovation & Partnerships
Office at IPO@lbl.gov.
NOTICE.  This Software was developed under funding from the
U.S. Department of Energy and the U.S. Government consequently retains
certain rights. As such, the U.S. Government has been granted for
itself and others acting on its behalf a paid-up, nonexclusive,
irrevocable, worldwide license in the Software to reproduce,
distribute copies to the public, prepare derivative works, and perform
publicly and display publicly, and to permit other to do so.
License for AMReX can be found at LICENSE.
Development Model
Development generally follows the following ideas:


New features are committed to the development branch.
Nightly regression testing is used to ensure that no answers
change (or if they do, that the changes were expected).
If a change is critical, we can cherry-pick the commit from
development to master.


Bug fixes, questions and contributions of new features are welcome!


Bugs should be reported through GitHub issues


We suggest asking questions through GitHub issues as well


Any contributions of new features that have the potential
to change answers should be done via pull requests.
A pull request should be generated from your fork of
amrex and target the development branch.
If there are a number of small commits making up the PR, we may
wish to squash commits upon merge to have a clean history.
Please ensure that your PR title and first post are descriptive,
since these will be used for a squashed commit message.
Please note the following:
If you choose to make contributions to the code
then you hereby grant a non-exclusive, royalty-free perpetual license
to install, use, modify, prepare derivative works,
incorporate into other computer software,
distribute, and sublicense such enhancements or derivative works
thereof, in binary and source code form.




On the first workday of each month, we perform a merge of
development into master.  For this merge to take place, we
need to be passing the regression tests.
To accommodate this need, we close the merge window into
development a few days before the merge day.  While the merge
window is closed, only bug fixes should be pushed into
development.  Once the merge from development -> master is
done, the merge window reopens.


Core Developers
People who make a number of substantive contributions will be named
""core developers"" of AMReX.  The criteria for becoming a core
developer are flexible, but generally involve one of the following:


100 non-trivial commits to amrex/Src/ and/or


addition of a new algorithm / module  and/or


substantial input into the code design process or testing


If a core developer is inactive for multiple years, we may reassess their
status as a core developer.
The current list of core developers is: Ann Almgren (LBNL), Vince Beckner, John Bell (LBNL), Johannes Blaschke (LBNL), Cy Chan (LBNL), Marcus Day (LBNL), Brian Friesen (NERSC), Kevin Gott (NERSC), Daniel Graves (LBNL), Max Katz (NVIDIA), Andrew Myers (LBNL), Tan Nguyen (LBNL), Andrew Nonaka (LBNL), Michele Rosso (LBNL), Sam Williams (LBNL), Weiqun Zhang (LBNL), Michael Zingale (Stonybrook University).
",130
joeynmt/joeynmt,Python,"Â   Joey NMT

Goal and Purpose
Joey NMT framework is developed for educational purposes.
It aims to be a clean and minimalistic code base to help novices
pursuing the understanding of the following questions.

How to implement classic NMT architectures (RNN and Transformer) in PyTorch?
What are the building blocks of these architectures and how do they interact?
How to modify these blocks (e.g. deeper, wider, ...)?
How to modify the training procedure (e.g. add a regularizer)?

In contrast to other NMT frameworks, we will not aim for
state-of-the-art results or speed through engineering or training tricks
since this often goes in hand with an increase in code complexity
and a decrease in readability.
However, Joey NMT re-implements baselines from major publications.
Contributors
Joey NMT is developed by Joost Bastings (University of Amsterdam) and Julia Kreutzer (Heidelberg University).
Features
We aim to implement the following features (aka the minimalist toolkit of NMT):

Recurrent Encoder-Decoder with GRUs or LSTMs
Transformer Encoder-Decoder
Attention Types: MLP, Dot, Multi-Head, Bilinear
Word-, BPE- and character-based input handling
BLEU, ChrF evaluation
Beam search with length penalty and greedy decoding
Customizable initialization
Attention visualization
Learning curve plotting

[Work in progress: Transformer, Multi-Head and Dot still missing.]
Coding
In order to keep the code clean and readable, we make use of:

Style checks: pylint with (mostly) PEP8 conventions, see .pylintrc.
Typing: Every function has documented input types.
Docstrings: Every function, class and module has docstrings describing their purpose and usage.
Unittests: Every module has unit tests, defined in test/unit/.
Travis CI runs the tests and pylint on every push to ensure the repository stays clean.

Installation
Joey NMT is built on PyTorch and torchtext for Python >= 3.5.

Clone this repository:
git clone https://github.com/joeynmt/joeynmt.git
Install the requirements:
cd joeynmt
pip3 install -r requirements.txt (you might want to add --user for a local installation).
Install joeynmt:
python3 setup.py install
Run the unit tests:
python3 -m unittest

Usage
For details, follow the tutorial in the docs.
Data Preparation
Parallel Data
For training a translation model, you need parallel data, i.e. a collection of source sentences and reference translations that are aligned sentence-by-sentence and stored in two files,
such that each line in the reference file is the translation of the same line in the source file.
Pre-processing
Before training a model on it, parallel data is most commonly filtered by length ratio, tokenized and true- or lowercased.
The Moses toolkit provides a set of useful scripts for this purpose.
In addition, you might want to build the NMT model not on the basis of words, but rather sub-words or characters (the level in JoeyNMT configurations).
Currently, JoeyNMT supports the byte-pair-encodings (BPE) format by subword-nmt.
Configuration
Experiments are specified in configuration files, in simple YAML format. You can find examples in the configs directory.
small.yaml contains a detailed explanation of configuration options.
Most importantly, the configuration contains the description of the model architecture (e.g. number of hidden units in the encoder RNN),
paths to the training, development and test data, and the training hyperparameters (learning rate, validation frequency etc.).
Training
Start
For training, run
python3 -m joeynmt train configs/small.yaml.
This will train a model on the training data specified in the config (here: small.yaml),
validate on validation data,
and store model parameters, vocabularies, validation outputs and a small number of attention plots in the model_dir (also specified in config).
Note that pre-processing like tokenization or BPE-ing is not included in training, but has to be done manually before.
Tip: Be careful not to overwrite models, set overwrite: False in the model configuration.
Validations
The validations.txt file in the model directory reports the validation results at every validation point.
Models are saved whenever a new best validation score is reached, in batch_no.ckpt, where batch_no is the number of batches the model has been trained on so far.
best.ckpt links to the checkpoint that has so far achieved the best validation score.
Visualization
JoeyNMT uses TensorboardX to visualize training and validation curves and attention matrices during training.
Launch Tensorboard with tensorboard --logdir model_dir/tensorboard (or python -m tensorboard.main ...) and then open the url (default: localhost:6006) with a browser.
For a stand-alone plot, run python3 scripts/plot_validation.py model_dir --plot_values bleu PPL --output_path my_plot.pdf to plot curves of validation BLEU and PPL.
CPU vs. GPU
For training on a GPU, set use_cuda in the config file to True. This requires the installation of required CUDA libraries.
Translating
There's 3 options for testing what the model has learned.
Whatever data you feed the model for translating, make sure it is properly pre-processed, just as you pre-processed the training data, e.g. tokenized and split into subwords (if working with BPEs).
1. Test Set Evaluation
For testing and evaluating on your parallel test/dev set, run
python3 -m joeynmt test configs/small.yaml --output_path out.
This will generate translations for validation and test set (as specified in the configuration) in out.[dev|test]
with the latest/best model in the model_dir (or a specific checkpoint set with load_model).
It will also evaluate the outputs with eval_metric.
If --output_path is not specified, it will not store the translation, and only do the evaluation and print the results.
2. File Translation
In order to translate the contents of a file not contained in the configuration (here my_input.txt), simply run
python3 -m joeynmt translate configs/small.yaml < my_input.txt > out.
The translations will be written to stdout or alternatively--output_path if specified.
3. Interactive
If you just want try a few examples, run
python3 -m joeynmt translate configs/small.yaml
and you'll be prompted to type input sentences that JoeyNMT will then translate with the model specified in the configuration.
Documentation and Tutorial
The docs include an overview of the NMT implementation, a walk-through tutorial for building, training, tuning, testing and inspecting an NMT system, the API documentation and FAQs.
Benchmarks
Benchmarks on small models trained on GPU/CPU on standard data sets are reported here.

IWSLT15 En-Vi, word-based
IWSLT14 De-En, 32000 joint BPE, word-based
WMT17 En-De and Lv-En, 32000 joint BPE

IWSLT English-Vietnamese
We compare against Tensorflow NMT on the IWSLT15 En-Vi data set as preprocessed by Stanford.
You can download the data with scripts/get_iwslt15_envi.sh, and then use configs/iwslt_envi_luong.yaml to replicate the experiment.



Systems
tst2012 (dev)
test2013 (test)




TF NMT (greedy)
23.2
25.5


TF NMT (beam=10)
23.8
26.1


Joey NMT (greedy)
23.2
25.8


Joey NMT (beam=10, alpha=1.0)
23.8
26.5


(Luong & Manning, 2015)
-
23.3



We also compare against xnmt which uses different hyperparameters, so we use a different configuration for Joey NMT too: configs/iwslt_envi_xnmt.yaml.



Systems
tst2012 (dev)
test2013 (test)




xnmt (beam=5)
25.0
27.3


Joey NMT (greedy)
24.6
27.4


Joey NMT (beam=5, alpha=1.0)
24.9
27.7



IWSLT  German-English
We compare against the baseline scores reported in (Wiseman & Rush, 2016) (W&R),
(Bahdanau et al., 2017) (B17) with tokenized, lowercased BLEU (using sacrebleu).
áºe compare a word-based model of the same size and vocabulary as in W&R and B17.
The script to obtain and pre-process the data is the one published with W&R.
Use configs/iwslt_deen_bahdanau.yaml for training the model.
On a K40-GPU word-level training took <1h, beam search decoding for both dev and test <2min.



Systems
level
dev
test
#params




W&R (greedy)
word
-
22.53



W&R (beam=10)
word
-
23.87



B17 (greedy)
word
-
25.82



B17 (beam=10)
word
-
27.56



Joey NMT (greedy)
word
28.41
26.68
22.05M


Joey NMT (beam=10, alpha=1.0)
word
28.96
27.03
22.05M



On CPU (use_cuda: False):
(approx 8-10x slower: 8h for training, beam search decoding for both dev and test 19min, greedy decoding 5min)



Systems
level
dev
test
#params




Joey NMT (greedy)
word
28.35
26.46
22.05M


Joey NMT (beam=10, alpha=1.0)
word
28.85
27.06
22.05M



In addition, we compare to a BPE-based GRU model with 32k (Groundhog style).
Use scripts/get_iwslt14_bpe.sh to pre-process the data and configs/iwslt14_deen_bpe.yaml to train the model.
This model is available for download here.



Systems
level
dev
test
#params




Joey NMT (greedy)
bpe
27.57

60.69M


Joey NMT (beam=5, alpha=1.0)
bpe
28.55
27.34
60.69M



WMT 17 English-German and Latvian-English
We compare against the results for recurrent BPE-based models that were reported in the Sockeye paper.
We only consider the Groundhog setting here, where toolkits are used out-of-the-box for creating a Groundhog-like model (1 layer, LSTMs, MLP attention).
The data is pre-processed as described in the paper (code).
Postprocessing is done with Moses' detokenizer, evaluation with sacrebleu.
Note that the scores reported for other models might not reflect the current state of the code, but the state at the time of the Sockeye evaluation.
Please also consider the difference in number of parameters despite ""the same"" setup: our models are the smallest in numbers of parameters.
English-German
Groundhog setting: configs/wmt_ende_default.yaml  with encoder rnn=500, lr=0.0003, init_hidden=""bridge"".



Systems
level
dev
test
#params




Sockeye (beam=5)
bpe
-
23.18
87.83M


OpenNMT-Py (beam=5)
bpe
-
18.66
87.62M


Joey NMT (beam=5)
bpe
24.33
23.45
86.37M



The Joey NMT model was trained for 4 days (14 epochs).
Latvian-English
Groundhog setting: configs/wmt_lven_default.yaml with encoder rnn=500, lr=0.0003, init_hidden=""bridge"".



Systems
level
dev
test
#params




Sockeye (beam=5)
bpe
-
14.40
?


OpenNMT-Py (beam=5)
bpe
-
9.98
?


Joey NMT (beam=5)
bpe
12.09
8.75
64.52M



Contributing
Since this codebase is supposed to stay clean and minimalistic, contributions addressing the following are welcome:

Code correctness
Code cleanliness
Documentation quality
Speed or memory improvements
resolving issues

Code extending the functionalities beyond the basics will most likely not end up in the master branch, but we're curions to learn what you used Joey for.
Use-cases and Projects
Here we'll collect projects and repositories that are based on Joey. If you used Joey for a project, publication or built some code on top of it, let us know and we'll link it here.
Projects:

TBD

Contact
Please leave an issue if you have questions or issues with the code.
For general questions, email us at joeynmt <at> gmail.com.
Naming
Joeys are infant marsupials.
",46
JingningShi/MtreeRing,R,"MtreeRing
Authors: Jingning Shi, Wei Xiang
License: GPL3






MtreeRing is a tool for automatically measuring tree-ring width using image processing techniques.
Installation
Install the stable version from CRAN
install.packages(""MtreeRing"")
or the development version from GitHub
# install.packages(""devtools"")
devtools::install_github(""JingningShi/MtreeRing"")
Ring-width measurement
1. Read an image
library(MtreeRing)
## Read and plot a tree ring image
img.name <- system.file(""001.png"", package = ""MtreeRing"")
t1 <- ring_read(img = img.name, dpi = 1200, plot = TRUE)
ring_read supports commonly used image formats, including png, tiff, jpg and bmp.
2. Detect ring borders
After plotting the image, the automatic detection of ring borders can be performed using three alternative methods: (1) watershed algorithm; (2) Canny edge detector; (3) a linear detection algorithm from R package measuRing.
## Split a long core sample into 2 pieces to
## get better display performance and use the
## watershed algorithm to detect ring borders:
t2 <- ring_detect(ring.data = t1, seg = 2, method = 'watershed')

Figure 1. The automatic detection of ring borders
3. Calculate ring-width series
If all ring borders are correctly identified, you can generate a ring-width series in data frame format. Use write.rwl to export the ring-width series to an rwl file.
rw.df <- ring_calculate(ring.data = t2, seriesID = ""940220"")
library(dplR) # A dendrochronological analysis package
fn <- tempfile(fileext="".rwl"")
write.rwl(rwl.df = rw.df, fname = fn, format = ""tucson"")
Shiny application
If you are not familiar with R and its command line interface, the shiny-based app is a good alternative.
MtreeRing::ring_app_launch()
This command allows to run a Shiny-based application within the system's default web browser. The app provides a beginner-friendly graphical interface and supports more flexible mouse-based interactions.
The dashboard has three components: a header, sidebar and body, like this

A workflow for the Shiny app can be found in the package vignette. Most steps are demonstrated with a gif to make the workflow more understandable.
vignette('app-MtreeRing')
Ring width correction
If an increment borer is used to extract samples, it is well known that the auger sometimes fails to traverse the pith of the sampled tree but passes through one side of the pith at a certain distance. Tangent lines of rings close to the pith are therefore not perpendicular to the horizontal path, which may lead to considerable errors in ring widths.
Under such conditions, you can create two paths by setting the argument incline = TRUE, or by ticking the checkbox ""Inclined tree rings"". See this example.

The line segment connecting two dots on the same ring should match the tangent of a tree ring border. The corrected ring width is estimated from the distance between adjacent rings and orientation of ring borders.
Code of conduct
Please note that the 'MtreeRing' project is released with a Contributor Code of Conduct. By contributing to this project, you agree to abide by its terms.
",2
yongzhuo/nlp_xiaojiang,Python,"nlp_xiaojiang
AugmentText
- åè¯ï¼æææ¯è¾å¥½ï¼
- EDAï¼åä¹è¯æ¿æ¢ãæå¥ãäº¤æ¢åå é¤ï¼ï¼ææè¿è¡ï¼
- HMM-markoï¼è´¨éè¾å·®ï¼
- syntaxï¼ä¾å­å¥æ³ãå¥æ³ãè¯­æ³ä¹¦ï¼ï¼ç®åå¥è¿å¯ï¼
- seq2seqï¼æ·±åº¦å­¦ä¹ åä¹å¥çæï¼ææä¸çæ³ï¼seq2seqä»£ç å¤§é½æ¯ [https://github.com/qhduan/just_another_seq2seq] çï¼ææä¸çæ³ï¼

ChatBot
- æ£ç´¢å¼ChatBot
    - åESé£æ ·ç´æ¥æ£ç´¢(å¦ä½¿ç¨fuzzywuzzy)ï¼åªè½å­é¢å¹é
    - æé å¥åéï¼æ£ç´¢é®ç­åºï¼è½å¤æ£ç´¢æåä¹è¯çå¥å­
- çæå¼ChatBotï¼todoï¼
    - seq2seq
    - GAN

ClassificationText
- bert+bi-lstm(keras) approach 0.78~0.79% acc of Weizhong Bank Intelligent Customer Service Question Matching Competition

FeatureProject
- bertå¥åéãææ¬ç¸ä¼¼åº¦
    - bert/extract_keras_bert_feature.py:æåbertå¥åéç¹å¾
    - bert/tet_bert_keras_sim.py:æµè¯bertå¥åécosinç¸ä¼¼åº¦
- normalization_utilæçæ¯æ°æ®å½ä¸å
    - 0-1å½ä¸åå¤ç
    - åå¼å½ä¸å
    - sigå½ä¸åå¤ç
- sim featureï¼MLï¼
    - distance_text_or_vec:åç§è®¡ç®ææ¬ãåéè·ç¦»ç­
    - distance_vec_TS_SSï¼TS_SSè®¡ç®è¯åéè·ç¦»
    - cut_td_idfï¼å°å°é»é¸¡è¯­æågossipç»å
    - sentence_sim_featureï¼è®¡ç®ä¸¤ä¸ªææ¬çç¸ä¼¼åº¦æèè·ç¦»ï¼ä¾å¦qqï¼é®é¢åé®é¢ï¼ï¼æèqaï¼é®é¢åç­æ¡ï¼

run(å¯ä»¥å¨win10ä¸,pycharmä¸è¿è¡)

1.åå»ºtf-idfæä»¶ç­ï¼è¿è¡2éè¦åè·1ï¼:
python cut_td_idf.py
2.è®¡ç®ä¸¤ä¸ªå¥å­é´çåç§ç¸ä¼¼åº¦ï¼åè®¡ç®ä¸ä¸ªé¢å®ä¹çï¼ç¶åå¯è¾å¥èªå®ä¹çï¼åè·1ï¼:
python sentence_sim_feature.py
3.chatbot_1è·èµ·æ¥(fuzzyæ£ç´¢-æ²¡)ï¼ç¬ç«ï¼ï¼
python chatbot_fuzzy.py
4.chatbot_2è·èµ·æ¥(å¥åéæ£ç´¢-è¯)ï¼ç¬ç«ï¼ï¼
python chatbot_sentence_vec_by_word.py
5.chatbot_3è·èµ·æ¥(å¥åéæ£ç´¢-å­)ï¼ç¬ç«ï¼ï¼
python chatbot_sentence_vec_by_char.py
6.æ°æ®å¢å¼ºï¼eda)ï¼                     python enhance_eda.py
7.æ°æ®å¢å¼ºï¼markoï¼:                   python enhance_marko.py
8.æ°æ®å¢å¼ºï¼translate_accountï¼:       python translate_tencent_secret.py
9.æ°æ®å¢å¼ºï¼translate_toolsï¼:         python translate_translate.py
10.æ°æ®å¢å¼ºï¼translate_webï¼:          python translate_google.py
11.æ°æ®å¢å¼ºï¼augment_seq2seqï¼:        åè· python extract_char_webank.pyçææ°æ®ï¼
åè· python train_char_anti.py
ç¶åè· python predict_char_anti.py
12.ç¹å¾è®¡ç®(bert)ï¼æåç¹å¾ãè®¡ç®ç¸ä¼¼åº¦ï¼:
run extract_keras_bert_feature.py run tet_bert_keras_sim.py

Data
- chinese_L-12_H-768_A-12ï¼è°·æ­é¢è®­ç»å¥½çæ¨¡åï¼
   githubé¡¹ç®ä¸­åªæ¯ä¸ä¼ é¨åæ°æ®ï¼éè¦çåå¾é¾æ¥: https://pan.baidu.com/s/1I3vydhmFEQ9nuPG2fDou8Q æåç : rket
   è§£ååå°±å¯ä»¥å¦
- chinese_vector
    githubé¡¹ç®ä¸­åªæ¯ä¸ä¼ é¨åæ°æ®ï¼éè¦çåå¾é¾æ¥: https://pan.baidu.com/s/1I3vydhmFEQ9nuPG2fDou8Q æåç : rket
    - æªåçé¨åword2vecè®­ç»è¯åéï¼èªå·±éè¦ä¸è½½å¨æææä¼å¥½ï¼
    - w2v_model_wiki_char.vecãw2v_model_wiki_word.vecé½åªæé¨å
- corpus
    githubé¡¹ç®ä¸­åªæ¯ä¸ä¼ é¨åæ°æ®ï¼éè¦çåå¾é¾æ¥: https://pan.baidu.com/s/1I3vydhmFEQ9nuPG2fDou8Q æåç : rket
    - webank(trainãdevãtest)
    - å°é»é¸¡ågossipé®ç­é¢æï¼æ°æ®æ²¡æ¸æ´ï¼,chicken_and_gossip.txt
    - å¾®ä¼é¶è¡åæ¯ä»å®ææ¬ç¸ä¼¼åº¦ç«èµæ°æ®ï¼ sim_webank.csv
- sentence_vec_encode_char
    - 1.txtï¼å­åéçæçå100000å¥åéï¼
- sentence_vec_encode_word
    - 1.txtï¼è¯åéçæçå100000å¥åéï¼
- tf_idfï¼chicken_and_gossip.txtçæçtf-idfï¼

requestments.txt
- python_Levenshtei
    - è°ç¨Levenshteinï¼æçpythonæ¯3.6ï¼
    - æå¼å¶æºæä»¶: https://www.lfd.uci.edu/~gohlke/pythonlibs/
    - æ¥æ¾python_Levenshtein-0.12.0-cp36-cp36m-win_amd64.whlä¸è½½å³å¯
- pyemd
- pyhanlp
    - ä¸å¥½ä¾èµJPype1-0.6.3-cp36-cp36m-win_amd64.whl

åè/æè°¢

eda_chineseï¼https://github.com/zhanlaoban/eda_nlp_for_Chinese
ä¸»è°å®¾æåå¨ï¼https://github.com/hankcs/MainPartExtractor
HMMçæå¥å­ï¼https://github.com/takeToDreamLand/SentenceGenerate_byMarkov
åä¹è¯ç­ï¼https://github.com/fighting41love/funNLP/tree/master/data/
å°çç¿»è¯ï¼http://www.niutrans.com/index.html

å¶ä»èµæ

bert(keras):https://github.com/CyberZHG/keras-bert
NLPæ°æ®å¢å¼ºæ±æ»:https://github.com/quincyliang/nlp-data-augmentation
ç¥ä¹NLPæ°æ®å¢å¼ºè¯é¢:https://www.zhihu.com/question/305256736/answer/550873100
chatbot_seq2seq_seqGanï¼æ¯è¾å¥½ç¨ï¼ï¼https://github.com/qhduan/just_another_seq2seq
èªå·±å¨æåèå¤©æºå¨äººæç¨: https://github.com/warmheartli/ChatBotCourse

",19
flexbooru/flexbooru,Kotlin,"Flexbooru
A booru client for Android, support Danbooru, Moebooru, Gelbooru, Sankaku, etc.







Translate
Click on this link and you can translate this app into your language.
Downlad
 or Github Releases
Screenshot
  
Thanks to

OkHttp: An HTTP+HTTP/2 client for Android and Java applications.
Retrofit: Type-safe HTTP client for Android and Java by Square.
Gson: A Java serialization/deserialization library to convert Java Objects into JSON and back.
TikXml: Modern XML Parser for Android.
Glide: An image loading and caching library for Android focused on smooth scrolling.
Picasso: A powerful image downloading and caching library for Android.
MaterialDrawer: A drawer with material 2 design.
SimpleMenuPreference: A preference displaying a simple menu, originally implemented by RikkaW. On pre-Lollipop devices it falls back to a ListPreference as the older devices can't handle elevation and animation properly introduced in API 21.
FlexboxLayout: A library project which brings the similar capabilities of CSS Flexible Box Layout Module to Android.
PhotoView: Implementation of ImageView for Android that supports zooming, by various touch gestures.
SubsamplingScaleImageView: Highly configurable, easily extendable deep zoom view for displaying huge images without loss of detail. Perfect for photo galleries, maps, building plans etc.
ExoPlayer: An application level media player for Android.
Kodein-DI: A very simple and yet very useful dependency retrieval container. It is very easy to use and configure.
KotlinCoroutineAdapter: A Retrofit 2 CallAdapter.Factory for Kotlin coroutine's Deferred.
Muzei: A live wallpaper that gently refreshes your home screen each day with famous works of art. It also recedes into the background, blurring and dimming artwork to keep your icons and widgets in the spotlight. Simply double touch the wallpaper or open the Muzei app to enjoy and explore the artwork in its full glory.

",134
xwings/tuya,Python,"all about reversing, exploit, ctf and misc
é¡¾åæä¹ æ¶é¸¦
@mail: kj _ xandora _ net
",14
mcidasv/mcidasv,Java,"This is the main trunk for SSEC's McIDAS-V Project.
Things of Interest
.                                   
âââ build-customized.xml            * User-customizable Ant build file.
âââ build.xml                       * Main Ant build file.
âââ docs                            
â   âââ javadoc                     * API documentation for developers.
â   âââ userguide                   * Project documentation.
âââ edu                             
â   âââ wisc                        
â       âââ ssec                    
â           âââ mcidas              
â           âââ mcidasv             * General managers and main application 
â               â                     code should go here, e.g., ViewManager, 
â               â                     McIDASV.java.
â               âââ chooser         * Data choosers should go here.
â               âââ control         * Display controls should go here.
â               âââ data            * Datasources should go here.
â               âââ display         * Displays code should go here.
â               âââ images          * DEPRECATED: please use appropriate
â               â                     directory within ""resources"".
â               âââ jython          * Linear Combination Jython Interpreter.
â               âââ monitors        * Monitor the state of a McIDAS-V session.
â               âââ probes          * Data probes.
â               âââ resources       * Non-code resources required by 
â               â   â                 McIDAS-V should reside here. Things
â               â   â                 like RBI, XML, and images.
â               â   âââ python      * Jython library code.
â               âââ servermanager   * Handles local and remote ADDE datasets.
â               âââ startupmanager  * Manage McIDAS-V startup options.
â               âââ supportform     * Submit McIDAS-V support requests.
â               âââ ui              * UI related classes here, e.g., UIManager.
â               âââ util            * Utility classes can go here.
|
âââ lib                             * McIDAS-V dependencies (other than VisAD/IDV).
|   |
|   âââ linux-amd64                 * 64-bit Linux dependencies.
|   âââ linux-i586                  * 32-bit Linux dependencies.
|   âââ macosx                      * OS X dependencies
|   âââ share                       * Platform independent dependencies. This is
|   |                                 where most JAR files will end up.
|   âââ windows-amd64               * 64-bit Windows dependencies.
|   âââ windows-i586                * 32-bit Windows dependencies.
|
âââ release                         * Files used by install4J.
âââ tools                           
â   âââ apidocs                     
â   âââ external                    
â       âââ orphan_icon_finder      
â       âââ pluginfeed              
â       âââ supportreq              
âââ ucar                            

Running McIDAS-V
Assuming you've cloned the repo, and have installed Java 8+:
ant jar.runlarge

Building a new release
Make sure IDV is up to date, then build the ""dist"" target:
ant dist

Run Install4J and build the installer packages.
Nightlies
A cron job that builds the ""nightly"" target runs daily at 4am:
ant nightly

There is a separate script on the webserver that pulls the completed build.
Acknowledgements
YourKit is kindly supporting open source projects with its full-featured Java
Profiler. YourKit, LLC is the creator of innovative and intelligent tools for
profiling Java and .NET applications. Take a look at YourKit's leading
software products: YourKit Java Profiler and YourKit .NET Profiler.
",3
Shougo/denite.nvim,Python,"denite.nvim

About

Denite is a dark powered plugin for Neovim/Vim to unite all interfaces.
It can replace many features or plugins with its interface.
It is like a fuzzy finder, but is more generic.
You can extend the interface and create the sources.
Some things you can do with it include:


Opening files


Switching buffers


Inserting the value of a register


Changing current directory


Searching for a string


Unite.vim was meant to be like Helm for Vim.
But the implementation is ugly and it's very slow.
Denite resolves Unite's problems. Here are some of its benefits:


Theoretically faster because the main process is executed by Python


Theoretically more stable because no other processes can be performed when
it runs.


The implementation is simpler than unite


Has greater potential to implement new features


Python3 is easier to work with than Vimscript


There are a lot of useful tools to keep code simple (linter, tester, etc...)
in Python3.


Unite is officially obsolete, minor bugs (or even major bugs) are
not fixed anymore


Requirements
Denite requires Neovim 0.3.0+ or Vim 8.0+ with if_python3.
If :echo has(""python3"") returns 1, then you're done.
Note: You need to install Python3.6.1+.
For neovim:
You must install ""pynvim"" module with pip
pip3 install --user pynvim

If you want to read the Neovim-python/python3 interface install documentation,
you should read :help provider-python.
For Vim8:
Please install nvim-yarp plugin for Vim8.
https://github.com/roxma/nvim-yarp
Please install vim-hug-neovim-rpc plugin for Vim8.
https://github.com/roxma/vim-hug-neovim-rpc
You must install ""pynvim"" module with pip
pip3 install --user pynvim

For Windows users

Install Vim from Vim Win32 Installer
releases
Download Python latest embeddable zip
file and copy the all files in
the zip file to the folder where you installed Vim.

Note: You need to do 1. and 2. with the common-arch files (x86 or x64).
Screenshots




",1337
fate0/proxylist,HTML,"proxylist

proxylist, generate by fate0/getproxy project in every 15 minute
",444
bcgov/dbcrss,Python,"
dbcrss
DataBC Application Feeds Service
Visualizations
DataBC Web Services
https://uptime.apps.gov.bc.ca 
Purpose
Service Status Page
License
Copyright 2016 Province of British Columbia

Licensed under the Apache License, Version 2.0 (the ""License"");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an ""AS IS"" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.

",2
sunsettrack4/xmltv_epg,None,"About the easyEPG project
This is the free platform to download EPG data for your TV setup.
All XMLTV files are compatible with tvHeadend, KODI and other platforms supporting XMLTV files.
Support my work

Paypal Donation Link

Get help

Forum: Kodinerds
Email: sunsettrack4@gmail.com

Download links
Unified EPG list

Zattoo DE+CH

Current supported sources

Zattoo DE
Zattoo CH
Wilmaa CH
Horizon DE
TVPlayer UK

",20
koalaverse/vip,HTML,"vip: Variable Importance Plots 







Overview
vip is an R package for constructing variable importance
plots (VIPs). VIPs are part of a larger framework referred to as
interpretable machine learning (IML), which includes (but not limited
to): partial dependence plots (PDPs) and individual conditional
expectation (ICE) curves. While PDPs and ICE curves (available in the R
package pdp) help visualize
feature effects, VIPs help visualize feature impact (either locally or
globally). An in-progress, but comprehensive, overview of IML can be
found here: https://github.com/christophM/interpretable-ml-book.
Installation
# The easiest way to get vip is to install it from CRAN:
install.packages(""vip"")

# Alternatively, you can install the development version from GitHub:
if (!requireNamespace(""devtools"")) {
  install.packages(""devtools"")
}
devtools::install_github(""koalaverse/vip"")
For details and example usage, visit the vip package
website.
",47
silvernoo/ac-rss,Python,"AC-RSS
è®¢éä»¥ä¸å°å
https://raw.githubusercontent.com/silvernoo/ac-rss/master/rrs/feed_110.xml
https://raw.githubusercontent.com/silvernoo/ac-rss/master/rrs/feed_164.xml
https://raw.githubusercontent.com/silvernoo/ac-rss/master/rrs/feed_184.xml
https://raw.githubusercontent.com/silvernoo/ac-rss/master/rrs/feed_73.xml
https://raw.githubusercontent.com/silvernoo/ac-rss/master/rrs/feed_74.xml
https://raw.githubusercontent.com/silvernoo/ac-rss/master/rrs/feed_75.xml
",17
CreatCodeBuild/brutal-algorithm-class,JavaScript,"brutal-algorithm-class
æææçè¯¾ãæå¼ºç®æ³ç­ãä»£ç ç¬è®°
",6
timi-liuliang/echo,C++,"


Echo
Introduction
Echo is a new game engine, which used more industry standard of nowadays for game development. The new design concept makes the engine simplicity to use. but more powerful.
Examples
Documentation
Download



Description
Files
Previous




Editor [Win32]
echo-setup-2018.10.09.exe
old version


Editor [Mac OS X 10.7 or later]
echo.dmg



Examples
echo-examples-master.zip




Build
[Windows Editor]

Install [Visual Studio 2017] [CMake] [Python 3]...
EnterFolder ""${echo_root_path}/build/editor/windows""
Double click ""cmake.bat""
Double click ""echo.sln""

[Windows App]
Features
Easy Concept
Scene manager is easy, No Entiy, No GameObject, No Component, No Prefab. Only Node and NodeTree.
Highly Efficient Workflow

Multi-Platform Support
iOS Android Html5 Windows Mac Linux Steam
New Industry Standard Support
gLtf2.0, Vulkan, Pbr, Real time ray tracing.
2D And 3D Seamless Transition Â 
Every node can be 2d or 3d. The core difference is the camera and the unit the node use. So you can just switch a node to 2d or 3d easily.
Easy To Program
Mostly, you'll use Lua as your main programming language. and also you can use c++ directly. the design of node tree makes the Lua logic code more easy to write. and the embedded Lua editor and embedded document help you write code just in the echo editor.
Except for Lua, You can also choose use embedded Scratch as the main development language. Which is a type of visual script inspired by MIT.  In the echo, Scratch is based on Lua, when running the app, It'll convert to Lua, Make sure it's good both at code merge and running efficiency.
If you really like other types of script language, you can tell us, or you can support it by modifying the c++ code directly.

Configurable Module
Most of the engine's Functionality was implemented by configurable modules. that means when you release your app, you can just choose the module you really need. which makes your app have smaller size and more efficiency running speed.
Animate Everything
With Timeline, You can animate everything. You can not only animate any Object's(Node, Setting, Res) any property. But also you can call any Object's any function.
Open Source
Echo is licensed under MIT license. You can just do what you want as your wish.
",84
notadd/ng-notadd,TypeScript,"




ng-notadd
Medium-Background solution based on Angular7 Material2
ä¸­æè¯´æ
Technology stack

Typescript
Angular
Material2
rxjs
Graphql

RELATED LINKS
DEMO
ng-notadd-mock-server
Quick start
clone & run mock-server
    git clone https://github.com/notadd/ng-notadd-mock-server.git
    
    cd ng-notadd-mock-server
    
    npm install
    npm start
clone & run ng-notadd
    git clone https://github.com/notadd/ng-notadd.git
     
    cd ng-notadd
     
    npm install
    npm start
    # or use ng cli
    ng serve
Roadmap
0.18.0

 component phone end compatible
 firebase (not available domestically) or other alternative support

0.19.0

 DIY Dashboard
 JSON generates a simple dashboard

0.20.0

 2K/4K screen adaptation

0.21.0

 built-in permission component
 Preliminary e2e unit test

1.0

 Perfect unit testing
 Overall fine tuning

1.1

 websocket support

1.2

 Support electron to build desktop apps

2.0

 Enterprise-Class custom forms
 Enterprise-Class form system
 Enterprise window/Pop window

Follow-up

 Excel online editing
 Word online editing

",246
SmallChi/JT808,C#,"JT808åè®®

åææ¡ä»¶

ææ¡è¿å¶è½¬æ¢ï¼äºè¿å¶è½¬åå­è¿å¶ï¼
ææ¡BCDç¼ç ãHexç¼ç ï¼
ææ¡åç§ä½ç§»ãå¼æï¼
ææ¡å¸¸ç¨åå°ï¼
ææ¡å¿«éctrl+cãctrl+vï¼
ææ¡ä»¥ä¸è£é¼æè½ï¼å°±å¯ä»¥å¼å§æ¬ç äºã

JT808æ°æ®ç»æè§£æ
æ°æ®å[JT808Package]



å¤´æ è¯
æ°æ®å¤´
æ°æ®ä½
æ ¡éªç 
å°¾æ è¯




Begin
JT808Header
JT808Bodies
CheckCode
End


7E
-
-
-
7E



æ°æ®å¤´[JT808Header]



æ¶æ¯ID
æ¶æ¯ä½å±æ§
ç»ç«¯ææºå·
æ¶æ¯æµæ°´å·




MsgId
JT808HeaderMessageBodyProperty
TerminalPhoneNo
MsgNum



æ°æ®å¤´-æ¶æ¯ä½å±æ§[JT808HeaderMessageBodyProperty]



æ¯å¦åå
å å¯æ è¯
æ¶æ¯ä½é¿åº¦
æ¶æ¯æ»åæ°
ååºå·




IsPackge
Encrypt
DataLength
PackgeCount
PackageIndex



æ¶æ¯ä½å±æ§[JT808Bodies]

æ ¹æ®å¯¹åºæ¶æ¯IDï¼MsgId

æ³¨æï¼æ°æ®åå®¹(é¤å»å¤´åå°¾æ è¯)è¿è¡è½¬ä¹å¤æ­
è½¬ä¹è§åå¦ä¸:

è¥æ°æ®åå®¹ä¸­æåºç°å­ç¬¦ 0x7e çï¼éæ¿æ¢ä¸ºå­ç¬¦ 0x7d ç´§è·å­ç¬¦ 0x02;
è¥æ°æ®åå®¹ä¸­æåºç°å­ç¬¦ 0x7d çï¼éæ¿æ¢ä¸ºå­ç¬¦ 0x7d ç´§è·å­ç¬¦ 0x01;

åè½¬ä¹çåå ï¼ç¡®è®¤JT808åè®®çTCPæ¶æ¯è¾¹çã
ä¸¾ä¸ªæ å­1
1.ç»åï¼

MsgId 0x0200:ä½ç½®ä¿¡æ¯æ±æ¥


JT808Package jT808Package = new JT808Package();

jT808Package.Header = new JT808Header
{
    MsgId = Enums.JT808MsgId.ä½ç½®ä¿¡æ¯æ±æ¥,
    MsgNum = 126,
    TerminalPhoneNo = ""123456789012""
};

JT808_0x0200 jT808_0x0200 = new JT808_0x0200();
jT808_0x0200.AlarmFlag = 1;
jT808_0x0200.Altitude = 40;
jT808_0x0200.GPSTime = DateTime.Parse(""2018-10-15 10:10:10"");
jT808_0x0200.Lat = 12222222;
jT808_0x0200.Lng = 132444444;
jT808_0x0200.Speed = 60;
jT808_0x0200.Direction = 0;
jT808_0x0200.StatusFlag = 2;
jT808_0x0200.JT808LocationAttachData = new Dictionary<byte, JT808_0x0200_BodyBase>();

jT808_0x0200.JT808LocationAttachData.Add(JT808_0x0200_BodyBase.AttachId0x01, new JT808_0x0200_0x01
{
    Mileage = 100
});

jT808_0x0200.JT808LocationAttachData.Add(JT808_0x0200_BodyBase.AttachId0x02, new JT808_0x0200_0x02
{
    Oil = 125
});

jT808Package.Bodies = jT808_0x0200;

byte[] data = JT808Serializer.Serialize(jT808Package);

var hex = data.ToHexString();

// è¾åºç»æHexï¼
// 7E 02 00 00 26 12 34 56 78 90 12 00 7D 02 00 00 00 01 00 00 00 02 00 BA 7F 0E 07 E4 F1 1C 00 28 00 3C 00 00 18 10 15 10 10 10 01 04 00 00 00 64 02 02 00 7D 01 13 7E

2.æå¨è§£åï¼
1.ååï¼
7E 02 00 00 26 12 34 56 78 90 12 00 (7D 02) 00 00 00 01 00 00 00 02 00 BA 7F 0E 07 E4 F1 1C 00 28 00 3C 00 00 18 10 15 10 10 10 01 04 00 00 00 64 02 02 00 (7D 01) 13 7E

2.è¿è¡åè½¬ä¹
7D 02 ->7E
7D 01 ->7D
åè½¬ä¹å
7E 02 00 00 26 12 34 56 78 90 12 00 7E 00 00 00 01 00 00 00 02 00 BA 7F 0E 07 E4 F1 1C 00 28 00 3C 00 00 18 10 15 10 10 10 01 04 00 00 00 64 02 02 00 7D 13 7E

3.æè§£
7E                  --å¤´æ è¯
02 00               --æ°æ®å¤´->æ¶æ¯ID
00 26               --æ°æ®å¤´->æ¶æ¯ä½å±æ§
12 34 56 78 90 12   --æ°æ®å¤´->ç»ç«¯ææºå·
00 7E               --æ°æ®å¤´->æ¶æ¯æµæ°´å·
00 00 00 01         --æ¶æ¯ä½->æ¥è­¦æ å¿
00 00 00 02         --æ¶æ¯ä½->ç¶æä½æ å¿
00 BA 7F 0E         --æ¶æ¯ä½->çº¬åº¦
07 E4 F1 1C         --æ¶æ¯ä½->ç»åº¦
00 28               --æ¶æ¯ä½->æµ·æé«åº¦
00 3C               --æ¶æ¯ä½->éåº¦
00 00               --æ¶æ¯ä½->æ¹å
18 10 15 10 10 10   --æ¶æ¯ä½->GPSæ¶é´
01                  --æ¶æ¯ä½->éå ä¿¡æ¯->éç¨
04                  --æ¶æ¯ä½->éå ä¿¡æ¯->é¿åº¦
00 00 00 64         --æ¶æ¯ä½->éå ä¿¡æ¯->æ°æ®
02                  --æ¶æ¯ä½->éå ä¿¡æ¯->æ²¹é
02                  --æ¶æ¯ä½->éå ä¿¡æ¯->é¿åº¦
00 7D               --æ¶æ¯ä½->éå ä¿¡æ¯->æ°æ®
13                  --æ£éªç 
7E                  --å°¾æ è¯

3.ç¨åºè§£åï¼
//1.è½¬æbyteæ°ç»
byte[] bytes = ""7E 02 00 00 26 12 34 56 78 90 12 00 7D 02 00 00 00 01 00 00 00 02 00 BA 7F 0E 07 E4 F1 1C 00 28 00 3C 00 00 18 10 15 10 10 10 01 04 00 00 00 64 02 02 00 7D 01 13 7E"".ToHexBytes();

//2.å°æ°ç»ååºåå
var jT808Package = JT808Serializer.Deserialize<JT808Package>(bytes);

//3.æ°æ®åå¤´
Assert.Equal(Enums.JT808MsgId.ä½ç½®ä¿¡æ¯æ±æ¥, jT808Package.Header.MsgId);
Assert.Equal(38, jT808Package.Header.MessageBodyProperty.DataLength);
Assert.Equal(126, jT808Package.Header.MsgNum);
Assert.Equal(""123456789012"", jT808Package.Header.TerminalPhoneNo);
Assert.False(jT808Package.Header.MessageBodyProperty.IsPackge);
Assert.Equal(0, jT808Package.Header.MessageBodyProperty.PackageIndex);
Assert.Equal(0, jT808Package.Header.MessageBodyProperty.PackgeCount);
Assert.Equal(JT808EncryptMethod.None, jT808Package.Header.MessageBodyProperty.Encrypt);

//4.æ°æ®åä½
JT808_0x0200 jT808_0x0200 = (JT808_0x0200)jT808Package.Bodies;
Assert.Equal((uint)1, jT808_0x0200.AlarmFlag);
Assert.Equal((uint)40, jT808_0x0200.Altitude);
Assert.Equal(DateTime.Parse(""2018-10-15 10:10:10""), jT808_0x0200.GPSTime);
Assert.Equal(12222222, jT808_0x0200.Lat);
Assert.Equal(132444444, jT808_0x0200.Lng);
Assert.Equal(60, jT808_0x0200.Speed);
Assert.Equal(0, jT808_0x0200.Direction);
Assert.Equal((uint)2, jT808_0x0200.StatusFlag);
//4.1.éå ä¿¡æ¯1
Assert.Equal(100, ((JT808_0x0200_0x01)jT808_0x0200.JT808LocationAttachData[JT808_0x0200_BodyBase.AttachId0x01]).Mileage);
//4.2.éå ä¿¡æ¯2
Assert.Equal(125, ((JT808_0x0200_0x02)jT808_0x0200.JT808LocationAttachData[JT808_0x0200_BodyBase.AttachId0x02]).Oil);

ä¸¾ä¸ªæ å­2
// ä½¿ç¨æ¶æ¯Idçæ©å±æ¹æ³åå»ºJT808Packageå
JT808Package jT808Package = Enums.JT808MsgId.ä½ç½®ä¿¡æ¯æ±æ¥.Create(""123456789012"",
    new JT808_0x0200 {
        AlarmFlag = 1,
        Altitude = 40,
        GPSTime = DateTime.Parse(""2018-10-15 10:10:10""),
        Lat = 12222222,
        Lng = 132444444,
        Speed = 60,
        Direction = 0,
        StatusFlag = 2,
        JT808LocationAttachData = new Dictionary<byte, JT808LocationAttachBase>
        {
            { JT808_0x0200_BodyBase.AttachId0x01,new JT808_0x0200_0x01{Mileage = 100}},
            { JT808_0x0200_BodyBase.AttachId0x02,new JT808_0x0200_0x02{Oil = 125}}
        }
});

byte[] data = JT808Serializer.Serialize(jT808Package);

var hex = data.ToHexString();
//è¾åºç»æHexï¼
//7E 02 00 00 26 12 34 56 78 90 12 00 01 00 00 00 01 00 00 00 02 00 BA 7F 0E 07 E4 F1 1C 00 28 00 3C 00 00 18 10 15 10 10 10 01 04 00 00 00 64 02 02 00 7D 01 6C 7E

ä¸¾ä¸ªæ å­3
// å¨å±éç½®
JT808GlobalConfig.Instance
    // æ³¨åèªå®ä¹ä½ç½®éå ä¿¡æ¯
    .Register_0x0200_Attach(0x06)
    //.SetMsgSNDistributed(//todo å®ç°IMsgSNDistributedæ¶æ¯æµæ°´å·)
    // æ³¨åèªå®ä¹æ°æ®ä¸è¡éä¼ ä¿¡æ¯
    //.Register_0x0900_Ext<>(//todo ç»§æ¿èªJT808_0x0900_BodyBaseç±»)
    // æ³¨åèªå®ä¹æ°æ®ä¸è¡éä¼ ä¿¡æ¯
    //.Register_0x8900_Ext<>(//todo ç»§æ¿èªJT808_0x8900_BodyBaseç±»)
    // è·³è¿æ ¡éªç éªè¯
    .SetSkipCRCCode(true);

ä¸¾ä¸ªæ å­4
éå°çé®é¢-å¤è®¾å¤å¤åè®®çèªå®ä¹ä½ç½®éå ä¿¡æ¯
åºæ¯ï¼
ä¸ä¸ªè®¾å¤ååå¯¹åºå¤ä¸ªè®¾å¤ç±»åï¼ä¸åè®¾å¤ç±»åå¯è½å­å¨ç¸åçèªå®ä¹ä½ç½®éå ä¿¡æ¯Idï¼å¯¼è´èªå®ä¹éå ä¿¡æ¯Idå²çªï¼æ æ³è§£æã
è§£å³æ¹å¼ï¼
1.å¡æ¯è§£æèªå®ä¹éå ä¿¡æ¯Idåè®®çï¼åè¿è¡åå²å­å¨ï¼ç¶åå¨æ ¹æ®å¤é¨çè®¾å¤ç±»åè¿è¡ç»ä¸å¤ç;
2.å¯ä»¥æ ¹æ®è®¾å¤ç±»ååä¸ªå·¥åï¼è§£è¦å¯¹å¬å±åºååå¨çä¾èµã
å¯ä»¥åèDemoTestçDemo5

è¦æ¯åªä½å¤§ä½¬è¿æå¶ä»çè§£å³æ¹å¼ï¼è¯·æ¨åç¥æä¸ï¼è°¢è°¢æ¨äºã

ä¸¾ä¸ªæ å­5
éå°çé®é¢-å¤åªä½æ°æ®ä¸ä¼ è¿è¡ååå¤ç
åºæ¯:
è®¾å¤å¨ä¸ä¼ å¤åªä½æ°æ®çæ¶åï¼ç±äºæ°æ®æ¯è¾å¤ï¼ä¸æ¬¡ä¸ä¼ ä¸äºï¼æä»¥éç¨ååæ¹å¼å¤çã
è§£å³æ¹å¼ï¼


ç¬¬ä¸åæ°æ®ä¸æ¥éç¨å¹³å¸¸çæ¹å¼å»è§£ææ°æ®ï¼


å½Nåæ°æ®ä¸æ¥ï¼éç¨ç»ä¸ååæ¶æ¯ä½å»æ¥æ¶æ°æ®ï¼æåå¨åå¹¶æä¸æ¡ã



æ®åç¥è¯ç¹ï¼ä¸è¬è¡ä¸ååæ¯æ256çæ´æ°åï¼å¤ªå¤ä¸è¡ï¼å¤ªå°ä¹ä¸è¡ï¼å¿é¡»ååå¥½ã

å¯ä»¥åèDemoTestçDemo6
NuGetå®è£



Package Name
Version
Downloads




Install-Package JT808




Install-Package JT808.Extensions.DependencyInjection





ä½¿ç¨BenchmarkDotNetæ§è½æµè¯æ¥åï¼åªæ¯ç©ç©ï¼ä¸è½å½çï¼
BenchmarkDotNet=v0.11.3, OS=Windows 10.0.17134.472 (1803/April2018Update/Redstone4)
Intel Core i7-8700K CPU 3.70GHz (Coffee Lake), 1 CPU, 12 logical and 6 physical cores
  [Host]     : .NET Framework 4.7.2 (CLR 4.0.30319.42000), 64bit RyuJIT-v4.7.3260.0
  Job-FVMQGI : .NET Framework 4.7.2 (CLR 4.0.30319.42000), 64bit RyuJIT-v4.7.3260.0
  Job-LGLQDK : .NET Core 2.2.1 (CoreCLR 4.6.27207.03, CoreFX 4.6.27207.03), 64bit RyuJIT

Platform=AnyCpu  Runtime=Clr  Server=False  




Method
Toolchain
N
Mean
Error
StdDev
Gen 0/1k Op
Gen 1/1k Op
Gen 2/1k Op
Allocated Memory/Op




0x0200Serialize
Default
100
3.199 ms
0.0417 ms
0.0390 ms
74.2188
-
-
475.79 KB


0x0200Deserialize
Default
100
3.007 ms
0.0379 ms
0.0355 ms
78.1250
-
-
501.57 KB


0x0200Serialize
.NET Core 2.2
100
2.507 ms
0.0157 ms
0.0139 ms
66.4063
-
-
424.22 KB


0x0200Deserialize
.NET Core 2.2
100
2.423 ms
0.0483 ms
0.0645 ms
70.3125
-
-
442.97 KB


0x0200Serialize
Default
10000
317.658 ms
5.1248 ms
4.7937 ms
7000.0000
-
-
47584.41 KB


0x0200Deserialize
Default
10000
302.344 ms
5.7195 ms
5.6174 ms
8000.0000
-
-
50160.67 KB


0x0200Serialize
.NET Core 2.2
10000
251.612 ms
3.2408 ms
2.7062 ms
6000.0000
-
-
42421.88 KB


0x0200Deserialize
.NET Core 2.2
10000
234.793 ms
2.5215 ms
2.2352 ms
7000.0000
-
-
44296.88 KB


0x0200Serialize
Default
100000
3,228.227 ms
26.2990 ms
23.3134 ms
77000.0000
-
-
475789.2 KB


0x0200Deserialize
Default
100000
2,999.779 ms
27.0077 ms
23.9416 ms
81000.0000
-
-
501566.45 KB


0x0200Serialize
.NET Core 2.2
100000
2,541.111 ms
20.8916 ms
18.5199 ms
69000.0000
-
-
424218.75 KB


0x0200Deserialize
.NET Core 2.2
100000
2,350.114 ms
11.5168 ms
10.2093 ms
72000.0000
-
-
442968.75 KB



JT808ç»ç«¯éè®¯åè®®æ¶æ¯å¯¹ç§è¡¨



åºå·
æ¶æ¯ID
å®ææåµ
æµè¯æåµ
æ¶æ¯ä½åç§°




1
0x0001
â
â
ç»ç«¯éç¨åºç­


2
0x8001
â
â
å¹³å°éç¨åºç­


3
0x0002
â
â
ç»ç«¯å¿è·³


4
0x8003
â
â
è¡¥ä¼ ååè¯·æ±


5
0x0100
â
â
ç»ç«¯æ³¨å


6
0x8100
â
â
ç»ç«¯æ³¨ååºç­


7
0x0003
â
â
ç»ç«¯æ³¨é


8
0x0102
â
â
ç»ç«¯é´æ


9
0x8103
â
â
è®¾ç½®ç»ç«¯åæ°


10
0x8104
â
â
æ¥è¯¢ç»ç«¯åæ°


11
0x0104
â
â
æ¥è¯¢ç»ç«¯åæ°åºç­


12
0x8105
â
â
ç»ç«¯æ§å¶


13
0x8106
â
â
æ¥è¯¢æå®ç»ç«¯åæ°


14
0x8107
â
æ¶æ¯ä½ä¸ºç©º
æ¥è¯¢ç»ç«¯å±æ§


15
0x0107
â
â
æ¥è¯¢ç»ç«¯å±æ§åºç­


16
0x8108
â
â
ä¸åç»ç«¯åçº§å


17
0x0108
â
â
ç»ç«¯åçº§ç»æéç¥


18
0x0200
â
â
ä½ç½®ä¿¡æ¯æ±æ¥


19
0x8201
â
â
ä½ç½®ä¿¡æ¯æ¥è¯¢


20
0x0201
â
â
ä½ç½®ä¿¡æ¯æ¥è¯¢åºç­


21
0x8202
â
â
ä¸´æ¶ä½ç½®è·è¸ªæ§å¶


22
0x8203
â
â
äººå·¥ç¡®è®¤æ¥è­¦æ¶æ¯


23
0x8300
â
â
ææ¬ä¿¡æ¯ä¸å


24
0x8301
â
â
äºä»¶è®¾ç½®


25
0x0301
â
â
äºä»¶æ¥å


26
0x8302
â
â
æé®ä¸å


27
0x0302
â
â
æé®åºç­


28
0x8303
â
â
ä¿¡æ¯ç¹æ­èåè®¾ç½®


29
0x0303
â
â
ä¿¡æ¯ç¹æ­/åæ¶


30
0x8304
â
â
ä¿¡æ¯æå¡


31
0x8400
â
â
çµè¯åæ¨


32
0x8401
â
â
è®¾ç½®çµè¯æ¬


33
0x8500
â
â
è½¦è¾æ§å¶


34
0x0500
â
â
è½¦è¾æ§å¶åºç­


35
0x8600
â
â
è®¾ç½®åå½¢åºå


36
0x8601
â
â
å é¤åå½¢åºå


37
0x8602
â
â
è®¾ç½®ç©å½¢åºå


38
0x8603
â
â
å é¤ç©å½¢åºå


39
0x8604
â
â
è®¾ç½®å¤è¾¹å½¢åºå


40
0x8605
â
â
å é¤å¤è¾¹å½¢åºå


41
0x8606
â
â
è®¾ç½®è·¯çº¿


42
0x8607
â
â
å é¤è·¯çº¿


43
0x8700
x
ä¸ä¸ªçæ¬
è¡é©¶è®°å½ä»ªæ°æ®ééå½ä»¤


44
0x0700
x
ä¸ä¸ªçæ¬
è¡é©¶è®°å½ä»ªæ°æ®ä¸ä¼ 


45
0x8701
x
ä¸ä¸ªçæ¬
è¡é©¶è®°å½ä»ªåæ°ä¸ä¼ å½ä»¤


46
0x0701
â
â
çµå­è¿åä¸æ¥


47
0x0702
â
â
é©¾é©¶åèº«ä»½ä¿¡æ¯ééä¸æ¥


48
0x8702
â
æ¶æ¯ä½ä¸ºç©º
ä¸æ¥é©¾é©¶åèº«ä»½ä¿¡æ¯è¯·æ±


49
0x0704
â
â
å®ä½æ°æ®æ¹éä¸ä¼ 


50
0x0705
â
â
CAN æ»çº¿æ°æ®ä¸ä¼ 


51
0x0800
â
â
å¤åªä½äºä»¶ä¿¡æ¯ä¸ä¼ 


52
0x0801
â
â
å¤åªä½æ°æ®ä¸ä¼ 


53
0x8800
â
â
å¤åªä½æ°æ®ä¸ä¼ åºç­


54
0x8801
â
â
æåå¤´ç«å³ææå½ä»¤


55
0x0805
â
â
æåå¤´ç«å³ææå½ä»¤åºç­


56
0x8802
â
â
å­å¨å¤åªä½æ°æ®æ£ç´¢


57
0x0802
â
â
å­å¨å¤åªä½æ°æ®æ£ç´¢åºç­


58
0x8803
â
â
å­å¨å¤åªä½æ°æ®ä¸ä¼ 


59
0x8804
â
â
å½é³å¼å§å½ä»¤


60
0x8805
â
â
åæ¡å­å¨å¤åªä½æ°æ®æ£ç´¢ä¸ä¼ å½ä»¤


61
0x8900
â
â
æ°æ®ä¸è¡éä¼ 


62
0x0900
â
â
æ°æ®ä¸è¡éä¼ 


63
0x0901
â
â
æ°æ®åç¼©ä¸æ¥


64
0x8A00
â
â
å¹³å° RSA å¬é¥


65
0x0A00
â
â
ç»ç«¯ RSA å¬é¥


66
0x8F00~0x8FFF
ä¿ç
ä¿ç
å¹³å°ä¸è¡æ¶æ¯ä¿ç


67
0x0F00~0x0FFF
ä¿ç
ä¿ç
ç»ç«¯ä¸è¡æ¶æ¯ä¿ç



",45
SmallChi/JT808,C#,"JT808åè®®

åææ¡ä»¶

ææ¡è¿å¶è½¬æ¢ï¼äºè¿å¶è½¬åå­è¿å¶ï¼
ææ¡BCDç¼ç ãHexç¼ç ï¼
ææ¡åç§ä½ç§»ãå¼æï¼
ææ¡å¸¸ç¨åå°ï¼
ææ¡å¿«éctrl+cãctrl+vï¼
ææ¡ä»¥ä¸è£é¼æè½ï¼å°±å¯ä»¥å¼å§æ¬ç äºã

JT808æ°æ®ç»æè§£æ
æ°æ®å[JT808Package]



å¤´æ è¯
æ°æ®å¤´
æ°æ®ä½
æ ¡éªç 
å°¾æ è¯




Begin
JT808Header
JT808Bodies
CheckCode
End


7E
-
-
-
7E



æ°æ®å¤´[JT808Header]



æ¶æ¯ID
æ¶æ¯ä½å±æ§
ç»ç«¯ææºå·
æ¶æ¯æµæ°´å·




MsgId
JT808HeaderMessageBodyProperty
TerminalPhoneNo
MsgNum



æ°æ®å¤´-æ¶æ¯ä½å±æ§[JT808HeaderMessageBodyProperty]



æ¯å¦åå
å å¯æ è¯
æ¶æ¯ä½é¿åº¦
æ¶æ¯æ»åæ°
ååºå·




IsPackge
Encrypt
DataLength
PackgeCount
PackageIndex



æ¶æ¯ä½å±æ§[JT808Bodies]

æ ¹æ®å¯¹åºæ¶æ¯IDï¼MsgId

æ³¨æï¼æ°æ®åå®¹(é¤å»å¤´åå°¾æ è¯)è¿è¡è½¬ä¹å¤æ­
è½¬ä¹è§åå¦ä¸:

è¥æ°æ®åå®¹ä¸­æåºç°å­ç¬¦ 0x7e çï¼éæ¿æ¢ä¸ºå­ç¬¦ 0x7d ç´§è·å­ç¬¦ 0x02;
è¥æ°æ®åå®¹ä¸­æåºç°å­ç¬¦ 0x7d çï¼éæ¿æ¢ä¸ºå­ç¬¦ 0x7d ç´§è·å­ç¬¦ 0x01;

åè½¬ä¹çåå ï¼ç¡®è®¤JT808åè®®çTCPæ¶æ¯è¾¹çã
ä¸¾ä¸ªæ å­1
1.ç»åï¼

MsgId 0x0200:ä½ç½®ä¿¡æ¯æ±æ¥


JT808Package jT808Package = new JT808Package();

jT808Package.Header = new JT808Header
{
    MsgId = Enums.JT808MsgId.ä½ç½®ä¿¡æ¯æ±æ¥,
    MsgNum = 126,
    TerminalPhoneNo = ""123456789012""
};

JT808_0x0200 jT808_0x0200 = new JT808_0x0200();
jT808_0x0200.AlarmFlag = 1;
jT808_0x0200.Altitude = 40;
jT808_0x0200.GPSTime = DateTime.Parse(""2018-10-15 10:10:10"");
jT808_0x0200.Lat = 12222222;
jT808_0x0200.Lng = 132444444;
jT808_0x0200.Speed = 60;
jT808_0x0200.Direction = 0;
jT808_0x0200.StatusFlag = 2;
jT808_0x0200.JT808LocationAttachData = new Dictionary<byte, JT808_0x0200_BodyBase>();

jT808_0x0200.JT808LocationAttachData.Add(JT808_0x0200_BodyBase.AttachId0x01, new JT808_0x0200_0x01
{
    Mileage = 100
});

jT808_0x0200.JT808LocationAttachData.Add(JT808_0x0200_BodyBase.AttachId0x02, new JT808_0x0200_0x02
{
    Oil = 125
});

jT808Package.Bodies = jT808_0x0200;

byte[] data = JT808Serializer.Serialize(jT808Package);

var hex = data.ToHexString();

// è¾åºç»æHexï¼
// 7E 02 00 00 26 12 34 56 78 90 12 00 7D 02 00 00 00 01 00 00 00 02 00 BA 7F 0E 07 E4 F1 1C 00 28 00 3C 00 00 18 10 15 10 10 10 01 04 00 00 00 64 02 02 00 7D 01 13 7E

2.æå¨è§£åï¼
1.ååï¼
7E 02 00 00 26 12 34 56 78 90 12 00 (7D 02) 00 00 00 01 00 00 00 02 00 BA 7F 0E 07 E4 F1 1C 00 28 00 3C 00 00 18 10 15 10 10 10 01 04 00 00 00 64 02 02 00 (7D 01) 13 7E

2.è¿è¡åè½¬ä¹
7D 02 ->7E
7D 01 ->7D
åè½¬ä¹å
7E 02 00 00 26 12 34 56 78 90 12 00 7E 00 00 00 01 00 00 00 02 00 BA 7F 0E 07 E4 F1 1C 00 28 00 3C 00 00 18 10 15 10 10 10 01 04 00 00 00 64 02 02 00 7D 13 7E

3.æè§£
7E                  --å¤´æ è¯
02 00               --æ°æ®å¤´->æ¶æ¯ID
00 26               --æ°æ®å¤´->æ¶æ¯ä½å±æ§
12 34 56 78 90 12   --æ°æ®å¤´->ç»ç«¯ææºå·
00 7E               --æ°æ®å¤´->æ¶æ¯æµæ°´å·
00 00 00 01         --æ¶æ¯ä½->æ¥è­¦æ å¿
00 00 00 02         --æ¶æ¯ä½->ç¶æä½æ å¿
00 BA 7F 0E         --æ¶æ¯ä½->çº¬åº¦
07 E4 F1 1C         --æ¶æ¯ä½->ç»åº¦
00 28               --æ¶æ¯ä½->æµ·æé«åº¦
00 3C               --æ¶æ¯ä½->éåº¦
00 00               --æ¶æ¯ä½->æ¹å
18 10 15 10 10 10   --æ¶æ¯ä½->GPSæ¶é´
01                  --æ¶æ¯ä½->éå ä¿¡æ¯->éç¨
04                  --æ¶æ¯ä½->éå ä¿¡æ¯->é¿åº¦
00 00 00 64         --æ¶æ¯ä½->éå ä¿¡æ¯->æ°æ®
02                  --æ¶æ¯ä½->éå ä¿¡æ¯->æ²¹é
02                  --æ¶æ¯ä½->éå ä¿¡æ¯->é¿åº¦
00 7D               --æ¶æ¯ä½->éå ä¿¡æ¯->æ°æ®
13                  --æ£éªç 
7E                  --å°¾æ è¯

3.ç¨åºè§£åï¼
//1.è½¬æbyteæ°ç»
byte[] bytes = ""7E 02 00 00 26 12 34 56 78 90 12 00 7D 02 00 00 00 01 00 00 00 02 00 BA 7F 0E 07 E4 F1 1C 00 28 00 3C 00 00 18 10 15 10 10 10 01 04 00 00 00 64 02 02 00 7D 01 13 7E"".ToHexBytes();

//2.å°æ°ç»ååºåå
var jT808Package = JT808Serializer.Deserialize<JT808Package>(bytes);

//3.æ°æ®åå¤´
Assert.Equal(Enums.JT808MsgId.ä½ç½®ä¿¡æ¯æ±æ¥, jT808Package.Header.MsgId);
Assert.Equal(38, jT808Package.Header.MessageBodyProperty.DataLength);
Assert.Equal(126, jT808Package.Header.MsgNum);
Assert.Equal(""123456789012"", jT808Package.Header.TerminalPhoneNo);
Assert.False(jT808Package.Header.MessageBodyProperty.IsPackge);
Assert.Equal(0, jT808Package.Header.MessageBodyProperty.PackageIndex);
Assert.Equal(0, jT808Package.Header.MessageBodyProperty.PackgeCount);
Assert.Equal(JT808EncryptMethod.None, jT808Package.Header.MessageBodyProperty.Encrypt);

//4.æ°æ®åä½
JT808_0x0200 jT808_0x0200 = (JT808_0x0200)jT808Package.Bodies;
Assert.Equal((uint)1, jT808_0x0200.AlarmFlag);
Assert.Equal((uint)40, jT808_0x0200.Altitude);
Assert.Equal(DateTime.Parse(""2018-10-15 10:10:10""), jT808_0x0200.GPSTime);
Assert.Equal(12222222, jT808_0x0200.Lat);
Assert.Equal(132444444, jT808_0x0200.Lng);
Assert.Equal(60, jT808_0x0200.Speed);
Assert.Equal(0, jT808_0x0200.Direction);
Assert.Equal((uint)2, jT808_0x0200.StatusFlag);
//4.1.éå ä¿¡æ¯1
Assert.Equal(100, ((JT808_0x0200_0x01)jT808_0x0200.JT808LocationAttachData[JT808_0x0200_BodyBase.AttachId0x01]).Mileage);
//4.2.éå ä¿¡æ¯2
Assert.Equal(125, ((JT808_0x0200_0x02)jT808_0x0200.JT808LocationAttachData[JT808_0x0200_BodyBase.AttachId0x02]).Oil);

ä¸¾ä¸ªæ å­2
// ä½¿ç¨æ¶æ¯Idçæ©å±æ¹æ³åå»ºJT808Packageå
JT808Package jT808Package = Enums.JT808MsgId.ä½ç½®ä¿¡æ¯æ±æ¥.Create(""123456789012"",
    new JT808_0x0200 {
        AlarmFlag = 1,
        Altitude = 40,
        GPSTime = DateTime.Parse(""2018-10-15 10:10:10""),
        Lat = 12222222,
        Lng = 132444444,
        Speed = 60,
        Direction = 0,
        StatusFlag = 2,
        JT808LocationAttachData = new Dictionary<byte, JT808LocationAttachBase>
        {
            { JT808_0x0200_BodyBase.AttachId0x01,new JT808_0x0200_0x01{Mileage = 100}},
            { JT808_0x0200_BodyBase.AttachId0x02,new JT808_0x0200_0x02{Oil = 125}}
        }
});

byte[] data = JT808Serializer.Serialize(jT808Package);

var hex = data.ToHexString();
//è¾åºç»æHexï¼
//7E 02 00 00 26 12 34 56 78 90 12 00 01 00 00 00 01 00 00 00 02 00 BA 7F 0E 07 E4 F1 1C 00 28 00 3C 00 00 18 10 15 10 10 10 01 04 00 00 00 64 02 02 00 7D 01 6C 7E

ä¸¾ä¸ªæ å­3
// å¨å±éç½®
JT808GlobalConfig.Instance
    // æ³¨åèªå®ä¹ä½ç½®éå ä¿¡æ¯
    .Register_0x0200_Attach(0x06)
    //.SetMsgSNDistributed(//todo å®ç°IMsgSNDistributedæ¶æ¯æµæ°´å·)
    // æ³¨åèªå®ä¹æ°æ®ä¸è¡éä¼ ä¿¡æ¯
    //.Register_0x0900_Ext<>(//todo ç»§æ¿èªJT808_0x0900_BodyBaseç±»)
    // æ³¨åèªå®ä¹æ°æ®ä¸è¡éä¼ ä¿¡æ¯
    //.Register_0x8900_Ext<>(//todo ç»§æ¿èªJT808_0x8900_BodyBaseç±»)
    // è·³è¿æ ¡éªç éªè¯
    .SetSkipCRCCode(true);

ä¸¾ä¸ªæ å­4
éå°çé®é¢-å¤è®¾å¤å¤åè®®çèªå®ä¹ä½ç½®éå ä¿¡æ¯
åºæ¯ï¼
ä¸ä¸ªè®¾å¤ååå¯¹åºå¤ä¸ªè®¾å¤ç±»åï¼ä¸åè®¾å¤ç±»åå¯è½å­å¨ç¸åçèªå®ä¹ä½ç½®éå ä¿¡æ¯Idï¼å¯¼è´èªå®ä¹éå ä¿¡æ¯Idå²çªï¼æ æ³è§£æã
è§£å³æ¹å¼ï¼
1.å¡æ¯è§£æèªå®ä¹éå ä¿¡æ¯Idåè®®çï¼åè¿è¡åå²å­å¨ï¼ç¶åå¨æ ¹æ®å¤é¨çè®¾å¤ç±»åè¿è¡ç»ä¸å¤ç;
2.å¯ä»¥æ ¹æ®è®¾å¤ç±»ååä¸ªå·¥åï¼è§£è¦å¯¹å¬å±åºååå¨çä¾èµã
å¯ä»¥åèDemoTestçDemo5

è¦æ¯åªä½å¤§ä½¬è¿æå¶ä»çè§£å³æ¹å¼ï¼è¯·æ¨åç¥æä¸ï¼è°¢è°¢æ¨äºã

ä¸¾ä¸ªæ å­5
éå°çé®é¢-å¤åªä½æ°æ®ä¸ä¼ è¿è¡ååå¤ç
åºæ¯:
è®¾å¤å¨ä¸ä¼ å¤åªä½æ°æ®çæ¶åï¼ç±äºæ°æ®æ¯è¾å¤ï¼ä¸æ¬¡ä¸ä¼ ä¸äºï¼æä»¥éç¨ååæ¹å¼å¤çã
è§£å³æ¹å¼ï¼


ç¬¬ä¸åæ°æ®ä¸æ¥éç¨å¹³å¸¸çæ¹å¼å»è§£ææ°æ®ï¼


å½Nåæ°æ®ä¸æ¥ï¼éç¨ç»ä¸ååæ¶æ¯ä½å»æ¥æ¶æ°æ®ï¼æåå¨åå¹¶æä¸æ¡ã



æ®åç¥è¯ç¹ï¼ä¸è¬è¡ä¸ååæ¯æ256çæ´æ°åï¼å¤ªå¤ä¸è¡ï¼å¤ªå°ä¹ä¸è¡ï¼å¿é¡»ååå¥½ã

å¯ä»¥åèDemoTestçDemo6
NuGetå®è£



Package Name
Version
Downloads




Install-Package JT808




Install-Package JT808.Extensions.DependencyInjection





ä½¿ç¨BenchmarkDotNetæ§è½æµè¯æ¥åï¼åªæ¯ç©ç©ï¼ä¸è½å½çï¼
BenchmarkDotNet=v0.11.3, OS=Windows 10.0.17134.472 (1803/April2018Update/Redstone4)
Intel Core i7-8700K CPU 3.70GHz (Coffee Lake), 1 CPU, 12 logical and 6 physical cores
  [Host]     : .NET Framework 4.7.2 (CLR 4.0.30319.42000), 64bit RyuJIT-v4.7.3260.0
  Job-FVMQGI : .NET Framework 4.7.2 (CLR 4.0.30319.42000), 64bit RyuJIT-v4.7.3260.0
  Job-LGLQDK : .NET Core 2.2.1 (CoreCLR 4.6.27207.03, CoreFX 4.6.27207.03), 64bit RyuJIT

Platform=AnyCpu  Runtime=Clr  Server=False  




Method
Toolchain
N
Mean
Error
StdDev
Gen 0/1k Op
Gen 1/1k Op
Gen 2/1k Op
Allocated Memory/Op




0x0200Serialize
Default
100
3.199 ms
0.0417 ms
0.0390 ms
74.2188
-
-
475.79 KB


0x0200Deserialize
Default
100
3.007 ms
0.0379 ms
0.0355 ms
78.1250
-
-
501.57 KB


0x0200Serialize
.NET Core 2.2
100
2.507 ms
0.0157 ms
0.0139 ms
66.4063
-
-
424.22 KB


0x0200Deserialize
.NET Core 2.2
100
2.423 ms
0.0483 ms
0.0645 ms
70.3125
-
-
442.97 KB


0x0200Serialize
Default
10000
317.658 ms
5.1248 ms
4.7937 ms
7000.0000
-
-
47584.41 KB


0x0200Deserialize
Default
10000
302.344 ms
5.7195 ms
5.6174 ms
8000.0000
-
-
50160.67 KB


0x0200Serialize
.NET Core 2.2
10000
251.612 ms
3.2408 ms
2.7062 ms
6000.0000
-
-
42421.88 KB


0x0200Deserialize
.NET Core 2.2
10000
234.793 ms
2.5215 ms
2.2352 ms
7000.0000
-
-
44296.88 KB


0x0200Serialize
Default
100000
3,228.227 ms
26.2990 ms
23.3134 ms
77000.0000
-
-
475789.2 KB


0x0200Deserialize
Default
100000
2,999.779 ms
27.0077 ms
23.9416 ms
81000.0000
-
-
501566.45 KB


0x0200Serialize
.NET Core 2.2
100000
2,541.111 ms
20.8916 ms
18.5199 ms
69000.0000
-
-
424218.75 KB


0x0200Deserialize
.NET Core 2.2
100000
2,350.114 ms
11.5168 ms
10.2093 ms
72000.0000
-
-
442968.75 KB



JT808ç»ç«¯éè®¯åè®®æ¶æ¯å¯¹ç§è¡¨



åºå·
æ¶æ¯ID
å®ææåµ
æµè¯æåµ
æ¶æ¯ä½åç§°




1
0x0001
â
â
ç»ç«¯éç¨åºç­


2
0x8001
â
â
å¹³å°éç¨åºç­


3
0x0002
â
â
ç»ç«¯å¿è·³


4
0x8003
â
â
è¡¥ä¼ ååè¯·æ±


5
0x0100
â
â
ç»ç«¯æ³¨å


6
0x8100
â
â
ç»ç«¯æ³¨ååºç­


7
0x0003
â
â
ç»ç«¯æ³¨é


8
0x0102
â
â
ç»ç«¯é´æ


9
0x8103
â
â
è®¾ç½®ç»ç«¯åæ°


10
0x8104
â
â
æ¥è¯¢ç»ç«¯åæ°


11
0x0104
â
â
æ¥è¯¢ç»ç«¯åæ°åºç­


12
0x8105
â
â
ç»ç«¯æ§å¶


13
0x8106
â
â
æ¥è¯¢æå®ç»ç«¯åæ°


14
0x8107
â
æ¶æ¯ä½ä¸ºç©º
æ¥è¯¢ç»ç«¯å±æ§


15
0x0107
â
â
æ¥è¯¢ç»ç«¯å±æ§åºç­


16
0x8108
â
â
ä¸åç»ç«¯åçº§å


17
0x0108
â
â
ç»ç«¯åçº§ç»æéç¥


18
0x0200
â
â
ä½ç½®ä¿¡æ¯æ±æ¥


19
0x8201
â
â
ä½ç½®ä¿¡æ¯æ¥è¯¢


20
0x0201
â
â
ä½ç½®ä¿¡æ¯æ¥è¯¢åºç­


21
0x8202
â
â
ä¸´æ¶ä½ç½®è·è¸ªæ§å¶


22
0x8203
â
â
äººå·¥ç¡®è®¤æ¥è­¦æ¶æ¯


23
0x8300
â
â
ææ¬ä¿¡æ¯ä¸å


24
0x8301
â
â
äºä»¶è®¾ç½®


25
0x0301
â
â
äºä»¶æ¥å


26
0x8302
â
â
æé®ä¸å


27
0x0302
â
â
æé®åºç­


28
0x8303
â
â
ä¿¡æ¯ç¹æ­èåè®¾ç½®


29
0x0303
â
â
ä¿¡æ¯ç¹æ­/åæ¶


30
0x8304
â
â
ä¿¡æ¯æå¡


31
0x8400
â
â
çµè¯åæ¨


32
0x8401
â
â
è®¾ç½®çµè¯æ¬


33
0x8500
â
â
è½¦è¾æ§å¶


34
0x0500
â
â
è½¦è¾æ§å¶åºç­


35
0x8600
â
â
è®¾ç½®åå½¢åºå


36
0x8601
â
â
å é¤åå½¢åºå


37
0x8602
â
â
è®¾ç½®ç©å½¢åºå


38
0x8603
â
â
å é¤ç©å½¢åºå


39
0x8604
â
â
è®¾ç½®å¤è¾¹å½¢åºå


40
0x8605
â
â
å é¤å¤è¾¹å½¢åºå


41
0x8606
â
â
è®¾ç½®è·¯çº¿


42
0x8607
â
â
å é¤è·¯çº¿


43
0x8700
x
ä¸ä¸ªçæ¬
è¡é©¶è®°å½ä»ªæ°æ®ééå½ä»¤


44
0x0700
x
ä¸ä¸ªçæ¬
è¡é©¶è®°å½ä»ªæ°æ®ä¸ä¼ 


45
0x8701
x
ä¸ä¸ªçæ¬
è¡é©¶è®°å½ä»ªåæ°ä¸ä¼ å½ä»¤


46
0x0701
â
â
çµå­è¿åä¸æ¥


47
0x0702
â
â
é©¾é©¶åèº«ä»½ä¿¡æ¯ééä¸æ¥


48
0x8702
â
æ¶æ¯ä½ä¸ºç©º
ä¸æ¥é©¾é©¶åèº«ä»½ä¿¡æ¯è¯·æ±


49
0x0704
â
â
å®ä½æ°æ®æ¹éä¸ä¼ 


50
0x0705
â
â
CAN æ»çº¿æ°æ®ä¸ä¼ 


51
0x0800
â
â
å¤åªä½äºä»¶ä¿¡æ¯ä¸ä¼ 


52
0x0801
â
â
å¤åªä½æ°æ®ä¸ä¼ 


53
0x8800
â
â
å¤åªä½æ°æ®ä¸ä¼ åºç­


54
0x8801
â
â
æåå¤´ç«å³ææå½ä»¤


55
0x0805
â
â
æåå¤´ç«å³ææå½ä»¤åºç­


56
0x8802
â
â
å­å¨å¤åªä½æ°æ®æ£ç´¢


57
0x0802
â
â
å­å¨å¤åªä½æ°æ®æ£ç´¢åºç­


58
0x8803
â
â
å­å¨å¤åªä½æ°æ®ä¸ä¼ 


59
0x8804
â
â
å½é³å¼å§å½ä»¤


60
0x8805
â
â
åæ¡å­å¨å¤åªä½æ°æ®æ£ç´¢ä¸ä¼ å½ä»¤


61
0x8900
â
â
æ°æ®ä¸è¡éä¼ 


62
0x0900
â
â
æ°æ®ä¸è¡éä¼ 


63
0x0901
â
â
æ°æ®åç¼©ä¸æ¥


64
0x8A00
â
â
å¹³å° RSA å¬é¥


65
0x0A00
â
â
ç»ç«¯ RSA å¬é¥


66
0x8F00~0x8FFF
ä¿ç
ä¿ç
å¹³å°ä¸è¡æ¶æ¯ä¿ç


67
0x0F00~0x0FFF
ä¿ç
ä¿ç
ç»ç«¯ä¸è¡æ¶æ¯ä¿ç



",45
joimxjtuse/FuncTest,Java,"å·¥ä½åå­¦ä¹ ä¸­éå°çä¸äºé®é¢åå¶æ´ç
ç®æ³
leet-code
é¢è¯é¢
è®¾è®¡æ¨¡å¼
ç»å¸çè®¾è®¡æ¨¡å¼
æ©å±çè®¾è®¡æ¨¡å¼
åºç¡ç¥è¯ç­
",2
beyondye/framework,PHP,"ENPHP Frameworkæ¯ä¸ä¸ªè½»éçº§çï¼å¼åå³ç¨çPHPæ¡æ¶ã
ç¹å«éåä¸­å°åç½ç«çå¼åå»ºè®¾ï¼èªå¸¦æ°æ®è¡¨éªè¯ï¼å¤æ°æ®åºåç¦»æ¯æï¼å¸¸ç¨çåºæä»¶ã
ä»¥ç®åé£äº80%éå¤åè½ä¸ºç®æ æé åºæ­¤æ¡æ¶ï¼å¦ææ¨åç¦ééçº§æ¡æ¶ï¼è¯·è¯è¯ENPHP Frameworkã
çæ¬åºä¾èµ

çæ¬ PHP7+
mb_stringæ©å±
GD2æ©å±

ææ¡£ç®å½ç´¢å¼



Â 
Â 
Â 
Â 




å¥å£æä»¶éç½®
å¸¸éè®¾ç½®
æ°æ®åºéç½®
èªå®ä¹éç½®æ°æ®å­å¸


å¨å±åéæ°ç»
æ°æ®åºåºæ¬æä½
Modelæ°æ®æ¨¡å
Modelæ°æ®éªè¯


Controlleræ§å¶å¨
Viewè§å¾
Helperå¸®å©å½æ°
Inputè¾å¥


Outputè¾åº
Sessionä¼è¯
Cookieç®¡ç
Langå¤è¯­è¨éç½®


Redisç¼å­
Securityå®å¨
Uploadä¸ä¼ æä»¶
Htmlæ ç­¾çæ


Gridè¡¨æ ¼çæ
Imageå¾çä¿®é¥°
Smtpåéé®ä»¶
Captchaéªè¯ç çæ


åºç¨ç¨åºç®å½å¸å±è¯´æ






ææ¡£åå®¹
ä¿çå±æ§åå½æ°æ¹æ³

ä¸æ¨èè¦çï¼é¤éä½ äºè§£å¨å±ä»£ç ã

ä¿ççå±æ§
$this->input //è¾å¥ç±»å®ä¾
$this->config //éç½®ç±»å®ä¾
$this->output //è¾åºç±»å®ä¾
$this->session //ä¼è¯ç±»å®ä¾
$this->cookie //cookieç±»å®ä¾
$this->lang //é»è®¤å¤è¯­è¨ç±»å®ä¾
$this->helper //å¸®å©ç±»å®ä¾
$this->security //å®å¨ç±»å®ä¾
$this->redis //redisç±»å®ä¾
$this->vars //å¨å±åéæ°ç»
$this->db //é»è®¤æ°æ®åºå®ä¾

ä¿ççæ¹æ³å½æ°
$this->db() //èªå®ä¹æ°æ®åºå¹¶è¿åå®ä¾
$this->lang() //èªå®ä¹è¯­è¨ç±»å¹¶è¿åå®ä¾
$this->model() //å è½½modelå¹¶è¿åå®ä¾
$this->redis() //èªå®ä¹rediså¹¶è¿åå®ä¾

å¥å£æä»¶éç½®

å¥å£æä»¶ä¸è¬æ¯ç½ç«çæ ¹ç®å½index.phpæä»¶ï¼æå ä¸ªéè¦çå¸¸ééç½®ã

è¿è¡ç¯å¢è®¾ç½®
è®¾ç½®è¿è¡ç¯å¢åéï¼ä¸ä¸ªå¼åå«ä¸ºæµè¯ç¯å¢ï¼äº§åç¯å¢ï¼å¼åç¯å¢ã
// test,production,development
define('ENVIRONMENT', 'development');
åºç¨ç®å½è®¾ç½®
æ¨å¼åçåºç¨ç¨åºç®å½å¸¸éAPP_DIRè®¾ç½®ã
define('APP_DIR', realpath('app_dir') . DIRECTORY_SEPARATOR);
æ¡æ¶ç®å½è®¾ç½®
æ¡æ¶ç³»ç»æä»¶ç®å½å¸¸éï¼å¯ä»¥å­æ¾å°å¶ä»å°æ¹ï¼ä»¥ä¾¿å±ç¨ååçº§ã
define('SYS_DIR', realpath('system_dir') . DIRECTORY_SEPARATOR);
æ§å¶å¨æ¨¡åè®¾ç½®
è®¾ç½®controlleræ¨¡åå¸¸éï¼æ¨¡åå¿é¡»æ¯APP_DIRç®å½ä¸moduleæä»¶å¤¹çå­ç®å½ã
define('MODULE', 'www');
æ¨¡æ¿è§å¾ç®å½è®¾ç½®
è®¾ç½®æ¨¡æ¿ç®å½å¸¸éï¼æ¨¡æ¿å¿é¡»æ¯APP_DIRç®å½ä¸templateæä»¶å¤¹çå­ç®å½ã
define('TEMPLATE', 'www');
å¸¸éè®¾ç½®

å¸¸éæä»¶ä½ç½®å¨APP_DIR/config/ä¸é¢ä¸ä¸ªå­ç®å½test,production,developmentä¸­çconstans.phpæä»¶åå«æç¯å¢è®¾ç½®ã

å°åè·¯ç±
å°åè·¯ç±éç½®,ä»¥/index.php?c=main&a=indexä¸ºä¾å­ã
cä»£è¡¨æ§å¶å¨ç±»åå­ï¼é»è®¤æ§å¶å¨ä¸ºMainã
aä»£è¡¨actionæ¹æ³åç§°ï¼é»è®¤actionä¸ºindexã
ä½ å¯ä»¥èªå®ä¹è®¾ç½®è¿äºå¼ã
define('DEFAULT_CONTROLLER', 'main');
define('DEFAULT_ACTION', 'index');
define('CONTROLLER_KEY_NAME', 'c');
define('ACTION_KEY_NAME', 'a');
å­ç¬¦ç¼ç 
è¾åºå­ç¬¦ç¼ç è®¾ç½®ï¼ä»¥ä¾¿$this->output->view()å$this->output->json()è¾åº
define('CHARSET', 'utf-8');
Cookieç¸å³è®¾ç½®
//ææåå
define('COOKIE_DOMAIN', 'test.com'); 

//æ¯å¦httpsåé
define('COOKIE_SECURE', false);

//ææè·¯å¾
define('COOKIE_PATH', '/');

//httpåªè¯»
define('COOKIE_HTTPONLY', false);

//è¿ææ¶é´ç§
define('COOKIE_EXPIRE', 0);
Sessionè®¾ç½®

//èªå®ä¹session cookieå
define('SESSION_COOKIE_NAME', 'SE');

//sessionä¿å­æ¶é´ï¼0ä¸ºå³é­æµè§å¨å³å¤±æï¼ç§ä¸ºåä½
define('SESSION_EXPIRE', 0);
å®å¨éç½®
//å å¯å®å¨æ··æ·å¼
define('ENCRYPTION_KEY', 'weryi9878sdfddtgtbsdfh');

//è¡¨åæäº¤token session åç§°
define('TOKEN_SESSION_NAME', '34efddddre');

//è¡¨åtokenå­æ®µå
define('TOKEN_INPUT_NAME', 'fh40dfk9dd8dkfje');

//tokenè¿ææ¶é´ï¼ç§ä¸ºåä½
define('TOKEN_EXPIRE', 3600);
å¤è¯­è¨åºç¨
//é»è®¤è¯­è¨ç¯å¢
define('LANG', 'zh_cn');
URLè½¬æ¢
URLéåè½¬æ¢è¾åºæ¨¡çï¼åè·¯ç±æ å³ï¼ä»¥éå$this->helper->url()ä½¿ç¨
//url éå
define('URL', ['mod_name'=>['controller_name/action_name'=>'/{controller_key}/{action_key}']]);

//ä¾å­ 

//æ³¨æ$this->helper->url()åæ°åæ°ç»keyçé¡ºåº
define('URL', [
    'www' => [ 
    //wwwè¡¨ç¤ºæ¨¡ååç§°
    
        'main/index' => '/',  
        //echo $this->helper->url(['c'=>'main','a'=>'index'])
        //è¾åº /
        
        'main/lists/type' => '/list/{type}.html',
         //echo $this->helper->url(['c'=>'main','a'=>'lists','type'=>'2'])
         //è¾åº /list/2.html
        
        'main/lists/type/page' => '/list/{type}_{page}.html'
         //echo $this->helper->url(['c'=>'main','a'=>'lists','type'=>'2','page'=>'34']) 
         //è¾åº /list/2_34.html
                 
    ]
]);
æ°æ®åºéç½®

æ°æ®åºæä»¶ä½ç½®å¨APP_DIR/config/ä¸é¢ä¸ä¸ªå­ç®å½test,production,developmentä¸­çdatabase.phpæä»¶åå«æç¯å¢è®¾ç½®ã
ææ¶åªæ¯æmysqli

defaultä¸ºé»è®¤æ°æ®åºï¼å¯ä»¥ç´æ¥$this->dbè®¿é®é»è®¤æ°æ®åº
$this->db('read)è®¿é®readæ°æ®åº
//ä¾å­

return [
    //é»è®¤æ°æ®åº
    'default' => 
    [
        'driver' => 'mysqli',
        'host' => 'set.database.to.hosts.file',
        'username' => 'root', 
        'password' => '123456',
        'database' => 'dataname',
        'port' => 3306,
        'charset' => 'utf8'
    ],
    
    //è¯»æ°æ®åº
    'read'=>
    [
        'driver' => 'mysqli',
        'host' => 'set.database.to.hosts.file',
        'username' => 'root', 
        'password' => '123456',
        'database' => 'dataname',
        'port' => 3306,
        'charset' => 'utf8'
    ]
];
èªå®ä¹éç½®æ°æ®å­å¸

èªå®ä¹éç½®æ°æ®å­å¸ï¼ä¸»è¦ä¸ºäºåºå¯¹æäºåºç¨è¾å¤çåæ°æ®å­å¨è®¿é®
ä¿å­äºAPP_DIR/configç®å½ä¸é¢PHPæä»¶åå®¹ä¸ºæ°ç»

ä»¥APP_DIR/config/test.phpä¸ºèä¾,éå$this->configä½¿ç¨
//test.phpåå®¹
return ['key2'=>'val2','key'=>['a','b','c'];

//var_dump $this->config->test
//è¾åº ['key2'=>'val2','key'=>['a','b','c']

//echo $this->config->test['key'][0]
//è¾åº a
å¨å±åéæ°ç»
å¨å±åéæ°ç»$varã
//å¨å±åéæ°ç»ï¼
//$this->vars å¯ä»¥ç´æ¥è®¿é®ï¼
//é»è®¤å·²åå«$this->vars['controller']å½åæ§å¶å¨å¼
//é»è®¤å·²åå«$this->vars['action']å½åactionå¼
$vars = [];
æ°æ®åºåºæ¬æä½

ææ¶åªæ¯æmysqli
éç½®å¥½æ°æ®åºä»¥åï¼æä»¬å¯ä»¥ $this->db è°ç¨é»è®¤æ°æ®åºã
æèå¯ä»¥$this->db('read')è°ç¨ä¸ä¸ªå·²éç½®ä¸º'read'çæ°æ®åºã

$this->db->query($sql) æ¹æ³
åå§SQLè¯­å¥æ§è¡ï¼å¦æ¯selectè¿åæ°æ®éï¼deleteï¼insertï¼updateè¿åå¸å°å¼ã
//è¿åä¸ä¸ªç»æéå¯¹è±¡å¥æ
$result=$this->db->query('select * from table1 where f=2;');

//è¿åæ°æ®çæ¡æ°ï¼intç±»å
$result->num_rows;

//è¿åç»æéå¶ä¸­ä¸æ¡æ°æ®ï¼é»è®¤ç¬¬ä¸æ¡ä»¥å¯¹è±¡å½¢å¼è¿åå­æ®µ
$result->row();

//ä»¥æ°ç»å½¢å¼è¿åç¬¬3æ¡æ°æ®
//$row['f'];
$row=$result->row(2,'array');


//ä»¥å¯¹è±¡å½¢å¼è¿åç¬¬4æ¡æ°æ®
//$row->f;
$row=$result->row(3,'object')


//è¿åæ°æ®éï¼é»è®¤å¯¹è±¡å½¢å¼
$recordset=$result->result();
foreach($recordset as $rs){
    echo $rs->f;
}

//æ°ç»å½¢å¼è¿åæ°æ®é
$recordset=$result->result('array');
foreach($recordset as $rs){
    echo $rs['f'];
}
$this->db->select($table,$condition=[]) æ¹æ³
æ¥è¯¢æ°æ®åºè¡¨è¿åæ°æ®éå¯¹è±¡ã

åæ°è¯´æ

$table æ°æ®è¡¨åç§°
$condition æ¥è¯¢æ¡ä»¶æ°ç»ï¼å¦æä¸ºç©ºè¿åå¨é¨


//æ¥è¯¢æ¡ä»¶
$condition= [
     'where' => ['f1'=>'2','f3>'=>'3','f4!='=>'8'], //whereæ¡ä»¶,æ¯æè¿ç®ç¬¦>,<,<>,!=,=,in,like,>=,<=
     'fields' => ['f1','f2','f3'],//è¿åå­æ®µ
     'orderby' => ['f1'=>'desc','f2'=>'asc'], //æåº
     'limit' => [0,20] //è¿åæ°æ®æ¡æ° ï¼ä¹å¯ä»¥æ¯ä¸ä¸ªintå¼ï¼å¦ï¼limit=>10
  ];
 
//è¿åæ°æ®å¥å¯¹è±¡
$recordset=$this->db->select('table1',$condition);
foreach($recordset->result() as $rs){
    echo $rs->f1;
}
$this->db->insert($table,$data) æ¹æ³
æå¥æ°æ®å°æ°æ®åºè¡¨ï¼è¿åå¸å°å¼ã

åæ°è¯´æ

$table æ°æ®è¡¨åç§° 
$data  æå¥è¡¨çæ°æ®æ°ç»


//éè¦æå¥çæ°æ®
$data=['f1'=>'1','f2'=>'2'];

$rs=$this->db->insert('table1',$data)ï¼
if($rs){
   //æå¥æåï¼è¿åæåä¸æ¡æå¥è¯­å¥äº§ççèªå¢ID
   $this->db->insert_id;
}
$this->db->delete($table,$where=[]) æ¹æ³
å é¤æ°æ®éï¼è¿åå¸å°å¼

åæ°è¯´æ

$table æ°æ®è¡¨åç§°
$where whereæ¡ä»¶æ°ç»ï¼ä¸ºç©ºå é¤å¨é¨ï¼è°¨æä½¿ç¨ï¼


//å é¤æ¡ä»¶
$data=['f1'=>'1','f2'=>'2'];

$rs=$this->db->delete('table1',$data)ï¼
if($rs){
   //å é¤æåï¼è¿åå½±åæ°æ®è¡æ°
   $this->db->affected_rows;
}
$this->db->escape($str) æ¹æ³
SQLè¯­å¥ä¸­çç¹æ®å­ç¬¦è¿è¡è½¬ä¹ï¼è¿åè½¬ä¹åå­ç¬¦ä¸²ã
//åè§ http://php.net/manual/zh/mysqli.real-escape-string.php
$this->db->escape('str');
$this->db->replace($table,$data) æ¹æ³
æ°æ®éä¸»é®å¦æå­å¨å°±æ¿æ¢ä¸ç¶æå¥æ°æ°æ®ï¼è¿åå¸å°å¼ã

åæ°è¯´æ

$table æ°æ®è¡¨åç§°
$data éè¦æä½çæ°æ®æ°ç»


//éè¦æå¥ææ¿æ¢çæ°æ®ï¼å¦æä¸»é®primary=1å·²å­å¨ï¼å³æ¿æ¢æ¬æ¡æ°æ®ï¼ä¸ç¶æå¥æ°æ°æ®ã
$data=['primary'=>1,'f1'=>'1','f2'=>'2'];

$rs=$this->db->replace('table1',$data)ï¼
$this->db->update($table,$data,$where=[]) æ¹æ³
æ´æ°æ°æ®ï¼è¿åå¸å°å¼æå½±åè¡æ°ã

åæ°è¯´æ

$table æ°æ®è¡¨åç§°
$data éè¦æ´æ°çæ°æ®æ°ç»
$where whereæ¡ä»¶ï¼ä¸ºç©ºæ´æ°å¨é¨


$data=['f1'=>'3','f3'=>'1'];
$where=['id'=>2];

$rs=$this->db->update('table1',$data,$where);

if($rs){
   //æ´æ°æåï¼è¿åå½±åæ°æ®è¡æ°
   $this->db->affected_rows;
 
}
$this->db->close() æ¹æ³
å³é­æ°æ®åºé¾æ¥ï¼è¿åå¸å°å¼ã
æ­£å¸¸æåµä¸ï¼æ¡æ¶å¨æ§è¡å®å°æåèªå¨å³é­é¾æ¥ï¼ä¹å¯ä»¥æåæå¨å³é­ã
//å³é­é»è®¤æ°æ®é¾æ¥
$this->db->close()ï¼

//å³é­readæ°æ®é¾æ¥
$this->db('read')->close()ï¼

Modelæ°æ®æ¨¡å

æ¯ä¸ªmodelå¿é¡»äºæ°æ®åºæä¸ªè¡¨å¯¹åºã
modelæä»¶å¿é¡»æ¾ç½®å¨APP_DIR/model/ç®å½ä¸ï¼æä»¶åä¸ç±»åä¸è´ï¼åºåå¤§å°åã

éè¿ç»§æ¿\system\Modelï¼æä»¬å¯ä»¥ä½¿ç¨æ¡æ¶èªå¸¦çåè½ä¾¿æ·æä½æ°æ®ã
ä¾å¦æä»¬åå»ºAPP_DIR/model/Tablemodel.phpã
//Tablemodel.php

//å½åç©ºé´
namespace model;

//ç±»å¿é¡»ç»§æ¿ä¸ä¸ªèªå®ä¹\inherit\Modelç±»ææ¯ç³»ç»\system\Modelç±»
class Tablemodel extends \inherit\Model
{

    //æé å½æ°å¿é¡»æ
    public function __construct()
    {
    
        //è¿è¡ä¸çº§æé å½æ°
        parent::__construct();
        
        //å¿é¡»è®¾ç½®ä¸ä¸ªæ°æ®è¡¨
        $this->table = 'test';
        
        //å¿é¡»è®¾ç½®ä¸ä¸ªä¸»é®
        $this->primary = 'id';

        //è®¾ç½®ä¸ä¸ªè¡¨çç»æï¼ä»¥ä¾¿éªè¯è¿æ»¤
        $this->schema = [
            'id' => [
                'validate' => ['regex' => '/^\d+$/', 'message' => 'ID ä¸è½ä¸ºç©º'],
                'literal' => 'ID',
                'default' => null,
                'required' => false
            ],
            'name' => [
                'validate' => ['regex' => '/^\S+$/', 'message' => 'åç§°ä¸è½ä¸ºç©º'],
                'literal' => 'åç§°',
                'default' => '',
                'required' => true
            ]];
    }

}

//æä»¬å¯ä»¥è¿æ ·è°ç¨model
$this->model('Tablemodel')->one(1);
$this->RDB å±æ§
è®¾ç½®è¯»æ°æ®åºï¼é»è®¤ä¸ºdefaultæ°æ®åº
$this->RDB='read_database';
$this->WDB å±æ§
è®¾ç½®åæ°æ®åºï¼é»è®¤ä¸ºdefaultæ°æ®åº
$this->WDB='write_database';
$this->table å±æ§
è®¾ç½®modelå¯¹åºæ°æ®è¡¨
$this->table='table1';
$this->primary å±æ§
è®¾ç½®æ°æ®è¡¨ä¸»é®å­æ®µ
$this->primary='id';
$this->schema å±æ§
è®¾ç½®æ°æ®è¡¨ç»æï¼ä»¥ä¾¿éªè¯è¿æ»¤ï¼æ°ç»keyå¿é¡»åå­æ®µåä¸è´

validate['regex'] æ­£åéªè¯å­æ®µæ°æ®åæ³æ§


validate['message'] æç¤ºä¿¡æ¯


filter è¿æ»¤æ°æ®ï¼blank|tag|entity ä¸ä¸ªå¼ç»åä½¿ç¨ï¼

blankæè¿ç»­å¤ä¸ªç©ºç½å­ç¬¦è½¬æ¢æä¸ä¸ª,
tagè¿æ»¤htmlæ ç­¾,
entityæhtmlæ ç­¾è½¬æ¢æå®ä½å­ç¬¦ã



literal å­æ®µçå­é¢åå­


default å­æ®µé»è®¤å¼


required æ¯å¦å¿é¡»å¡«åå­æ®µ

      $this->schema = [
            'id' => [
                'validate' => ['regex' => '/^\d+$/', 'message' => 'ID ä¸è½ä¸ºç©º'],
                'literal' => 'ID',
                'default' => null,
                'required' => false
            ],
            'name' => [
                'validate' => ['regex' => '/^\S+$/', 'message' => 'åç§°ä¸è½ä¸ºç©º'],
                'filter'=>'blank|tag|entity'
                'literal' => 'åç§°',
                'default' => '',
                'required' => true
            ]
      ];
$this->all($fields) æ¹æ³
è·åæ°æ®è¡¨å¨é¨æ°æ®é,å¤§è¡¨è°¨æä½¿ç¨ã
$recordset=$this->all(['fname1','fname2']);

//æ³¨æç´æ¥è¿åæ°æ®éï¼èä¸æ¯resultå¯¹è±¡
foreach($recordset as $rs){
    echo $rs->fname1;
}

$this->belongs($model, $relation_model, $relation_foreign_name, $where, $condition) æ¹æ³
å¤å¯¹å¤è·åè¡¨æ°æ®,è¿åå¯¹è±¡æ°æ®é

åæ°è¯´æ

$model éè¦å³èçmodelåç§°
$relation_model å³ç³»è¡¨modelåç§°
$relation_foreign_name å³èè¡¨ä¸»é®åå¨å³ç³»è¡¨ä¸­çå­æ®µå




$where=['local_relation_filed_name' => 'local_primary_value']

$local_relation_filed_name æ¬è¡¨å¨å³ç³»è¡¨å­æ®µå
$local_primary_value æ¬è¡¨ä¸»é®å¼





$condition åè§$this->select()åæ°



$this->belongs($model, $relation_model, $relation_foreign_name, $where, $condition);

$this->count($where=[]) æ¹æ³
è·åæ°æ®è¡¨æ°æ®æ¡æ°,éåmyisamè¡¨ã
//å¸¦æ¡ä»¶çè®¡ç®
$this->count(['field'=>'val']);

//è·åè¡¨æ»æ¡æ°
$this->count();
$this->delete($where=[]) æ¹æ³
å é¤è¡¨æ°æ®ï¼æåè¿åtrueä¸ç¶è¿åfalseã
$rs=$this->delete(['f1'=>'2']);
if($rs){
    //å é¤æåè¿åtrue
    echo $rs;
}
$this->hasMany($model,$where,$condition=[]) æ¹æ³
ä¸å¯¹å¤è·åå¯è¡¨æ°æ®,è¿åå¯¹è±¡æ°æ®éã

åæ°è¯´æ

$model éè¦å³èçmodel




$where=['foreign_name' => 'local_primary_value']

$foreign å¤è¡¨å­æ®µå
$local_primary_value æ¬è¡¨ä¸»é®å¼





$condition åè§$this->select()åæ°


$this->hasMany($model, $where, $condition);
$this->hasOne($model,$primary_value) æ¹æ³
ä¸å¯¹ä¸è·åæ°æ®,è¿åä¸è¡å¯¹è±¡æ°æ®ã

åæ°è¯´æ

$model å³èçmodel
$primary_value ä¸»é®å¯ä¸å¼


$this->hasOne($model, $primary_value);
$this->insert($data=[]) æ¹æ³
æå¥æ°æ®ï¼è¿åå¸å°å¼ã
$data=['f1'=>'1','f1'=>'2'];

$rs=$this->insert($data);

if($rs){
    //æå¥æå
}
$this->lastid() æ¹æ³
è·åæåæå¥çèªå¢ä¸»é®IDã
$data=['f1'=>'1','f1'=>'2'];

$rs=$this->insert($data);

if($rs){
    //è·åæåæå¥èªå¢ä¸»é®
    echo $this->lastid();
}
$this->one($id) æ¹æ³
éè¿ä¸»é®æ°å­IDæå¯ä¸å­æ®µè·åä¸æ¡è®°å½ã
//å¦ææ¯ä¸»é®æ°å­id
$this->one(12);

//å¦ææ¯å¯ä¸å­æ®µ
$this->one(['uniqname'=>'abc']);
$this->query($sql) æ¹æ³
æ§è¡éç¨SQLè¯­å¥,
å¦ææ¯selectè¿ååºç¡æ°æ®åºresultå¯¹è±¡ï¼
æ§è¡updateï¼insertï¼deleteè¿åå¸å°å¼ã
$result=$this->query('select * from table1');
$this->select($condition=[]) æ¹æ³
ææ¡ä»¶è·åè¡¨æ°æ®å¯¹è±¡é,åæ°ä¸ºç©ºï¼è¿åå¨é¨æ°æ®ã
$condition=[
     'where' => ['f1'=>'2'],
     'fields' => ['f1','f2'],
     'orderby' => ['f1'=>'desc','f2'=>'asc'],
     'limit' => [0,20] //æ 'limit'=>20
   ];

$this->select($condition);
$this->update($data,$where=[]) æ¹æ³
æ´æ°æ°æ®è®°å½ï¼æåè¿åtrueï¼å¤±è´¥è¿åfalse
$data=['f1'=>2,'f2'=>3];
$where=['id'=>12];

$rs=$this->update($data,$where);

if($rs){
    //ä¿®æ¹æåï¼è¿åå½±åtrue
    echo $rs;
}
$this->where($where,$fields=[]) æ¹æ³
ææ¡ä»¶è¿åæ°æ®å¯¹è±¡é,ä¸»è¦ä¸ºäºç®å$this->select()
$where=['f1'=>'2'];
$fields=['f1','f2'];
$this->where($where,$fields);
$this->safe å±æ§
éªè¯è¿æ»¤å¥åºå­æ®µæ°æ®ï¼è¿åsystem/Safeå®ä¾ã

å·ä½åè§ ææ¡£Modelæ°æ®éªè¯é¨å

//å¯ä»¥å¨æ§å¶å¨è¿æ ·è°ç¨
$this->model('Tablemodel')->safe->clear($data);
Modelæ°æ®éªè¯

Modelæ°æ®éªè¯ï¼ä¸ºäºç¨æ·è¾å¥æ°æ®çåæ³æ§ï¼
æä¾äºå ä¸ªå®ç¨æ¹æ³å½æ°ä»¥éåModelç$this->schemaå±æ§ä½¿ç¨ã

$this->safe->illegalFields å±æ§

æ¥åè¿åéªè¯ä¸éè¿éæ³å­æ®µåæ°ç»

$this->safe->notMemberFields å±æ§

æ¥åè¿åä¸å¨è¡¨å­æ®µä¸­çéæ³å­æ®µåæ°ç»

$this->safe->incompleteFields å±æ§

æ¥åè¿åæªå®æåå¿é¡»å¡«åçå­æ®µåæ°ç»

$this->safe->clear($data) æ¹æ³
æ¸çä¸å­å¨äºschemaéé¢çå­æ®µï¼
ä¸æ¯æåçå­æ®µä¿å­äº$this->notMemberFields
è¿åæ¸çåçæ°æ®
//æ¸çä¹åçæ°æ®
$beforedata=[
     //åå¦nomemberä¸å­å¨äº$this->schemaä¸­ï¼å°è¢«æ¸çæ
    'notmember'=>'val',
    //åå¦f1å­æ®µåå­å¨äº$this->schema
    'f1'=>'val'
];

//æ¸çä¹å
$afterdata=$this->safe->clear($data);

//è¾åº['f1'=>'val']
var_dump($afterdata);

//è¾åºä¸æ¯æåå­æ®µå['notmember']
var_dump($this->notMemberFields);
$this->safe->complete($data) æ¹æ³
éªè¯æ¯å¦ç¼ºå°å¿è¦å­æ®µï¼
ç¼ºå°çå¿è¦å­æ®µä¿å­äº$this->incompleteFields
è¿åå¸å°å¼
//åå¦$this->schemaåå«å­æ®µf1,f2å¿é¡»å¡«åä¸è½ä¸ºç©º

//æ³¨æ$dataæ²¡æåå«å­æ®µf2
$data=['f1'=>'val'];

//éªè¯å®æ´æ§
$result=$this->safe->complete($data);

if($result){
   //éè¿å®æ´æ§éªè¯
}else{
    //æ²¡æéè¿éªè¯

    var_dump($this->incompleteFields);
    //è¾åº['f2']
}
$this->safe->merge($data) æ¹æ³
ä¸schemaé»è®¤æ°æ®è¦çåå¹¶ï¼å¹¶ä¸æ¸çä¸å­å¨äºschemaéé¢çå­æ®µï¼
ä¸æ¯æåçå­æ®µä¿å­äº$this->notMemberFields
è¿ååå¹¶åæ¸ççæ°æ®
//åå¦$this->schemaä¸­å­å¨f1å­æ®µï¼é»è®¤å¼ç­äºval1

//æ³¨æf1ç°å¨çå¼ä¸ºval2
$data=['f1'=>'val2','notmember'=>'valxx'];

//åå¹¶è¦çæ°æ®å¹¶æ¸çéæåå­æ®µ
$result=$this->safe->merge($data);

//è¾åº['f1'=>'val2']
var_dump($result);

//è¾åºä¸æ¯æåå­æ®µå['notmember']
var_dump($this->notMemberFields);

$this->safe->validate($data) æ¹æ³
éªè¯æ°æ®åæ³æ§ï¼éæ³å­æ®µä¿å­äº$this->illegalFields
è¿åå¸å°å¼
//åå¦$this->schemaä¸­å­æ®µf1å¿é¡»ä¸ºintç±»å

//æ³¨æf1æ¯å­ç¬¦ä¸²
$data=['f1'=>'val'];

//éªè¯åæ³æ§
$result=$this->safe->validate($data);

if($result){
   //éè¿åæ³æ§éªè¯
}else{
    //æ²¡æéè¿éªè¯

    var_dump($this->illegalFields);
    //è¾åº['f1']
}
Controlleræ§å¶å¨
åå»ºä¸ä¸ªæ§å¶å¨

æ§å¶å¨æä»¶å¿é¡»æ¾ç½®å¨APP_DIR/module/module_nameç®å½ä¸ï¼æä»¶åå¿é¡»åç±»åä¸è´ã


å¿é¡»ç»§æ¿system/Controllerã

åå»ºä¸ä¸ªæ§å¶å¨ï¼ä»¥APP_DIR/module/www/Testcontroller.phpä¸ºä¾ã
//å½åç©ºé´
namespace module\www;

//Testcontrollerç»§æ¿èªå®çinherit/Controlleræsystem/Controller
class Testcontroller extends \inherit\Controller
{
    public function index()
    {
        $data['hello_world']='hello wolrd';
        
        //è°ç¨ä¸ä¸ªmodel
        $this->model('Testmodel')->select();
        
        //è·åè¡¨åå¨é¨å­æ®µæ°æ®
        $postdata=$this->input->post();
        
        //æ¸çä¸æ¯schemaæåå­æ®µ
        $afterdata=$this->model('Testmodel')->safe->clear($data);
        
        //æå¥è¡¨åæäº¤çæ°æ®å°æ°æ®åº
        $this->model('Testmodel')->insert($afterdata);

        //è§å¾è¾åº
        $this->output->view('main',$data);
    }
}
Viewè§å¾

è§å¾æ¨¡æ¿æä»¶å¿é¡»æ¾ç½®APP_DIR/template/module_name/ç®å½ä¸é¢


æ¨¡æ¿æä»¶é½æ¯æ åçåçphpä¸htmæ··åä»£ç ï¼æ¡æ¶æ²¡æä¸é¨çæ¨¡æ¿åè½

åå»ºè§å¾æ¨¡æ¿
ä¾å¦æä»¬åå»ºä¸ä¸ªAPP_DIR/template/www/test.phpï¼wwwä¸ºmoduleæ¨¡ååã
<html>
    <head><title><?php echo $title; ?></title></head>
    <body>
        <h1>
            <?php echo $heading; ?>
        </h1>
        <div><?php echo $content; ?></div>
    </body>
</html>
æä»¬å¯ä»¥å¨æ§å¶å¨éè°ç¨æ¨¡æ¿ã
æ¯å¦ä¸é¢ä»£ç ï¼
//æ¨¡æ¿åé
$data=['title'=>'ç½é¡µæ é¢','heading'=>'å°æ é¢','content'=>'åå®¹'];

//åªéè¦å¡«åæä»¶åï¼æ¯æå­ç®å½
$this->output->view('test'ï¼$data);
Helperå¸®å©å½æ°

èªå®ä¹å¸®å©å½æ°æä»¶å¿é¡»æ¾ç½®APP_DIR/helper/ç®å½ä¸é¢


å¿é¡»ä»¥ç±»çå½¢å¼ç»ç»åè½å½æ°

èªå®ä¹helperå½æ°æ¹æ³
ä¾å¦æä»¬åå»ºAPP_DIR/helper/Testhelper.php
//å½åç©ºé´
namespace helper;

//æå¯ä»¥ç»§æ¿\system\System,ä»¥ä¾¿ä½¿ç¨æ¡æ¶åå»ºå±æ§åå½æ°æ¹æ³,å¦æä¸éè¦å¯ä»¥å¿½ç¥
class Testhelper extends \system\System
{
    public function returntex($param){
    
      //åªæç»§æ¿\system\Systemæè½è°ç¨æ­¤æ¹æ³
      $this->input->get('str');
      
      return $param;
    }
}
//æä»¬å¯ä»¥å¨æ§å¶å¨ï¼è§å¾ï¼modeléé¢è¿æ ·è°ç¨
//$this->helper->testhelper->returntex('str');
$this->helper->url($param=[],$path=ENTRY,$anchor='') æ¹æ³

æ­¤æ¹æ³æ¡æ¶èªå¸¦


åæ°è¯´æ

param   æ¥è¯¢å­ç¬¦ä¸²æ°ç» 
path    å¥å£æä»¶è·¯å¾ï¼é»è®¤å¼ ENTRYå¸¸éå¼ 
anchor  éç¹


éåå¸¸éURLä½¿ç¨ï¼è¿åè¢«å¹éçURLå°åå­ç¬¦ä¸²
//æ³¨æ$this->helper->url()åæ°åæ°ç»keyçé¡ºåº
define('URL', [
    'www' => [ 
    //wwwè¡¨ç¤ºæ¨¡ååç§°
    
        'main/index' => '/',  
        //echo $this->helper->url(['c'=>'main','a'=>'index'])
        //è¾åº /
        
        'main/lists/type' => '/list/{type}.html',
         //echo $this->helper->url(['c'=>'main','a'=>'lists','type'=>'2'])
         //è¾åº /list/2.html
        
        'main/lists/type/page' => '/list/{type}_{page}.html'
         //echo $this->helper->url(['c'=>'main','a'=>'lists','type'=>'2','page'=>'34']) 
         //è¾åº /list/2_34.html
                 
    ]
]);
ä¸å¹éURLå¸¸éè¿å
//åå¦å¥å£æä»¶ä¸ºindex.php 

$this->helper->url();
//è¾åº /index.php?c=main&a=index

$this->helper->url(['p1'=>'1','p2'=>2]);
//è¾åº /index.php?c=main&a=index&p1=1&p2=2

//æ³¨æaåæ°å/mod/list.phpä»¥åanchor
$this->helper->url(['a'=>'lists','p1'=>'1','p2'=>2],'/mod/list.php','anchor');
//è¾åº /mod/list.php?c=main&a=lists&p1=1&p2=2#anchor
$this->helper->pager($size, $total, $page, $url, $visible = 5) æ¹æ³
æ¡æ¶èªå¸¦åé¡µæ¹æ³
//æ¯ä¸ªé¡µé¢10æ¡æ°æ®
$size=10;

//æ°æ®æ»æ°
$total=100;

//å½åé¡µç 
$page=$this->input->get('page',1);

//å°åæ¨¡æ¿
$url='/index/list/<%page%>.html';

//æ¾ç¤ºå¤å°ä¸ªé¡µç é¾æ¥
$visible=5;

//è°ç¨pager
$pager=$this->helper->pager($size, $total, $page, $url, $visible);

echo $pager;
//è¾åºHTML
//
//<div class=""pager"">
//<a class=""number"" href=""/index/list/1.html"">1</a>
//<a class=""number "" href=""/index/list/2.html"">2</a>
//<a class=""number "" href=""/index/list/3.html"">3</a>
//<a class=""number "" href=""/index/list/4.html"">4</a>
//<a class=""number "" href=""/index/list/5.html"">5</a>
//<span class=""ellipsis"">...</span>
//<a  class=""number"" href=""/index/list/10"">10</a>
//<a href=""/index/list/2.html"" class=""next"">ä¸ä¸é¡µ</a>
//<span class=""info"">å± 100 æ¡è®°å½</span>
//</div>
Inputè¾å¥
$this->input->get() æ¹æ³
è·åå°åæ¥è¯¢å­ç¬¦ä¸²å¼ï¼ä¸å¡«åæ°è¿åå¨é¨æ°æ®æ°ç»
//å¦ævar_nameä¸ºnullï¼å°±è¿åé»è®¤å¼default_str
$this->input->get('var_name','default_str');

//è¿åå¨é¨æ°æ®
$this->input->get();
$this->input->post() æ¹æ³
è·åè¡¨åæ°æ®ï¼æ²¡æåæ°è¿åå¨é¨è¡¨åå­æ®µæ°ç»
//å­æ®µä¸å­å¨è¿ånull
$this->input->post('field_name');

//è¿åå¨é¨
$this->input->post();
$this->input->ip() æ¹æ³
è·åv4 IPå°å
//å¦ææ²¡æè·åæåè¿å0.0.0.0
$this->input->ip();
$this->input->isAjax() æ¹æ³
å¤æ­æ¯å¦ajaxè¯·æ±ï¼åç«¯å¿é¡»å¸¦HTTP_X_REQUESTED_WITHè¯·æ±å¤´é¨
è¿åå¸å°å¼
//$_SERVER['HTTP_X_REQUESTED_WITH'] == 'XMLHttpRequest'
$this->input->isAjax();
$this->input->body() æ¹æ³
è·ååå§è¯·æ±æ°æ®,ä¸è¬ç¨äºAPIæ¥å£
$this->input->body();
$this->input->referer() æ¹æ³
è·åä¸ä¸ä¸ªæ¥æºå°åurlï¼ä»¥ä¾¿éå®å
//å¦ææ²¡æä¸ºç©º
$prev_url=$this->input->referer();

//éå®å
$this->output->redirect($prev_url);
$this->input->method() æ¹æ³
è·åå½åè¯·æ±æ¹æ³
//è¿å POSTï¼GETï¼OPTIONç­
$this->input->method();
Outputè¾åº
$this->output->compress($string) æ¹æ³
å é¤htmlå¤ä½ç©ºç½å­ç¬¦
è¿åå¤çä¹åçå­ç¬¦ä¸²
$string='<b style=""""    >  str </b><div>   ste  </div>';

$result=$this->output->compress($string);

echo $result;
//è¾åº <b style="""">str</b><div>ste</div>
$this->output->error($name = 'general', $data =[]) æ¹æ³

éè¯¯é¡µé¢æ¨¡æ¿å¿é¡»æ¾ç½®å¨APP_DIR/error/ç®å½ä¸é¢


åæ°è¯´æ

$nameæ¨¡æ¿æä»¶åï¼é»è®¤æ¨¡æ¿ genrnal
$dataåéæ°æ®æ°ç»ï¼é»è®¤æ°ç» $data=['heading' => 'Error Message', 'message' => 'An error occurred.']


éè¯¯é¡µé¢è®¾ç½®,èªå¨echoåå®¹
//éç¨éè¯¯é¡µé¢,
$this->output->error();

//èªå®ä¹éè¯¯é¡µé¢ï¼åå¦APP_DIR/error/404.phpå·²å­å¨
$this->output->error('404',['title'=>'Not Found']);
$this->output->json($status, $message, $data=[], $return=false) æ¹æ³
è¾åºjsonæ ¼å¼æ°æ®

åæ°è¯´æ

$status è®¾ç½®ä¸ä¸ªç¶æç 
$message è®¾ç½®ä¸ä¸ªç¶ææ¶æ¯å­ç¬¦ä¸²
$data éè¦è¾åºçæ°ç»æ°æ®ï¼é»è®¤ä¸ºç©ºæ°ç»
$return è®¾ç½®å¸å°å¼ï¼æ¯å¦è¿ååå®¹èªå®ä¹echoè¾åºï¼é»è®¤èªå¨echoåå®¹


$this->output->json('1002','æä½æå',['data'=>'val','data2'=>'val2']);
//è¾åº {'status':'1002','message':'æä½æå','data':{'data1':'val','data2':'val2'}}

//æè¿åå¼çèªå®ä¹è¾åº
$result=$this->output->json('1002','æä½æå',['data'=>'val','data2'=>'val2'],true);
echo $result;
$this->output->redirect($uri, $http_response_code=302) æ¹æ³
è¯·æ±éå®å

åæ°è¯´æ

$uri éå®åå°å
$http_response_code  httpå¤´ååºç ï¼é»è®¤å¼ä¸º302


//è½¬å°index.phpï¼é»è®¤ååºç 302
$this->output->redirect('/index.php');

//éå®åå°404é¡µé¢
$this->output->redirect('/notfound.php',404);
$this->output->status($http_status_code) æ¹æ³
è®¾ç½®ååºå¤´
$this->output->status('404');
//å¦å header('HTTP/1.1 404 Not Found',true)
$this->output->view($view, $data = [], $return = false, $compress = false) æ¹æ³
è¾åºè§å¾,èªå¨echoè¾åºã

åæ°è¯´æ

$view è§å¾æ¨¡æ¿æä»¶åç§°
$data è§å¾åéæ°æ®æ°ç»
$return æ¯å¦è¿ååå®¹èªå¨è¾åºï¼é»è®¤å¼false
$compress æ¯å¦åç¼©HTMLï¼é»è®¤å¼false


//åå¦å·²å­å¨APP_DIR/template/www/test.php

//æ¨¡æ¿æ°æ®
$data['var1'=>'val','var2'=>'val'];

//æ¡æ¶èªå¨echoè¾åºï¼
$this->output->view('test',$data);

//è¿åèªå®ä¹echoè¾åºï¼å¹¶åç¼©html
$result=$this->output->view('test',$data,true,true);
echo $result
Sessionä¼è¯
$this->session->delete($name) æ¹æ³

å é¤ä¸ä¸ªä¼è¯åç´ ï¼å¯ä»¥åæ¶å é¤å¤ä¸ª,æ²¡æè¿åå¼ã

//è®¾ç½®ä¸ä¸ªsessionåç´ 
$this->session->set('name','bob');
$this->session->set('name2','foo');

//å é¤ï¼
$this->session->delete('name');

//å é¤å¤ä¸ª
$this->session->delete(['name','name2']);
$this->session->destroy() æ¹æ³

æ³¨éå½åä¼è¯ï¼è¿åå¸å°å¼ã

$this->session->flash($name) æ¹æ³

åå¾æä¸ªä¼è¯å­æ®µçå¼ä¹åå é¤æ­¤ä¼è¯å­æ®µï¼å­æ®µä¸å­å¨è¿ånullã

$this->session->get($name) æ¹æ³

åå¾æä¸ªä¼è¯å­æ®µï¼å­æ®µä¸å­å¨è¿ånullã

$this->session->set($name,$value='') æ¹æ³

è®¾ç½®ä¸ä¸ªä¼è¯å­æ®µï¼æ°¸è¿è¿åtrueã

$this->session->regenerate() æ¹æ³

ä½¿ç¨æ°çæçä¼è¯IDæ´æ°ç°æä¼è¯IDã

Cookieç®¡ç
$this->cookie->delete($name) æ¹æ³
å é¤ä¸ä¸ªæå¤ä¸ªcookie,åæ°æ¥åä¸ä¸ªå­ç¬¦ä¸²æä¸ä¸ªæ°ç»,è¿åå¸å°å¼ã
//å é¤æä¸ªcookie
$this->cookie->delete('name');

//å é¤å¤ä¸ªcookie
$this->cookie->delete(['name1','name2','name3']);
$this->cookie->get($name) æ¹æ³
è·åä¸ä¸ªcookieå¼ï¼å¦æ$nameä¸å­å¨è¿ånullã
$this->cookie->set($name, $value, $expire = COOKIE_EXPIRE, $path = COOKIE_PATH, $domain = COOKIE_DOMAIN, $secure = COOKIE_SECURE, $httponly = COOKIE_HTTPONLY) æ¹æ³
è®¾ç½®ä¸ä¸ªcookie,è¿åå¸å°å¼ã
åæ°è¯´æ


$name cookieåå­




$value cookieå¼




$expire è¿ææ¶é´ï¼å¦æè®¾ç½®0ï¼å³é­æµè§å¨å¤±æï¼é»è®¤å¼COOKIE_EXPIREå¸¸é




$path ææè·¯å¾ï¼é»è®¤å¼COOKIE_PATHå¸¸é




$domain ææååï¼é»è®¤å¼COOKIE_DOMAINå¸¸é




$secure æ¯å¦httpsï¼é»è®¤å¼COOKIE_SECUREå¸¸é




$httponly æ¯å¦httpåªè¯»ï¼é»è®¤å¼COOKIE_HTTPONLYå¸¸é


$this->cookie->many($data, $expire = COOKIE_EXPIRE, $path = COOKIE_PATH, $domain = COOKIE_DOMAIN, $secure = COOKIE_SECURE, $httponly = COOKIE_HTTPONLY) æ¹æ³
è®¾ç½®å¤ä¸ªcookie,è¿åboolå¼ã

åæ°è¯´æ

$dataæ¯ä¸ä¸ªæ°ç»ï¼ä¾å¦$data=['name'=>'val','name2'>'val2']. 
å¶å®åæ°åè $this->cookie->set()æ¹æ³


Langå¤è¯­è¨éç½®

è¯­è¨åå¿é¡»æ¾ç½®APP_DIR/languageç®å½ä¸é¢ã

æä¹åå»ºè¯­è¨å
æä»¬ä»¥en_usåzh_cnä¸ºä¾ï¼
åå»ºè±æAPP_DIR/language/en_us/test.php
<?php
return ['test'=>'test','good'=>'very good'];
åå»ºä¸­æAPP_DIR/language/zh_cn/test.php
<?php
return ['test'=>'æµè¯','good'=>'éå¸¸å¥½'];
è°ç¨è¯­è¨å
echo $this->lang('zh_cn')->test['good'];
//è¾åº éå¸¸å¥½

echo $this->lang('en_us')->test['good'];
//è¾åº very good

//å¦æè®¾ç½®äºLANGå¸¸éä¸ºzh_cnï¼æä»¬å¯ä»¥è¿æ ·è°ç¨
echo $this->lang->test['good'];
// è¾åº éå¸¸å¥½
Redisç¼å­

å¿é¡»å®è£redisæ©å±æè½ä½¿ç¨

éç½®redisæå¡å¨
æ¾ç½®éç½®æä»¶redis.phpå°APP_DIR/config/development(test æ production)ç®å½ä¸ã
æä»¶ä»£ç åå®¹ï¼
<?php
return [
    //é»è®¤
    'default' => [
        'host' => 'set.redis.to.hosts.file', 
        'port' => 6379, 
        'password' => '', 
        'database' => 0, 
        'timeout' => 30, 
        'serialization' => true //æ¯å¦èªå¨åºåå
        ],
    //éåæå¡å¨
    'queue' => [
        'host' => 'set.redis.to.hosts.file', 
        'port' => 6379, 
        'password' => '', 
        'database' => 0, 
        'timeout' => 30, 
        'serialization' => true //æ¯å¦èªå¨åºåå
        ]
];
è°ç¨redisæå¡
æææ¹æ³å½æ°åå±æ§åç»§æ¿åçredisæ¨¡å
//å¦æè®¾ç½®äºdefaultæå¡å¨ï¼æä»¬å¯ä»¥è¿æ ·è°ç¨
$this->redis->get('key');

//è°ç¨ä¸ä¸ªèªå®ä¹redisæå¡
$this->redis('queue')->get('key');
Securityå®å¨

æ­¤ç±»æä¾äºä¸äºå¸¸ç¨çå®å¨æ¹æ³å½æ°

$this->security->blank($str) æ¹æ³
æå¤ä¸ªç©ºç½å­ç¬¦è½¬æ¢æä¸ä¸ªç©ºç½å­ç¬¦,å·²è¢«modeléªè¯å¼ç¨ã
$str='  dd    dd        d  ';
echo $this->security->blank($str);
// è¾åº ' dd dd d '
$this->security->entity($str) æ¹æ³
æhtmlæ ç­¾è½¬æ¢æå®ä½å­ç¬¦,å·²è¢«modeléªè¯å¼ç¨ã

å¦åphpåå»ºå½æ° htmlspecialchars($str, ENT_QUOTES | ENT_HTML401, CHARSET);

$this->security->tag($str) æ¹æ³
æ¸çhtmlæ ç­¾,å·²è¢«modeléªè¯å¼ç¨ã

å¦åphpåå»ºå½æ°strip_tags($str)

$this->security->token() æ¹æ³
çæä¸ä¸ªè¡¨åtokenå¼ï¼è¿åå­ç¬¦ä¸²ã
<input name=""_tokenname_"" value=""<?php echo $this->security->token() ?>"" />
$this->security->tokenName() æ¹æ³
çæä¸ä¸ªè¡¨åtokenåå­ï¼è¿åå­ç¬¦ä¸²ã
<input name=""<?php echo $this->security->tokenName() ?>"" value=""<?php echo $this->security->token() ?>"" />
$this->security->checkToken() æ¹æ³
éªè¯ä¸ä¸ªè¢«æäº¤ä¸æ¥çtokenæ¯å¦ææ,è¿åå¸å°å¼ã
if($this->security->checkToken()){

    //token ææ

}
Uploadä¸ä¼ æä»¶
ç±»æ¹æ³åå±æ§è¯´æ
//è®¾ç½®ä¿å­ç®å½
$upload->dir='/www/upload';

//è®¾ç½®è¢«åè®¸çæä»¶ç±»åæ°ç»
$upload->extension=['jpg','gif'];

//è®¾ç½®æ¥åè¡¨åæ°æ®å­æ®µ
$upload->data=$_FILES['filedata'];

//èªå®æä»¶åï¼å¦æä¸å¡«åï¼å°èªå¨è®¾ç½®ã
$upload->filename='filename';

//è®¾ç½®ä¸ä¼ æä»¶å¤¹æéç ï¼é»è®¤0777
$upload->mode='0777';

//å¿è¦å±æ§è®¾ç½®å®æ¯ï¼æ§è¡ä¸ä¼ å¤çï¼è¿åå¸å°å¼ã
$upload->execute();

//æ§è¡å®ç»æè¿åç¶æç 
$upload->code;
// è¯¦ç»è¯·æ¥ç $upload::ERROR_MSG

//æ§è¡å®ç»æè¿åæ¶æ¯æç¤º
$upload->message;
// è¯¦ç»è¯·æ¥ç $upload::ERROR_MSG
ä»£ç ä¾å­
//å®ä¾ä¸ä¼ ç±»
$upload = new \system\library\Upload();

//è®¾ç½®è¢«åè®¸çæä»¶æ©å±
$upload->extension = ['jpg', 'gif', 'png', 'jpge'];

//è®¾ç½®ä¸ä¼ ä¿å­ç®å½
$upload->dir = $_SERVER['DOCUMENT_ROOT'] . '/upload/' .date('y/nd/');

//æ¥åè¡¨åæ°æ®å­æ®µ
$upload->data = $_FILES['filedata'];

//èªå®ä¹çæä¸ä¸ªæä»¶å
$upload->filename = uniqid();

//æ§è¡ä¸ä¼ æä½
if ($upload->execute()) {
    echo $upload->code; // è¾åº '0'
    echo $upload->message; //è¾åº 'ä¸ä¼ æå'
    echo $upload->filename; //è¾åºå®æçæä»¶å+æç»æ©å±å
    return;
}

Htmlæ ç­¾çæ
çæhtmlæ ç­¾
ç®åä»£ç ä¾å­
//åæ°æ°ç»
$param=[
    [
        //æ ç­¾åp
        'name'='p',
        
        //æ ç­¾çå±æ§
        'properties'=>['name'=>'ptag'],
        
        //å­æ ç­¾åç´ 
        'elements'=>[
            [
                'name'='i',
                'properties'=>['name'=>'itag']
            ]
    ],
    [   //æ ç­¾div
        'name'='div',
        
        //æ ç­¾å±æ§
        'properties'=>['name'=>'pdiv'],
    ]
];

//åå»ºç±»å®ä¾
$html= new \System\Library\Html();

//çææ ç­¾
echo $html->tags($param);
//è¾åº 
//<p name=""ptag"">
//    <i name=""itag""></i>
//</p>
//<div name=""pdiv""></div>
Gridè¡¨æ ¼çæ
å¾ä¼å
$grid->fields
$grid->setField()
$grid->filters
$grid->filters()
$grid->setFilter()
$this->tools
$this->tools()
$grid->setTool()
$grid->table()
Imageå¾çä¿®é¥°
å¯¹å¾çè¿è¡å æ°´å°åç¼©æ¾æä½
ç®åä»£ç ä¾å­
//åå»ºå®ä¾
$image= new \System\Library\Image();

//è®¾ç½®å¾çå®½åº¦
$image->width=300;

//è®¾ç½®å¾çé«åº¦
$image->height=300;

//æºæä»¶è·¯å¾
$image->source='G:\fw.png';

//å¤çä¹åä¿å­è·¯å¾
$image->save='G:\fw300.png';

//æ°´å°å­ä½å¤§å°
$image->fontsize=20;

//å­ä½æä»¶è·¯å¾
$image->font=APP_DIR.'font/1.ttf';

//å¾çè´¨é
$image->quality=90;

//ææ¬æ°´å°
$image->text='text';

//æ¯å¦å¼å¯æ°´å°åè½ï¼é»è®¤false
$image->watermark=true;

//æ°´å°æä»¶å°åï¼å¾çä¼å
$image->markimg='G:\water.png';

//å¤çå¾çï¼è¿åå¸å°å¼
if($image->resize()){

    //å¤çç»æç¶æç 
    $image->code;
    
    //å¤çç»æè¿åä¿¡æ¯
    $image->message;
}

//å·ä½ç¶æç åç¶æä¿¡æ¯è¯·æ¥ç $image::MAG å¸¸é
Smtpåéé®ä»¶
SMTPé®ä»¶åé, æ¯æåéçº¯ææ¬é®ä»¶åHTMLæ ¼å¼çé®ä»¶
ä»£ç ä¾å­
//è®¾ç½®smtpæå¡å¨
$mail = new \system\library\Smtp([
    'server'=>'smtp.qq.com',
    'username' => ""name"",
    'password' => ""123456"",
    'port' => 25
  ]); 

//è®¾ç½®åä»¶äºº
$mail->from(""XXXXX""); 

//è®¾ç½®åä»¶äººåå­
$mail->fromname(""XXXXX""); 

//è®¾ç½®æ¶ä»¶äººï¼å¤ä¸ªæ¶ä»¶äººï¼è°ç¨å¤æ¬¡
$mail->to(""XXXXX""); 

//è®¾ç½®æéï¼å¤ä¸ªæéï¼è°ç¨å¤æ¬¡
$mail->cc(""XXXX""); 

//è®¾ç½®ç§å¯æéï¼å¤ä¸ªç§å¯æéï¼è°ç¨å¤æ¬¡
$mail->bcc(""XXXXX""); 

//è®¾ç½®é®ä»¶ä¸»é¢
$mail->subject(""test""); 

//è®¾ç½®é®ä»¶åå®¹
$mail->body(""<b>test</b>"");

//åéé®ä»¶ï¼è¿åå¸å°å¼
if($mail->send()){
    //åéæå
}else{
    //åéå¤±è´¥ï¼è¿åéè¯¯ä¿¡æ¯
    $mail->error();
}
Captchaéªè¯ç çæ
$captcha->bgcolor å±æ§
è®¾ç½®éªè¯ç èæ¯16è¿å¶é¢è²
$captcha->bgcolor='#333333';
$captcha->showBorder å±æ§
è®¾ç½®æ¯å¦æ¾ç¤ºè¾¹æ¡ï¼å¸å°å¼
$captcha->showBorder=true;
$captcha->borderColor å±æ§
è®¾ç½®éªè¯ç è¾¹æ¡16è¿å¶é¢è²
$captcha->borderColor='#cccccc';
$captcha->charLen å±æ§
è®¾ç½®éªè¯ç çä½æ°
$captcha->charLen=4;
$captcha->fontPath å±æ§
è®¾ç½®å­ä½æ¾ç½®ç®å½,ç»å¯¹è·¯å¾ï¼é»è®¤ç®å½APP_DIR/font/
$captcha->fontPath=APP_DIR.'/font/';
$captcha->width å±æ§
è®¾ç½®å¾çå®½åº¦ï¼åä½åç´ 
$captcha->height å±æ§
è®¾ç½®å¾çé«åº¦ï¼åä½åç´ 
$captcha->getCode() æ¹æ³
è·åçæçæå­ï¼ä»¥ä¾¿ä¿å­å°session
$captcha->create() æ¹æ³
çææ¸²æå¾å
$captcha->show() æ¹æ³
åéæ¾ç¤ºå°æµè§å¨
ç®åä»£ç ä¾å­
//åå¦å°å index.php?c=captcha&a=showimg

$authcode = new \system\library\Captcha();
$authcode->create();
$this->session->set('authcode', $authcode->getCode());
$authcode->show();

//html imgæ ç­¾æ¾ç¤º <img src=""index.php?c=captcha&a=showimg"" />
åºç¨ç¨åºç®å½å¸å±è¯´æ

applicationç®å½å¸¦*å·çç®å½å¿é¡»è®¾ç½®

|--system ç³»ç»æ¡æ¶ç¨åºç®å½ 
â--application åºç¨ç¨åºç®å½  
    |--helper   èªå®ä¹å·¥å·å¸®å©åº*  
    |--library  èªå®ä¹å¬å±ç±»åº  
    |--language è¯­è¨åç®å½*
    |--font     å­ä½ç®å½*
    |--document å¼åææ¡£ç®å½  
    |--module   æ§å¶å¨æ¨¡å*
    |    â--www  åºç¨æ¨¡åå  
    |       â--main.php å·ä½controllerä¸å¡é»è¾æä»¶  
    |--model modelæä»¶ç®å½*
    |   â--test.php å·ä½æ°æ®model 
    |--template  è§å¾æ¨¡æ¿æä»¶*
    |   â--www  æ¨¡åå   
    |       â--main.php å·ä½æ¨¡æ¿æä»¶  
    |--config éç½®æä»¶ç®å½*
    |   |--development å¼åç¯å¢éç½®  
    |   |   |--database.php æ°æ®åºéç½®æä»¶  
    |   |   |--constans.php å¸¸ééç½®æä»¶  
    |   |   â--redis.php rediséç½®æä»¶  
    |   |--test å¼åç¯å¢éç½®  
    |   |   |--database.php   
    |   |   |--constans.php   
    |   |   â--redis.php   
    |   â--production äº§åç¯å¢éç½®  
    |       |--database.php   
    |       |--constans.php   
    |       â--redis.php   
    |--inherit modelåcontrolleréåç»§æ¿ç®å½*
    |   |--controller.php   
    |   â--model.php   
    â--public  åºç¨ç¨åºå¥å£ç®å½  
        |--static éææä»¶èµæº  
        â--www  æ­¤ç®å½ç»ååç¨  
            â--index.php å¥å£æä»¶  

",19
getk2/k2,PHP,"

You've already been there... Joomla is a great content management system. In fact it's considered one of the best in the world. But the default article system in Joomla is both spartan and confusing to configure and template in newer versions! In Joomla 1.5 it was just a title and your content body. In Joomla 2.5 article images where introduced as separate fields (but without any auto-resizing) and in Joomla 3.x tags where introduced as a separate component. Have you seen the options to configure all these?
This is where K2 comes in.
K2 was built as a complete replacement of the default article system in Joomla. Install it like any Joomla extension, import your articles from the default Joomla article system and you instantly get a host of new features for your existing content: rich content forms for items (think of Joomla articles with additional fields for article images, videos, podcasts & other audio files, image galleries and attachments), hassle-free image management (uploaded item images are auto-resized to 6 configurable dimensions, either globally or per category - you can now forget about using Photoshop resizing!), comments, tagging, built-in options to extend content forms (e.g. to create product catalogs), powerful content modules fetching K2 content in any way you can imagine, frontend editing with easy to use access control settings (for content-heavy websites), powerful yet easy templating (and sub-templating) for going above the ""Joomla average"", extended user profiles, user groups, blogs, a powerful plugin API to extend item/category/user forms, ""drag and drop"" media manager and many more!
K2 is the ideal solution for managing your content, regardless of site ""size"": you can use it from a small blog to a complex corporate site or even a multi-author environment (portals, magazines etc.). To provide a practical example, using K2, you can transform your Joomla website to a news/magazine site with author blogs, product catalogs, work portfolio, knowledge base, download/document manager, directory listing, event listing and more, all this bundled under one package! And since K2 is extensible with additional fields to its base item form, you can easily create category-specific content types, e.g. article, blog post, product page, directory listing.
It's no wonder that K2 powers some of the biggest and most popular Joomla sites ever built worldwide!
These integrated features in K2 not only save website administrators precious management time (from managing a dozen extensions which would otherwise be required), but they also allow for better performance.
K2 was actually built on these 4 principles: feature-rich content in Joomla, ease of use (for any type of user), flexible templating, performance
And best of all? K2 is totally free to use!
Some facts about K2

Actively powers more than 300,000 websites worldwide (metrics are gathered since v2.7.0).
It has been downloaded more than 3 million times since March 2009.
Almost all template clubs provide K2 specific styling and display K2 as part of their demo sites.
There are hundreds of extensions supporting or integrating K2 in the Joomla Extensions Directory - see: https://extensions.joomla.org/search?q=k2
The Joomla Magazine and JoomlaGov.info (the directory for government websites built with Joomla) are powered by K2
K2 is used in some of the top Joomla websites worldwide by organizations like the Harvard University, The National Institute of Technology in Brazil, the UK's NHS, Top Gear, Groupama, Amnesty International, ActionAid, The High Court of Australia, Arturia, Cyrus Audio and many, many more.
K2 is co-designed and co-developed by JoomlaWorks (established in 2006) and Nuevvo (established in 2010), both award winning & acclaimed Joomla-centric companies.
K2 is compatible with Joomla 1.5, 2.5 and the latest 3.x releases.

Downloading K2
You can find the latest stable release on: https://getk2.org
If you are looking for the latest developer build (a snapshot from this Github repository) just use Github's ""Download ZIP"" button.
Resources
The K2 Community is the ultimate destination for everything K2! From discussions in the Community Forum to Extensions & Templates in the ""K2 Extensions Directory"", as well as a wealth of video tutorials, documentation, tips & a showcase of Joomla sites built with K2.
More at: https://getk2.org

Copyright Â© 2006-2018 JoomlaWorks Ltd. & Nuevvo Webware P.C.
",113
andrewrothstein/ansible-vagrant,None,"andrewrothstein.vagrant

Installs vagrant
Requirements
See meta/main.yml
Role Variables
See defaults/main.yml
Dependencies
See meta/main.yml
Example Playbook
-  hosts: servers
   roles:
     - andrewrothstein.vagrant
License
MIT
Author Information
Andrew Rothstein andrew.rothstein@gmail.com
",2
im-not-a-programmer/admin,Vue,"åå°ç®¡çç³»ç»éª¨æ¶
å®è£node_modules
npm install

å¼åç¯å¢
npm start

åå¸
npm run build

æµè¯ç¯å¢
npm run test

",2
ziangzhang10/data_bootcamp_final_project,Jupyter Notebook,"data_bootcamp_final_project
Satellite Data + Machine Learning: Final Project for the Rice Data Analytics Bootcamp.
",2
JohnnySn0w/MoD,JavaScript,"

MoD: MUD on Discord 
A wot?
For the uninitiated, a MUD is a Multi-User Dungeon. Think text-based adventure game, but as an online multiplayer game
And you stuck that on Discord?
Yeah, and man, rate limited messages per channel is a pain.
So yeah, the bot can take hand-crafted game modules and run a MUD with them. A skeleton on which to drape the flesh of world-building.
Ok. How do I run it?
See the Setup section of the wiki!

Features thus far:
Basic demo dungeon

This is the basic framework for a dungeon, and serves as a short example of what can be done at a simple level. It can easily be replaced with whatever your actual world is.

Administrative commands

db â allows for simple queries to the database, as well as functionality for on-the-fly creation of game elements
notbusy - a short-term fix for a higher level problem, fixes a player's busy status if the bot gets interrupted. Will be removed in the future when the true solution is implemented.
test â in-house manufactured unit testing

Player commands

Look â returns a description of items, rooms, npcs, enemies,
Move â change rooms in the mud
Attack â specify a target, and get whackin'
Stats â get a pm of current player stats
Talk â chat it up with an npc
Discard/Equip - discard or equip an item, respectively
Help - display available commands and syntax
Inventory - get a pm of your inventory

Prospective future features:

Automated generation of channels for game rooms from database entries
Custom player descriptions for RP
Change nickname for RP
Player housing

",2
HarryShomer/Hockey-Scraper,Python,"



Hockey-Scraper

Purpose
This package is designed to allow people to scrape both NHL and NWHL data. For the NHL, one can scrape the Play by Play
and Shift data off of the National Hockey League (NHL) API and website for all preseason, regular season, and playoff
games since the 2007-2008 season. For the NWHL, one is able to scrape the Play by Play data off of their API and website
for all preseason, regular season, and playoff games since the 2015-2016 season.

Prerequisites
You are going to need to have python installed for this. This should work for both python 2.7 and 3 (I recommend having
from at least version 3.6.0 but earlier versions should be fine).
If you donât have python installed on your machine, Iâd recommend installing it through the anaconda distribution. Anaconda comes with a bunch of libraries pre-installed so itâs easier to start off.

Installation
To install all you need to do is open up your terminal and type in:
pip install hockey_scraper


NHL Usage

Standard Scrape Functions
Scrape data on a season by season level:
import hockey_scraper

# Scrapes the 2015 & 2016 season with shifts and stores the data in a Csv file
hockey_scraper.scrape_seasons([2015, 2016], True)

# Scrapes the 2008 season without shifts and returns a dictionary containing the pbp Pandas DataFrame
scraped_data = hockey_scraper.scrape_seasons([2008], False, data_format='Pandas')

Scrape a list of games:
import hockey_scraper

# Scrapes the first game of 2014, 2015, and 2016 seasons with shifts and stores the data in a Csv file
hockey_scraper.scrape_games([2014020001, 2015020001, 2016020001], True)

# Scrapes the first game of 2007, 2008, and 2009 seasons with shifts and returns a Dictionary with the Pandas DataFrames
scraped_data = hockey_scraper.scrape_games([2007020001, 2008020001, 2009020001], True, data_format='Pandas')

Scrape all games in a given date range:
import hockey_scraper

# Scrapes all games between 2016-10-10 and 2016-10-20 without shifts and stores the data in a Csv file
hockey_scraper.scrape_date_range('2016-10-10', '2016-10-20', False)

# Scrapes all games between 2015-1-1 and 2015-1-15 without shifts and returns a Dictionary with the pbp Pandas DataFrame
scraped_data = hockey_scraper.scrape_date_range('2015-1-1', '2015-1-15', False, data_format='Pandas')

The dictionary returned by setting the default argument ""data_format"" equal to ""Pandas"" is structured like:
{
  # Both of these are always included
  'pbp': pbp_df,
  'errors': scraping_errors,

  # This is only included when the argument 'if_scrape_shifts' is set equal to True
  'shifts': shifts_df
}

Scraped files can also be saved in a separate directory if wanted. This allows one to re-scrape games quicker as we
don't need to retrieve them. This is done by specifying the keyword argument 'docs_dir' equal to True to automatically
create, store, and look in the home directory. Or you can provide your own directory where you want everything to be
stored (it must exist beforehand).
import hockey_scraper

# Create or try to refer to a directory in the home repository
# Will create a directory called 'hockey_scraper_data' in the home directory (if it doesn't exist)
hockey_scraper.scrape_seasons([2015, 2016], True, docs_dir=True)

# Path to the given directory
USER_PATH = ""/....""

# Scrapes the 2015 & 2016 season with shifts and stores the data in a Csv file
# Also includes a path for an existing directory for the scraped files to be placed in or retrieved from.
hockey_scraper.scrape_seasons([2015, 2016], True, docs_dir=USER_PATH)

# Once could chose to re-scrape previously saved files by making the keyword argument rescrape=True
hockey_scraper.scrape_seasons([2015, 2016], True, docs_dir=USER_PATH, rescrape=True)


Live Scraping
Here is a simple example of a way to setup live scraping. I strongly suggest checking out
this section of the docs if you plan on using this.
import hockey_scraper as hs


def to_csv(game):
    """"""
    Store each game DataFrame in a file

    :param game: LiveGame object

    :return: None
    """"""

    # If the game:
    # 1. Started - We recorded at least one event
    # 2. Not in Intermission
    # 3. Not Over
    if game.is_ongoing():
        # Get both DataFrames
        pbp_df = game.get_pbp()
        shifts_df = game.get_shifts()

        # Print the description of the last event
        print(game.game_id, ""->"", pbp_df.iloc[-1]['Description'])

        # Store in CSV files
        pbp_df.to_csv(f""../hockey_scraper_data/{game.game_id}_pbp.csv"", sep=',')
        shifts_df.to_csv(f""../hockey_scraper_data/{game.game_id}_shifts.csv"", sep=',')

if __name__ == ""__main__"":
    # B4 we start set the directory to store the files
    # You don't have to do this but I recommend it
    hs.live_scrape.set_docs_dir(""../hockey_scraper_data"")

    # Scrape the info for all the games on 2018-11-15
    games = hs.ScrapeLiveGames(""2018-11-15"", if_scrape_shifts=True, pause=20)

    # While all the games aren't finished
    while not games.finished():
        # Update for all the games currently being played
        games.update_live_games(sleep_next=True)

        # Go through every LiveGame object and apply some function
        # You can of course do whatever you want here.
        for game in games.live_games:
            to_csv(game)


NWHL Usage
Scrape data on a season by season level:
import hockey_scraper

# Scrapes the 2015 & 2016 season and stores the data in a Csv file
hockey_scraper.nwhl.scrape_seasons([2015, 2016])

# Scrapes the 2008 season and returns a Pandas DataFrame containing the pbp
scraped_data = hockey_scraper.nwhl.scrape_seasons([2017], data_format='Pandas')

Scrape a list of games:
import hockey_scraper

# Scrape some games and store the results in a Csv file
# Also saves the scraped pages
hockey_scraper.nwhl.scrape_games([14694271, 14814946, 14689491], docs_dir=""...Path you specified"")

Scrape all games in a given date range:
import hockey_scraper

# Scrapes all games between 2016-10-10 and 2017-01-01 and returns a Pandas DataFrame containing the pbp
hockey_scraper.nwhl.scrape_date_range('2016-10-10', '2017-01-01', data_format='pandas')

The full documentation can be found here.

Contact
Please contact me for any issues or suggestions. For any bugs or anything related to the code please open an issue.
Otherwise you can email me at Harryshomer@gmail.com.
",58
voken100g/AutoSSR,None,"Free ShadowsocksRåè´¹ ShadowsocksR æå¡
Latest update at: Sun May 12 02:18:48 UTC 2019

Introduction (English)
ä¸­æè¯´æ

20 stable servers:



ID
ASN
Server Country
Online




#.C51C
AS57494
Russia
18 hrs


#.3769
AS46844
United States
29 hrs


#.F90F
AS57494
Russia
166 hrs


#.3FE9
AS36352
United States
70 hrs


#.5B8A
AS36352
United States
12 hrs


#.ED26
AS203380
United Kingdom
14 hrs


#.973A
AS63949
Japan
18 hrs


#.BE3E
AS63949
United States
29 hrs


#.207F
AS63949
United States
29 hrs


#.B147
AS63949
Singapore
13 hrs


#.442C
AS40676
United States
21 hrs


#.B3BB
AS8075
United States
12 hrs


#.D254
AS40676
United States
12 hrs


#.F3D9
AS36352
United States
46 hrs


#.EA20

Japan
32 hrs


#.3008
AS56630
Italy
12 hrs


#.1A68
AS57494
Russia
12 hrs


#.9ED9
AS36352
United States
113 hrs


#.07A9
AS36352
United States
32 hrs


#.CF05
AS44220
Romania
60 hrs



39 online servers:



ID
ASN
Server Country
Online




#.C51C
AS57494
Russia
18 hrs


#.3769
AS46844
United States
29 hrs


#.A8BA
AS54600
China
1 hrs


#.F90F
AS57494
Russia
166 hrs


#.3FE9
AS36352
United States
70 hrs


#.5B8A
AS36352
United States
12 hrs


#.ED26
AS203380
United Kingdom
14 hrs


#.2DE5
AS57494
Russia
2 hrs


#.5607
AS63949
Japan
10 hrs


#.973A
AS63949
Japan
18 hrs


#.BE3E
AS63949
United States
29 hrs


#.207F
AS63949
United States
29 hrs


#.B147
AS63949
Singapore
13 hrs


#.418E
AS16509
Singapore
3 hrs


#.442C
AS40676
United States
21 hrs


#.B3BB
AS8075
United States
12 hrs


#.DB95
AS40676
United States
9 hrs


#.ECD6
AS40676
United States
10 hrs


#.D254
AS40676
United States
12 hrs


#.4C14
AS16509
Japan
1 hrs


#.8988
AS16509
Singapore
10 hrs


#.D833
AS16509
Japan
1 hrs


#.6F49
AS63949
Japan
9 hrs


#.F80F
AS51659
Russia
1 hrs


#.4AEC
AS31798
Canada
8 hrs


#.F3D9
AS36352
United States
46 hrs


#.B6E3
AS31798
Canada
10 hrs


#.DF1F
AS16509
South Korea
10 hrs


#.A07C
AS16509
South Korea
1 hrs


#.EA20

Japan
32 hrs


#.3008
AS56630
Italy
12 hrs


#.EE8F
AS40676
India
10 hrs


#.1A68
AS57494
Russia
12 hrs


#.186F
AS56630
Russia
8 hrs


#.24E2
AS63949
Japan
7 hrs


#.9ED9
AS36352
United States
113 hrs


#.07A9
AS36352
United States
32 hrs


#.03E7
AS56322
Hungary
4 hrs


#.CF05
AS44220
Romania
60 hrs



46 recent servers:



ID
ASN
Server Country
Online




#.C51C
AS57494
Russia
18 hrs


#.3769
AS46844
United States
29 hrs


#.A8BA
AS54600
China
1 hrs


#.F90F
AS57494
Russia
166 hrs


#.3FE9
AS36352
United States
70 hrs


#.5B8A
AS36352
United States
12 hrs


#.ED26
AS203380
United Kingdom
14 hrs


#.1C65
AS57494
Russia
1 hrs offline


#.2DE5
AS57494
Russia
2 hrs


#.E1D5
AS57494
Russia
1 hrs offline


#.5607
AS63949
Japan
10 hrs


#.D1A6
AS35916
United States
1 hrs offline


#.973A
AS63949
Japan
18 hrs


#.BE3E
AS63949
United States
29 hrs


#.207F
AS63949
United States
29 hrs


#.B147
AS63949
Singapore
13 hrs


#.418E
AS16509
Singapore
3 hrs


#.442C
AS40676
United States
21 hrs


#.B3BB
AS8075
United States
12 hrs


#.DB95
AS40676
United States
9 hrs


#.ECD6
AS40676
United States
10 hrs


#.D254
AS40676
United States
12 hrs


#.17C3
AS137571
China
1 hrs offline


#.4C14
AS16509
Japan
1 hrs


#.8988
AS16509
Singapore
10 hrs


#.D833
AS16509
Japan
1 hrs


#.6F49
AS63949
Japan
9 hrs


#.F80F
AS51659
Russia
1 hrs


#.E21E
AS16509
Singapore
1 hrs offline


#.4AEC
AS31798
Canada
8 hrs


#.F3D9
AS36352
United States
46 hrs


#.B6E3
AS31798
Canada
10 hrs


#.DF1F
AS16509
South Korea
10 hrs


#.A07C
AS16509
South Korea
1 hrs


#.EA20

Japan
32 hrs


#.3008
AS56630
Italy
12 hrs


#.EE8F
AS40676
India
10 hrs


#.EA15
AS40676
United States
1 hrs offline


#.1A68
AS57494
Russia
12 hrs


#.186F
AS56630
Russia
8 hrs


#.CC09
AS4760
Hong Kong
6 hrs offline


#.24E2
AS63949
Japan
7 hrs


#.9ED9
AS36352
United States
113 hrs


#.07A9
AS36352
United States
32 hrs


#.03E7
AS56322
Hungary
4 hrs


#.CF05
AS44220
Romania
60 hrs



",27
guyellis/plant,JavaScript,"plant
Running live at Plaaant
To get a feel a well chronicled orchard of fruit trees visit
Guy Ellis' Orchard
and use the ""Filter"" input near the top of the page to find fruit trees you might be interested
in learning about.
Plant is a website app to help you manage growing trees and plant.





Project Objectives

Versions
Questions


For Developers

Architecture Notes
Developer Setup



Objectives

Allow users to track the plants that they're growing.

Provide stats on growth rates.
Pull in weather information.
Compare against other growers.


Allow users to research plants to grow.

Users can search within a radius of their location for plants others are
growing.
Users can determine likelihood of success.


Assist users in management of their plants.

Send alerts to users when action needs to be taken based on time-of-year
or on weather. For example, should prune/fertilize on X Date, or ""there's
a freeze warning, you need to protect your avocado tree.""


Usability

Users should be able to post entries about a tree from their yard on a smart
phone.
Users should be able to take photos and add them to a plant entry from
their smart phone while making a post.
Users should be able to operate the app while disconnected with syncing
done later.



Versions
0.0.1 MVP

User can create an account using OAuth from their Google account.
User can add/delete/update each plant in their yard.
User can add entries to each plant. Each entry will have a date and
details.

0.0.2 and beyond

Add features/fields to user's account.

Add Facebook as OAuth option.
Allow user to add their GPS location to their account.


Add features to a plant post.

Allow photos to be added.
Add markdown for details to allow for formatting.


Add structured fields for each plant.

Dates for planting, germination.
Multi-bud - treat each scion as its own tree but group on this.
Perennial/annual (other?)


Add structured fields for data entry posts.

E.g. height, width etc. to calculate growth rates.
Applications of fertilizer, mulch etc for reporting on growth effectiveness.
Start and end dates for harvest. (Allow for reporting on year round
production and prediction.)
Volume harvested.


Perform calculations on entries to show changes. e.g. growth in gallons per
week.
Use user's GPS location to pull in weather data from date of first plant
entry to current date.
Keep user's weather data up-to-date.
Use user's GPS location to allow them to compare their plants to the same
plants in nearby locations.
Allow users to add parentage/genealogy to their plants.

i.e. if another user gave them a plant or they planted another plant from
one that they're already documenting on the system then they can link a parent
plant.


Support multi-bud trees.

Allow for structured data entry for root stock(s) and multiple scions.
Allow dates for adding scions to trees.


Allow for termination date of plants.

Distinguish between perennial and annuals. i.e. plants that are designed
to die annually and those that aren't. Helps in reporting life and reason
for death or disposal of perennial.


Search

User can find a male pollinator for their female plant within a certain
radius of their location.



Questions
If you have questions or want to communicate with the maintainers of the
project then please create an issue.
For Developers
Architecture
Components
plant
Components in the /app/components/plant folder.
Component naming uses CRUD (Create, Read, Update, Delete) names to identify what the component does.

Plant

Container for showing and managing a single plant
All other components in this section are used by the Plant component directly or indirectly. i.e. Plant is the top parent


PlantRead

Shows the details of the Plant
PlantEdit hidden


PlantEdit

Create or Update a Plant.
PlantRead hidden


Notes

Manages the Hide/Show ""add note"" functionality
Container to show a list of Notes


NoteEdit

Create or Update a Note.


NoteRead

Shows the details of a Note



plants
Components in the /app/components/plants folder.
Components for managing a collection and the listing of plants.
Developer Setup
Facebook and Google OAuth
You can start the site without setting up Facebook credentials.
As long as the NODE_ENV is not set to production you will be able to login as a dev user.
You do, however, need to set the Facebook and Google environment variables to a non-empty value.
In your ~/.bashrc or equivalent file (or a script you source before you start the server) set the following:
export PLANT_FB_ID=<facebook-app-id>
export PLANT_FB_SECRET=<facebook-app-secret>
export PLANT_GOOGLE_ID=<google-app-id>
export PLANT_GOOGLE_SECRET=<google-app-secret>

If want to use Facebook OAuth then you'll need to setup credentials.
(As with any site, the layout and options change over time so these instructions are an approximation.)

Go to developers.facebook.com and on the menus click on My Apps and then select Add a New App.
Select a WWW Website.
Add a name (Plant is good) and click Create New Facebook App ID.
There's a button to the top right to Skip Quickstart - hit that.
You should end up on the Dashboard. From here you want the App ID and App Secret.
Set the PLANT_FB_ID and PLANT_FB_SECRET environment variables to these values.

MongoDB
If you have Docker installed then it will pull down and spin-up MongoDB for you when you start the server.
Otherwise, you need to install Docker (recommended) or MongoDB.
Running the site

Clone the repo locally.
npm i
Terminal Window #1: npm run server

Starts the server on port 3001 using the /devops/run-server.sh script. Edit this script to fine tune how the server starts.


Terminal Window #2: npm start

Starts the Webpack Dev Server on port 9090


Navigate: http://localhost:9090

Running the tests
npm t

Debugging with VSCode

Start MongoDB
Terminal #1: Start the App/API Server with npm run server
Terminal #2: Start the Dev Server with npm start
VSCode: Select Chrome from Debug launch options and hit F5

",6
xndcn/smzdm.com,None,"smzdm.com
",10
narcitymedia/lilium-cms,JavaScript,"
Lilium CMS V4
Lilium is a lightning-fast, web based content management system built with Node.JS. Its power resides in its intelligent caching engine which reduces CPU usage, RAM, and database access.
If server-side rendering is preferred over client-side rendering, Lilium offers a simplified way of generating HTML documents, storing them on disk or RAM, and serving them faster than most HTML preprocessors. It is possible to use either LML2 which ressembles PHP, or LML3 which is an easy to use routine using Javascript template strings.
The platform has its own framework and unique API. Lilium makes it easy to create a mobile app for a website, and is network based. It can hold multiple domains for a single instance, can use multiple different databases. It is compatible with content delivery network services.
Lilium does not use Express, Mongoose, or other heavy libraries. Instead, it implements its own web server using native NodeJS libraries.
Open source details
Narcity Media is using Lilium CMS in production. However, it is currently using the V3. That means this version is not ready for production just yet. We still invite you to try the CMS and have fun with it, but we recommend to wait until the V4 is stable before deploying a website.
Installation guide
All NodeJS packages are to be installed, and are documented in the package file. You can simply run npm run setupdev in the Lilium root folder.
Automated installation
Lilium was built on Linux, and is meant to be run on Linux. Even though it will technically work on Mac, Lilium is not guaranteed to be stable on other operation systems.
The CMS requires NodeJS v8+, and MongoDB v3+. You can follow online tutorials on how to install both of these before running the npm scripts, but it's a faily simple process.
Installing NodeJS
You can follow this tutorial from the official NodeJS website.
From the nodesource instructions
# Using Ubuntu
curl -sL https://deb.nodesource.com/setup_11.x | sudo -E bash -
sudo apt-get install -y nodejs

# Using Debian, as root
curl -sL https://deb.nodesource.com/setup_11.x | bash -
apt-get install -y nodejs

Installing MongoDB
You can follow this tutorial from the official MongoDB website.
Only run one of the following depending on your Ubuntu distro
# For Ubuntu 18
echo ""deb [ arch=amd64 ] https://repo.mongodb.org/apt/ubuntu bionic/mongodb-org/4.0 multiverse"" | sudo tee /etc/apt/sources.list.d/mongodb-org-4.0.list

# For Ubuntu 16
echo ""deb [ arch=amd64,arm64 ] https://repo.mongodb.org/apt/ubuntu xenial/mongodb-org/4.0 multiverse"" | sudo tee /etc/apt/sources.list.d/mongodb-org-4.0.list

# For Ubuntu 14
echo ""deb [ arch=amd64 ] https://repo.mongodb.org/apt/ubuntu trusty/mongodb-org/4.0 multiverse"" | sudo tee /etc/apt/sources.list.d/mongodb-org-4.0.list

Then
sudo apt-get update
sudo apt-get install -y mongodb-org
sudo service mongod start

And MongoDB should be running. To make sure the installation was successful, you can open a shell using mongo.
Installing Lilium for development
You can clone Lilium in your favourite installation directory. At Narcity Media, we like to use /usr/share/lilium or ~/dev/lilium. Make sure the directory is owned by you, not by root. Also make sure to install it in a directory that is also owned by you since other sibling directories might be needed.
Simply cd to the directory you want to use, and git clone https://github.com/narcitymedia/lilium-cms.
Then, cd lilium-cms and npm install && npm run setupdev.
Once the installation process exits, you can start the CMS using npm start or node index.prod.js. Your browser should load the CMS if you browse to localhost:8080/lilium.
The development username and password are : lilium and lilium. Make sure to change them if you plan on deploying on a production machine.
Web panel for development
The CMS frontend is located under /apps/lilium. It is a Preact app, and is transpiled using Webpack and Babel.
Required dependencies
MAC:
brew install pkg-config cairo libpng jpeg giflib imagemagick redis
UBUNTU:
sudo apt-get install libcairo2-dev libjpeg8-dev libpango1.0-dev libgif-dev build-essential g++ libkrb5-dev imagemagick redis-server
The dependencies will be installed automatically during the npm run setupdev process. You can however install then manually if you prefer.
Localhost connections to MongoDB
If mongo still refuses to connect from NodeJS eventhough it works using the terminal cli, you might have to enable or disable authentication from your mongo config file (typically located in /etc/mongod.conf, under security: authentication).
This information can be found easily online using search queries such as ""Enable MongoDB authentication"". We ran into this issue on multiple occasion, and it ended up being a different solution every time.
MongoDB with brew
On Mac, sometimes the MongoDB service will refuse connections from Lilium for obscure reasons. Our temporary solution it to start a mongod instance in a seperate terminal and add the desired parameters including the database path and authentation db. You also get an additional output stream from mongod.
There likely is a better solution to make this work with brew service, but like mentionned earlier, we don't actively support MacOS nor do we recommend to run Lilium in production on a different OS than Linux.
I want to code, too
That must mean you're amazing. See the Lilium CMS Wiki and get started!
Script mode
It is possible to run a Javascript file in script mode. It will prevent Lilium from loading the listeners, CAIJ and other modules related to networking. The websites and databases will still be loaded on a single thread, and the script passed as an argument will be executed.
node ./includes/runscript.js [script.js]
Random quote API
In older version, we used a random quote provider to add a cute message to The Daily Lilium, which is Lilium's newspaper.
http://api.forismatic.com/api/1.0/?method=getQuote&format=json&lang=en
Working with nginx
Nginx works well with Lilium. The following configuration is the most simplified version you can use. The config works with a Lilium instance located at /usr/share/lilium/lilium-cms, and runs at port 8080.
Since Lilium does not handle HTTPS requests, using nginx in front of Lilium makes it possible to have a fully operational SSL website running on Lilium, without the SSL overhead during the local proxy upstream.
Using Certbot or LetsEncrypt, you can quicky generate an HTTPS cert.
Basic nginx configuration file
upstream lilium_proxy  {
        server 127.0.0.1:8080;
        keepalive 64;
}

map $http_sec_websocket_key $upgr {
    """"      """";           # If the Sec-Websocket-Key header is empty, send no upgrade header
    default ""websocket"";  # If the header is present, set Upgrade to ""websocket""
}

map $http_sec_websocket_key $conn {
    """"      $http_connection;  # If no Sec-Websocket-Key header exists, set $conn to the incoming Connection header
    default ""upgrade"";         # Otherwise, set $conn to upgrade
}

proxy_cache_path /usr/share/lilium/html/nginxcache levels=1:2 keys_zone=my_cache:10m max_size=10g inactive=60m use_temp_path=off;

server {
        listen 80;

        server_name localhost;
        # port_in_redirect off;

        large_client_header_buffers 8 32k;
        index index.html;

        location / {
                proxy_cache my_cache;
                proxy_cache_revalidate on;
                proxy_cache_min_uses 3;
                proxy_cache_use_stale error timeout updating http_500 http_502 http_503 http_504;
                proxy_cache_lock on;

                alias /usr/share/lilium/html/default/;
                try_files $uri $uri.html @lilium;
        }

        location /(lilium|login)/ {
                try_files @lilium =404;
        }

        location @lilium {
                proxy_set_header X-Real-IP $remote_addr;
                proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
                proxy_set_header Host $http_host;
                proxy_set_header Host $host;
                proxy_set_header X-NginX-Proxy true;

                # prevents 502 bad gateway error
                proxy_buffers 8 32k;
                proxy_buffer_size 64k;

                proxy_pass http://lilium_proxy;
                proxy_redirect off;

                # enables WS support
                proxy_http_version 1.1;
                proxy_set_header Upgrade $upgr;
                proxy_set_header Connection $conn;
        }
}

Production version
4.1.0
Founder

Erik Desjardins

Contributors

Erik Desjardins
Samuel Rondeau-Millaire
Daniel McAuley
Gabriel Cardinal
Narcity Media inc.


License
Mozilla Public License Version 2.0
About the license
TL;DR : You can use the CMS to make money as long as it remains open source. The typical use case involves no additional work.
Both individuals and businesses are allowed to use Lilium CMS.
You are allowed to host a copy of Lilium CMS, modify it, redistribute it, create something different with it.
One important thing to note : you must disclose the source code, copyright, and must document any modification done. A copy of the license must be available. However, this does not mean you need to credit Narcity Media on your website or anything of the sort. Simply make the source code available and highlight the modifications if any.
That being said, you can still use Lilium CMS for almost any purposes.
Like most open source licenses, Narcity Media is not liable if anything happens with your server, data, etc. Lilium CMS does not come with a warranty.
The previous information is not legal advice, but should give you a good idea.
Mozilla Public License Version 2.0 is a simple, permissive license with conditions easy to respect. There have a great FAQ here.
Copyright
Â© Narcity Media, 2019
",5
guyellis/plant-image-lambda,JavaScript,"plant-image-lambda

Image Lambda for Plant Project
Data Flow
Notes
During the upgrade from Node 4 to Node 8 more dependencies were added. This caused the code
size (of the zip package) to increase from 2.4 MB to 5.4 MB. (July 1, 2018).
",2
tolo7010/hak.lnk,None,"hak.lnk
Project Name: hak.lnk
Description: Resource Links For Hackers
Author: tolo7010

General Web Penetration Guides / Courses / Tutorials
Mobile Penetration Guides / Courses / Tutorials
Tools
CTFs / Challenges / Labs
Vulnerability Database
Infosec News
Community Forums / Discussion Boards
Personal Blogs
Useful Git Projects

Please contact me if you see broken links or there are other interesting links which should be added.
",18
PCGen/pcgen,Java,"How to compile PCGen?
Check out our WIKI: http://wiki.pcgen.org/Building_PCGen
",247
Zongsoft/Zongsoft.CoreLibrary,C#,"Zongsoft.CoreLibrary
æ¦è¿°
Zongsoft.CoreLibrary ç±»åºæä¾äº.NETå¼åçå¸¸ç¨åè½éä»¥åä¸äºç¸å¯¹äº.NET BCLä¸­è¿è¡äºåè½å¼ºåçå®ç°ãéç¨C#è¯­è¨å¼åï¼æ¯æè·¨å¹³å°å¯è¿è¡å¨ WindowsãLinuxãMac OSX ç­å¹³å°ä¸­ã

æ¬¢è¿å¤§å®¶å¨ GitHub ä¸æäº¤åé¦ç»æä»¬ï¼ä¸ºæä»¬ç¹èµ(Star)ã
å¦æä½ æ¿æå¸®å©æä»¬å®åãç¿»è¯ææ¡£ï¼æåèä¾ä»£ç é½è¯·è´ä¿¡ç»æï¼zongsoft@gmail.comã9555843@qq.com
é¡¹ç®ç»æ


Common

è¯¥å½åç©ºé´ååæ¬ä¸äºå¸¸ç¨çå·¥å·ç±»ãå¶ä¸­åæ¬ç¸å¯¹ .NET BCL ä¸­è¿è¡äºåè½å¼ºåç Convert ç±»ï¼å¯¹æä¸¾ç±»åæä½ç EnumUtility ç±»ï¼ISequenceåºåå¨ãIAccumulatorç´¯å å¨æ¥å£ä»¥åä¸äºæ©å±ç±»ã



Collections

è¯¥å½åç©ºé´ååæ¬æå³éåçç±»ãå¶ä¸­åæ¬ç¸å¯¹.NET BCLä¸­ååéåç±»è¿è¡äºåè½å¼ºåç NamedCollectionBaseãCollection<T>ãQueue ç±»ï¼ä»¥åè¡¨ç¤ºæ åå±æ¬¡ç»æç HierarchicalNodeãHierarchicalNodeCollectionãCategoryãCategoryCollection è¿äºç±»ï¼ä»¥åä¸ä¸ªæ¯æçº¿ç¨å®å¨çæä¾å¯¹è±¡æ± ç®¡çç ObjectPool ç±»åæ¯ææå®å®¹ç§¯çåå­ç¼å­ObjectCacheã



Communication

è¯¥å½åç©ºé´ååæ¬è¿è¡éè®¯åèªå®ä¹éè®¯åè®®åè§£æçåºç±»ãæ¥å£ï¼è®¾è®¡éè®¯å¤çç¨åºæ¶åºå°½éä½¿ç¨è¿éå®ä¹çæ¥å£æåºç±»ãå·ä½å®ç°è¯·åè Zongsoft.Net é¡¹ç®ã


Composition

è¯¥å½åç©ºé´ååæ¬âæ§è¡ç®¡é(ExecutionPipelines)âæ¨¡å¼çå¨é¨æ¥å£åå®ç°ï¼æ§è¡ç®¡éæ¯ä¸å¥å¼ºå¤§çæ©å±æ¥å£æ¹æ¡ï¼éè®¯å±ç Communication.Net.TcpServer å Communication.Net.FtpServer ç±»åéç¨è¯¥æºå¶æ¥ä¿è¯æå¡å¨ç«¯çæ©å±æ§ã





ComponentModel

è¯¥å½åç©ºé´ååæ¬ä¸äºç¸å¯¹ .NET BCL ä¸­è¿è¡äºåè½å¼ºåç TypeConverterï¼è­¬å¦ï¼EnumConverterãCustomBooleanConverterãGuidConverter ç±»ï¼è¡¨ç¤ºåºç¨ç¨åºä¸ä¸æç ApplicationContextBase ç±»ï¼è¯¥åºç±»æä¾äºä¸ä¸ªåºç¨ç¨åºå¯è½ä¼ä½¿ç¨å°çå¸¸ç¨æå¡ï¼å¶ä¸­ç AliasAttribute ç±»å¯ç¨æ¥å®ä¹æä¸¾é¡¹æå¶ä»åç´ çå«ç§°ã



Data

è¯¥å½åç©ºé´ååæ¬è¿è¡æ°æ®è®¿é®ç¸å³ç±»åæ¥å£ï¼æä»¬æä¾äºä¸ä¸ªæ¯æå¤åºåæ¶è®¿é®ãæ¨ªååè¡¨çåå¸å¼å³ç³»åæ°æ®åºORMå¼æï¼æå³è¿ä¸ªå¼æçè¯¦ç»ä¿¡æ¯è¯·è®¿é® Zongsoft.Data é¡¹ç®ã



Diagnostics

è¯¥å½åç©ºé´ååæ¬æ¥å¿å¤çãè¯æ­è·è¸ªç¸å³çç±»åæ¥å£ã



Expressions

è¯¥å½åç©ºé´ååæ¬ä¸ä¸ªè¡¨è¾¾å¼è§£æä»¥åè¯æ³è§£æç­åè½å®ç°ã



IO

è¯¥å½åç©ºé´ååæ¬ä¸ä¸ªèææä»¶ç®å½ç³»ç»çåè½éï¼ä½¿ç¨è¯¥èææä»¶ç³»ç»å¯éç¦»ä¸åæä½ç³»ç»ä¸­IOå¤ççå·®å¼ï¼å¹¶æ¯æå¶ä»å¤é¨æä»¶ç³»ç»çæ©å±ãå·ä½å®ç°å¯åè Zongsoft.Externals.Aliyun è¿ä¸ªé¡¹ç®ä¸­çåå¸å¼æä»¶å­å¨é¨åã



Messaging

è¯¥å½åç©ºé´ååå«ä¸ä¸ªæ¶æ¯éåå¤ççæ½è±¡æ¥å£ï¼å·ä½å®ç°å¯åè Zongsoft.Externals.Aliyun è¿ä¸ªé¡¹ç®ä¸­çæ¶æ¯éåé¨åã



Options

è¯¥å½åç©ºé´ååå«äºä¸å¥éé¡¹éç½®å¤ççç±»åæ¥å£ï¼è¿å¥éé¡¹éç½®ä»¥æ åç»ææ¥ç»ç»åºç¨åçææéé¡¹éç½®æ°æ®ï¼è®¿é®è¿äºéç½®æ°æ®ä»¥éç¨çé»è¾è·¯å¾çæ¹å¼æ¥è¿è¡ã



Configuration

è¯¥å½åç©ºé´ååæ¬ä¸å¥å¨æ°çéç½®æä»¶çå¼åæ¥å£ï¼è¯¥å¥æ¥å£å®å¨å¼å®¹ .NET BCL ä¸­ç System.Configuration çç¼ç¨æ¨¡å¼ã


ä¸ºä»ä¹æä»¬è¦éæ°ç¼åä¸å¥ç±»ä¼¼çéç½®å¼åæ¥å£ï¼å ä¸º .NET BCL èªå¸¦çéç½®çæºå¶å¤ªè¿èè¿å¤æãå¹¶ä¸æ©å±æ§ä¹ä¸æ¯å¤ªåå¥½ï¼æä»¬å¸æåºç¨æ¨¡åçéç½®åºè¯¥åè¯¥åºç¨æ¨¡åä¸æ ·æ¯å¯è¢«æä»¶åçï¼å®ä»¬å¿é¡»å¯éæææå¹¶ä¸ä¿è¯æ¨¡åä¹é´çéç¦»æ§ï¼å½ä¸åæ¨¡åè¢«ç»è£å¨ä¸èµ·çæ¶åï¼è¿äºåç¦»çéé¡¹éç½®æ°æ®å°èªå¨ç»ç»æä¸ä¸ªå®æ´çé»è¾æ ã



Profiles

è¯¥å½åç©ºé´ååæ¬ä¸å¥å¯¹ Windows ä¸­ INI éç½®æä»¶çå¼åæ¥å£ï¼å¹¶ä¸æ¯æå¯¹ Section ä»¥å±æ¬¡ç»æçè®¿é®æ¹å¼ã





Reflection

è¯¥å½åç©ºé´ååæ¬ä¸ä¸ªå¯¹æåå¨æè®¿é®çç±»ã



Resources

è¯¥å½åç©ºé´ååæ¬ä¸ä¸ªå¯¹èµæºå¤çç ResourceUtility å·¥å·ç±»ã



Runtime


Caching

è¯¥å½åç©ºé´ååå« Buffer å Cache è¿ä¸¤ç§ç¼å­æºå¶çåè½éã



BufferManager æä¾äºå¨é¢ç¹åéä¸ç¡®å®å¤§å°çåå­çæ®µçåºæ¯ä¸çä¸ä¸ªå¾å¥½çè§£å³æ¹æ¡ï¼è­¬å¦å¨ TCP éè®¯ä¸­ï¼æ¥æ¶ç«¯å¹¶åçæ¶å°åä¸ªåéç«¯åéè¿æ¥çæ°æ®çæ®µï¼å¯ä»¥éç¨ BufferManager æ¥å°è¿äºä¸´æ¶æ°æ®çæ®µä¿å­èµ·æ¥å¾å°æ´ä¸ªæ°æ®åæ¥æ¶å®æåååé¦ç»ä¸å±åºç¨å®æ´çæ°æ®åã




ICache è¡¨ç¤ºæä½ç¼å­çæ¥å£ï¼MemoryCache æ¯å®çä¸ä¸ªåå­ç¼å­çå®ç°ï¼è¿ç¨ç¼å­æ¡ä¾å¯åè Zongsoft.Externals.Redis é¡¹ç®ã




Serialization

è¯¥å½åç©ºé´ååæ¬äºä¸å¥åºåååååºååçç¸å³ç±»åæ¥å£ï¼å¶ä¸­åæ¬åºäºå­å¸(Dictionary)çææ¬è¿ä¸¤ç§å¸¸ç¨åºååå®ç°ãç±äº .NET BCL ä¸­å¹¶æ²¡ææä¾å³äºåºååå¨çç»ä¸æ¥å£ï¼æä»¥ä½¿ç¨ ISerializer è¿ä¸ªæ¥å£å¯ä»¥éç¦»ç¹å®ææ¯çå®ç°ãéè¿ Serializer ç±»ç Json å±æ§å¯è·å¾ä¸ä¸ªææ¬åºååå¨ï¼éè¿ DictionarySerializer ç±»ç Default å±æ§å¯è·å¾ä¸ä¸ªå­å¸åºååå¨ã





Security

è¯¥å½åç©ºé´ååæ¬ä¸ä¸ª PasswordUtility å¯ç æä½çå·¥å·ç±»ï¼ä»¥åä¸å®å¨ãææç¸å³çåºç±»åæ¥å£ã


Membership

è¯¥å½åç©ºé´ååæ¬ä¸å¥å®æ´çåºäºè§è²å®å¨çææç®¡çæ¥å£ï¼å®è¿åå«äºä¸ä¸ªæä½³å®è·µçæ¹æ¡ãå·ä½å®ç°è¯·åè Zongsoft.Security é¡¹ç®ã





Services

è¯¥å½åç©ºé´ååæ¬ä¸å¥æå¡è®¿é®åç®¡çç IServiceProviderãIServiceProviderFactory æ¥å£åå®ç° ServiceProviderãServiceProviderFactoryï¼ä»¥åä¸å¥æå³å½ä»¤è£éæ¨¡å¼çæ¥å£åå®ç°ï¼è¿æä¸ä¸ªåå°æå¡çå·¥ä½è IWorker æ¥å£å WorkerBase åºç±»ã



Terminals

è¯¥å½åç©ºé´ååæ¬ä¸å¥ç»ç«¯ç¨åºçæ¥å£åå®ç°ï¼ä½¿ç¨è¯¥å®ç°å¯ä»¥å¿«éçå®æä¸ä¸ªå¼ºå¤§çåºäºæ§å¶å°çåºç¨ã


Commands

è¯¥å½åç©ºé´ååæ¬å³äºç»ç«¯ç¨åºçä¸äºå¸¸ç¨å½ä»¤çå®ç°ç±»ï¼è­¬å¦ ExitCommandãClearCommandãHelpCommand ç­ç±»ã





Text

è¯¥å½åç©ºé´ååæ¬ä¸å¥åºäºæ­£åè¡¨è¾¾å¼çææ¬è¡¨è¾¾å¼çè§£æãå¤ççç±»ã



Transactions

è¯¥å½åç©ºé´ååæ¬æå³äºå¡çç±»åæ¥å£ï¼æå³åºç¨äºå¡æ¯æçå®ç°å¯åè Zongsoft.Data æ°æ®å¼æ ä¸­çäºå¡æ¯æã



å¼ç¨è¯´æ
æ¬é¡¹ç®ä¸­çææä»£ç åæªåèè¿ä»»ä½ç¹å®å®ç°ï¼ç¹æ­¤å£°æï¼
ææåè®®

Zongsoft.CoreLibrary æ¯åºäº LGPL v2.1ææåè®®ã
æ¨å¯ä»¥å°æ¬é¡¹ç®åºç¨äºåä¸æ´»å¨ä¸­ï¼ä½æ¯å¿é¡»ç¡®ä¿å¯¹æ¬é¡¹ç®çå®æ´ï¼å«çæå£°æï¼å¼ç¨ï¼ä¸è¦åå²æé¨åå¼ç¨è¯¥é¡¹ç®çæºç ï¼æä»¬ä¿çè¿½ç©¶è¿åææåè®®çæå©ã


ä¸ºä»ä¹è¦å¼æºï¼
ä½æ±æ»´æ°´ä¹æºæ¢æ±å¤§æµ·ä¹å¿ã
",47
yin1999/code_sharing,C++,"æ­¤ä»£ç åºç¨äºä¿å­æåé¢æéè¿å¶å®éå¾æ¥è§¦å°æèè§£å³é®é¢äº§çä»£ç ã
",2
igortorres17/SGSA,Java,"SGSA
Sistema de Gerenciamento de ServiÃ§os Automotivos (SGSA) Ã© um software desenvolvido pelos estudantes HÃ©rcules Moreira, Igor Torres, Ricardo Otaviano e Matheus Cruvinel do curso de AnÃ¡lise e Desenvolvimento de Sistemas do Instituto Federal do TriÃ¢ngulo Mineiro. O programa foi proposto pelo professor da disciplina de ProgramaÃ§Ã£o Visual, Eduardo Siqueira.
Recursos
Gerenciamento de Clientes, ServiÃ§os, VeÃ­culos e PeÃ§as

Cadastro
VisualizaÃ§Ã£o
AlteraÃ§Ã£o
ExclusÃ£o

Ordem de ServiÃ§o (OS)

EmissÃ£o de Ordem de ServiÃ§o
InclusÃ£o de ServiÃ§os e PeÃ§as na OS
InclusÃ£o de MecÃ¢nico ResponsÃ¡vel
ImpressÃ£o de OS

AutenticaÃ§Ã£o

Acesso atravÃ©s de nome de usuÃ¡rio e senha
NÃ­veis de acesso (PermissÃ£o)

",2
Lombiq/Combinator,C#,"Combinator Orchard module Readme
Project Description
An Orchard CMS module that combines and minifies external stylesheets and javascript files to cut down on load times.
Features

Combines and minifies css files
Combines and minifies javascript files
If local and remote resources are mixed (like a local js files with one from a CDN) preserves their original order
Preserves conditional resources and minifies (if multiple with the same condition are after each other, also combines) them
Can combine remote (CDN) resources
Can embed images into stylesheets as data urls
Experimental image sprite generation support
Resource sets can be defined for better client-side caching: you can create sets of resources that are combined separately (e.g. all jQuery scripts can be in their individual file)
Ability to share processed resources between tenants in a multi-tenant application so a set of resources is only processed once, not for every tenant (resource sharing)
Busts browser cache when resources are updated (with a query string parameter containing a time stamp)
Ability to set custom resource domain
Exposing resource processing events
LESS and SASS preprocessors, contribution of Onestop Internet, Inc.
Command line command for emptying cache (""combinator empty"")
Info comment in bundled resources about which resources were combined
Tuned to be fast
With custom IStorageProvider can work in cloud hosting too (if there is no write access to the Media folder anyway)
Import/export settings
Administration page:

Adjust combination exclusion filter
Enable/disable combination of CDN resources
Set up resource domain
Enable/disable minification and adjust exclusion filter
Enable/disable image embedding and adjust exclusion filter
Enable/disable image sprite generation
Define resource sets
Enable/disable for admin site
Empty cache



The module is also available for DotNest sites.
You can download an install the module from the Orchard Gallery.
For known issues and future plans please see the Issue Tracker.
Please make sure to read the Documentation!
The module's source is available in two public source repositories, automatically mirrored in both directions with Git-hg Mirror:

https://bitbucket.org/Lombiq/combinator (Mercurial repository)
https://github.com/Lombiq/Combinator (Git repository)

Bug reports, feature requests and comments are warmly welcome, please do so via GitHub.
Feel free to send pull requests too, no matter which source repository you choose for this purpose.
This project is developed by Lombiq Technologies Ltd. Commercial-grade support is available through Lombiq.
",6
nemosminer/NemosMiner,PowerShell,"NemosMiner
Updated 12 May 2019






Copyright (c) 2018-2019 Nemo and MrPlus
This is free software, and you are welcome to redistribute it
under certain conditions.
https://github.com/nemosminer/NemosMiner/blob/master/LICENSE
by Nemo/Minerx117
with Help From MrPlusGH and grantemsley
 Click to Join Discord

Have questions? Need help? We're on Discord: https://discord.gg/2BCqPxe
NemosMiner Monitors mining pools in real-time in order to find the most profitable Algo
 GUI and easy configuration
 Auto Benchmarks Each algo to get optimal speeds 
 Fully automated 
 Auto Downloads Miners
 Auto Updates
 Monitoring


Easy configuration, easy start:
  Run NemosMiner.bat
  1. Config tab
  2. Set your Wallet address and Username
  3. Select your pool 
  4. Save Config
  5. Start
  
  note: 2. you only need to change Username if you are using Miningpoolhub
  
 Algo selection / removal

  +algo for algo selection
  -algo for algo removal

  If ""+"" Used, all selected algo have to be listed
  If ""Minus"" Used, all algo selected but exluded ones.

  Do not combine + and - for the same algo

 Examples:
 Algo list = -x16r
 Will mine anything but x16r

 Algo list = -x16r,-bcd
 Will mine anything but x16r and bcd

 Algo list = +x16r
 Will mine only x16r

 Algo list = +x16r,+bcd
 Will mine only x16r and BCD

 Algo list blank
 Will mine anything

Pools variants
  24hr - uses last 24hour Actual API too request profit
     -Low switching rate
  plus - uses advanced calculations to reduce switching
     -Medium switching rate
  normal - uses current estimate API too request profit
     -High switching rate

Developer/Contributors Donation:
list and wallets is publicly available at: https://nemosminer.com/data/devlist.json
  There is a 5 minute per day donation (0.3%), that can be changed in the config (Minimum is 3)0.2%
  We want to stay completely transparent on the way donations are managed in the product. Donations occurs once every 24 hours for the selected amount of time (default 5 minutes). The first donation sequence occurs 1 hour after miners are started. If Interval is set higher than the donation time, the interval will prime. Example for default parameters. Miners started at 10, First donation cycle runs at 10:55 untill 11, Next donation cycle occurs 24 hours after.All donation time and addresses are recording in the logs folder.

NemosMiner Monitoring Server : https://nemosminer.com
 Keep tabs on all your mining rigs from one place
 You can now optionally monitor all your workers remotely, both in the GUI and via https://nemosminer.com  
 Monitoring setup instructions https://nemosminer.com/setup.php 

GUI
  Since version 3.0 NemosMiner has a GUI making it easy to configure and run.
  Relies on config files. No need to edit bat files. Simply run NemosMiner 
  Set the config on the config tab, save, close, run

Pause mining
  Ability to pause miners while keeping other jobs running (pause button)
  This will stop mining activity
  BrainPlus will still run in the background avoiding the learning phase on resume
  EarningTracker will still run in the background avoiding the learning phase on resume

prerun
  Ability to run a batch prior switching to a specific algo.
  For example, can be used to set per algo OC via nvidiaInspector
  Simply create a file named <AlgoName>.bat in prerun folder
  If <AlgoName>.bat does not exist, will try to launch prerun/default.bat
  Use overclock with caution

Per pools config (Advanced)
    - **This is for advanced users. Do not use if you do not know what you are doing.**
    - You can now set specific options per pool. For example, you can mine NiceHash on the internal wallet and other pools on a valid wallet. This configuration is provided as an example in Config\PoolsConfig-NHInternal.json
      - Available options
        - Wallet = your wallet address
        - UserName = your MPH user name
        - WorkerName = your worker name
        - PricePenaltyFactor = See explanation below
    - Algorithm = List of included or excluded Aglo on pool (see example files)
      - Usage
        - The file Config\PoolsConfig.json contains per pool configuration details. If a pool is listed in this file,
    the specific settings will be taken into account. If not, the setting for the entry name default will be used.
    **Do not delete the default entry.**
        - Edit Config\PoolsConfig.json
        - Add an entry for the pool you want to customize
          - The name must be the NemosMiner name for the pool. ie. for ahashpool, if you use Plus. The name is ahashpoolplus.
          - (**careful with json formating ;)**)
          - Best way is to duplicate the default entry
    - Note that the GUI only updates the default entry. Any other changes need to be done manualy

PricePenaltyFactor
    - When using advanced per pool configuration, it is possible to add a penalty factor for a specific pool. This simply adds as a multiplicator on estimations presented by the pool.
    - Example scenario
      - NiceHash has a 4% fee - Set PricePenaltyFactor to 0.96 (1-0.04)
      - You feel like a pool is exaggerating his estimations by 10% - Set PricePenaltyFactor to 0.9

zergpoolplus/nlpoolplus/ahashpoolplus/zpoolplus/blazepoolplus/phiphipoolplus/blockmastersplus/hashrefineryplus
  Uses calculations based on 24hractual and currentestimate ahashpool prices to get more realistic estimate.
  Includes some trust index based on past 1hr currentestimate variation from 24hr.
  AND is NOT sensible to spikes.
  This shows less switching than following Current Estimate and more switching that following the 24hr Actual.
  Better profitability.

Earnings Tracking
  Displays BTC/H and BTC/D as well a estimation of when the pool payment threshold will be reached.
  Supported pools:
        ahashpool
        zpool
        nicehash
        miningpoolhub (partial)
  If mining more that one pools, shows stats for any supported pool
  Press key e in the console window to show/hide earnings

Support running multiple instances
  **Experimental**
  More than one instance of NemosMiner can run on the same rig
  Each instance must be placed in it's own directory
  Miner has to be started prior the launch of the next instance

Optional miners (Advanced)
  Some miners are not enabled by default in NemosMiner for a variety of reasons:
   
          These are closed source and therefore not enabled in NemosMiner by default.
          Use at your own risk.

  For advanced users, check the Optional Miners checkbox on the Config tab to enable these miners.

CustomMiners (Advanced)
  Users can place any miner.ps1 from miners/optionalminers or custom user created miner.ps1 files, in CustomMiners folder 
  leaving miners and optionalminers disabled in config will enable CustomMiners folder 

Algo switching log
  Simple algo switching log in csv switching.log file found in Logs folder.
  You can easily track switching rate.

Console Display Options
  Use -UIStyle Light or -UIStyle Full in config.json
        Full = Usual display (Default)
        Light = Show only currently mining info
  UIStyle automaticaly swtiches to Full during benchmarking.

In session console display toggle
  Press key s in the window to switch between light and full display
  Press key e in the window to show/hide earnings 
  Will toggle display at next refresh

New version notification
  NemosMiner will notify new version availability


If you have Windows 7, 8, or 8.1, please update PowerShell:
update PowerShell
some miners may need 'Visual C++ 2015' if you don't already have it: (install both x86 & x64)
Visual C++ Redistributable for Visual Studio 2015/2014
some miners may need 'Visual C++ 2013' if you don't already have it: (install both x86 & x64)
Visual C++ Redistributable for Visual Studio 2013/2012
running multiple cards its recommended to increase Virtual Memory 64gb is optimal
recommended/optimal Windows Nvidia driver 430.39
Windows10
Windows7, 8, 8.1
recommended/optimal Linux Nvidia driver 430.09
Linux/Hiveos
Made for & Tested with 6x1070 6x1070ti 6x1080 6x1080ti 6x1660ti 6x2060 6x2070 6x2080 6x2080ti(users have reported up to 12cards working have not tested myself)
Some miners do not support more that 9 cards

Licensed under the GNU General Public License v3.0
Permissions of this strong copyleft license are conditioned on making available complete source code of licensed works and modifications, which include larger works using a licensed work, under the same license. Copyright and license notices must be preserved. Contributors provide an express grant of patent rights. https://github.com/nemosminer/NemosMiner/blob/master/LICENSE
",218
firstcontributions/first-contributions,None,"



First Contributions
It's hard. It's always hard the first time you do something. Especially when you are collaborating, making mistakes isn't a comfortable thing. We wanted to simplify the way new open-source contributors learn & contribute for the first time.
Reading articles & watching tutorials can help, but what's better than actually doing the stuff in a practice environment? This project aims at providing guidance & simplifying the way beginners make their first contribution. If you are looking to make your first contribution, follow the steps below.
If you're not comfortable with command line, here are tutorials using GUI tools.
Read this in other languages.
ð®ð³
ð²ð²
ð®ð©
ð«ð·
ðªð¸

ð³ð±
ð±ð¹
ð·ðº
ð§ð¬
ð¸ð°
ð¯ðµ
ð»ð³
ðµð±
ð®ð·
ð®ð·
ð°ð· ð°ðµ
ð©ðª
ð©ð°
ð¨ð³
ð¹ð¼
ð¬ð·
ðªð¬
ð¸ð¦
ðºð¦
ð§ð·
ðµð¹
ð®ð¹
ð¹ð­
ð´
ð³ðµ
ðµð°
ð§ð©
ð²ð© ð·ð´
ð¹ð·
ð¸ðª
ð²ð¾
ð¸ð®
ð®ð±
ð¨ð¿

ð²ð½
ðµð­
ð¿ð¦
ð¿ð¦
ð°ðª
ð³ð¬

If you don't have git on your machine, install it.
Fork this repository
Fork this repository by clicking on the fork button on the top of this page.
This will create a copy of this repository in your account.
Clone the repository

Now clone the forked repository to your machine. Go to your GitHub account, open the forked repository, click on the clone button and then click the copy to clipboard icon.
Open a terminal and run the following git command:
git clone ""url you just copied""

where ""url you just copied"" (without the quote marks) is the url to this repository (your fork of this project). See the previous steps to obtain the url.

For example:
git clone https://github.com/this-is-you/first-contributions.git

where this-is-you is your GitHub username. Here you're copying the contents of the first-contributions repository in GitHub to your computer.
Create a branch
Change to the repository directory on your computer (if you are not already there):
cd first-contributions

Now create a branch using the git checkout command:
git checkout -b <add-your-new-branch-name>

For example:
git checkout -b add-alonzo-church

(The name of the branch does not need to have the word add in it, but it's a reasonable thing to include because the purpose of this branch is to add your name to a list.)
Make necessary changes and commit those changes
Now open Contributors.md file in a text editor, add your name to it. Don't add it at the beginning or end of the file. Put it anywhere in between. Now, save the file.

If you go to the project directory and execute the command git status, you'll see there are changes.
Add those changes to the branch you just created using the git add command:
git add Contributors.md

Now commit those changes using the git commit command:
git commit -m ""Add <your-name> to Contributors list""

replacing <your-name> with your name.
Push changes to GitHub
Push your changes using the command git push:
git push origin <add-your-branch-name>

replacing <add-your-branch-name> with the name of the branch you created earlier.
Submit your changes for review
If you go to your repository on GitHub, you'll see a  Compare & pull request button. Click on that button.

Now submit the pull request.

Soon I'll be merging all your changes into the master branch of this project. You will get a notification email once the changes have been merged.
Where to go from here?
Congrats!  You just completed the standard fork -> clone -> edit -> PR workflow that you'll encounter often as a contributor!
Celebrate your contribution and share it with your friends and followers by going to web app.
You could join our slack team in case you need any help or have any questions. Join slack team.
Now let's get you started with contributing to other projects. We've compiled a list of projects with easy issues you can get started on. Check out the list of projects in web app.
Additional material
Tutorials Using Other Tools











GitHub Desktop
Visual Studio 2017
GitKraken
Visual Studio Code



Self-Promotion
If you liked this project, star it on GitHub.
If you're feeling especially charitable, follow Roshan on
Twitter and
GitHub.
 
",6630
luyikk/NetX,C#,"NetX
è°­éäºRPCåACTORçå®ç¾ç»å
",2
bg1bgst333/Sample,Java,"Sample
Sample Program
",4
knqyf263/fanal,Go,"fanal
Static Analysis Library for Containers





Feature

Detect OS
Extract OS packages
Extract libraries used by an application

Bundler, Composer, npm, Pipenv, Cargo



Example
See cmd/fanal/
package main

import (
	""context""
	""flag""
	""fmt""
	""log""
	""os""

	""golang.org/x/xerrors""

	""github.com/knqyf263/fanal/cache""

	""github.com/knqyf263/fanal/analyzer""
	_ ""github.com/knqyf263/fanal/analyzer/library/bundler""
	_ ""github.com/knqyf263/fanal/analyzer/library/composer""
	_ ""github.com/knqyf263/fanal/analyzer/library/npm""
	_ ""github.com/knqyf263/fanal/analyzer/library/pipenv""
	_ ""github.com/knqyf263/fanal/analyzer/library/cargo""
	_ ""github.com/knqyf263/fanal/analyzer/os/alpine""
	_ ""github.com/knqyf263/fanal/analyzer/os/amazonlinux""
	_ ""github.com/knqyf263/fanal/analyzer/os/debianbase""
	_ ""github.com/knqyf263/fanal/analyzer/os/opensuse""
	_ ""github.com/knqyf263/fanal/analyzer/os/redhatbase""
	_ ""github.com/knqyf263/fanal/analyzer/pkg/apk""
	_ ""github.com/knqyf263/fanal/analyzer/pkg/dpkg""
	_ ""github.com/knqyf263/fanal/analyzer/pkg/rpm""
	""github.com/knqyf263/fanal/extractor""
	""golang.org/x/crypto/ssh/terminal""
)

func main() {
	if err := run(); err != nil {
		log.Fatal(err)
	}
}

func run() (err error) {
	ctx := context.Background()
	tarPath := flag.String(""f"", ""-"", ""layer.tar path"")
	clearCache := flag.Bool(""clear"", false, ""clear cache"")
	flag.Parse()

	if *clearCache {
		if err = cache.Clear(); err != nil {
			return xerrors.Errorf(""error in cache clear: %w"", err)
		}
	}

	args := flag.Args()

	var files extractor.FileMap
	if len(args) > 0 {
		files, err = analyzer.Analyze(ctx, args[0])
		if err != nil {
			return err
		}
	} else {
		rc, err := openStream(*tarPath)
		if err != nil {
			return err
		}

		files, err = analyzer.AnalyzeFromFile(ctx, rc)
		if err != nil {
			return err
		}
	}

	os, err := analyzer.GetOS(files)
	if err != nil {
		return err
	}
	fmt.Printf(""%+v\n"", os)

	pkgs, err := analyzer.GetPackages(files)
	if err != nil {
		return err
	}
	fmt.Printf(""Packages: %d\n"", len(pkgs))

	libs, err := analyzer.GetLibraries(files)
	if err != nil {
		return err
	}
	for filepath, libList := range libs {
		fmt.Printf(""%s: %d\n"", filepath, len(libList))
	}
	return nil
}

func openStream(path string) (*os.File, error) {
	if path == ""-"" {
		if terminal.IsTerminal(0) {
			flag.Usage()
			os.Exit(64)
		} else {
			return os.Stdin, nil
		}
	}
	return os.Open(path)
}


Notes
When using latest tag, that image will be cached. After latest tag is updated, you need to clear cache.
",3
PCSX2/pcsx2,C++,"PCSX2
  
PCSX2 is a free and open-source PlayStation 2 (PS2) emulator. Its purpose is to emulate the PS2's hardware, using a combination of MIPS CPU Interpreters, Recompilers and a Virtual Machine which manages hardware states and PS2 system memory. This allows you to play PS2 games on your PC, with many additional features and benefits.
Project Details
The PCSX2 project has been running for more than ten years. Past versions could only run a few public domain game demos, but newer versions can run many games at full speed, including popular titles such as Final Fantasy X and Devil May Cry 3. Visit the PCSX2 homepage to check the latest compatibility status of games (with more than 2000 titles tested), or ask for help in the official forums.
The latest officially released stable version is version 1.4.0.
Installers and binaries for both Windows and Linux are available from our website.
Development builds are also available from our website.
System Requirements
Minimum

OS: Windows Vista SP2 or newer or GNU/Linux (32-bit or 64-bit)
CPU: Any that supports SSE2 (Pentium 4 and up, Athlon64 and up) @ 1600 STR or better
GPU: DirectX 10 GPU or better
RAM: 2GB or more

Recommended

OS: Windows 7/8/8.1/10 (64-bit) or GNU/Linux (64-bit)
CPU: Intel Haswell (or AMD equivalent) @ 2000 STR or better
GPU: DirectX 11 GPU or greater
RAM: 4GB or more

Notes


You need the Visual C++ 2015 x86 Redistributables for this version to work.
Note: Visual C++ 2017 is directly compatible with Visual C++ 2015. While the project is built with Visual C++ 2015, either version will work.


PCSX2 1.4.0 is the last stable version to support Windows XP and Direct3D9. Windows XP is no longer getting updates (including security-related updates), and graphics drivers for Windows XP are older and no longer maintained.


Make sure to update your operating system, drivers, and DirectX (if applicable) to ensure you have the best experience possible. Having a newer GPU is also recommended so you have the latest supported drivers.


Because of copyright issues, and the complexity of trying to work around it, you need a BIOS dump extracted from a legitimately-owned PS2 console to use the emulator. For more information about the BIOS and how to get it from your console, visit this page.


PCSX2 mainly takes advantage of 2 CPU cores. As of this commit PCSX2 can now take advantage of more than 2 cores using the MTVU speedhack. This can be a significant speedup on CPUs with 3+ cores, but it may be a slowdown on GS-limited games (or on CPUs with fewer than 2 cores).


Requirements benchmarks are based on a statistic from the Passmark CPU bench marking software. When we say ""STR"", we are referring to Passmark's ""Single Thread Rating"" statistic. You can look up your CPU on https://cpubenchmark.net to see how it compares to PCSX2's requirements.


Screenshots








",3220
autonomous-robot-competition2019/Team-Green,C++,"Team-Green
",2
terrence2/openfa,Rust,"OpenFA
An attempt at a black-box, open-source re-implementation of the Janes Fighters Anthology's engine.



Progress

The FA engine uses many different files. Some of these are standard formats; some of them are straightforward text;
but most are extremely weird relics of a bygone computing age.
Standard formats



Extension
Asset




11K
Sound


5K
Sound


8K
Sound


XMI
eXtended MIdi



Textual



Extension
Asset
Parsed




AI
AI Program



ECM
ECM Type



GAS
Fuel Tank Type



INF
Info Page Text



JT
proJectile Type
x


M
Mission
x


MM
Mission Map
x


MT
Mission Text



NT
Npc Type
x


OT
Object Type
x


PT
Plane Type
x


SEE
Sensor Type



SEQ
Scene Timelines



TXT
Campaign Blurbs




Portable Executable Wrapper



Extension
Asset
Parsed




BI
AI Binary



CAM
Campaign



DLG
Dialog Menus



FNT
Font
x


HGR




HUD




LAY
Terrain Palette
x


MC




MNU
Menus



MUS




PTS




SH
Shape
x



Custom Binary



Extension
Asset
Parsed




BIN




CB8




FBC




PAL
Palette
x


PIC
Picture
x


T2
Terrain
x


VDO
Video




Specific Format Notes

PAL: PALETTE.PAL is the only file of this type. It contains palette data consisting of 256 3-byte entries.
Each byte contains a 6-bit (VGA) color, so must be shifted by 2 for use in modern systems. Large parts of this
palette contain the ""transparent"" color #FF00FF. These sections are used by the terrain and (presumably) the HUD/menu
to give custom look and feel to each area and plane.
SH: Shape files contain a virtual machine using word codes inside the PE wrapper, with embedded fragments of x86.
Execution jumps between virtual and machine instructions in order to achieve most dynamic plane effects.
T2: Just heights and metadata about the terrain. The textures to be rendered onto that heightmap are stored
in the MM/M files in tmap and tdict sections. Both the textures and the base colors in the T2 itself are outside
the range of the base PALETTE.PAL and depend on a fragment of the LAY file being copied into the right part of
the palette. Time-of-day effects as well as distance fogging are acheived by swapping out the palette with values
from the LAY.
VDO: These files start with RATPAC, which is probably short for Rate-Packed. This is probably a standard
format of some sort. Unfortunately, a basic google search for files with that header turned up absolutely
nothing. We need a guru who knows about ancient video encoding standards.

Development Environment Setup

git clone https://github.com/terrence2/openfa.git
cd openfa
mkdir -p test_data/{un,}packed/{USNF,USMF,ATF,ATFNATO,ATFGOLD,USNF97,FA}/installdir
Copy *.LIB from the CD and Installation directory into test_data/packed/<GAME>/
Copy any loose T2 files from the Installation directory (ATFNATO and earlier only) into test_data/packed/<GAME>/installdir/
Install the Rust language via rustup.rs
(Optional) cd into apps/unlib and run cargo run -- -o ../../test_data/unpacked/<GAME>/<LIB> ../../test_data/packed/<GAME>/<LIB> on
each of the libs that you would like to have available as raw files. This are generally faster and easier to work with when
developing than the raw LIB files
Run sh_explorer by changing directory into apps/sh_explorer/ and running cargo run -- -t <GAME>:<FILE.SH> (for example cargo run -- -t FA:F18.SH)
Run mm_explorer by changing directory into apps/mm_explorer/ and running cargo run -- -t <GAME>:<FILE.MM> (for example cargo run -- -t FA:UKR.MM)

",3
zlgopen/awtk-lite-service,C,"awtk-lite-service
ä¸ºAWTKå¼åçè½»éçº§æå¡æ¡æ¶ï¼ä»¥åå¸¸è§æå¡çå®ç°ã
ä¸ãæ¦è¿°
å¨å¼åAWTKåºç¨ç¨åºæ¶ï¼ææ¶éè¦è°ç¨èæ¶å¾é¿çå½æ°ï¼å¦æå¨GUIçº¿ç¨ç´æ¥è°ç¨ï¼å°±ä¼é»å¡GUIçº¿ç¨ï¼è®©çé¢æ æ³å·æ°ãè¿æ¶æä»¬éè¦åå»ºä¸ä¸ªçº¿ç¨ï¼æè¿ä¸ªå½æ°æ¾å¨çº¿ç¨ä¸­æ§è¡ï¼è®©åæ­¥è°ç¨åæå¼æ­¥è°ç¨ï¼ç­å®æ§è¡å®æåéç¥GUIçº¿ç¨æ´æ°çé¢ã
å¤çº¿ç¨ç¼ç¨æ¯ä»¶éº»ç¦çäºæï¼å¾å®¹æåºç°éè¯¯ï¼èä¸åºç°é®é¢ä¹åå¾é¾æ¥æ¾åå ãlite-serviceçç®çå°±æ¯ä¸ºäºç®åè¿ä¸ªå¼åè¿ç¨ï¼å®æä¾äºä¸ä¸ªè½»éçº§çæå¡æ¡æ¶ï¼å¯ä»¥æ¹ä¾¿çå®ç°åºäºçº¿ç¨çæå¡ï¼èè°ç¨èä¸éäºè§£çº¿ç¨ç¸å³çä¸è¥¿ï¼å°±å¯ä»¥æåæ­¥è°ç¨è½¬æ¢æå¼æ­¥è°ç¨ã
é¤äºæå¡æ¡æ¶å¤ï¼æä»¬ä¹å°æä¾ä¸äºåºç¡çæå¡ï¼å¦ï¼å¼æ­¥åãHTTPç½ç»è¯·æ±ãåªä½æ­æ¾å¨åå¶å®ä¸äºå¸¸è§æå¡ã

è¯·æ³¨æ: è¿éåè®¾è°ç¨èæ¯GUIçº¿ç¨ï¼æ§è¡ç»æåäºä»¶ä¼åç»GUIçº¿ç¨ï¼äºä»¶å¤çå½æ°æ¯å¨GUIçº¿ç¨æ§è¡çï¼å¯ç´æ¥æä½GUIæ§ä»¶ã

1.ç¼è¯ï¼
æ¬é¡¹ç®ä¾èµAWTKï¼è¯·å°AWTKåå°åçº§ç®å½ï¼åç¼è¯AWTKï¼ç¶ååç¼è¯æ¬é¡¹ç®ï¼
scons

2.è¿è¡Demoï¼

å¼æ­¥è¯·æ±çdemo

./bin/demo_async


HTTPè¯·æ±çdemo

./bin/demo_http


æµè¯HTTPä¹åï¼éè¦ç¨nodejså¯å¨æ¬å°HTTPæå¡ï¼
node server/index.js


äºãæå¡æ¡æ¶
1. æå¡çç±»åã
å¸¸è§çæå¡æä»¥ä¸å ç§æåµï¼


å¨åå°çº¿ç¨æ§è¡ä¸ä¸ªå½æ°ï¼æ§è¡å®æåï¼å°ç»æè¿åç»è°ç¨èãæ¯å¦æå¼WIFIï¼æå¼å®åéç¥è°ç¨èï¼è°ç¨èæ´æ°çé¢ã


å¨åå°çº¿ç¨æ§è¡ä¸ä¸ªå½æ°ï¼å¨æ§è¡çè¿ç¨ä¸­ï¼æè¿åº¦ä¿¡æ¯éç¥è°ç¨èï¼ææ¶è°ç¨èä¹åæ¶æ§è¡ãå¦HTTPè¯·æ±å°±æ¯è¿æ ·ï¼ä¸è½½çè¿åº¦ä¿¡æ¯éè¦éç¥è°ç¨èï¼è®©ç¨æ·ç¥éå½åè¿åº¦ï¼ç¨æ·ä¹å¯ä»¥éæ¶åæ¶ä¸è½½ã


å¨åå°çº¿ç¨æ§è¡ä¸ä¸ªå½æ°ï¼å¨æ§è¡çè¿ç¨ä¸­ï¼æå¡è¿å¯ä»¥æ¥æ¶è°ç¨èçè¯·æ±ãå¦åªä½æ­æ¾å¨ï¼å¨æ­æ¾çè¿ç¨ä¸­å¯ä»¥æ¥åæåãåè¿ååéç­æä½ã


æå¡å¯ä»¥å®æå°±éåºï¼ä¹å¯ä»¥å¸¸é©»åå­ï¼éæ¶ååºè¯·æ±ã
2. è°ç¨èè¯·æ±æå¡


éè¿åå§ååæ°åè¯æå¡è¦åçäºæã


éè¿å±äº«ç¶æåè¯æå¡è¦åçäºæã


éè¿è¯·æ±éååè¯æå¡è¦åçäºæã


3. æå¡éç¥è°ç¨è
æå¡éè¿idle_queueå½æ°ï¼æäºä»¶/ç»æåéå°GUIçº¿ç¨ï¼å¨idleå½æ°ä¸­ï¼æ§è¡è°ç¨èæä¾çåè°å½æ°ãæä»¥å¨åè°å½æ°ä¸­å¯ä»¥ç´æ¥æä½GUIæ§ä»¶ã
4. åºç¡ç»ä»¶
æ ¹æ®ä»¥ä¸è¿äºæåµï¼lite serviceæä¾äºä¸äºåºç¡ç»ä»¶ï¼ä»¥ç®åå¼åè¿ç¨ã


**è¯·æ±éåã**è°ç¨èéè¿å®åéè¯·æ±ï¼æå¡éè¿å®ååè¯·æ±ã


**æå¡åºç±»ã**æä¾äºæå¡éè¦çåºç¡åè½ï¼å¹¶å®ä¹äºå·ä½æå¡éè¦å®ç°çæ¥å£ã


**æå¡çº¿ç¨ã**æå¡çº¿ç¨çç®¡çï¼ç®åæ²¡ä½¿ç¨çº¿ç¨æ± ï¼ä»¥åå®ééè¦è¿è¡å®åã


ä¸ãasyncæå¡
asyncæå¡æä¸ä¸ªåæ­¥å½æ°è½¬æä¸ä¸ªå¼æ­¥å½æ°ãä½¿ç¨æ¹æ³å¦ä¸ï¼
ä¸é¢è¿ä¸ªå½æ°èæ¶3ç§ï¼å¨GUIçº¿ç¨æ§è¡å°±ä¼è®©çé¢æ æ³å·æ°ï¼æä»¥éè¦å¼æ­¥åå¤çã
static ret_t do_sth_take_time(void* ctx) {
  sleep_ms(3000);

  return RET_OK;
}

ä¸ºäºè®©å®å¼æ­¥æ§è¡ï¼æä»¬å®ä¹ä¸ä¸ªæ¥åç»æçå½æ°(å¯éï¼å¦ä¸è¦æ§è¡ç»æï¼ä½¿ç¨NULLå³å¯)ï¼
static ret_t on_do_sth_take_time_done(void* ctx, ret_t result) {

  return RET_OK;
}

ç¶åè°ç¨async_callè½¬æ¢ä¸ºå¼æ­¥è°ç¨ï¼
async_call(do_sth_take_time, on_do_sth_take_time_done, widget);


å·ä½ç¨æ³è¯·åèï¼demos/demo_async.c

åãHTTPæå¡
ç®åå®ç°äºGET/POST/DELETE/PUTåç§æ¹æ³ï¼å¯ä»¥æ»¡è¶³å¸¸è§çREST APIè°ç¨ãä½ä¸éåå¤§æä»¶ä¼ è¾ååæ¶å¤§éå¹¶åè¯·æ±ã
æ¥åäºä»¶çåè°å½æ°çååï¼
typedef ret_t (*http_request_on_event_t)(void* ctx, http_request_t* request, http_response_t* resp);

åèµ·è¯·æ±çå½æ°ï¼
ret_t http_request(http_request_t* request);

å¦ï¼
  request = http_request_create_get(url, on_http_event, widget);
  http_request(request);


ä»¥ä¸å ç¹å¼å¾æ³¨æï¼

resp->done ä¸ºTRUEè¡¨ç¤ºè¯·æ±æåå®æã
resp->fail ä¸ºTRUEè¡¨ç¤ºè¯·æ±å¤±è´¥ã
resp->done æè resp->fail ä¸ºTRUEè¡¨ç¤ºè¯·æ±å®æäºï¼æ­¤æ¶æå¯ä»¥éæ¾requestå¯¹è±¡ã
resp->body æ¯è¿åçåå®¹ã
resp->body_size æ¯è¿åçåå®¹çé¿åº¦ã
resp->status_code æ¯HTTPååºç ã
resp->header æ¯ååºå¤´ã
è®¾ç½®request->abortæ å¿æ¥åæ¶è¯·æ±ï¼åæ¶è¯·æ±æ¯å¼æ­¥ã


å·ä½ç¨æ³è¯·åèï¼demos/demo_http.c

äºãåªä½æ­æ¾
åºäºffmpegå®ç°åªä½æ­æ¾åè½(TODO)
å­ãAPIææ¡£
APIææ¡£
",3
guyellis/plant,JavaScript,"plant
Running live at Plaaant
To get a feel a well chronicled orchard of fruit trees visit
Guy Ellis' Orchard
and use the ""Filter"" input near the top of the page to find fruit trees you might be interested
in learning about.
Plant is a website app to help you manage growing trees and plant.





Project Objectives

Versions
Questions


For Developers

Architecture Notes
Developer Setup



Objectives

Allow users to track the plants that they're growing.

Provide stats on growth rates.
Pull in weather information.
Compare against other growers.


Allow users to research plants to grow.

Users can search within a radius of their location for plants others are
growing.
Users can determine likelihood of success.


Assist users in management of their plants.

Send alerts to users when action needs to be taken based on time-of-year
or on weather. For example, should prune/fertilize on X Date, or ""there's
a freeze warning, you need to protect your avocado tree.""


Usability

Users should be able to post entries about a tree from their yard on a smart
phone.
Users should be able to take photos and add them to a plant entry from
their smart phone while making a post.
Users should be able to operate the app while disconnected with syncing
done later.



Versions
0.0.1 MVP

User can create an account using OAuth from their Google account.
User can add/delete/update each plant in their yard.
User can add entries to each plant. Each entry will have a date and
details.

0.0.2 and beyond

Add features/fields to user's account.

Add Facebook as OAuth option.
Allow user to add their GPS location to their account.


Add features to a plant post.

Allow photos to be added.
Add markdown for details to allow for formatting.


Add structured fields for each plant.

Dates for planting, germination.
Multi-bud - treat each scion as its own tree but group on this.
Perennial/annual (other?)


Add structured fields for data entry posts.

E.g. height, width etc. to calculate growth rates.
Applications of fertilizer, mulch etc for reporting on growth effectiveness.
Start and end dates for harvest. (Allow for reporting on year round
production and prediction.)
Volume harvested.


Perform calculations on entries to show changes. e.g. growth in gallons per
week.
Use user's GPS location to pull in weather data from date of first plant
entry to current date.
Keep user's weather data up-to-date.
Use user's GPS location to allow them to compare their plants to the same
plants in nearby locations.
Allow users to add parentage/genealogy to their plants.

i.e. if another user gave them a plant or they planted another plant from
one that they're already documenting on the system then they can link a parent
plant.


Support multi-bud trees.

Allow for structured data entry for root stock(s) and multiple scions.
Allow dates for adding scions to trees.


Allow for termination date of plants.

Distinguish between perennial and annuals. i.e. plants that are designed
to die annually and those that aren't. Helps in reporting life and reason
for death or disposal of perennial.


Search

User can find a male pollinator for their female plant within a certain
radius of their location.



Questions
If you have questions or want to communicate with the maintainers of the
project then please create an issue.
For Developers
Architecture
Components
plant
Components in the /app/components/plant folder.
Component naming uses CRUD (Create, Read, Update, Delete) names to identify what the component does.

Plant

Container for showing and managing a single plant
All other components in this section are used by the Plant component directly or indirectly. i.e. Plant is the top parent


PlantRead

Shows the details of the Plant
PlantEdit hidden


PlantEdit

Create or Update a Plant.
PlantRead hidden


Notes

Manages the Hide/Show ""add note"" functionality
Container to show a list of Notes


NoteEdit

Create or Update a Note.


NoteRead

Shows the details of a Note



plants
Components in the /app/components/plants folder.
Components for managing a collection and the listing of plants.
Developer Setup
Facebook and Google OAuth
You can start the site without setting up Facebook credentials.
As long as the NODE_ENV is not set to production you will be able to login as a dev user.
You do, however, need to set the Facebook and Google environment variables to a non-empty value.
In your ~/.bashrc or equivalent file (or a script you source before you start the server) set the following:
export PLANT_FB_ID=<facebook-app-id>
export PLANT_FB_SECRET=<facebook-app-secret>
export PLANT_GOOGLE_ID=<google-app-id>
export PLANT_GOOGLE_SECRET=<google-app-secret>

If want to use Facebook OAuth then you'll need to setup credentials.
(As with any site, the layout and options change over time so these instructions are an approximation.)

Go to developers.facebook.com and on the menus click on My Apps and then select Add a New App.
Select a WWW Website.
Add a name (Plant is good) and click Create New Facebook App ID.
There's a button to the top right to Skip Quickstart - hit that.
You should end up on the Dashboard. From here you want the App ID and App Secret.
Set the PLANT_FB_ID and PLANT_FB_SECRET environment variables to these values.

MongoDB
If you have Docker installed then it will pull down and spin-up MongoDB for you when you start the server.
Otherwise, you need to install Docker (recommended) or MongoDB.
Running the site

Clone the repo locally.
npm i
Terminal Window #1: npm run server

Starts the server on port 3001 using the /devops/run-server.sh script. Edit this script to fine tune how the server starts.


Terminal Window #2: npm start

Starts the Webpack Dev Server on port 9090


Navigate: http://localhost:9090

Running the tests
npm t

Debugging with VSCode

Start MongoDB
Terminal #1: Start the App/API Server with npm run server
Terminal #2: Start the Dev Server with npm start
VSCode: Select Chrome from Debug launch options and hit F5

",6
xndcn/smzdm.com,None,"smzdm.com
",10
Mindjet/LiteWeather,Kotlin,"LiteWeather
The app is available here.
Screenshot

",5
narcitymedia/lilium-cms,JavaScript,"
Lilium CMS V4
Lilium is a lightning-fast, web based content management system built with Node.JS. Its power resides in its intelligent caching engine which reduces CPU usage, RAM, and database access.
If server-side rendering is preferred over client-side rendering, Lilium offers a simplified way of generating HTML documents, storing them on disk or RAM, and serving them faster than most HTML preprocessors. It is possible to use either LML2 which ressembles PHP, or LML3 which is an easy to use routine using Javascript template strings.
The platform has its own framework and unique API. Lilium makes it easy to create a mobile app for a website, and is network based. It can hold multiple domains for a single instance, can use multiple different databases. It is compatible with content delivery network services.
Lilium does not use Express, Mongoose, or other heavy libraries. Instead, it implements its own web server using native NodeJS libraries.
Open source details
Narcity Media is using Lilium CMS in production. However, it is currently using the V3. That means this version is not ready for production just yet. We still invite you to try the CMS and have fun with it, but we recommend to wait until the V4 is stable before deploying a website.
Installation guide
All NodeJS packages are to be installed, and are documented in the package file. You can simply run npm run setupdev in the Lilium root folder.
Automated installation
Lilium was built on Linux, and is meant to be run on Linux. Even though it will technically work on Mac, Lilium is not guaranteed to be stable on other operation systems.
The CMS requires NodeJS v8+, and MongoDB v3+. You can follow online tutorials on how to install both of these before running the npm scripts, but it's a faily simple process.
Installing NodeJS
You can follow this tutorial from the official NodeJS website.
From the nodesource instructions
# Using Ubuntu
curl -sL https://deb.nodesource.com/setup_11.x | sudo -E bash -
sudo apt-get install -y nodejs

# Using Debian, as root
curl -sL https://deb.nodesource.com/setup_11.x | bash -
apt-get install -y nodejs

Installing MongoDB
You can follow this tutorial from the official MongoDB website.
Only run one of the following depending on your Ubuntu distro
# For Ubuntu 18
echo ""deb [ arch=amd64 ] https://repo.mongodb.org/apt/ubuntu bionic/mongodb-org/4.0 multiverse"" | sudo tee /etc/apt/sources.list.d/mongodb-org-4.0.list

# For Ubuntu 16
echo ""deb [ arch=amd64,arm64 ] https://repo.mongodb.org/apt/ubuntu xenial/mongodb-org/4.0 multiverse"" | sudo tee /etc/apt/sources.list.d/mongodb-org-4.0.list

# For Ubuntu 14
echo ""deb [ arch=amd64 ] https://repo.mongodb.org/apt/ubuntu trusty/mongodb-org/4.0 multiverse"" | sudo tee /etc/apt/sources.list.d/mongodb-org-4.0.list

Then
sudo apt-get update
sudo apt-get install -y mongodb-org
sudo service mongod start

And MongoDB should be running. To make sure the installation was successful, you can open a shell using mongo.
Installing Lilium for development
You can clone Lilium in your favourite installation directory. At Narcity Media, we like to use /usr/share/lilium or ~/dev/lilium. Make sure the directory is owned by you, not by root. Also make sure to install it in a directory that is also owned by you since other sibling directories might be needed.
Simply cd to the directory you want to use, and git clone https://github.com/narcitymedia/lilium-cms.
Then, cd lilium-cms and npm install && npm run setupdev.
Once the installation process exits, you can start the CMS using npm start or node index.prod.js. Your browser should load the CMS if you browse to localhost:8080/lilium.
The development username and password are : lilium and lilium. Make sure to change them if you plan on deploying on a production machine.
Web panel for development
The CMS frontend is located under /apps/lilium. It is a Preact app, and is transpiled using Webpack and Babel.
Required dependencies
MAC:
brew install pkg-config cairo libpng jpeg giflib imagemagick redis
UBUNTU:
sudo apt-get install libcairo2-dev libjpeg8-dev libpango1.0-dev libgif-dev build-essential g++ libkrb5-dev imagemagick redis-server
The dependencies will be installed automatically during the npm run setupdev process. You can however install then manually if you prefer.
Localhost connections to MongoDB
If mongo still refuses to connect from NodeJS eventhough it works using the terminal cli, you might have to enable or disable authentication from your mongo config file (typically located in /etc/mongod.conf, under security: authentication).
This information can be found easily online using search queries such as ""Enable MongoDB authentication"". We ran into this issue on multiple occasion, and it ended up being a different solution every time.
MongoDB with brew
On Mac, sometimes the MongoDB service will refuse connections from Lilium for obscure reasons. Our temporary solution it to start a mongod instance in a seperate terminal and add the desired parameters including the database path and authentation db. You also get an additional output stream from mongod.
There likely is a better solution to make this work with brew service, but like mentionned earlier, we don't actively support MacOS nor do we recommend to run Lilium in production on a different OS than Linux.
I want to code, too
That must mean you're amazing. See the Lilium CMS Wiki and get started!
Script mode
It is possible to run a Javascript file in script mode. It will prevent Lilium from loading the listeners, CAIJ and other modules related to networking. The websites and databases will still be loaded on a single thread, and the script passed as an argument will be executed.
node ./includes/runscript.js [script.js]
Random quote API
In older version, we used a random quote provider to add a cute message to The Daily Lilium, which is Lilium's newspaper.
http://api.forismatic.com/api/1.0/?method=getQuote&format=json&lang=en
Working with nginx
Nginx works well with Lilium. The following configuration is the most simplified version you can use. The config works with a Lilium instance located at /usr/share/lilium/lilium-cms, and runs at port 8080.
Since Lilium does not handle HTTPS requests, using nginx in front of Lilium makes it possible to have a fully operational SSL website running on Lilium, without the SSL overhead during the local proxy upstream.
Using Certbot or LetsEncrypt, you can quicky generate an HTTPS cert.
Basic nginx configuration file
upstream lilium_proxy  {
        server 127.0.0.1:8080;
        keepalive 64;
}

map $http_sec_websocket_key $upgr {
    """"      """";           # If the Sec-Websocket-Key header is empty, send no upgrade header
    default ""websocket"";  # If the header is present, set Upgrade to ""websocket""
}

map $http_sec_websocket_key $conn {
    """"      $http_connection;  # If no Sec-Websocket-Key header exists, set $conn to the incoming Connection header
    default ""upgrade"";         # Otherwise, set $conn to upgrade
}

proxy_cache_path /usr/share/lilium/html/nginxcache levels=1:2 keys_zone=my_cache:10m max_size=10g inactive=60m use_temp_path=off;

server {
        listen 80;

        server_name localhost;
        # port_in_redirect off;

        large_client_header_buffers 8 32k;
        index index.html;

        location / {
                proxy_cache my_cache;
                proxy_cache_revalidate on;
                proxy_cache_min_uses 3;
                proxy_cache_use_stale error timeout updating http_500 http_502 http_503 http_504;
                proxy_cache_lock on;

                alias /usr/share/lilium/html/default/;
                try_files $uri $uri.html @lilium;
        }

        location /(lilium|login)/ {
                try_files @lilium =404;
        }

        location @lilium {
                proxy_set_header X-Real-IP $remote_addr;
                proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
                proxy_set_header Host $http_host;
                proxy_set_header Host $host;
                proxy_set_header X-NginX-Proxy true;

                # prevents 502 bad gateway error
                proxy_buffers 8 32k;
                proxy_buffer_size 64k;

                proxy_pass http://lilium_proxy;
                proxy_redirect off;

                # enables WS support
                proxy_http_version 1.1;
                proxy_set_header Upgrade $upgr;
                proxy_set_header Connection $conn;
        }
}

Production version
4.1.0
Founder

Erik Desjardins

Contributors

Erik Desjardins
Samuel Rondeau-Millaire
Daniel McAuley
Gabriel Cardinal
Narcity Media inc.


License
Mozilla Public License Version 2.0
About the license
TL;DR : You can use the CMS to make money as long as it remains open source. The typical use case involves no additional work.
Both individuals and businesses are allowed to use Lilium CMS.
You are allowed to host a copy of Lilium CMS, modify it, redistribute it, create something different with it.
One important thing to note : you must disclose the source code, copyright, and must document any modification done. A copy of the license must be available. However, this does not mean you need to credit Narcity Media on your website or anything of the sort. Simply make the source code available and highlight the modifications if any.
That being said, you can still use Lilium CMS for almost any purposes.
Like most open source licenses, Narcity Media is not liable if anything happens with your server, data, etc. Lilium CMS does not come with a warranty.
The previous information is not legal advice, but should give you a good idea.
Mozilla Public License Version 2.0 is a simple, permissive license with conditions easy to respect. There have a great FAQ here.
Copyright
Â© Narcity Media, 2019
",5
guyellis/plant-image-lambda,JavaScript,"plant-image-lambda

Image Lambda for Plant Project
Data Flow
Notes
During the upgrade from Node 4 to Node 8 more dependencies were added. This caused the code
size (of the zip package) to increase from 2.4 MB to 5.4 MB. (July 1, 2018).
",2
tolo7010/hak.lnk,None,"hak.lnk
Project Name: hak.lnk
Description: Resource Links For Hackers
Author: tolo7010

General Web Penetration Guides / Courses / Tutorials
Mobile Penetration Guides / Courses / Tutorials
Tools
CTFs / Challenges / Labs
Vulnerability Database
Infosec News
Community Forums / Discussion Boards
Personal Blogs
Useful Git Projects

Please contact me if you see broken links or there are other interesting links which should be added.
",18
PCGen/pcgen,Java,"How to compile PCGen?
Check out our WIKI: http://wiki.pcgen.org/Building_PCGen
",247
Zongsoft/Zongsoft.CoreLibrary,C#,"Zongsoft.CoreLibrary
æ¦è¿°
Zongsoft.CoreLibrary ç±»åºæä¾äº.NETå¼åçå¸¸ç¨åè½éä»¥åä¸äºç¸å¯¹äº.NET BCLä¸­è¿è¡äºåè½å¼ºåçå®ç°ãéç¨C#è¯­è¨å¼åï¼æ¯æè·¨å¹³å°å¯è¿è¡å¨ WindowsãLinuxãMac OSX ç­å¹³å°ä¸­ã

æ¬¢è¿å¤§å®¶å¨ GitHub ä¸æäº¤åé¦ç»æä»¬ï¼ä¸ºæä»¬ç¹èµ(Star)ã
å¦æä½ æ¿æå¸®å©æä»¬å®åãç¿»è¯ææ¡£ï¼æåèä¾ä»£ç é½è¯·è´ä¿¡ç»æï¼zongsoft@gmail.comã9555843@qq.com
é¡¹ç®ç»æ


Common

è¯¥å½åç©ºé´ååæ¬ä¸äºå¸¸ç¨çå·¥å·ç±»ãå¶ä¸­åæ¬ç¸å¯¹ .NET BCL ä¸­è¿è¡äºåè½å¼ºåç Convert ç±»ï¼å¯¹æä¸¾ç±»åæä½ç EnumUtility ç±»ï¼ISequenceåºåå¨ãIAccumulatorç´¯å å¨æ¥å£ä»¥åä¸äºæ©å±ç±»ã



Collections

è¯¥å½åç©ºé´ååæ¬æå³éåçç±»ãå¶ä¸­åæ¬ç¸å¯¹.NET BCLä¸­ååéåç±»è¿è¡äºåè½å¼ºåç NamedCollectionBaseãCollection<T>ãQueue ç±»ï¼ä»¥åè¡¨ç¤ºæ åå±æ¬¡ç»æç HierarchicalNodeãHierarchicalNodeCollectionãCategoryãCategoryCollection è¿äºç±»ï¼ä»¥åä¸ä¸ªæ¯æçº¿ç¨å®å¨çæä¾å¯¹è±¡æ± ç®¡çç ObjectPool ç±»åæ¯ææå®å®¹ç§¯çåå­ç¼å­ObjectCacheã



Communication

è¯¥å½åç©ºé´ååæ¬è¿è¡éè®¯åèªå®ä¹éè®¯åè®®åè§£æçåºç±»ãæ¥å£ï¼è®¾è®¡éè®¯å¤çç¨åºæ¶åºå°½éä½¿ç¨è¿éå®ä¹çæ¥å£æåºç±»ãå·ä½å®ç°è¯·åè Zongsoft.Net é¡¹ç®ã


Composition

è¯¥å½åç©ºé´ååæ¬âæ§è¡ç®¡é(ExecutionPipelines)âæ¨¡å¼çå¨é¨æ¥å£åå®ç°ï¼æ§è¡ç®¡éæ¯ä¸å¥å¼ºå¤§çæ©å±æ¥å£æ¹æ¡ï¼éè®¯å±ç Communication.Net.TcpServer å Communication.Net.FtpServer ç±»åéç¨è¯¥æºå¶æ¥ä¿è¯æå¡å¨ç«¯çæ©å±æ§ã





ComponentModel

è¯¥å½åç©ºé´ååæ¬ä¸äºç¸å¯¹ .NET BCL ä¸­è¿è¡äºåè½å¼ºåç TypeConverterï¼è­¬å¦ï¼EnumConverterãCustomBooleanConverterãGuidConverter ç±»ï¼è¡¨ç¤ºåºç¨ç¨åºä¸ä¸æç ApplicationContextBase ç±»ï¼è¯¥åºç±»æä¾äºä¸ä¸ªåºç¨ç¨åºå¯è½ä¼ä½¿ç¨å°çå¸¸ç¨æå¡ï¼å¶ä¸­ç AliasAttribute ç±»å¯ç¨æ¥å®ä¹æä¸¾é¡¹æå¶ä»åç´ çå«ç§°ã



Data

è¯¥å½åç©ºé´ååæ¬è¿è¡æ°æ®è®¿é®ç¸å³ç±»åæ¥å£ï¼æä»¬æä¾äºä¸ä¸ªæ¯æå¤åºåæ¶è®¿é®ãæ¨ªååè¡¨çåå¸å¼å³ç³»åæ°æ®åºORMå¼æï¼æå³è¿ä¸ªå¼æçè¯¦ç»ä¿¡æ¯è¯·è®¿é® Zongsoft.Data é¡¹ç®ã



Diagnostics

è¯¥å½åç©ºé´ååæ¬æ¥å¿å¤çãè¯æ­è·è¸ªç¸å³çç±»åæ¥å£ã



Expressions

è¯¥å½åç©ºé´ååæ¬ä¸ä¸ªè¡¨è¾¾å¼è§£æä»¥åè¯æ³è§£æç­åè½å®ç°ã



IO

è¯¥å½åç©ºé´ååæ¬ä¸ä¸ªèææä»¶ç®å½ç³»ç»çåè½éï¼ä½¿ç¨è¯¥èææä»¶ç³»ç»å¯éç¦»ä¸åæä½ç³»ç»ä¸­IOå¤ççå·®å¼ï¼å¹¶æ¯æå¶ä»å¤é¨æä»¶ç³»ç»çæ©å±ãå·ä½å®ç°å¯åè Zongsoft.Externals.Aliyun è¿ä¸ªé¡¹ç®ä¸­çåå¸å¼æä»¶å­å¨é¨åã



Messaging

è¯¥å½åç©ºé´ååå«ä¸ä¸ªæ¶æ¯éåå¤ççæ½è±¡æ¥å£ï¼å·ä½å®ç°å¯åè Zongsoft.Externals.Aliyun è¿ä¸ªé¡¹ç®ä¸­çæ¶æ¯éåé¨åã



Options

è¯¥å½åç©ºé´ååå«äºä¸å¥éé¡¹éç½®å¤ççç±»åæ¥å£ï¼è¿å¥éé¡¹éç½®ä»¥æ åç»ææ¥ç»ç»åºç¨åçææéé¡¹éç½®æ°æ®ï¼è®¿é®è¿äºéç½®æ°æ®ä»¥éç¨çé»è¾è·¯å¾çæ¹å¼æ¥è¿è¡ã



Configuration

è¯¥å½åç©ºé´ååæ¬ä¸å¥å¨æ°çéç½®æä»¶çå¼åæ¥å£ï¼è¯¥å¥æ¥å£å®å¨å¼å®¹ .NET BCL ä¸­ç System.Configuration çç¼ç¨æ¨¡å¼ã


ä¸ºä»ä¹æä»¬è¦éæ°ç¼åä¸å¥ç±»ä¼¼çéç½®å¼åæ¥å£ï¼å ä¸º .NET BCL èªå¸¦çéç½®çæºå¶å¤ªè¿èè¿å¤æãå¹¶ä¸æ©å±æ§ä¹ä¸æ¯å¤ªåå¥½ï¼æä»¬å¸æåºç¨æ¨¡åçéç½®åºè¯¥åè¯¥åºç¨æ¨¡åä¸æ ·æ¯å¯è¢«æä»¶åçï¼å®ä»¬å¿é¡»å¯éæææå¹¶ä¸ä¿è¯æ¨¡åä¹é´çéç¦»æ§ï¼å½ä¸åæ¨¡åè¢«ç»è£å¨ä¸èµ·çæ¶åï¼è¿äºåç¦»çéé¡¹éç½®æ°æ®å°èªå¨ç»ç»æä¸ä¸ªå®æ´çé»è¾æ ã



Profiles

è¯¥å½åç©ºé´ååæ¬ä¸å¥å¯¹ Windows ä¸­ INI éç½®æä»¶çå¼åæ¥å£ï¼å¹¶ä¸æ¯æå¯¹ Section ä»¥å±æ¬¡ç»æçè®¿é®æ¹å¼ã





Reflection

è¯¥å½åç©ºé´ååæ¬ä¸ä¸ªå¯¹æåå¨æè®¿é®çç±»ã



Resources

è¯¥å½åç©ºé´ååæ¬ä¸ä¸ªå¯¹èµæºå¤çç ResourceUtility å·¥å·ç±»ã



Runtime


Caching

è¯¥å½åç©ºé´ååå« Buffer å Cache è¿ä¸¤ç§ç¼å­æºå¶çåè½éã



BufferManager æä¾äºå¨é¢ç¹åéä¸ç¡®å®å¤§å°çåå­çæ®µçåºæ¯ä¸çä¸ä¸ªå¾å¥½çè§£å³æ¹æ¡ï¼è­¬å¦å¨ TCP éè®¯ä¸­ï¼æ¥æ¶ç«¯å¹¶åçæ¶å°åä¸ªåéç«¯åéè¿æ¥çæ°æ®çæ®µï¼å¯ä»¥éç¨ BufferManager æ¥å°è¿äºä¸´æ¶æ°æ®çæ®µä¿å­èµ·æ¥å¾å°æ´ä¸ªæ°æ®åæ¥æ¶å®æåååé¦ç»ä¸å±åºç¨å®æ´çæ°æ®åã




ICache è¡¨ç¤ºæä½ç¼å­çæ¥å£ï¼MemoryCache æ¯å®çä¸ä¸ªåå­ç¼å­çå®ç°ï¼è¿ç¨ç¼å­æ¡ä¾å¯åè Zongsoft.Externals.Redis é¡¹ç®ã




Serialization

è¯¥å½åç©ºé´ååæ¬äºä¸å¥åºåååååºååçç¸å³ç±»åæ¥å£ï¼å¶ä¸­åæ¬åºäºå­å¸(Dictionary)çææ¬è¿ä¸¤ç§å¸¸ç¨åºååå®ç°ãç±äº .NET BCL ä¸­å¹¶æ²¡ææä¾å³äºåºååå¨çç»ä¸æ¥å£ï¼æä»¥ä½¿ç¨ ISerializer è¿ä¸ªæ¥å£å¯ä»¥éç¦»ç¹å®ææ¯çå®ç°ãéè¿ Serializer ç±»ç Json å±æ§å¯è·å¾ä¸ä¸ªææ¬åºååå¨ï¼éè¿ DictionarySerializer ç±»ç Default å±æ§å¯è·å¾ä¸ä¸ªå­å¸åºååå¨ã





Security

è¯¥å½åç©ºé´ååæ¬ä¸ä¸ª PasswordUtility å¯ç æä½çå·¥å·ç±»ï¼ä»¥åä¸å®å¨ãææç¸å³çåºç±»åæ¥å£ã


Membership

è¯¥å½åç©ºé´ååæ¬ä¸å¥å®æ´çåºäºè§è²å®å¨çææç®¡çæ¥å£ï¼å®è¿åå«äºä¸ä¸ªæä½³å®è·µçæ¹æ¡ãå·ä½å®ç°è¯·åè Zongsoft.Security é¡¹ç®ã





Services

è¯¥å½åç©ºé´ååæ¬ä¸å¥æå¡è®¿é®åç®¡çç IServiceProviderãIServiceProviderFactory æ¥å£åå®ç° ServiceProviderãServiceProviderFactoryï¼ä»¥åä¸å¥æå³å½ä»¤è£éæ¨¡å¼çæ¥å£åå®ç°ï¼è¿æä¸ä¸ªåå°æå¡çå·¥ä½è IWorker æ¥å£å WorkerBase åºç±»ã



Terminals

è¯¥å½åç©ºé´ååæ¬ä¸å¥ç»ç«¯ç¨åºçæ¥å£åå®ç°ï¼ä½¿ç¨è¯¥å®ç°å¯ä»¥å¿«éçå®æä¸ä¸ªå¼ºå¤§çåºäºæ§å¶å°çåºç¨ã


Commands

è¯¥å½åç©ºé´ååæ¬å³äºç»ç«¯ç¨åºçä¸äºå¸¸ç¨å½ä»¤çå®ç°ç±»ï¼è­¬å¦ ExitCommandãClearCommandãHelpCommand ç­ç±»ã





Text

è¯¥å½åç©ºé´ååæ¬ä¸å¥åºäºæ­£åè¡¨è¾¾å¼çææ¬è¡¨è¾¾å¼çè§£æãå¤ççç±»ã



Transactions

è¯¥å½åç©ºé´ååæ¬æå³äºå¡çç±»åæ¥å£ï¼æå³åºç¨äºå¡æ¯æçå®ç°å¯åè Zongsoft.Data æ°æ®å¼æ ä¸­çäºå¡æ¯æã



å¼ç¨è¯´æ
æ¬é¡¹ç®ä¸­çææä»£ç åæªåèè¿ä»»ä½ç¹å®å®ç°ï¼ç¹æ­¤å£°æï¼
ææåè®®

Zongsoft.CoreLibrary æ¯åºäº LGPL v2.1ææåè®®ã
æ¨å¯ä»¥å°æ¬é¡¹ç®åºç¨äºåä¸æ´»å¨ä¸­ï¼ä½æ¯å¿é¡»ç¡®ä¿å¯¹æ¬é¡¹ç®çå®æ´ï¼å«çæå£°æï¼å¼ç¨ï¼ä¸è¦åå²æé¨åå¼ç¨è¯¥é¡¹ç®çæºç ï¼æä»¬ä¿çè¿½ç©¶è¿åææåè®®çæå©ã


ä¸ºä»ä¹è¦å¼æºï¼
ä½æ±æ»´æ°´ä¹æºæ¢æ±å¤§æµ·ä¹å¿ã
",47
yin1999/code_sharing,C++,"æ­¤ä»£ç åºç¨äºä¿å­æåé¢æéè¿å¶å®éå¾æ¥è§¦å°æèè§£å³é®é¢äº§çä»£ç ã
",2
igortorres17/SGSA,Java,"SGSA
Sistema de Gerenciamento de ServiÃ§os Automotivos (SGSA) Ã© um software desenvolvido pelos estudantes HÃ©rcules Moreira, Igor Torres, Ricardo Otaviano e Matheus Cruvinel do curso de AnÃ¡lise e Desenvolvimento de Sistemas do Instituto Federal do TriÃ¢ngulo Mineiro. O programa foi proposto pelo professor da disciplina de ProgramaÃ§Ã£o Visual, Eduardo Siqueira.
Recursos
Gerenciamento de Clientes, ServiÃ§os, VeÃ­culos e PeÃ§as

Cadastro
VisualizaÃ§Ã£o
AlteraÃ§Ã£o
ExclusÃ£o

Ordem de ServiÃ§o (OS)

EmissÃ£o de Ordem de ServiÃ§o
InclusÃ£o de ServiÃ§os e PeÃ§as na OS
InclusÃ£o de MecÃ¢nico ResponsÃ¡vel
ImpressÃ£o de OS

AutenticaÃ§Ã£o

Acesso atravÃ©s de nome de usuÃ¡rio e senha
NÃ­veis de acesso (PermissÃ£o)

",2
Zongsoft/Zongsoft.CoreLibrary,C#,"Zongsoft.CoreLibrary
æ¦è¿°
Zongsoft.CoreLibrary ç±»åºæä¾äº.NETå¼åçå¸¸ç¨åè½éä»¥åä¸äºç¸å¯¹äº.NET BCLä¸­è¿è¡äºåè½å¼ºåçå®ç°ãéç¨C#è¯­è¨å¼åï¼æ¯æè·¨å¹³å°å¯è¿è¡å¨ WindowsãLinuxãMac OSX ç­å¹³å°ä¸­ã

æ¬¢è¿å¤§å®¶å¨ GitHub ä¸æäº¤åé¦ç»æä»¬ï¼ä¸ºæä»¬ç¹èµ(Star)ã
å¦æä½ æ¿æå¸®å©æä»¬å®åãç¿»è¯ææ¡£ï¼æåèä¾ä»£ç é½è¯·è´ä¿¡ç»æï¼zongsoft@gmail.comã9555843@qq.com
é¡¹ç®ç»æ


Common

è¯¥å½åç©ºé´ååæ¬ä¸äºå¸¸ç¨çå·¥å·ç±»ãå¶ä¸­åæ¬ç¸å¯¹ .NET BCL ä¸­è¿è¡äºåè½å¼ºåç Convert ç±»ï¼å¯¹æä¸¾ç±»åæä½ç EnumUtility ç±»ï¼ISequenceåºåå¨ãIAccumulatorç´¯å å¨æ¥å£ä»¥åä¸äºæ©å±ç±»ã



Collections

è¯¥å½åç©ºé´ååæ¬æå³éåçç±»ãå¶ä¸­åæ¬ç¸å¯¹.NET BCLä¸­ååéåç±»è¿è¡äºåè½å¼ºåç NamedCollectionBaseãCollection<T>ãQueue ç±»ï¼ä»¥åè¡¨ç¤ºæ åå±æ¬¡ç»æç HierarchicalNodeãHierarchicalNodeCollectionãCategoryãCategoryCollection è¿äºç±»ï¼ä»¥åä¸ä¸ªæ¯æçº¿ç¨å®å¨çæä¾å¯¹è±¡æ± ç®¡çç ObjectPool ç±»åæ¯ææå®å®¹ç§¯çåå­ç¼å­ObjectCacheã



Communication

è¯¥å½åç©ºé´ååæ¬è¿è¡éè®¯åèªå®ä¹éè®¯åè®®åè§£æçåºç±»ãæ¥å£ï¼è®¾è®¡éè®¯å¤çç¨åºæ¶åºå°½éä½¿ç¨è¿éå®ä¹çæ¥å£æåºç±»ãå·ä½å®ç°è¯·åè Zongsoft.Net é¡¹ç®ã


Composition

è¯¥å½åç©ºé´ååæ¬âæ§è¡ç®¡é(ExecutionPipelines)âæ¨¡å¼çå¨é¨æ¥å£åå®ç°ï¼æ§è¡ç®¡éæ¯ä¸å¥å¼ºå¤§çæ©å±æ¥å£æ¹æ¡ï¼éè®¯å±ç Communication.Net.TcpServer å Communication.Net.FtpServer ç±»åéç¨è¯¥æºå¶æ¥ä¿è¯æå¡å¨ç«¯çæ©å±æ§ã





ComponentModel

è¯¥å½åç©ºé´ååæ¬ä¸äºç¸å¯¹ .NET BCL ä¸­è¿è¡äºåè½å¼ºåç TypeConverterï¼è­¬å¦ï¼EnumConverterãCustomBooleanConverterãGuidConverter ç±»ï¼è¡¨ç¤ºåºç¨ç¨åºä¸ä¸æç ApplicationContextBase ç±»ï¼è¯¥åºç±»æä¾äºä¸ä¸ªåºç¨ç¨åºå¯è½ä¼ä½¿ç¨å°çå¸¸ç¨æå¡ï¼å¶ä¸­ç AliasAttribute ç±»å¯ç¨æ¥å®ä¹æä¸¾é¡¹æå¶ä»åç´ çå«ç§°ã



Data

è¯¥å½åç©ºé´ååæ¬è¿è¡æ°æ®è®¿é®ç¸å³ç±»åæ¥å£ï¼æä»¬æä¾äºä¸ä¸ªæ¯æå¤åºåæ¶è®¿é®ãæ¨ªååè¡¨çåå¸å¼å³ç³»åæ°æ®åºORMå¼æï¼æå³è¿ä¸ªå¼æçè¯¦ç»ä¿¡æ¯è¯·è®¿é® Zongsoft.Data é¡¹ç®ã



Diagnostics

è¯¥å½åç©ºé´ååæ¬æ¥å¿å¤çãè¯æ­è·è¸ªç¸å³çç±»åæ¥å£ã



Expressions

è¯¥å½åç©ºé´ååæ¬ä¸ä¸ªè¡¨è¾¾å¼è§£æä»¥åè¯æ³è§£æç­åè½å®ç°ã



IO

è¯¥å½åç©ºé´ååæ¬ä¸ä¸ªèææä»¶ç®å½ç³»ç»çåè½éï¼ä½¿ç¨è¯¥èææä»¶ç³»ç»å¯éç¦»ä¸åæä½ç³»ç»ä¸­IOå¤ççå·®å¼ï¼å¹¶æ¯æå¶ä»å¤é¨æä»¶ç³»ç»çæ©å±ãå·ä½å®ç°å¯åè Zongsoft.Externals.Aliyun è¿ä¸ªé¡¹ç®ä¸­çåå¸å¼æä»¶å­å¨é¨åã



Messaging

è¯¥å½åç©ºé´ååå«ä¸ä¸ªæ¶æ¯éåå¤ççæ½è±¡æ¥å£ï¼å·ä½å®ç°å¯åè Zongsoft.Externals.Aliyun è¿ä¸ªé¡¹ç®ä¸­çæ¶æ¯éåé¨åã



Options

è¯¥å½åç©ºé´ååå«äºä¸å¥éé¡¹éç½®å¤ççç±»åæ¥å£ï¼è¿å¥éé¡¹éç½®ä»¥æ åç»ææ¥ç»ç»åºç¨åçææéé¡¹éç½®æ°æ®ï¼è®¿é®è¿äºéç½®æ°æ®ä»¥éç¨çé»è¾è·¯å¾çæ¹å¼æ¥è¿è¡ã



Configuration

è¯¥å½åç©ºé´ååæ¬ä¸å¥å¨æ°çéç½®æä»¶çå¼åæ¥å£ï¼è¯¥å¥æ¥å£å®å¨å¼å®¹ .NET BCL ä¸­ç System.Configuration çç¼ç¨æ¨¡å¼ã


ä¸ºä»ä¹æä»¬è¦éæ°ç¼åä¸å¥ç±»ä¼¼çéç½®å¼åæ¥å£ï¼å ä¸º .NET BCL èªå¸¦çéç½®çæºå¶å¤ªè¿èè¿å¤æãå¹¶ä¸æ©å±æ§ä¹ä¸æ¯å¤ªåå¥½ï¼æä»¬å¸æåºç¨æ¨¡åçéç½®åºè¯¥åè¯¥åºç¨æ¨¡åä¸æ ·æ¯å¯è¢«æä»¶åçï¼å®ä»¬å¿é¡»å¯éæææå¹¶ä¸ä¿è¯æ¨¡åä¹é´çéç¦»æ§ï¼å½ä¸åæ¨¡åè¢«ç»è£å¨ä¸èµ·çæ¶åï¼è¿äºåç¦»çéé¡¹éç½®æ°æ®å°èªå¨ç»ç»æä¸ä¸ªå®æ´çé»è¾æ ã



Profiles

è¯¥å½åç©ºé´ååæ¬ä¸å¥å¯¹ Windows ä¸­ INI éç½®æä»¶çå¼åæ¥å£ï¼å¹¶ä¸æ¯æå¯¹ Section ä»¥å±æ¬¡ç»æçè®¿é®æ¹å¼ã





Reflection

è¯¥å½åç©ºé´ååæ¬ä¸ä¸ªå¯¹æåå¨æè®¿é®çç±»ã



Resources

è¯¥å½åç©ºé´ååæ¬ä¸ä¸ªå¯¹èµæºå¤çç ResourceUtility å·¥å·ç±»ã



Runtime


Caching

è¯¥å½åç©ºé´ååå« Buffer å Cache è¿ä¸¤ç§ç¼å­æºå¶çåè½éã



BufferManager æä¾äºå¨é¢ç¹åéä¸ç¡®å®å¤§å°çåå­çæ®µçåºæ¯ä¸çä¸ä¸ªå¾å¥½çè§£å³æ¹æ¡ï¼è­¬å¦å¨ TCP éè®¯ä¸­ï¼æ¥æ¶ç«¯å¹¶åçæ¶å°åä¸ªåéç«¯åéè¿æ¥çæ°æ®çæ®µï¼å¯ä»¥éç¨ BufferManager æ¥å°è¿äºä¸´æ¶æ°æ®çæ®µä¿å­èµ·æ¥å¾å°æ´ä¸ªæ°æ®åæ¥æ¶å®æåååé¦ç»ä¸å±åºç¨å®æ´çæ°æ®åã




ICache è¡¨ç¤ºæä½ç¼å­çæ¥å£ï¼MemoryCache æ¯å®çä¸ä¸ªåå­ç¼å­çå®ç°ï¼è¿ç¨ç¼å­æ¡ä¾å¯åè Zongsoft.Externals.Redis é¡¹ç®ã




Serialization

è¯¥å½åç©ºé´ååæ¬äºä¸å¥åºåååååºååçç¸å³ç±»åæ¥å£ï¼å¶ä¸­åæ¬åºäºå­å¸(Dictionary)çææ¬è¿ä¸¤ç§å¸¸ç¨åºååå®ç°ãç±äº .NET BCL ä¸­å¹¶æ²¡ææä¾å³äºåºååå¨çç»ä¸æ¥å£ï¼æä»¥ä½¿ç¨ ISerializer è¿ä¸ªæ¥å£å¯ä»¥éç¦»ç¹å®ææ¯çå®ç°ãéè¿ Serializer ç±»ç Json å±æ§å¯è·å¾ä¸ä¸ªææ¬åºååå¨ï¼éè¿ DictionarySerializer ç±»ç Default å±æ§å¯è·å¾ä¸ä¸ªå­å¸åºååå¨ã





Security

è¯¥å½åç©ºé´ååæ¬ä¸ä¸ª PasswordUtility å¯ç æä½çå·¥å·ç±»ï¼ä»¥åä¸å®å¨ãææç¸å³çåºç±»åæ¥å£ã


Membership

è¯¥å½åç©ºé´ååæ¬ä¸å¥å®æ´çåºäºè§è²å®å¨çææç®¡çæ¥å£ï¼å®è¿åå«äºä¸ä¸ªæä½³å®è·µçæ¹æ¡ãå·ä½å®ç°è¯·åè Zongsoft.Security é¡¹ç®ã





Services

è¯¥å½åç©ºé´ååæ¬ä¸å¥æå¡è®¿é®åç®¡çç IServiceProviderãIServiceProviderFactory æ¥å£åå®ç° ServiceProviderãServiceProviderFactoryï¼ä»¥åä¸å¥æå³å½ä»¤è£éæ¨¡å¼çæ¥å£åå®ç°ï¼è¿æä¸ä¸ªåå°æå¡çå·¥ä½è IWorker æ¥å£å WorkerBase åºç±»ã



Terminals

è¯¥å½åç©ºé´ååæ¬ä¸å¥ç»ç«¯ç¨åºçæ¥å£åå®ç°ï¼ä½¿ç¨è¯¥å®ç°å¯ä»¥å¿«éçå®æä¸ä¸ªå¼ºå¤§çåºäºæ§å¶å°çåºç¨ã


Commands

è¯¥å½åç©ºé´ååæ¬å³äºç»ç«¯ç¨åºçä¸äºå¸¸ç¨å½ä»¤çå®ç°ç±»ï¼è­¬å¦ ExitCommandãClearCommandãHelpCommand ç­ç±»ã





Text

è¯¥å½åç©ºé´ååæ¬ä¸å¥åºäºæ­£åè¡¨è¾¾å¼çææ¬è¡¨è¾¾å¼çè§£æãå¤ççç±»ã



Transactions

è¯¥å½åç©ºé´ååæ¬æå³äºå¡çç±»åæ¥å£ï¼æå³åºç¨äºå¡æ¯æçå®ç°å¯åè Zongsoft.Data æ°æ®å¼æ ä¸­çäºå¡æ¯æã



å¼ç¨è¯´æ
æ¬é¡¹ç®ä¸­çææä»£ç åæªåèè¿ä»»ä½ç¹å®å®ç°ï¼ç¹æ­¤å£°æï¼
ææåè®®

Zongsoft.CoreLibrary æ¯åºäº LGPL v2.1ææåè®®ã
æ¨å¯ä»¥å°æ¬é¡¹ç®åºç¨äºåä¸æ´»å¨ä¸­ï¼ä½æ¯å¿é¡»ç¡®ä¿å¯¹æ¬é¡¹ç®çå®æ´ï¼å«çæå£°æï¼å¼ç¨ï¼ä¸è¦åå²æé¨åå¼ç¨è¯¥é¡¹ç®çæºç ï¼æä»¬ä¿çè¿½ç©¶è¿åææåè®®çæå©ã


ä¸ºä»ä¹è¦å¼æºï¼
ä½æ±æ»´æ°´ä¹æºæ¢æ±å¤§æµ·ä¹å¿ã
",47
yin1999/code_sharing,C++,"æ­¤ä»£ç åºç¨äºä¿å­æåé¢æéè¿å¶å®éå¾æ¥è§¦å°æèè§£å³é®é¢äº§çä»£ç ã
",2
igortorres17/SGSA,Java,"SGSA
Sistema de Gerenciamento de ServiÃ§os Automotivos (SGSA) Ã© um software desenvolvido pelos estudantes HÃ©rcules Moreira, Igor Torres, Ricardo Otaviano e Matheus Cruvinel do curso de AnÃ¡lise e Desenvolvimento de Sistemas do Instituto Federal do TriÃ¢ngulo Mineiro. O programa foi proposto pelo professor da disciplina de ProgramaÃ§Ã£o Visual, Eduardo Siqueira.
Recursos
Gerenciamento de Clientes, ServiÃ§os, VeÃ­culos e PeÃ§as

Cadastro
VisualizaÃ§Ã£o
AlteraÃ§Ã£o
ExclusÃ£o

Ordem de ServiÃ§o (OS)

EmissÃ£o de Ordem de ServiÃ§o
InclusÃ£o de ServiÃ§os e PeÃ§as na OS
InclusÃ£o de MecÃ¢nico ResponsÃ¡vel
ImpressÃ£o de OS

AutenticaÃ§Ã£o

Acesso atravÃ©s de nome de usuÃ¡rio e senha
NÃ­veis de acesso (PermissÃ£o)

",2
Lombiq/Combinator,C#,"Combinator Orchard module Readme
Project Description
An Orchard CMS module that combines and minifies external stylesheets and javascript files to cut down on load times.
Features

Combines and minifies css files
Combines and minifies javascript files
If local and remote resources are mixed (like a local js files with one from a CDN) preserves their original order
Preserves conditional resources and minifies (if multiple with the same condition are after each other, also combines) them
Can combine remote (CDN) resources
Can embed images into stylesheets as data urls
Experimental image sprite generation support
Resource sets can be defined for better client-side caching: you can create sets of resources that are combined separately (e.g. all jQuery scripts can be in their individual file)
Ability to share processed resources between tenants in a multi-tenant application so a set of resources is only processed once, not for every tenant (resource sharing)
Busts browser cache when resources are updated (with a query string parameter containing a time stamp)
Ability to set custom resource domain
Exposing resource processing events
LESS and SASS preprocessors, contribution of Onestop Internet, Inc.
Command line command for emptying cache (""combinator empty"")
Info comment in bundled resources about which resources were combined
Tuned to be fast
With custom IStorageProvider can work in cloud hosting too (if there is no write access to the Media folder anyway)
Import/export settings
Administration page:

Adjust combination exclusion filter
Enable/disable combination of CDN resources
Set up resource domain
Enable/disable minification and adjust exclusion filter
Enable/disable image embedding and adjust exclusion filter
Enable/disable image sprite generation
Define resource sets
Enable/disable for admin site
Empty cache



The module is also available for DotNest sites.
You can download an install the module from the Orchard Gallery.
For known issues and future plans please see the Issue Tracker.
Please make sure to read the Documentation!
The module's source is available in two public source repositories, automatically mirrored in both directions with Git-hg Mirror:

https://bitbucket.org/Lombiq/combinator (Mercurial repository)
https://github.com/Lombiq/Combinator (Git repository)

Bug reports, feature requests and comments are warmly welcome, please do so via GitHub.
Feel free to send pull requests too, no matter which source repository you choose for this purpose.
This project is developed by Lombiq Technologies Ltd. Commercial-grade support is available through Lombiq.
",6
horyus/ethvtx,JavaScript,"


Ethereum-Ready & Framework-Agnostic Redux Store Configuration

Introduction
ethvtx is an Ethereum-Ready & Framework-Agnostic Redux configuration. This package contains all the tools to build an efficient Redux store for your Dapp. Our goal was to create a tool that will allow Dapp developers to efficiently fetch and manipulate informations about the Ethereum Blockchain. By minimizing the amount of requests and by caching and reusing as much data as possible, we decrease the impact that our apps have on the Ethereum nodes.
A complete set of dispatcher and getters are exposed to the developer and can be used directly inside any of the mapStateToProps or mapDispatchToProps functions to properly recover informations or emit actions.
The store handles transactions, accounts, contracts and blocks. Each single section has its own set of dispatchers and getters, and all are well documented in the official documentation,
Installation
npm install --save ethvtx redux redux-saga
More informations here
Documentation
An extensive usage documentation can be found here
Questions ?  !
Examples
Embark Showcase Project
There is an example project showcasing how to use ethvtx in an embark project.
It can be found here
React TS Showcase Application
The repository contains a complete React Typescript Showcase.
To setup the showcase, run:
git clone https://github.com/horyus/ethvtx
cd ethvtx
npm install
npm run build
cd examples
npm run setup
Then, from the examples directory, run:
npm run start
You can then visit the app from http://localhost:3000.
Be sure to have Metamask installed, and quadruple-check that you aren't on the Main Ethereum Network before testing transactions :) .
Status



Service
Status




Travis CI



Coveralls




",108
carlosedu13/APS_Landing_Page,CSS,"GreenTech the harmony of nature and innovation
We are a company based on the harmony between the environment and technology.

The Landing Page
Our landing page aims to guide people to a safe electronic disposal mode that still brings a point system so our taxpayers can reap rewards for caring for the environment.
Example materials

Old Mobile
Batteries
Cables
Broken TV
Broken DVD
Old iPod
Broken Notebook or/and PC
General Hardware


",3
phanrahan/mantle,Verilog,"Mantle


Mantle is part of the Magma ecosystem
of python programming tools for FPGAs.
Magma
is a programming model for building hardware.
The main abstraction in Magma is a Circuit.
Circuits are created and then wired together.
Magma circuits can be saved as structural verilog files.
Mantle
is a library of useful circuits.
Examples of mantle circuits are logic operators,
arithmetic operators,
comparison operators,
multiplexers,
decoders and encoders,
registers,
counters,
shift regiseters
and memory.
Loam
is used to model FPGAs, peripherals, parts (ICs) and boards.
Loam makes it easy to build applications
on a variety of different FPGA demonstration boards.
Currently, Mantle supports generic verilog
and the Lattice ice40
(and its open source icestorm toolchain).
A Xilinx (spartan3, spartan6, zynq) backends will be released soon.
An Altera backend is in the works.
Documentation
Documentation is hosted at http://magma-mantle.readthedocs.io/
You can also browse the markdown files contained in docs/ directly.

Combinational logic

Logical Operators
Arithmetic Operators
Comparison Operators
Multiplexers
Decoders, Encoders, and Arbiters


Sequential logic

Flip-flops and Register
Counters
Shift Registers


Memory

There also exist libraries for low-level FPGA-specific primitives.

ICE40 Primitives

Configuring Mantle
By default Mantle is configured to use the CoreIR implementation, equivalent to:
import magma as m
m.set_mantle_target(""coreir"")

Other options include: verilog and lattice.
Mantle can also be configured to synthesize low-level primitives
for a particular FPGA.
For example, to use mantle with the Lattice ice40,
set the MANTLE_TARGET  environment variable.
m.set_mantle_target(""ice40"")
Setup

Follow these instructions to install magma

$ git clone https://github.com/phanrahan/mantle
$ cd mantle
$ pip install pytest
$ pip install -e .
$ ./scripts/run_tests.sh  # this should pass

",18
Baltazar-Ortega/findme_base,TypeScript,"findme_base
Instrucciones
Entrar al proyecto y ejecutar
npm install
Reparticion de tareas
La reparticion de tareas irÃ¡ cambiando segun se vayan terminando cosas
Comienzo de la aplicacion
Onboarding -> Autenticacion
Perdidos -> Dashboard (Cris)
Se puede ir

Pagina detalle de cada perro
Funcionalidad de cada card

(Rodolfo)

Descubrir como compartir en redes sociales una card de perro
Manual de uso de la aplicacion (10 paginas)
Presentacion de diapositivas

(Baltazar)

Formulario Encontrado
Formulario crear anuncio

Encontrados -> Dashboard (Charlie)

Cards encontrados
PÃ¡gina detalle encontrado

Logo y nombre de la aplicacion (Reyna)

Modal alguien encontrÃ³ a tu perro

Workflow

UI - Todo lo visual. Usar imagenes sacadas de internet
Los datos se guardarÃ¡n en arrays en los servicios, temporalmente
Implementacion de Firebase como base de datos
Autenticacion con Firebase
Adicion del feature de los mapas
onboarding
Refactorizacion del codigo para la version final
Publicacion

",2
cuthbertLab/music21,Python,"music21
music21 -- A Toolkit for Computational Musicology
Copyright Â© 2006-2019, Michael Scott Cuthbert and cuthbertLab
For more information, visit:
http://web.mit.edu/music21 or http://music21.readthedocs.org/en/latest/index.html
And to install, see:
http://web.mit.edu/music21/doc/usersGuide/usersGuide_01_installing.html
Music21 runs on Python 3.5+.  Version 4 was the last version to support Python 2
Released under either the BSD (3-clause) or GNU LGPL license according to your choice. See LICENSE.
Externally provided software (including the MIT licensed Lilypond/MusicXML test Suite) and
music encoding in the corpus may have different licenses. A no-corpus version of music21
is available also on GitHub


Mailing list
See: https://groups.google.com/forum/#!forum/music21list
Community Code of Conduct
Music21 encourages contributions, discussions, and usage from all people interested in
music and computers. This encouragement extends to all people regardless of (among other aspects)
gender, race, sexual orientation, disability, religion, appearance, veteran status,
gender identity, socioeconomic status, or nationality.
Members of the community will strive to be friendly, patient, and welcoming, especially of
viewpoints and experiences different from our own. We reject harassment and contributions
(in mail, comments, or code) that belittle individuals or groups of people.
We ask all members of the community to be mindful particularly about assumptions of the
gender of users (choice of pronouns in comments and code). We recognize that members
sometimes make mistakes and will, in general, accept sincere regrets for such cases.
Blatant or repeated violations of the code will result in the removal of the
contributorâs participation in the community.
The maintainers of music21 and associated sites will commit themselves to enforcing
this code of conduct. Users who notice violations, including instances of abuse,
harassment, or otherwise unacceptable behavior are requested to contact cuthbert@mit.edu.
Maintainers will respect confidentiality with regards to reports.
",839
donaldRwilliams/BGGM,R,"
BGGM
This package is described in Williams and Mulder (2019) and Williams (2018). The methods are separated into two Bayesian approaches for inference: hypothesis testing and estimation. The former is described in Williams and Mulder (2018a), and allows for testing for the presence of edges with the Bayes factor. One-sided hypothesis testing is also possible. These methods can also provide evidence for the null hypothesis. There are extensions for confirmatory hypothesis testing in GGMs, that can include inequality or equality constraints on the partial correlations. Further, it is possible to assess differences as well as similarities (i.e., the null hy-pothesis) between GGMs with the posterior predictive distribution and Bayesianmodel selection. The latter allows for testing hypothesized changes in graphicalstructures between, for example, control and treatment groups.
The estimation based methods are described in Williams (2018). The methods offer advantages compared to classical methods, in that a measure of uncertainty is provided for all parameters. For example, each node has a distribution for the variance explained (i.e., Bayesian R2). Measures of out-of-sample performance are also available, which also have a measure of uncertainty. The model is selected with credible interval exclusion of zero.
Williams, D. R. (2018, September 20). Bayesian Inference for Gaussian Graphical Models: Structure Learning, Explanation, and Prediction. (pre-print)
Williams, D. R., & Mulder, J. (2019, January 14). Bayesian Hypothesis Testing for Gaussian Graphical Models:Conditional Independence and Order Constraints. (pre-print)
Williams, D. R., Rast, P., Pericchi, L. R., & Mulder, J. (2019). Comparing Gaussian Graphical Models with the Posterior Predictive Distribution and Bayesian Model Selection. (pre-print)
Installation
You can install BGGM from git hub with:
# install.packages(""devtools"")
devtools::install_github(""donaldRwilliams/BGGM"")

Estimation
=============

1.1 Structure Learning
By structure learning we are referring to selecting the graph (i.e., the edge set E), which consists of those edges determinedto be non-zero. For demonstrative purposes, we consider a relatively small number of variables (pâ=â5). This The package BGGM offers a convenient analytic solution for estimating GGMs. It is implemented with:
# load pacakges
# install.packages(""devtools"")
# devtools::install_github(""donaldRwilliams/BGGM"")
library(BGGM)
library(ggplot2)
library(ggraph)

# p = 5
Y <- BGGM::bfi[,1:5]

# analytic solution
fit_analytic <- estimate(Y, analytic = T)
summary(fit_analytic)
#> BGGM: Bayesian Gaussian Graphical Models 
#> --- 
#> Type: Estimation (Analytic Solution) 
#> Posterior Samples: 
#> Observations (n): 2709 
#> Variables (p): 5 
#> Edges: 10 
#> --- 
#> Call: 
#> estimate.default(x = Y, analytic = T)
#> --- 
#> Date: Sat May 11 19:49:11 2019
Note summary(.) provides information about the fitted model, including that the analytic solution was used, the number of observations (n) and variables (p), and the number of edges.
The edge set is then selected with:
E <- select(fit_analytic, ci_width = 0.95)
summary(E)
#> BGGM: Bayesian Gaussian Graphical Models 
#> --- 
#> Type: Selected Graph (Analytic Solution) 
#> Credible Interval: 95 % 
#> Connectivity: 80 % 
#> --- 
#> Call:
#> select.estimate(x = fit_analytic, ci_width = 0.95)
#> --- 
#> Selected:
#>  
#> Partial correlations 
#>  
#>       1     2     3    4    5
#> 1  0.00 -0.24 -0.11 0.00 0.00
#> 2 -0.24  0.00  0.29 0.16 0.16
#> 3 -0.11  0.29  0.00 0.18 0.36
#> 4  0.00  0.16  0.18 0.00 0.12
#> 5  0.00  0.16  0.36 0.12 0.00
#> --- 
#>  
#> Adjacency 
#>  
#>   1 2 3 4 5
#> 1 0 1 1 0 0
#> 2 1 0 1 1 1
#> 3 1 1 0 1 1
#> 4 0 1 1 0 1
#> 5 0 1 1 1 0
#> ---
The analytic solution works directly with the precision matrix, and thus, there is not an option to summarize the posterior distributions. This is because the non-standardized elements are in the opposite direction (Â±) of the partial correlations, which in our experience, can lead to confusion. To summarize the posteriors change analytic = T to analytic = F:
fit_sampling <- estimate(Y, analytic = F)
E <- select(fit_sampling, ci_width = 0.95)
summary(E, summarize = T, digits = 2)
#> BGGM: Bayesian Gaussian Graphical Models 
#> --- 
#> Type: Selected Graph (Sampling) 
#> Credible Interval: 95 % 
#> Connectivity: 80 % 
#> --- 
#> Call:
#> select.estimate(x = fit_sampling, ci_width = 0.95)
#> --- 
#> Estimates: 
#>  
#>  egde post_mean post_sd   2.5%  97.5%
#>  1--2   -0.2400   0.018 -0.275 -0.204
#>  1--3   -0.1073   0.020 -0.145 -0.069
#>  2--3    0.2870   0.018  0.251  0.322
#>  1--4   -0.0074   0.019 -0.046  0.031
#>  2--4    0.1650   0.019  0.129  0.202
#>  3--4    0.1778   0.019  0.142  0.214
#>  1--5   -0.0089   0.019 -0.047  0.029
#>  2--5    0.1557   0.019  0.118  0.192
#>  3--5    0.3589   0.017  0.326  0.392
#>  4--5    0.1209   0.019  0.083  0.159
#> ---
Note that edge corresponds to that particular entry in the partial correlation matrix--i.e., 1--2 is the relation between the first and second variables, respectively.
BGGM provide several options for plotting, with each implemented as a S3 generic. For example, the partial correlations can be plotted with:
# p = 10
Y <- BGGM::bfi[,1:10]

# sampling required
fit_sampling <- estimate(Y, analytic = F)

# plot
plot_1A <- plot(fit_sampling, 
                ci_width = 0.95, 
                width = 0.1,  
                size = 2) +
            coord_cartesian() +
            theme(axis.text.x = element_text(angle = 90))
  
plot_1A

This example nicely demonstrates how the plot objects can be further customarized with ggplot2. There are two options for visualizing the selected graph. The heatmap plot is generated with:
# select the graph
E <- select(fit_sampling, ci_width = 0.95)

plot_1B <- plot(E, 
                type = ""heatmap"", 
                lower_tri = TRUE) +
           ggtitle(""Heatmap Plot"") + 
           theme(plot.title = element_text(size = 15))
plot_1B

Here lower_tri = TRUE controls which partial correlations are plotted. In this case, only the lower triangular elements are included in the plot. This can be changed with lower_tri = FALSE.
On the other hand, a ânetworkâ plot can be obtained with:
plot_1C <- plot(E, type = ""network"", 
                layout ='circle',
                node_outer = 8,
                node_inner = 7,
                node_text_size = 4) +
           ggtitle(""Network Plot"") +
           theme(plot.title = element_text(size = 15))
plot_1C

A key feature of BGGM is extending inference beyond identifying non-zero partialcorrelations. The region of practical equivalence can be used for this purpose, as it allowsfor determining which relations are practically zero. In this case, we follow Cohenâs guidelines, wherein 0.1 is considered asmall effect.This is implemented with:
# p = 10
Y <- BGGM::bfi[,1:10]

# sample from posterior
fit_sample <- estimate(Y, samples = 5000, analytic = F)

# select the graph
E <- select(fit_sample, rope = 0.1, prob = 0.95)
#> ci_width is ignored

# summary for first 10 rows
head(E, nrow = 10, summarize = T, digits = 2)
#> BGGM: Bayesian Gaussian Graphical Models 
#> --- 
#> Type: Selected Graph (Sampling) 
#> Probability: 0.95 
#> Region of Practical Equivalence:[-0.1, 0.1]
#> Connectivity: 31.1 % 
#> --- 
#> Call:
#> select.estimate(x = fit_sample, rope = 0.1, prob = 0.95)
#> --- 
#> pr_out: post prob outside of rope 
#> pr_in: post prob inside of rope 
#> --- 
#> Estimates: 
#>  
#>  egde post_mean post_sd pr_out  pr_in
#>  1--2    -0.244   0.019   1.00 0.0000
#>  1--3    -0.106   0.019   0.63 0.3652
#>  2--3     0.286   0.018   1.00 0.0000
#>  1--4    -0.015   0.019   0.00 1.0000
#>  2--4     0.161   0.019   1.00 0.0008
#>  3--4     0.161   0.019   1.00 0.0012
#>  1--5    -0.016   0.019   0.00 1.0000
#>  2--5     0.145   0.019   0.99 0.0120
#>  3--5     0.354   0.017   1.00 0.0000
#>  4--5     0.114   0.019   0.76 0.2376
#> ---
The argument prob = 0.95 requires that 95 % of the posterior density be in or out of the rope to be considered practically equivalent or different from zero. With this decision rule, as seen with head(.), edges 1--4 and 1--5 are practically equivalent to zero. This inference is made possible with BGGM.
In this case, plot(.) returns two objects: (1) the selected edges; (2) those for which there is support for the null values. These plots are displayed. This is implemented with:
plts <- plot(E, type = ""network"",
             layout ='circle',
             node_outer = 10, 
             node_inner = 9, 
             node_text_size = 6) 

plot_1D <- plts$plot_nonzero + 
             ggtitle(""Practically Non-zero"") +
             theme(plot.title = element_text(size = 15))
             
plot_1E <- plts$plot_zero + 
              ggtitle(""Practically Zero"") +
              theme(plot.title = element_text(size = 15))
             
cowplot::plot_grid(plot_1D, plot_1E)

We emphasize that GGMs are often thought to capture conditionally independent relations--i.e., evidence for the null hypothesis of no effect, conditional on the other variables in the model. However, the dominant approach assesses conditional dependence (Ïi**jââ â0), and then sets the off-diagonal elements to zero otherwise. BGGM can explicitly answers the question of conditional independence.
3.2 Edge differences
Differences between partial correlations are often tested in GGMs; for example, with a classical (i.e., frequentist) approach that is implemented in bootnet. One contribution ofBGGMis providing Bayesian analogs for commonly used methods, as well as extensions to those methods. In this case, we can use posterior probabilities to determine which edges are practically equivalent. This is implemented with:
# edge differences
edge_difference <- edge_compare(fit_sample, contrast = ""all"", ci_width = 0.95, rope = 0.1)
#> ci_width is ignored for decision rule, but used in for plotting

# summary for first 5 rows
head(edge_difference, nrow = 5)
#> BGGM: Bayesian Gaussian Graphical Models 
#> --- 
#> Type: Edge comparison(s) 
#> Credible Interval: 95 % 
#> Region of Practical Equivalence:[-0.1, 0.1]
#> --- 
#> Call:
#> edge_compare.estimate(x = fit_sample, contrast = ""all"", ci_width = 0.95, 
#>     rope = 0.1)
#> --- 
#> Estimates: 
#>  
#>   contrast post_mean post_sd pr_out pr_in
#>  1--2-1--3    -0.137   0.031  0.886 0.114
#>  1--2-2--3    -0.529   0.024  1.000 0.000
#>  1--2-1--4    -0.229   0.029  1.000 0.000
#>  1--2-2--4    -0.404   0.026  1.000 0.000
#>  1--2-3--4    -0.404   0.027  1.000 0.000
#> ---
This output includes the posterior mean and standard deviation for each difference. Further, pr_out is the proportion of samples included between (Â±) 0.1. This can be interpreted as the posterior probability of practical equivalence, which has been defined with the argument rope = 0.1. Further, this powerful function can be used to assess specific contrasts. This can be accomplished, for example, with 5--1 - 6--10. Note that care must be taken when specifying the contrasts, as an error will arise if they are not in the proper format.
The object edge_difference can the be plotted with:
plot_diff <- plot(edge_difference, prob = .99)
plot_2A <- plot_diff$plt_nonzero + ggtitle(""Practically Different"") 


Hypothesis Testing
=====================


Comparing GGMs
=================


",2
systemd/systemd,C,"systemd - System and Service Manager







Details
General information about systemd can be found in the systemd Wiki.
Information about build requirements is provided in the README file.
Consult our NEWS file for information about what's new in the most recent systemd versions.
Please see the Hacking guide for information on how to hack on systemd and test your modifications.
Please see our Contribution Guidelines for more information about filing GitHub Issues and posting GitHub Pull Requests.
When preparing patches for systemd, please follow our Coding Style Guidelines.
If you are looking for support, please contact our mailing list or join our IRC channel.
Stable branches with backported patches are available in the stable repo.
",4796
earthlab/streamstats,Python,"StreamStats








Python package for interfacing with the USGS StreamStats API.

Free software: MIT license
Documentation: https://streamstats-python.readthedocs.io.


Features

Get the GeoJSON of the watershed containing a spatial point in the U.S.


Credits
This package was created with Cookiecutter and the audreyr/cookiecutter-pypackage project template.
",3
ucb-stat133/stat133-spring-2019,HTML,"Stat 133: Concepts in Computing with Data

Policies
Staff
Piazza
FAQ


Calendar

Instructor: Gaston Sanchez
Lecture: MWF 3:00-4:00pm VLSB 2050
Tentative calendar (weekly topics), subject to change depending on
the pace of the course.
Notes (ð) involves material discussed in class.
Reading (ð) involves material that expands lecture topics, as well as coding examples that you should practice on your own.
Misc (ð°) is supporting material that is worth taking a look at.


0. Course Introduction

ð Dates: Jan 22-25
ð Topics: Welcome to Stat 133. We begin with the usual review of the course policies/logistics, expectations, topics in a nutshell, etc. Then, we move on with an unconventional introduction to computing with data using my favorite analogy ""Data Analysis is a lot like Cooking"".
ð Notes:

Welcome to Stat 133
Data Analysis is a lot like cooking
Data Analysis Cycle: Example


ð Reading:

Course policies
Piazza etiquette
FAQs


ð¬ Lab: No lab
ð° Misc:

What is Data Science?


ð To Do:

Install R
Install RStudio Desktop (open source version, free)




1. The Big Picture and R Survival Skills

ð Dates: Jan 28-Feb 01
ð Topics: First things first. At the conceptual level we'll discuss how data analysis projects usually start with a Research Question. Also, we'll describe how Data can actually be seen from a triangular perspective (i.e. my ""3 Views of Data""). At the practical level, you'll begin learning basic survival skills for R, followed by an overall review of the RStudio workspace. Then we move on to discuss basic data types and their implementation in R around vectors and other data structures.
ð Notes:

The Starting Point: Research Questions
The Three Views of Data
Be the Boss of your Data (talk and chalk)
Data Types and Vectors


ð Reading:

First contact with R (tutorial)
Intro to Rmd files (tutorial)


ð¬ Lab:

Getting started with R and RStudio (due Feb-01, open till Feb-17)


ð° Misc:

Introduction to R Markdown (by RStudio)


ð¡ Cheat sheet:

RStudio cheat sheet
R markdown cheat sheet


ð¯ WARM-UP 1:

Markdown practice (due Feb-03, open till Feb-17)




2. More Data Structures: Arrays, Lists, and Dataframes

ð Dates: Feb 04-08
ð Topics: In this week you'll keep learning more about R data structures like arrays and lists. More specifically, we'll focus on fundamental concepts like atomicity, vectorization, recycling, and subsetting. And given that we are studying vectors and its cousins, we'll briefly review the traditional base graphics approach that is based on R vectors.
ð Notes:

Arrays and Factors and Lists
Data Frames part 1 and part 2
Data Tables (introduction) and Spreadsheets


ð Reading:

Intro to vectors (tutorial)
Intro to Data Technologies (preface, chapter 1, and chapter 5) (by Paul Murrell)


ð¬ Lab:

Getting started with vectors and factors (due Feb-08, open till Feb-17)


ð° Misc:

chapter 20: Vectors (R for Data Science by Grolemund and Wickham)


ð¡ Cheat sheet:

Base R


ð¯ WARM-UP 2:

Basic Data Objects (due Feb-10, open till Feb-17)




3. Transforming and Visualizing Tabular Data

ð Dates: Feb 11-15
ð Topics: Because data tables are so ubiquitous, you will have the chance to practice some data manipulation operations on data frames. Also, we'll discuss some considerations when importing tables (in R). Likewise, we begin a comprehensive discussion on concepts for data visualization.
ð Notes:

Importing tables part 1 and part 2
Datavis: Classic Examples and Introduction
Datavis: Encoding Data in Graphs
Datavis: The Visual System


ð Reading:

Organizing data in spreadsheets (by Karl Broman)
""dplyr"" tutorial slides (by Hadley Wickham)


ð¬ Lab:

Data Frame Basics (due Feb-17)


ð° Misc:

tibbles vignette
Introduction to dplyr (by Hadley Wickham)


ð¡ Cheat sheet:

Data transformation cheat sheet
Data visualization with ggplot2


ð¯ WARM-UP 3:

Basic Data Manipulation (due Feb-17)




4. More Visualization

ð Dates: Feb 18-22 (Holiday Feb-18)
ð Topics: We continue reviewing more concepts of data visualization. At the practical level, it's important that you learn how to manipulate them via R data frames in a more modern and syntactic way. How? By following the data plying framework provided by the package ""dplyr"".
ð Notes:

Datavis: Using Color
Datavis: Effective Charts


ð Reading:

""ggplot2"" lecture (by Karthik Ram)


ð¬ Lab:

Data Wrangling and Graphics (due Feb-22)


ð° Misc:

Tidy Data (by Hadley Wickham)


ð¡ Cheat sheet:

Data transformation cheat sheet


ð¯ WARM-UP 4:

More Data Wrangling (due Feb-27)




5. Housekeeping: Filesystem and Bash Commands

ð Dates: Feb 25-Mar 01
ð Topics: Data Analysis Projects (DAPs) are made of files and directories. Therefore, we need to review some fundamental concepts such as the file-system, the command line interface, and some basic shell commands.
ð Notes:

Filesystem Basics
File Paths
Shell Basics
Command Line
Working with files


ð Reading:

Linux Tutorial lessons 1-5 (by Ryan Chadwick)
The Unix Shell lessons 1-3 (by Software Carpentry)


ð¬ Lab:

Command Line Basics (due Mar-01)


ð° Misc:

Linux Command Line tutorial (by Guru99)


ð¡ Cheat sheet:

command line cheat sheet


ð¯ WORK-OUT 1:

GSW Shot Charts (due Mar-13)




6. Housekeeping: Version Control with Git and GitHub

ð Dates: Mar 04-08
ð Topics: We continue talking about filestructure topics, and we introduce basic notions of version control systems (VCS) using Git, and the companion hosting platform GitHub.
On the Data side, we begin our discussion about Tables: the most common form in which data is stored, handled, and manipulated. Consequently, we need to talk about the typical storage formats of tabular data, and the relationship between tables and R data frames.
ð Notes:

Git Basics
Git Workflow


ð Reading:

Read sections 4 to 9 in Part I Installation (Happy Git and GitHub for the useR by Jenny Bryan et al.)


ð¬ Lab:

Git Basics (due Mar-08)


ð° Misc:

Data Import (R for Data Science by Grolemund and Wickham)


ð¡ Cheat sheet:

Data import cheat sheet
git cheat sheet


ð MIDTERM 1: Friday Mar-08


7. Transition to Programming Basics for Data Analysis (part 1)

ð Dates: Mar 11-15
ð Topics: You donât need to be an expert programmer to be a data scientist, but learning more about programming allows you to automate common tasks, and solve new problems with greater ease. We'll discuss how to write basic functions, the notion of R expressions, and an introduction to conditionals.
ð Notes:

Creating functions (tutorial)
Introduction to functions (tutorial)
Introduction to R expressions and conditionals (tutorial)


ð¬ Lab:

Getting started with functions and conditionals (due Mar-15)


ð° Misc:

chapter 19: Functions (R for Data Science by Grolemund and Wickham)


ð¯ WARM-UP 5:

Functions (due Mar-20)




8. Programming Basics for Data Analysis (part 2)

ð Dates: Mar 18-22
ð Topics: In addition to writing functions to reduce duplication in your code, you also need to learn about iteration, which helps you when you need to do the same operation several times. Namely, we review control flow structures such as for loops, while loops, repeat loops, and the apply family functions.
ð Notes:

Introduction to loops (tutorial)
More about functions (tutorial)
Functions (Advanced R by H. Wickham)
Environments (Advanced R by H. Wickham)


ð¬ Lab:

Getting started with loops (due Mar-22)


ð° Misc:

chapter 21: Iteration (R for Data Science by Grolemund and Wickham)


ð¯ WARM-UP 6:

Loops and simulations (due Apr-03)




Spring Recess

ð Dates: Mar 25-29
ð Topics: Recharge your batteries


9. Testing Functions and Introduction to Shiny Apps

ð Dates: Apr 01-05
ð Topics: We begin with an introduction to the package ""testthat"" which provides a nice framework for testing functions. Jointly, we will discuss Shiny apps which provide an interesting companion to R, making it quick and simple to deliver interactive analysis and graphics on any web browser. In lab, you'll learn how to perform basic manipulation of strings.
ð Notes:

Intro to testing functions (tutorial)
shiny tutorial (by Grolemund)


ð Reading:

testthat: Get started with testing (by Wickham)
Character strings in R (r4strings by Sanchez)
Basic string manipulations (r4strings by Sanchez)


ð¬ Lab:

Getting started with strings (due Apr-05)


ð° Misc:

chapter 14: Strings (R for Data Science by Grolemund and Wickham)


ð¡ Cheat sheet:

Stringr cheat sheet


ð¯ WORK-OUT 2:

Shiny App (due Apr-17)




10. More Shiny Apps and Introduction to Regular Expressions

ð Dates: Apr 08-12
ð Topics: Random numbers have many applications in science and computer programming, especially when there are significant uncertainties in a phenomenon of interest. In this part of the course we'll look at some basic problems involving working with random numbers and creating simulations. Additionally, we continue the discussion about character strings with a first contact to Regular Expressions.
ð Notes:

Introduction to random numbers
Coin toss shiny app
Regexpal tester tool.


ð Reading:

Part 1 - How to build a Shiny app (video)


ð¬ Lab:

Random numbers and simulations (due Apr-12)


ð° Misc:

Part 2 - How to customize reactions (video)
Part 3 - How to customize appearance (video)


ð¡ Cheat sheet:

shiny cheat sheet


ð¯ WORK-OUT 2:

Keep working on your workout02 assignment.




11. More Regular Expressions

ð Dates: Apr 15-19
ð Topics: At its heart, computing involves working with numbers. However, a considerable amount of information and data is in the form of text. To unleash the power of strings manipulation, we need to take things to the next level and learn about Regular Expressions. Namely, Regular expressions are a tool that allows us to describe a certain amount of text called ""patterns"". We'll describe the basic concepts of regex and the common operations to match text patterns.
ð Notes:

Long Jump World Record example
Log file example


ð Reading:

Handling Strings in R (by Sanchez)


ð¬ Lab:

Regular Expressions (due Apr-19)


ð¡ Cheat sheet:

Regular Expressions cheat sheet


ð¯ WORK-OUT 3:

R Package (due May-03)




12. R packaging (part 1)

ð Dates: Apr 22-26
ð Topics: Packages are the fundamental units of reproducible R code. They include reusable functions, the documentation that describes how to use them, and sample data. In this part we'll start describing how to turn your code into an R package.
ð Notes:

Programming S3 Classes
Methods (by Sanchez)


ð Reading:

Package Structure (R packages by Wickham)
See package components: http://r-pkgs.had.co.nz/ (R packages by Wickham)


ð¬ Lab:

HTML and Web scraping (due Apr-26)


ð¡ Cheat sheet:

Package Development cheat sheet


ð¯ WORK-OUT 3:

R Package




13. R Packaging (part 2)

ð Dates: Apr 29-May 03
ð Topics: Creating an R package can seem overwhelming at first. So we'll keep working on the creation of a relatively basic package. This will give you the opportunity to apply most of the concepts seen in the course.
ð Notes:

Pack YouR Code (by Sanchez)


ð Reading:

See package components: http://r-pkgs.had.co.nz (R packages by Wickham)


ð¬ Lab:

Take advantage of lab discussion to work on the workout03 assignment


ð¡ Cheat sheet:

Package Development cheat sheet


ð¯ WORK-OUT 3:

Keep working on your workout03 assignment. (due May-03)




14. RRR Week and Final Exam

ð Dates: May 06-10
ð Topics: Prepare for final examination
ð Notes:

No lecture. Instructor will hold OH (in 309 Evans)


ð FINAL: May-15th, 7-10 pm, in Wheeler 150

More details about the final will be posted on bCourses




",19
wz2cool/mybatis-dynamic-query,Java,"MyBatis Dynamic Query





The MyBatis Dynamic Query framework makes it easier to generate ""where"" and ""order"" expression dynamically in mapper xml.
mybatis-dynamic-query comes to solve four problem:

no need write lots of code in xml.
filtering or sorting maintained by java code.
hot update ""where"" and ""order"" expression.
save filter or sort descriptor and re-use them.

Docs
ä¸­æææ¡£1.x
|
ä¸­æææ¡£2.x
Database support

H2
MySql
SqlServer
Postresql
Oracle (TODO)

Maven
<dependency>
    <groupId>com.github.wz2cool</groupId>
    <artifactId>mybatis-dynamic-query</artifactId>
    <version>2.0.11</version>
</dependency>
Dynamic Query example

create two tables by sql.

DELETE FROM category;
INSERT INTO category (category_id, category_name, description) VALUES
  (1, 'Beverages', 'test'),
  (2, 'Condiments', 'test'),
  (3, 'Oil', 'test');

DELETE FROM product;
INSERT INTO product (product_id, category_id, product_name, price) VALUES
  (1, 1, 'Northwind Traders Chai', 18.0000),
  (2, 2, 'Northwind Traders Syrup', 7.5000),
  (3, 2, 'Northwind Traders Cajun Seasoning', 16.5000),
  (4, 3, 'Northwind Traders Olive Oil', 16.5000);

create a model map to this table.

public class ProductView {
    @Column(name = ""product_id"", table = ""product"")
    private Long productID;
    @Column(name = ""product_name"", table = ""product"")
    private String productName;
    @Column(name = ""price"", table = ""product"")
    private BigDecimal price;

    @Column(name = ""category_id"", table = ""category"")
    private Long categoryID;
    @Column(name = ""category_name"", table = ""category"")
    private String categoryName;
    @Column(name = ""description"", table = ""category"")
    private String description;

    // get, set method.
}

create a dynamic select in mapper interface / xml.

List<ProductView> getProductViewsByDynamic(Map<String, Object> params);
<select id=""getProductViewsByDynamic"" parameterType=""java.util.Map""
        resultType=""com.github.wz2cool.dynamic.mybatis.db.model.entity.view.ProductView"">
    SELECT
    <choose>
        <when test=""columnsExpression != null and columnsExpression !=''"">
            ${columnsExpression}
        </when>
        <otherwise>
            *
        </otherwise>
    </choose>
    FROM product LEFT JOIN category ON product.category_id = category.category_id
    <if test=""whereExpression != null and whereExpression != ''"">WHERE ${whereExpression}</if>
    <if test=""orderByExpression != null and orderByExpression != ''"">ORDER BY ${orderByExpression}</if>
</select>

generate expression and param map (NOTE: expression string also put into map).

@Test
public void testMultiTablesFilter() throws Exception {
    FilterDescriptor priceFilter1 =
            new FilterDescriptor(ProductView.class, ProductView::getPrice,
                    FilterOperator.GREATER_THAN_OR_EQUAL, 6);
    FilterDescriptor priceFilter2 =
            new FilterDescriptor(ProductView.class, ProductView::getPrice,
                    FilterOperator.LESS_THAN, 10);
    FilterDescriptor categoryNameFilter =
            new FilterDescriptor(ProductView.class, ProductView::getCategoryName,
                    FilterOperator.START_WITH, ""Co"");

    SortDescriptor idDescSort =
            new SortDescriptor(ProductView.class, ProductView::getProductID, SortDirection.DESC);

    Map<String, Object> params =
            // NOTE: we recommend you to set ""columnsExpressionPlaceholder""
            // in case of duplicated column name in two tables.
            // è¿éä½ ä¹å¯ä»¥ä¸ç»åçç«ä½ï¼ä½æ¯æ¨èä½¿ç¨ï¼é²æ­¢ä¸¤ä¸ªè¡¨æéå¤çåå­
            MybatisQueryProvider
                    .createInstance(ProductView.class, ""columnsExpression"")
                    .addFilters(""whereExpression"",
                            priceFilter1, priceFilter2, categoryNameFilter)
                    .addSorts(""orderByExpression"", idDescSort)
                    .toQueryParam();

    List<ProductView> result = northwindDao.getProductViewsByDynamic(params);
    assertEquals(true, result.size() > 0);
}
output result
==>  Preparing: SELECT product.product_id AS product_id, product.price AS price, category.description AS description, category.category_name AS category_name, product.product_name AS product_name, category.category_id AS category_id 
FROM product LEFT JOIN category ON product.category_id = category.category_id WHERE (product.price >= ? AND product.price < ? AND category.category_name LIKE ?) 
==> Parameters: 6(Integer), 10(Integer), Co%(String)
<==    Columns: PRODUCT_ID, PRICE, DESCRIPTION, CATEGORY_NAME, PRODUCT_NAME, CATEGORY_ID
<==        Row: 2, 7.5000, test, Condiments, Northwind Traders Syrup, 2
<==      Total: 1
Dynamic Query Mapper
DynamicQueryMapper is based on tk.mybatis.mapper.
spring boot configuration

add dependency

<!-- base -->
<dependency>
    <groupId>com.github.wz2cool</groupId>
    <artifactId>mybatis-dynamic-query</artifactId>
    <version>2.0.2</version>
</dependency>
<!-- register mapper -->
<dependency>
    <groupId>tk.mybatis</groupId>
    <artifactId>mapper-spring-boot-starter</artifactId>
    <version>1.1.3</version>
</dependency>
<!-- mybatis -->
<dependency>
    <groupId>org.mybatis</groupId>
    <artifactId>mybatis</artifactId>
    <version>3.4.4</version>
</dependency>
<dependency>
    <groupId>org.mybatis.spring.boot</groupId>
    <artifactId>mybatis-spring-boot-starter</artifactId>
    <version>1.3.0</version>
</dependency>
<!-- spring boot web already has jackson-->
<!--  <dependency>
    <groupId>com.fasterxml.jackson.core</groupId>
    <artifactId>jackson-databind</artifactId>
    <version>2.9.0</version>
</dependency>-->
<!-- spring boot -->
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-web</artifactId>
</dependency>
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-aop</artifactId>
</dependency>
<dependency>
    <groupId>org.mybatis.spring.boot</groupId>
    <artifactId>mybatis-spring-boot-starter</artifactId>
    <version>1.2.0</version>
</dependency>

register DynamicQueryMapper in application.properties file.

mapper.mappers[0]=com.github.wz2cool.dynamic.mybatis.mapper.DynamicQueryMapper

scan mappers.

@SpringBootApplication
@MapperScan(basePackages = ""com.github.wz2cool.mdqtest.mapper"")
@EnableSwagger2
public class Application {
    public static void main(String[] args) {
        SpringApplication.run(Application.class, args);
    }
}
create mapper
public interface ProductDao extends DynamicQueryMapper<Product> {
}

",20
MarkMoHR/Awesome-Image-Colorization,None,"Awesome-Image-Colorization
A collection of Deep Learning based Image Colorization papers and demos, including Automatic and User Guided (i.e. with User Interaction) colorization, as well as video colorization.

Feel free to create a PR or an issue.


Outline

Automatic Image Colorization
User Guided Image Colorization

Based on color strokes
Based on reference color image
Based on color palette
Based on language(text)


Video Colorization

Automatically
Based on reference




1. Automatic Image Colorization



Paper
Source
Code/Project Link




Learning Large-Scale Automatic Image Colorization
ICCV 2015
[project] [code]


Deep Colorization
ICCV 2015



Learning Representations for Automatic Colorization
ECCV 2016
[project] [code]


Colorful Image Colorization
ECCV 2016
[project] [code]


Let there be Color!: Joint End-to-end Learning of Global and Local Image Priors for Automatic Image Colorization with Simultaneous Classification
SIGGRAPH 2016
[project] [code]


Unsupervised Diverse Colorization via Generative Adversarial Networks
ECML-PKDD 2017
[code]


Learning Diverse Image Colorization
CVPR 2017
[code]


Structural Consistency and Controllability for Diverse Colorization
ECCV 2018



Pixelated Semantic Colorization
1901.10889




2. User Guided Image Colorization
2.1 Based on color strokes



Image Type
Paper
Source
Code/Project Link




Manga
Manga colorization
SIGGRAPH 2006



Line art / Sketch
Auto-painter: Cartoon Image Generation from Sketch by Using Conditional Generative Adversarial Networks
1705.01908
[code]


Natural Gray-Scale
Real-Time User-Guided Image Colorization with Learned Deep Priors
SIGGRAPH 2017
[project] [code1] [code2]


Sketch
Scribbler: Controlling Deep Image Synthesis with Sketch and Color
CVPR 2017



Line art
User-Guided Deep Anime Line Art Colorization with Conditional Adversarial Networks
ACM MM 2018
[code]


Line art
Two-stage Sketch Colorization
SIGGRAPH Asia 2018
[code]


Natural Gray-Scale
Interactive Deep Colorization Using Simultaneous Global and Local Inputs (also palette based)
ICASSP 2019



Line art / Sketch
Outline Colorization through Tandem Adversarial Networks
Online Demo
[Demo] [code]


Line art
Paints Chainer
Online Demo
[Demo] [code]


Line art
Style2paints
Online Demo
[Demo] [code]


Manga
MangaCraft
Online Demo
[Demo]



2.2 Based on reference color image



Image Type
Paper
Source
Code/Project Link




Manga
Comicolorization: Semi-Automatic Manga Colorization (also palette based)
SIGGRAPH Asia 2017
[code]


Sketch
TextureGAN: Controlling Deep Image Synthesis with Texture Patches
CVPR 2018
[code]


Natural Gray-Scale
Deep Exemplar-based Colorization
SIGGRAPH 2018
[code]


Natural Gray-Scale
Example-Based Colourization Via Dense Encoding Pyramids (also palette based)
Pacific Graphics 2018
[code]


Natural Gray-Scale
A Superpixel-based Variational Model for Image Colorization
TVCG 2019



Natural Gray-Scale
Automatic Example-based Image Colourisation using Location-Aware Cross-Scale Matching
TIP 2019




2.3 Based on color palette



Image Type
Paper
Source
Code/Project Link




Natural Image
Palette-based Photo Recoloring
SIGGRAPH 2015
[project]


Manga
Comicolorization: Semi-Automatic Manga Colorization (also reference based)
SIGGRAPH Asia 2017
[code]


Natural Gray-Scale
Coloring with Words: Guiding Image Colorization Through Text-based Palette Generation (also text based)
ECCV 2018
[code]


Natural Gray-Scale
Example-Based Colourization Via Dense Encoding Pyramids (also reference based)
Pacific Graphics 2018
[code]


Natural Gray-Scale
Interactive Deep Colorization Using Simultaneous Global and Local Inputs (also strokes based)
ICASSP 2019




2.4 Based on language or text



Image Type
Paper
Source
Code/Project Link




Natural Gray-Scale / Sketch
Language-Based Image Editing with Recurrent Attentive Models
CVPR 2018
[code]


Natural Gray-Scale
Coloring with Words: Guiding Image Colorization Through Text-based Palette Generation (also palette based)
ECCV 2018
[code]


Scene Sketch
LUCSS: Language-based User-customized Colorization of Scene Sketches
1808.10544
[code]



3. Video Colorization
3.1 Automatically



Paper
Source
Code/Project Link




Fully Automatic Video Colorization with Self-Regularization and Diversity
CVPR 2019




3.2 Based on reference



Paper
Source
Code/Project Link




Switchable Temporal Propagation Network
ECCV 2018



Tracking Emerges by Colorizing Videos
ECCV 2018
[code]


Deep Exemplar-based Video Colorization
CVPR 2019




",11
pypa/warehouse,Python,"Warehouse
Warehouse is the software that powers PyPI.
See our development roadmap, documentation, and
architectural overview.

Getting Started
You can run Warehouse locally in a development environment using
docker and docker-compose. See Getting started
documentation for instructions on how to set it up.
The canonical deployment of Warehouse is in production at pypi.org.

Discussion
If you run into bugs, you can file them in our issue tracker.
You can also join the chat channels #pypa (general packaging
discussion and user support) and #pypa-dev (discussion about
development of packaging tools) on Freenode, or the pypa-dev
mailing list, to ask questions or get involved.

Testing
Read the running tests and linters section of our documentation to
learn how to test your code.  For cross-browser testing, we use an
open source account from BrowserStack. If your pull request makes
any change to the user interface, it will need to be tested to confirm
it works in our supported browsers.


Code of Conduct
Everyone interacting in the Warehouse project's codebases, issue trackers, chat
rooms, and mailing lists is expected to follow the PyPA Code of Conduct.
",2154
Lombiq/Lombiq-Fields,C#,"Lombiq Fields Orchard module readme
An Orchard CMS module that adds some useful content fields:

Media Library Upload Field: a modified version of Media Library Picker Field that enables users to upload files attached to content items.
Money Field: a field for storing money-related values such as amount and currency using the .NET Money type.

The fields have their separate features that you can enable; after this the fields will be available to be added to content types. Note that the fields also have content type-level settings.
The module is also available for DotNest sites.
The module's source is available in two public source repositories, automatically mirrored in both directions with Git-hg Mirror:

https://bitbucket.org/Lombiq/lombiq-fields (Mercurial repository)
https://github.com/Lombiq/Lombiq-Fields (Git repository)

This project is developed by Lombiq Technologies Ltd. Commercial-grade support is available through Lombiq.
",2
damng/hackernews-rss-with-inlined-content,Python,"hackernews-rss-inlined-content
Loads the hackerness rss and inlines the contents of the pages. Chrome with Selenium loads the page, dom-distiller makes the contents like they're in firefox's reader mode, and the resulting html is served as the entry description. The 300 or so entries become about 5mb. PDFs and things that yield no usible text preview will remain as they were on the old feed.
I invoke it as:
  xvfb-run python main.py

I used xvfb-run instead of headless mode because extensions are not supported in headless. One directory up, in ""../dat"", is a chrome user profile data directory that is copied for each instance of the browser run and deleted when finished. You can initialize it and add whatever extensions you want. The resulting rss file is then commited/pushed on here and served via gitpages.
This is hack level code.
The feed is available at https://damng.github.io/hackernews-rss-with-inlined-content/output.rss
If you find this useful, don't give me anything. Instead, go to http://templeos.org, donate to the TempleOS project and become a Templar. Dontate to the Brain and Behavior Research Foundation (https://www.bbrfoundation.org/).
",10
subspacecloud/subspace,HTML,"Subspace - A simple WireGuard VPN server GUI

Screenshots
Screenshot 1
Screenshot 2
Screenshot 3
Screenshot 4
Features

WireGuard VPN Protocol

The most modern and fastest VPN protocol.


Single Sign-On (SSO) with SAML

Support for SAML providers like G Suite and Okta.


Add Devices

Connect from Mac OS X, Windows, Linux, Android, or iOS.


Remove Devices

Removes client key and disconnects client.


Auto-generated Configs

Each client gets a unique downloadable config file.



Run Subspace on Portal Cloud
Portal Cloud is a hosting service that enables anyone to run open source cloud applications.
Sign up for Portal Cloud and get $15 free credit with code Portal15.
Run Subspace on a VPS
Running Subspace on a VPS is designed to be as simple as possible.

Public Docker image.
Single static Go binary with assets bundled.
Automatic TLS using Let's Encrypt.
Redirects http to https.
Works with a reverse proxy or standalone.

1. Get a server
Recommended Specs

Type: VPS or dedicated
Distribution: Ubuntu 16.04 (Xenial)
Memory: 512MB or greater

2. Add a DNS record
Create a DNS A record in your domain pointing to your server's IP address.
Example: subspace.example.com  A  172.16.1.1
3. Enable Let's Encrypt
Subspace runs a TLS (""SSL"") https server on port 443/tcp. It also runs a standard web server on port 80/tcp to redirect clients to the secure server. Port 80/tcp is required for Let's Encrypt verification.
Requirements

Your server must have a publicly resolvable DNS record.
Your server must be reachable over the internet on ports 80/tcp and 443/tcp and 51820/udp (WireGuard).

Usage
Example usage:
$ subspace --http-host subspace.example.com
Usage
  -backlink string
        backlink (optional)
  -datadir string
        data dir (default ""/data"")
  -debug
        debug mode
  -help
        display help and exit
  -http-addr string
        HTTP listen address (default "":80"")
  -http-host string
        HTTP host
  -http-insecure
        enable sessions cookies for http (no https) not recommended
  -letsencrypt
        enable TLS using Let's Encrypt on port 443 (default true)
  -version
        display version and exit
Run as a Docker container
Install WireGuard on the host
The container expects WireGuard to be installed on the host. The official image is subspacecloud/subspace.
add-apt-repository -y ppa:wireguard/wireguard
apt-get update
apt-get install -y wireguard

# Remove dnsmasq because it will run inside the container.
apt-get remove -y dnsmasq

# Set DNS server.
echo nameserver 1.1.1.1 >/etc/resolv.conf

# Load modules.
modprobe wireguard
modprobe iptable_nat
modprobe ip6table_nat

# Enable IP forwarding
sysctl -w net.ipv4.ip_forward=1
sysctl -w net.ipv6.conf.all.forwarding=1

Follow the official Docker install instructions: Get Docker CE for Ubuntu
Make sure to change the --env SUBSPACE_HTTP_HOST to your publicly accessible domain name.
# Your data directory should be bind-mounted as `/data` inside the container using the `--volume` flag.
$ mkdir /data

docker create \
    --name subspace \
    --restart always \
    --network host \
    --cap-add NET_ADMIN \
    --volume /usr/bin/wg:/usr/bin/wg \
    --volume /data:/data \
    --env SUBSPACE_HTTP_HOST=subspace.example.com \
    subspacecloud/subspace:latest

$ sudo docker start subspace

$ sudo docker logs subspace

<log output>

Updating the container image
Pull the latest image, remove the container, and re-create the container as explained above.
# Pull the latest image
$ sudo docker pull subspacecloud/subspace

# Stop the container
$ sudo docker stop subspace

# Remove the container (data is stored on the mounted volume)
$ sudo docker rm subspace

# Re-create and start the container
$ sudo docker create ... (see above)
Help / Reporting Bugs
Email support@portal.cloud
",285
subspacecloud/subspace,HTML,"Subspace - A simple WireGuard VPN server GUI

Screenshots
Screenshot 1
Screenshot 2
Screenshot 3
Screenshot 4
Features

WireGuard VPN Protocol

The most modern and fastest VPN protocol.


Single Sign-On (SSO) with SAML

Support for SAML providers like G Suite and Okta.


Add Devices

Connect from Mac OS X, Windows, Linux, Android, or iOS.


Remove Devices

Removes client key and disconnects client.


Auto-generated Configs

Each client gets a unique downloadable config file.



Run Subspace on Portal Cloud
Portal Cloud is a hosting service that enables anyone to run open source cloud applications.
Sign up for Portal Cloud and get $15 free credit with code Portal15.
Run Subspace on a VPS
Running Subspace on a VPS is designed to be as simple as possible.

Public Docker image.
Single static Go binary with assets bundled.
Automatic TLS using Let's Encrypt.
Redirects http to https.
Works with a reverse proxy or standalone.

1. Get a server
Recommended Specs

Type: VPS or dedicated
Distribution: Ubuntu 16.04 (Xenial)
Memory: 512MB or greater

2. Add a DNS record
Create a DNS A record in your domain pointing to your server's IP address.
Example: subspace.example.com  A  172.16.1.1
3. Enable Let's Encrypt
Subspace runs a TLS (""SSL"") https server on port 443/tcp. It also runs a standard web server on port 80/tcp to redirect clients to the secure server. Port 80/tcp is required for Let's Encrypt verification.
Requirements

Your server must have a publicly resolvable DNS record.
Your server must be reachable over the internet on ports 80/tcp and 443/tcp and 51820/udp (WireGuard).

Usage
Example usage:
$ subspace --http-host subspace.example.com
Usage
  -backlink string
        backlink (optional)
  -datadir string
        data dir (default ""/data"")
  -debug
        debug mode
  -help
        display help and exit
  -http-addr string
        HTTP listen address (default "":80"")
  -http-host string
        HTTP host
  -http-insecure
        enable sessions cookies for http (no https) not recommended
  -letsencrypt
        enable TLS using Let's Encrypt on port 443 (default true)
  -version
        display version and exit
Run as a Docker container
Install WireGuard on the host
The container expects WireGuard to be installed on the host. The official image is subspacecloud/subspace.
add-apt-repository -y ppa:wireguard/wireguard
apt-get update
apt-get install -y wireguard

# Remove dnsmasq because it will run inside the container.
apt-get remove -y dnsmasq

# Set DNS server.
echo nameserver 1.1.1.1 >/etc/resolv.conf

# Load modules.
modprobe wireguard
modprobe iptable_nat
modprobe ip6table_nat

# Enable IP forwarding
sysctl -w net.ipv4.ip_forward=1
sysctl -w net.ipv6.conf.all.forwarding=1

Follow the official Docker install instructions: Get Docker CE for Ubuntu
Make sure to change the --env SUBSPACE_HTTP_HOST to your publicly accessible domain name.
# Your data directory should be bind-mounted as `/data` inside the container using the `--volume` flag.
$ mkdir /data

docker create \
    --name subspace \
    --restart always \
    --network host \
    --cap-add NET_ADMIN \
    --volume /usr/bin/wg:/usr/bin/wg \
    --volume /data:/data \
    --env SUBSPACE_HTTP_HOST=subspace.example.com \
    subspacecloud/subspace:latest

$ sudo docker start subspace

$ sudo docker logs subspace

<log output>

Updating the container image
Pull the latest image, remove the container, and re-create the container as explained above.
# Pull the latest image
$ sudo docker pull subspacecloud/subspace

# Stop the container
$ sudo docker stop subspace

# Remove the container (data is stored on the mounted volume)
$ sudo docker rm subspace

# Re-create and start the container
$ sudo docker create ... (see above)
Help / Reporting Bugs
Email support@portal.cloud
",285
FengGuanxi/HDU-Experience,C++,"é¡¹ç®ç®ä»ï¼
æ¬é¡¹ç®æä¸ºåæææ­çµå­¦å­æä¾åç§ä¿¡æ¯ï¼å­¦ä¹ èµæä»¥åçæ´»ç»éªç­ã
èªç«ç¸ä¼ ï¼åªä¸ºæ´å¥½çæ­çµã
æ»ä½ç»æï¼

å­¦ä¹ 

ç¼è¯åç
C++
Cè¯­è¨
æä½ç³»ç»
Java
å¤§å­¦ç©ç
å¤§è
çµå­ä¹¦
çµè·¯ä¸æ¨¡æçµå­ææ¯åºç¡
çµè·¯åç
çµè·¯åæ
æ¦çè®º
é«ç­æ°å­¦
å·¥ç¨å¶å¾
èç 
ç¦»æ£æ°å­¦
è®¡ç®æºå¾å½¢å­¦
è®¡ç®æºç³»ç»ç»æ
è®¡ç®æºç»æåç
è®¡ç®æºç½ç»
é©¬å
æ°å­å¾è±¡å¤ç
æ°å­çµè·¯
æ°å­¦å»ºæ¨¡
æ°æ®åºåçç²
æ°æ®ç»æ
ç®æ³å¯¼è®º
ç½ç»ç¼ç¨
è½¯ä»¶å·¥ç¨
éä¿¡åç
å¾åå¤çä¸åæ
visual basic
çº¿æ§ä»£æ°
ä¿¡å·ä¸ç³»ç»
ç°ä»£ç»æµç®¡çåºç¡
è±è¯­


æé¡¹

æ¬¢è¿æä¾èµææèå»ºè®®(æå¿)ï¼é®ç®±ï¼1007384211@qq.comï¼èç³»æ
èªæ¿é¼å±(æææèµ åå°è¢«ç¨äºè´­ä¹°å­¦ä¹ èµæ)~




",52
132yse/fre,JavaScript,"
Fre
ð» Fast 1kB React like library with the same hooks API





Feature

ð really functionalComponent, hooks API, render props
ð Fiber Reconciler and hash keyed diff algorithm
ð­ minimal but wonderful , just 1 KB , no dependences

Introduction
Fre (pronounced /fri:/, like free) is a tiny and perfect js library, It means Free! ~
Use
yarn add fre
import { h, render, useState } from 'fre'

function Counter() {
  const [count, setCount] = useState(0)
  return (
    <div>
      <h1>{count}</h1>
      <button onClick={() => setCount(count + 1)}>+</button>
    </div>
  )
}

render(<Counter />, document.getElementById('root'))

Hooks API
react hooks API is a miracle, and fre will make it become a leading role
useState
useState is a base API, It will receive initial state and return a Array
You can use it many times, new state is available when component is rerender
function Counter() {
  const [up, setUp] = useState(0)
  const [down, setDown] = useState(0)
  return (
    <div>
      <h1>{up}</h1>
      <button onClick={() => setUp(up + 1)}>+</button>
      <h1>{down}</h1>
      <button onClick={() => setDown(down -1)}>-</button>
    </div>
  )
}

render(<Counter />, document.getElementById('root'))
useReducer
useReducer and useState are almost the sameï¼but useReducer needs a global reducer
function reducer(state, action) {
  switch (action.type) {
    case 'up':
      return { count: state.count + 1 }
    case 'down':
      return { count: state.count - 1 }
  }
}

function Counter() {
  const [state, dispatch] = useReducer(reducer, { count: 1 })
  return (
    <div>
      {state.count}
      <button onClick={() => dispatch({ type: 'up' })}>+</button>
      <button onClick={() => dispatch({ type: 'down' })}>+</button>
    </div>
  )
}

render(<Counter />, document.getElementById('root'))
useEffect
useEffect takes two parameters, the first is a effect callback and the second is an array, usually props
When the array changes, the effect callback will run after commitWork
function Counter({ flag }) {
  const [count, setCount] = useState(0)
  useEffect(() => {
    document.title = 'count is ' + count
  }, [flag])
  return (
    <div>
      <h1>{count}</h1>
      <button onClick={() => setCount(count + 1)}>+</button>
    </div>
  )
}

render(<Counter />, document.getElementById('root'))
useMemo
useMemo has the same parameters as useEffect, but useMemo will be ran immediately.
function Counter() {
  const [count, setCount] = useState(0)
  return (
    <div>
      <h1>{count}</h1>
      <button onClick={() => setCount(count + 1)}>+</button>
      {(useMemo(<Sex />), [])}
    </div>
  )
}

render(<Counter />, document.getElementById('root'))
useContext
Context is the state of external create, internal use
When it changes, all components that own useContext will rerender
const ctx = createContext(0)

function App() {
  const [count, setCount] = useContext(ctx)
  return (
    <div>
      <h1>{count}</h1>
      <button onClick={() => setCount(count + 1)}>+</button>
      <Other />
    </div>
  )
}

function Other() {
  const count = useContext(ctx)[0]
  return <h1>{count}</h1>
}
FunctionalComponent
functionalComponent is a new components scheme
function App() {
  const [count, setCount] = useState(0)
  return (
    <div>
      <h1>{count}</h1>
      <button onClick={() => setCount(count + 1)}>+</button>
      <Sex count={count}/>
    </div>
  )
}

function Sex(props){
  const [sex, setSex] = useState('boy')
  return (
    <div>
      <h2>{props.count}</h2>
      <h1>{sex}</h1>
      <button onClick={() => {sex==='boy'?setSex('girl'):setSex('boy')}}>x</button>
    </div>
  )
}

render(<App />, document.getElementById('root'))
props
Props are used for component communication
function App() {
  const [sex, setSex] = useState('boy')
  return (
    <div>
      <Sex sex={sex} />
      <button
        onClick={() => (sex === 'boy' ? setSex('girl') : setSex('boy'))}
      />
    </div>
  )
}
function Sex(props) {
  return <div>{props.sex}</div>
}
Props contains children to render all the child elements of itself
const HelloBox = () => (
  <Box>
    <h1>Hello world !</h1>
  </Box>
)

const Box = props => <div>{props.children}</div>
Hooks do not support HOC and extends, but render props/children are supported by default
const HelloBox = () => (
  <Box>
    {value => {
      return <h1>{value}</h1>
    }}
  </Box>
)

const Box = props => <div>{props.children('hello world!')}</div>
Fiber
Fiber is a priority scheduling scheme.
It uses the traversal form of linked list to achieve time slicing
hash.keyed diff
Fre implements a compact diff algorithm
It uses hash to mark locations for easy comparison
JSX
The default export h function needs to be configured
import { h } from 'fre'
{
  ""plugins"": [
    [""transform-react-jsx"", { ""pragma"":""h"" }]
  ]
}
If it is a browser environment, recommend to use htm
License
MIT Â©132yse inspired by anu
",415
haskell-works/cabal-cache,Haskell,"cabal-cache

Tool for caching built cabal new-build packages.
The tool is useful in development when you want to share your build haskell package dependencies of
of a particular project with another developer and also in CI where caching is useful for reducing
build times.
cabal-cache supports syncing to an archive directory or to an S3 bucket.
Installation
Several installation methods are available.
From source
cabal new-install cabal-cache
Ubuntu binaries
Dowload Ubuntu binaries from https://github.com/haskell-works/cabal-cache/releases
Using Homebrew on Mac OS X
brew tap haskell-works/homebrew-haskell-works git@github.com:haskell-works/homebrew-haskell-works.git
brew update
brew install cabal-cache
Example usage
Syncing built packages with S3 requires you have an S3 bucket with AWS
credentials stored in the AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY environent variables.
You should also know the AWS region the bucket was created in.
Sync to archive
Change into your project directory.
Build the project with cabal v2-build.  This will ensure your dependencies are built and
will produce a plan.json file that is required for the cabal-cache tool to know which built
packages to sync up.
Run the following command to sync to S3.
cabal-cache sync-to-archive --threads 16 --archive-uri s3://my-cabal-cache-bucket/archive --region Sydney
Run the following command to sync to archive directory.
cabal-cache sync-to-archive --threads 16 --archive-uri archive --region Sydney
Sync from S3
Change into your project directory.
Build the project with cabal v2-configure.  This will product a plan.json file that is required
for the cabal-cache tool to know which built packages to sync down.
Run the following command to sync from S3.
cabal-cache sync-from-archive --threads 16 --archive-uri s3://my-cabal-cache-bucket/archive --region Sydney
Run the following command to sync from archive directory.
cabal-cache sync-from-archive --threads 16 --archive-uri archive --region Sydney
The archive
Archive tarball format
Built packages are stored in tarballs which contain the following files:
x ${compiler_id}/${package_id}/_CC_METADATA/store-path
x ${compiler_id}/lib/libHS${package_id}-*.dylib
x ${compiler_id}/${package_id}
x ${compiler_id}/package.db/${package_id}.conf
Aside from the files in the _CC_METADATA directory, everything else is copied verbatim from cabal
store from the corresponding location.  This includes the conf file which may contain absolute paths
that would cause the built package to be non-relocatable.
As a work-around, the tarball also inclues the _CC_METADATA/store-path
file which stores the cabal store path from which the cached package was derived.
Upon unpacking, cabal-cache will rewrite the conf file to contain the new store path using the
information store in the _CC_METADATA/store-path file.  _CC_METADATA directory and its contents
will be additionally unpacked making it easy to recognise packages that have been restored using
cabal-cache.
Archive directory structure
The archive contains files in the following locations:
/Users/jky/moo-archive/${archive_version}/${compiler_id}/${package_id}.tar.gz
/Users/jky/moo-archive/${archive_version}/${store_hash}/${compiler_id}/${package_id}.tar.gz
Both tarballs are identical.  If they both exist then the first may be a symlink to the second
when store on the filesystem.
The direct subdirectories of the archive is the ${archive_verson}, for example v1.  This is the
version of the archive format.  This corresponds to the major version of the cabal-cache package.
The next directory may be the ${store_hash} or the ${compiler_id}.  If it is the ${store_hash}
then the ${compiler_id} will be a subdirectory of that.
The ${store_hash} is the hash of the store path from which the cached package originally came.
cabal-cache will preferentially restore using this version if it is available and the ${store_hash}
matches the cabal store path that is being restore to.
If the package matching the ${store_hash} cannot be found, cabal-cache will fallback to the version
without the ${store_hash}.
A version without a ${store-hash} may not exist.  See Caveats for more information.
Caveats
Packages that use absolute paths to the cabal store
Packages sometimes do things that cause their built artefacts to contain absolute paths to the cabal
store.  This unfortunately makes such built packages non-relocatable.
It is recommended that you use a fixed cabal store path rather than the default $HOME/.cabal/store
to avoid any potential issues.
See https://github.com/haskell/cabal/issues/4097 for more information.
Following are examples of how this might happen:
Paths_$pkgname
Paths_$pkgname modules have embedded within them the absolute path to the package in the cabal store
which means that packages that use some features of this module are not relocatable depending on what
they do.
Packages may query this module to get access to the package's cabal store share directory which
contains data files that the package can read at runtime.  Using cabal-cache for such packages
could mean that the package will be unable to find such data files.
To protect against this, cabal-cache will by default not sync packages down from the archive
if the package's cabal store share directory contain unusual files or directories unless the
${store_hash} matches.  Currently it only considers the doc subdirectory to be usual.  More
exceptions may be added later.
",22
SplendidStrontium/splendidstrontium.github.io,CSS,"splendidstrontium.github.io
@TODO

sitemap.html

",2
mfrasco/Metrics,R,"Metrics



How to Install this Package
This package is distributed from CRAN. From the R prompt, run install.packages(""Metrics"").
Metrics Repo
This repository contains code for the Metrics package in R. Metrics was created by Ben Hamner and came from this github repo. Hamner's repo contains packages for common machine learning metrics in several programming languages, not just R. On 2017-04-21, CRAN orphaned the R package. To revive the status of the R package, I cloned the original and created this repo. I have added new metrics, improved documentation, and fixed bugs. This repository will be the home of active development on the Metrics R package moving forward.
Community Feedback
If you notice anything wrong with the Metrics package or have any ideas on how to improve it, please create an issue in this github repository that describes your issue. I also welcome improvements to this package via a pull request. This is a simple R package, which makes it perfect for first time open source contributors. Here is a guide that walks you through how to make an open source contribution.
What Metrics are Included in this Package?
All functions in the Metrics package take at least two arguments: actual and predicted. In the table below, I abbreviate actual as x and predicted as y for the sake of mathematical brevity.



Metric Type
Metric Name
Function Name
Formula




regression
Squared Error
se



regression
Mean Squared Error
mse



regression
Root Mean Squared Error
rmse



regression
Absolute Error
ae



regression
Mean Absolute Error
mae



regression
Absolute Percent Error
ape



regression
Mean Absolute Percent Error
mape



regression
Symmetric Mean Absolute Percent Error
smape



regression
Squared Log Error
sle



regression
Mean Squared Log Error
msle



regression
Root Mean Squared Log Error
rmsle



regression
Relative Squared Error
rse



regression
Root Relative Squared Error
rrse



regression
Relative Absolute Error
rae



time series
Mean Absolute Scaled Error
mase



classification
Classification Error
ce



classification
Accuracy
accuracy



classification
F1 Score
f1



binary classification
Area Under ROC Curve
auc
. help(auc) for details.


binary classification
Log Loss
ll



binary classification
Mean Log Loss
logloss



binary classification
Precision
precision



binary classification
Recall
recall



binary classification
F-beta Score
fbeta_score




",69
Ultimate-Hosts-Blacklist/www.shallalist.de,Python,"About www.shallalist.de


About Ultimate-Hosts-Blacklist
Ultimate-Hosts-Blacklist serve a place to test and keep a track on each input sources that are present into Ultimate Hosts Blacklist.
As Ultimate Hosts Blacklist grew up it became impossible to test the whole repository, as it takes weeks to finish. That's why we use the GitHub organization system in order to create different repository for each list that are present into Ultimate Hosts Blacklist.

About PyFunceble
PyFunceble like Funceble is A tool to check domains or IP availability by returning 3 possible status: ACTIVE, INACTIVE or INVALID.
It also has been described by one of its most active user as:

[An] excellent script for checking ACTIVE, INACTIVE and EXPIRED domain names.

If you need further informations about PyFunceble or Funceble please report to our Wiki page and/or if you don't find any answer feel free to create an issue into one of the Dead Hosts's or Py-Funceble's repositories.
About the status returned by PyFunceble
For an up to date version of this part please report to the Status section of our Wiki.
ACTIVE
This status is returned when one of the following cases is met:


We can extract the expiration date from Lookup().whois().

Please note that we don't check if the date is in the past.



Lookup().nslookup() don't return server can't find domain-name.me: NXDOMAIN.


HTTOCode().get() return one the following code [100, 101, 200, 201, 202, 203, 204, 205, 206].


INACTIVE
This status is returned when all the following cases are met:

We can't extract the expiration date from Lookup().whois().
Lookup().nslookup() return server can't find domain-name.me: NXDOMAIN.

INVALID
This status is returned when the following case is met:


Domain extension has an invalid format or is unregistered in IANA Root Zone Database.

Understand by this that the extension is not present into the iana-domains-db.json file.



",2
baguette/crux-ports,Shell,"crux-ports
Some ports for the CRUX operating system. This README was modified from CRUX MATE's.
Quickstart
This git repository is also a ports collection. You can enable it like so:
On your CRUX Linux target installation download the file /etc/ports/baguette.httpup:
curl https://raw.githubusercontent.com/baguette/crux-ports/master/baguette.httpup -o /etc/ports/baguette.httpup

Enable the contrib ports collection rsync in /etc/ports if it's not already enabled:
mv contrib.rsync.inactive contrib.rsync

Edit the file /etc/prt-get.conf and enable the contrib collection (it is needed for some dependencies). Then in /etc/prt-get.conf put
prtdir /usr/ports/baguette 

Then issue
ports -u

at the command line to get the ports collection (and any updates to other port collections)
Installing the awesome window manager
Issue the following command:
prt-get depinst awesome

When this completes (it will take some time - assuming there are no problems or conflicts), enable the dbus daemon at startup in your /etc/rc.conf file (example below)
SERVICES=(dbus net crond) 

If using startx configure your .xinitrc with
exec awesome

Then issue 'startx' at the command line. Assuming kernel compile options are correct you should find yourself with a working awesome desktop (basic).
Adwaita
The Adwaita GTK+ theme is included in the gnome-themes-standard package.  The Adwaita icon theme is included in the adwaita-icon-theme package. To use them with GTK+2, add the following lines to /usr/etc/gtk-2.0/gtkrc
gtk-icon-theme-name = ""Adwaita""
gtk-theme-name = ""Adwaita""

Haskell Platform
The haskell-platform-bin port provides the Haskell Platform. It installs into the non-standard location /usr/local/haskell. This is normally a big no-no for CRUX, but I could not figure out how to get it to install in any other location and still work properly.
Once the package is installed, you need to add /usr/local/haskell/ghc-7.10.3-x86_64/bin to your PATH to use it.
Issues
If anything doesn't work as described in this README, please report your issues.
",3
baguette/crux-ports,Shell,"crux-ports
Some ports for the CRUX operating system. This README was modified from CRUX MATE's.
Quickstart
This git repository is also a ports collection. You can enable it like so:
On your CRUX Linux target installation download the file /etc/ports/baguette.httpup:
curl https://raw.githubusercontent.com/baguette/crux-ports/master/baguette.httpup -o /etc/ports/baguette.httpup

Enable the contrib ports collection rsync in /etc/ports if it's not already enabled:
mv contrib.rsync.inactive contrib.rsync

Edit the file /etc/prt-get.conf and enable the contrib collection (it is needed for some dependencies). Then in /etc/prt-get.conf put
prtdir /usr/ports/baguette 

Then issue
ports -u

at the command line to get the ports collection (and any updates to other port collections)
Installing the awesome window manager
Issue the following command:
prt-get depinst awesome

When this completes (it will take some time - assuming there are no problems or conflicts), enable the dbus daemon at startup in your /etc/rc.conf file (example below)
SERVICES=(dbus net crond) 

If using startx configure your .xinitrc with
exec awesome

Then issue 'startx' at the command line. Assuming kernel compile options are correct you should find yourself with a working awesome desktop (basic).
Adwaita
The Adwaita GTK+ theme is included in the gnome-themes-standard package.  The Adwaita icon theme is included in the adwaita-icon-theme package. To use them with GTK+2, add the following lines to /usr/etc/gtk-2.0/gtkrc
gtk-icon-theme-name = ""Adwaita""
gtk-theme-name = ""Adwaita""

Haskell Platform
The haskell-platform-bin port provides the Haskell Platform. It installs into the non-standard location /usr/local/haskell. This is normally a big no-no for CRUX, but I could not figure out how to get it to install in any other location and still work properly.
Once the package is installed, you need to add /usr/local/haskell/ghc-7.10.3-x86_64/bin to your PATH to use it.
Issues
If anything doesn't work as described in this README, please report your issues.
",3
goragod/GCMS,PHP,"GCMS 13.3.0
GCMS à¹à¸à¹à¸ Ajax CMS à¸ªà¸¡à¸à¸¹à¸£à¸à¹à¹à¸à¸ à¸à¸µà¹à¸à¸±à¸à¸à¸²à¹à¸à¸¢à¸à¸à¹à¸à¸¢à¸à¸±à¹à¸à¸£à¸°à¸à¸ à¹à¸à¸·à¹à¸­à¹à¸«à¹à¸à¸²à¸£à¹à¸à¹à¸à¸²à¸ CMS à¹à¸à¸ Ajax à¹à¸à¹à¸à¹à¸£à¸·à¹à¸­à¸à¸à¸µà¹à¸à¹à¸²à¸¢à¸à¸¶à¹à¸ à¹à¸¥à¸°à¹à¸à¹à¸à¸±à¸à¸«à¸²à¸à¸­à¸ Ajax à¸à¸µà¹à¹à¸à¹à¸à¸à¸µà¹à¸à¸±à¸à¸§à¸¥ à¸à¸±à¹à¸à¹à¸à¹à¸£à¸·à¹à¸­à¸à¸à¸²à¸£à¸£à¸­à¸à¸£à¸±à¸à¸«à¸¥à¸²à¸¢à¸à¸£à¸²à¸§à¹à¸à¸­à¸£à¹, à¸à¸²à¸£à¸à¸´à¸à¸à¸²à¸£à¹à¸à¹à¸à¸²à¸ Javascript, à¸à¸²à¸£ Refresh à¸«à¸à¹à¸², à¸à¸²à¸£ Bookmark, à¸à¸²à¸£à¹à¸à¹à¸à¸²à¸à¸à¸¸à¹à¸¡ History à¸à¸­à¸à¸à¸£à¸²à¸§à¹à¸à¸­à¸£à¹ à¹à¸¥à¸°à¸à¸µà¹à¸ªà¸³à¸à¸±à¸à¸à¸·à¸­ SEO
GCMS à¹à¸«à¸¡à¸²à¸°à¸ªà¸¡à¸ªà¸³à¸«à¸£à¸±à¸à¸à¸²à¸£à¸à¸³à¹à¸§à¹à¸à¹à¸à¸à¹à¸à¸±à¹à¸§à¹à¸ à¸à¸±à¹à¸à¹à¸§à¹à¸à¹à¸à¸à¹à¸ªà¹à¸§à¸à¸à¸¸à¸à¸à¸¥ à¸«à¸à¹à¸§à¸¢à¸à¸²à¸à¸£à¸²à¸à¸à¸²à¸£ à¸«à¸£à¸·à¸­à¹à¸§à¹à¸à¹à¸à¸à¹à¸­à¸·à¹à¸à¹ à¸à¸±à¹à¸à¹à¸à¹à¸à¸à¸²à¸à¹à¸¥à¹à¸ à¹à¸à¸à¸à¸à¸¶à¸à¹à¸§à¹à¸à¹à¸à¸à¹à¸à¸à¸²à¸à¹à¸«à¸à¹ à¸à¹à¸§à¸¢à¸à¸²à¸£à¸­à¸­à¸à¹à¸à¸à¸à¸µà¹à¹à¸à¹à¸à¸­à¸´à¸ªà¸£à¸°à¹à¸à¸à¸²à¸£à¸à¸£à¸±à¸à¸à¸£à¸¸à¸à¸«à¸à¹à¸²à¹à¸§à¹à¸ à¹à¸¡à¹à¸¡à¸¸à¹à¸à¹à¸à¹à¸à¹à¸à¸à¸µà¹à¹à¸§à¹à¸à¹à¸à¸à¹à¹à¸à¸à¹à¸à¹à¸à¸à¸«à¸à¸¶à¹à¸à¹à¸à¸¢à¹à¸à¸à¸²à¸° à¹à¸¥à¸°à¸¡à¸µà¸à¸¸à¸à¸ªà¸¡à¸à¸±à¸à¸´à¹à¸à¸·à¹à¸­à¸à¸à¹à¸à¸à¹à¸­à¸à¸²à¸£à¸­à¸­à¸à¹à¸à¸à¹à¸§à¹à¸à¹à¸à¸à¹à¸à¸±à¹à¸§à¹à¸à¹à¸à¹à¸à¹à¸²à¸¢ à¸à¸­à¸à¸à¸²à¸à¸à¸µà¹ GCMS à¸¢à¸±à¸à¹à¸«à¸¡à¸²à¸°à¸ªà¸¡à¹à¸à¹à¸à¸­à¸¢à¹à¸²à¸à¸¢à¸´à¹à¸ à¸ªà¸³à¸«à¸£à¸±à¸à¸à¸¹à¹à¸à¸µà¹à¸à¸­à¸à¸­à¸­à¸à¹à¸à¸à¹à¸§à¹à¸à¸à¹à¸§à¸¢à¸à¸±à¸§à¹à¸­à¸ à¸à¹à¸§à¸¢à¸à¸²à¸£à¹à¸à¹ GCMS à¹à¸à¹à¸à¸à¸·à¹à¸à¸à¸²à¸à¸à¸­à¸à¹à¸§à¹à¸à¹à¸à¸·à¹à¸­à¸à¸à¸²à¸ GCMS à¸¡à¸µà¸£à¸°à¸à¸à¸à¸·à¹à¸à¸à¸²à¸à¸à¸£à¸à¸à¹à¸§à¸ à¹à¸¥à¸°à¸­à¸­à¸à¹à¸à¸à¹à¸¡à¸à¸¹à¸¥à¸à¸²à¸¡à¸à¸§à¸²à¸¡à¸à¹à¸­à¸à¸à¸²à¸£à¹à¸à¸·à¹à¸­à¹à¸à¹à¸à¸²à¸à¸£à¹à¸§à¸¡à¸à¸±à¸ GCMS à¸à¸¶à¹à¸à¸à¸³à¹à¸«à¹à¸à¸£à¸°à¸«à¸¢à¸±à¸à¹à¸§à¸¥à¸²à¹à¸à¸à¸²à¸£à¸­à¸­à¸à¹à¸à¸à¹à¸§à¹à¸à¸¥à¸à¹à¸à¹à¸à¸­à¸¢à¹à¸²à¸à¸¡à¸²à¸
à¸«à¸²à¸à¸à¸¸à¸à¸¡à¸µà¸à¹à¸­à¸ªà¸à¸ªà¸±à¸¢ à¸à¹à¸­à¹à¸ªà¸à¸­à¹à¸à¸° à¸«à¸£à¸·à¸­à¸à¹à¸­à¸à¸à¸²à¸£à¸à¸§à¸²à¸¡à¸à¹à¸§à¸¢à¹à¸«à¸¥à¸·à¸­à¹à¸à¸µà¹à¸¢à¸§à¸à¸±à¸ GCMS à¸à¸¸à¸à¸ªà¸²à¸¡à¸²à¸£à¸à¸«à¸²à¸à¸§à¸²à¸¡à¸à¹à¸§à¸¢à¹à¸«à¸¥à¸·à¸­à¸à¸±à¹à¸à¹à¸à¹à¸à¸µà¹ https://goragod.com à¹à¸¥à¸°à¸à¸¸à¸à¸ªà¸²à¸¡à¸²à¸£à¸à¹à¸ªà¸à¸à¸à¸§à¸²à¸¡à¸à¸´à¸à¹à¸«à¹à¸à¸à¸­à¸à¸à¸¸à¸à¸à¹à¸­ GCMS à¸£à¸§à¸¡à¸à¸¶à¸à¸à¸±à¸à¸«à¸²à¹à¸à¸à¸²à¸£à¹à¸à¹à¸à¸²à¸ à¸à¸¥à¸­à¸à¸à¸à¸à¹à¸­à¸à¸´à¸à¸à¸¥à¸²à¸à¸à¹à¸²à¸à¹ à¸à¸­à¸ GCMS à¹à¸à¹ à¸à¸§à¸²à¸¡à¸à¸´à¸à¹à¸«à¹à¸à¸à¸­à¸à¸à¸¸à¸à¸à¸°à¸à¹à¸§à¸¢à¸à¸¡à¹à¸à¸à¸²à¸£à¸à¸±à¸à¸à¸² GCMS à¹à¸«à¹à¸à¸µà¸¢à¸´à¹à¸à¸à¸¶à¹à¸à¹à¸à¹à¸­à¸à¸²à¸¨à¸à¹à¸­à¹à¸

à¹à¸§à¹à¸à¹à¸à¸à¹à¸«à¸¥à¸±à¸ GCMS http://gcms.in.th
à¸à¸±à¸§à¸­à¸¢à¹à¸²à¸à¹à¸§à¹à¸à¹à¸à¸à¹à¸à¸±à¹à¸§à¹à¸ http://demo.gcms.in.th
à¸à¸±à¸§à¸­à¸¢à¹à¸²à¸à¹à¸§à¹à¸à¹à¸£à¸à¹à¸£à¸µà¸¢à¸à¸«à¸£à¸·à¸­ à¸­à¸à¸. http://school.gcms.in.th

à¸à¹à¸­à¸à¸à¸¥à¸à¸à¸²à¸£à¸à¸³ GCMS à¹à¸à¹à¸à¹à¸à¸²à¸

GCMS à¹à¸à¹à¸ Ajax CMS à¸à¸à¸´à¸ Open Source à¸à¸µà¹à¹à¸à¸à¸à¹à¸²à¸¢à¹à¸«à¹à¸à¸±à¸à¸à¸¸à¸à¸à¸à¸ªà¸²à¸¡à¸²à¸£à¸à¸à¸³à¹à¸à¹à¸à¹à¸à¸²à¸à¹à¸à¹ à¸à¸£à¸µ à¹à¸à¸¢à¸¡à¸µà¹à¸à¸·à¹à¸­à¸à¹à¸à¸§à¹à¸² à¸à¹à¸­à¸à¸à¸´à¸à¸à¹à¸­à¸à¸§à¸²à¸¡à¸«à¸£à¸·à¸­à¹à¸à¸£à¸·à¹à¸­à¸à¸«à¸¡à¸²à¸¢à¸à¸­à¸à¸à¸¹à¹à¸à¸±à¸à¸à¸²à¹à¸§à¹à¹à¸ªà¸¡à¸­ (https://goragod.com à¹à¸¥à¸° http://www.webshopready.com)
à¸«à¹à¸²à¸¡à¸à¸³ GCMS à¸«à¸£à¸·à¸­ à¸ªà¹à¸§à¸à¸«à¸à¸¶à¹à¸à¸ªà¹à¸§à¸à¹à¸à¸à¸­à¸ GCMS à¹à¸ à¸à¸³à¸«à¸à¹à¸²à¸¢ à¸à¹à¸²à¸¢ à¹à¸à¸ à¸«à¸£à¸·à¸­ à¹à¸à¹à¸à¸²à¸à¸à¸±à¸à¸à¸¸à¸à¸à¸¥à¸à¸µà¹à¸ªà¸²à¸¡ à¹à¸§à¹à¸à¹à¸à¹à¸à¸°à¹à¸à¹à¸£à¸±à¸à¸à¸§à¸²à¸¡à¸¢à¸´à¸à¸¢à¸­à¸¡à¸à¸²à¸à¸à¸¹à¹à¸à¸±à¸à¸à¸²
à¸à¸¸à¸à¸ªà¸²à¸¡à¸²à¸£à¸à¸à¸±à¸à¸à¸²à¸à¹à¸­à¸¢à¸­à¸ à¹à¸à¸´à¹à¸¡à¹à¸à¸´à¸¡ à¹à¸à¹à¹à¸ à¸«à¸£à¸·à¸­ à¸à¸±à¸à¹à¸à¸¥à¸ GCMS à¹à¸à¹à¹à¸à¸·à¹à¸­à¸à¸²à¸£à¹à¸à¹à¸à¸²à¸à¸ªà¹à¸§à¸à¸à¸¸à¸à¸à¸¥ à¹à¸à¸¢à¸à¹à¸­à¸à¸à¸´à¸à¸à¹à¸­à¸à¸§à¸²à¸¡à¸«à¸£à¸·à¸­à¹à¸¥à¹à¸à¸à¸­à¸à¸à¸¹à¹à¸à¸±à¸à¸à¸²à¹à¸§à¹à¹à¸ªà¸¡à¸­à¹à¸¡à¹à¸§à¹à¸²à¸à¸°à¹à¸à¸¥à¸µà¹à¸¢à¸à¹à¸à¸¥à¸à¹à¸à¸¡à¸²à¸à¸à¹à¸­à¸¢à¹à¸à¹à¹à¸«à¸à¸à¹à¸à¸²à¸¡
à¸à¸¸à¸à¸ªà¸²à¸¡à¸²à¸£à¸à¸à¸±à¸à¸à¸² à¹à¸¡à¸à¸¹à¸¥à¹à¸ªà¸£à¸´à¸¡ à¸«à¸£à¸·à¸­ à¸§à¸´à¸à¹à¸à¹à¸ à¸«à¸£à¸·à¸­ à¸ªà¹à¸§à¸à¸à¸£à¸°à¸à¸­à¸à¸­à¸·à¹à¸à¹à¸ (à¸à¸­à¸à¸à¸²à¸à¸à¸µà¹à¸¡à¸µà¹à¸à¸à¸à¹à¸²à¸¢à¹à¸à¸¢à¸à¸¹à¹à¸à¸±à¸à¸à¸²à¸­à¸¢à¸¹à¹à¹à¸¥à¹à¸§) à¹à¸à¸·à¹à¸­à¹à¸à¹à¸«à¸£à¸·à¸­à¹à¸à¸·à¹à¸­à¸à¸³à¸«à¸à¹à¸²à¸¢ à¸à¹à¸²à¸¢ à¹à¸à¸à¹à¸à¹ à¹à¸à¸¢à¹à¸«à¹à¸ªà¸´à¸à¸à¸´à¹à¹à¸à¹à¸à¸à¸­à¸à¸à¸¹à¹à¸à¸±à¸à¸à¸²à¹à¸­à¸ (à¸à¸²à¸¢à¸«à¸£à¸·à¸­à¹à¸à¸à¹à¸à¸à¸²à¸°à¹à¸¡à¸à¸¹à¸¥)
à¸«à¸²à¸à¸à¸¸à¸à¸à¹à¸­à¸à¸à¸²à¸£à¸à¸³ GCMS à¹à¸à¹à¸à¹à¸à¸±à¸à¸à¸¸à¸à¸¥à¸à¸µà¹à¸ªà¸²à¸¡ à¸«à¸£à¸·à¸­ à¹à¸à¸·à¹à¸­à¸à¸²à¸¢ à¸«à¸£à¸·à¸­à¸à¹à¸­à¸à¸à¸²à¸£à¸à¸³à¹à¸à¸£à¸·à¹à¸­à¸à¸«à¸¡à¸²à¸¢à¸«à¸£à¸·à¸­à¸à¹à¸­à¸à¸§à¸²à¸¡à¸à¸­à¸à¸à¸¹à¹à¸à¸±à¸à¸à¸²à¸­à¸­à¸ à¸à¸¸à¸à¸ªà¸²à¸¡à¸²à¸£à¸à¸à¸´à¸à¸à¹à¸­à¸à¸±à¸à¸à¸¹à¹à¸à¸±à¸à¸à¸²à¹à¸à¹à¹à¸à¸¢à¸à¸£à¸ à¸à¸²à¸¡à¸à¸µà¹à¸­à¸¢à¸¹à¹à¹à¸ https://goragod.com

à¸à¸²à¸£à¸à¸´à¸à¸à¸±à¹à¸à¹à¸¥à¸°à¸­à¸±à¸à¹à¸à¸£à¸

à¸à¸²à¸§à¸à¹à¹à¸«à¸¥à¸à¹à¸à¹à¸à¸à¸±à¹à¸à¸«à¸¡à¸à¸à¸²à¸ Github
à¸à¸²à¸£à¸­à¸±à¸à¹à¸à¸£à¸ à¸à¹à¸­à¸à¸à¸²à¸§à¸à¹à¹à¸«à¸¥à¸ Theme à¹à¸à¸à¸´à¸à¸à¸±à¹à¸à¹à¸«à¸¡à¹à¸à¹à¸§à¸¢
à¹à¸à¸à¹à¸à¸¥à¹à¹à¸¥à¸°à¸­à¸±à¸à¹à¸«à¸¥à¸à¹à¸à¸¥à¹à¸à¸±à¹à¸à¸«à¸¡à¸à¹à¸à¸¢à¸±à¸ Server
à¸à¸´à¸à¸à¸±à¹à¸à¸«à¸£à¸·à¸­à¸­à¸±à¸à¹à¸à¸£à¸ GCMS à¹à¸à¸¢à¹à¸£à¸µà¸¢à¸ http://domain.tld/install/ à¹à¸¥à¸°à¸à¸³à¸à¸²à¸¡à¸à¸±à¹à¸à¸à¸­à¸à¸à¹à¸²à¸à¹à¸à¸µà¹à¸à¸±à¸§à¸­à¸±à¸à¹à¸à¸£à¸à¹à¸à¹à¸
à¸à¸à¸ªà¸­à¸à¹à¸£à¸µà¸¢à¸à¹à¸§à¹à¸à¹à¸à¸à¹ à¹à¸à¸¢à¹à¸à¹à¸²à¸£à¸°à¸à¸à¹à¸­à¸à¸¡à¸´à¸
à¸¥à¸à¹à¸à¹à¸£à¹à¸à¸à¸­à¸£à¸µà¹ install/ à¸­à¸­à¸

à¹à¸à¸à¸£à¸à¸µà¸à¸µà¹à¹à¸à¹à¸à¸à¸²à¸£à¸­à¸±à¸à¹à¸à¸£à¸ à¸«à¸¥à¸±à¸à¸à¸²à¸à¸à¸²à¸£à¸­à¸±à¸à¹à¸à¸£à¸à¹à¸ªà¸£à¹à¸à¸ªà¸´à¹à¸ à¸ªà¸¡à¸²à¸à¸´à¸à¸à¸¸à¸à¸à¸à¸à¸°à¸à¹à¸­à¸à¸à¸­à¸£à¸«à¸±à¸ªà¸à¹à¸²à¸à¹à¸«à¸¡à¹ à¸«à¸²à¸à¹à¸­à¸à¸¡à¸´à¸à¹à¸¡à¹à¸ªà¸²à¸¡à¸²à¸£à¸à¹à¸à¹à¸²à¸£à¸°à¸à¸à¹à¸à¹ à¹à¸«à¹à¸à¸³à¹à¸à¸´à¸à¸à¸²à¸£à¸à¸±à¸à¸à¸µà¹
à¹à¸à¸´à¸à¸à¸²à¸£à¸²à¸ xxx_user (xxx à¸à¸·à¸­ prefix à¸à¸­à¸à¸à¸²à¸à¸à¹à¸­à¸¡à¸¹à¸¥) à¸¡à¸­à¸à¸«à¸²à¸£à¸²à¸¢à¸à¸²à¸£ id 1 (à¸«à¸£à¸·à¸­à¸£à¸²à¸¢à¸à¸²à¸£à¸­à¸µà¹à¸¡à¸¥à¹à¸à¸­à¸à¸à¸±à¸§à¹à¸­à¸) à¹à¸¥à¹à¸§à¸à¸£à¸­à¸à¸à¹à¸²à¸à¹à¸²à¸à¹à¸à¹à¸²à¸à¸¥à¹à¸²à¸à¸¥à¸à¹à¸à¸à¸²à¸£à¸²à¸

à¸à¸­à¸¥à¸±à¸¡à¸à¹ email à¹à¸«à¹à¸à¸£à¸­à¸ admin@localhost
à¸à¸­à¸¥à¸±à¸¡à¸à¹ password à¹à¸«à¹à¸à¸£à¸­à¸ 378b16462af3df83bc996c94706d5edd1c750a7a
à¸à¸­à¸¥à¸±à¸¡à¸à¹ salt à¹à¸«à¹à¸à¸£à¸­à¸ 5ba77fe459b43

à¸à¸°à¸ªà¸²à¸¡à¸²à¸£à¸à¹à¸à¹à¸²à¸£à¸°à¸à¸à¹à¸à¸¢à¹à¸à¹à¸à¸±à¸à¸à¸µ à¸­à¸µà¹à¸¡à¸¥à¹ admin@localhost à¹à¸¥à¸°à¸£à¸«à¸±à¸ªà¸à¹à¸²à¸ admin à¹à¸à¹ (à¸«à¸¥à¸±à¸à¸à¸²à¸à¹à¸à¹à¸²à¸£à¸°à¸à¸à¹à¸à¹à¹à¸¥à¹à¸§ à¹à¸«à¹à¹à¸à¸¥à¸µà¹à¸¢à¸à¸­à¸µà¹à¸¡à¸¥à¹à¹à¸¥à¸°à¸£à¸«à¸±à¸ªà¸à¹à¸²à¸à¸à¸¥à¸±à¸à¹à¸à¹à¸à¹à¸«à¸¡à¸·à¸­à¸à¹à¸à¸´à¸¡ à¹à¸à¸¢à¸à¸³à¹à¸à¸´à¸à¸à¸²à¸£à¸à¸à¸£à¸°à¸à¸à¹à¸«à¹à¹à¸£à¸µà¸¢à¸à¸£à¹à¸­à¸¢à¸à¹à¸§à¸¢)
à¸à¸±à¸§à¸­à¸±à¸à¹à¸à¸£à¸à¹à¸¡à¹à¸£à¸­à¸à¸£à¸±à¸à¸à¸²à¸£à¸­à¸±à¸à¹à¸à¸£à¸à¸à¸²à¸ GCMS à¹à¸§à¸­à¸£à¹à¸à¸±à¹à¸à¸à¹à¸³à¸à¸§à¹à¸² 9.1.0 à¸à¸°à¸à¸£à¸±à¸ à¹à¸à¸¢à¸à¸°à¸à¹à¸­à¸à¸à¸³à¸à¸²à¸£à¸­à¸±à¸à¹à¸à¸£à¸à¹à¸«à¹à¹à¸à¹à¸ 9.1.0 à¸à¹à¸­à¸à¸à¸¶à¸à¸à¸°à¸­à¸±à¸à¹à¸à¸£à¸à¹à¸«à¹à¹à¸à¹à¸à¹à¸§à¸­à¸£à¹à¸à¸±à¹à¸à¸¥à¹à¸²à¸ªà¸¸à¸à¹à¸à¹
à¸à¸²à¸£à¸­à¸±à¸à¹à¸à¸£à¸à¸à¸²à¸ GCMS 11.0.0 à¸à¸¶à¹à¸à¹à¸ à¹à¸«à¹à¸¥à¸à¹à¸à¹à¸£à¹à¸à¸à¸­à¸£à¸µà¹ Gcms/ Kotchasan/ PDF/ Widgets/ admin/ ckeditor/ js/ modules/ à¸­à¸­à¸ à¹à¸¥à¹à¸§à¸­à¸±à¸à¹à¸«à¸¥à¸à¹à¸à¸¥à¹à¸à¸±à¹à¸à¸«à¸¡à¸à¸à¸²à¸à¸à¸µà¹à¸à¸²à¸§à¸à¹à¹à¸«à¸¥à¸à¹à¸ à¹à¸à¹à¸à¸à¸à¸µà¹ à¹à¸ªà¸£à¹à¸à¹à¸¥à¹à¸§à¸à¸¶à¸à¹à¸£à¸µà¸¢à¸à¸à¸±à¸§à¸à¸´à¸à¸à¸±à¹à¸
à¸à¸²à¸£à¸­à¸±à¸à¹à¸à¸£à¸à¸à¸²à¸ GCMS 11.2.0 à¸à¸¶à¹à¸à¹à¸ à¹à¸«à¹à¸­à¸±à¸à¹à¸«à¸¥à¸à¹à¸à¸¥à¹à¸à¸±à¹à¸à¸«à¸¡à¸à¸à¸²à¸à¸à¸µà¹à¸à¸²à¸§à¸à¹à¹à¸«à¸¥à¸à¹à¸à¹à¸à¸à¸à¸µà¹à¹à¸à¸¥à¹à¹à¸à¸´à¸¡à¹à¸à¹à¹à¸¥à¸¢à¹à¸ªà¸£à¹à¸à¹à¸¥à¹à¸§à¹à¸£à¸µà¸¢à¸à¸à¸±à¸§à¸à¸´à¸à¸à¸±à¹à¸

",4
dluciano/pokedex,JavaScript,"
The project description can be founded here: Challenge
The pokedex is a challange I founded in github and it's a brilliant way to learn Angular and other concepts. Main knowledge applied in this project are: convert an image to a functional web page, use of frontend libraries and technologies: SASS, HTML5, Angular 6. Also CI/CD, and DRY was used because I started the project from a template of Angular with a huge amount of already done solutions (integration to jenkis, e2e with protractor, angular 6, webpack, and so on).
Tech stack:

Angular 6
NPM
Travis CI
Docker
Typescript
TSLint
Karma
Jasmine
Protractor
Webpack
Git/Github
Polyfills
Serverless/SPA/Pokeapi
Pokeapi-js-wrapper

Screens: The pokeapi proxy service is down :( I will upload it later when I implement the JS wrapper of the pokedex api or if the proxy server go online again. Nonetheless, it looks like the screens in the challange.


Docker Hub Image

Thanks to the team of â PatrickJS the template is a valuable asset.
Thanks for the awesome idea of the challenge challenge
Thanks for the template
Thanks for the library of pokedex for javascript (not implemented yet but I will)

",2
betteridiot/terminal_support,Vim script,"Terminal_support
Repo containing files used for customizing the terminal and vim

Instructions
Note: if you are mac user, just change .bashrc to .bash_profile
Also, to allow for powerline-shell support, perfom the following:
pip install powerline-shell

Clone the repo

git clone https://github.com/betteridiot/terminal_support.git

Move into directory

cd terminal_support
Note: If you are using a conda-build of Python:
Change line 113 to your /etc/profile.d/conda.sh and uncomment both lines 113-114

Now move all the files to your $HOME directory using the provided script

./build_terminal.sh
Note: this script will move any pre-existing files that overlap with this
repo into a folder in your home directory called backup. If any of the
provided files cause any issues, just recover previous files from this directory.
Additionally: If you would like to utilize powerline-shell support (and you installed it
with pip, perform the following:
cp powerline-bashrc/.bashrc ~/

What this does

Gives you a more colorful prompt
Adds git-prompt support that lists the current branch the current repo is on
Puts directories before files when listing them (ll)
Makes sure your history is large enough
Makes your tab = 4 spaces
gives you access to jupyter lab using the alias jlab

As long as your current environment has JupyterLab installed, it will run it, silence all the output, and put it in the background (not locking your prompt)



",2
PermiJW/signSGD-with-Majority-Vote,Python,"signSGD-with-Majority-Vote
This repository contains the code used for paper:

signSGD with Majority Vote is Commnunication Efficient and Byzantine Fault Tolerant

This code was originally forked from the End to end ImageNet training.
Pre-installation
Downloading ImageNet

You can download ImageNet from Kaggle.
You can download from our S3 bucket (s3://signum-majority-vote/dataset/ILSVRC.tar) (reproduction purpose only).

C++ extension installation

Put the folder 'main/bit2byte-extension' to the directory of the PyTorch source code
Execute this command on the directory of 'bit2byte-extension'
python setup.py install
You can find more information about C++ extension in PyTorch documentation

Experiments
Note: You have to execute following commands in each instance.
ImageNet Benchmark
Execute following commands on the directory of 'main'
Training Signum

ulimit -n 1000000
sudo /home/ubuntu/anaconda3/envs/fastai/bin/python3 -m torch.distributed.launch \ --nproc_per_node=1 --nnodes=[number of instances] --node_rank=[rank of instance] --master_addr=""0.0.0.0"" \ --master_port=1235 benchmark_main.py ~/ILSVRC/Data/CLS-LOC -a resnet50 -b 128 --lr 0.0001 \ --epochs 80 --save-dir ./ --world-size [number of instances] --print-freq 200 --compress --dist_backend gloo --weight-decay 1e-4 --momentum 0.9 --warm-up \ --dist-url [parameter sever's url]

Training Vanilla SGD

ulimit -n 1000000
sudo /home/ubuntu/anaconda3/envs/fastai/bin/python3 -m torch.distributed.launch \ --nproc_per_node=1 --nnodes=[number of instances] --node_rank=[rank of instance] --master_addr=""0.0.0.0"" \ --master_port=1235 benchmark_main.py ~/ILSVRC/Data/CLS-LOC -a resnet50 -b 128 --lr 0.1 \ --epochs 80 --save-dir ./ --world-size [number of instances] --print-freq 200 --all_reduce --dist_backend nccl --weight-decay 0.1 --momentum 0.9 --warm-up \ --dist-url [parameter sever's url]

QRNN Benchmark
Execute following commands on the directory of 'benchmark/QRNN'
Training Signum

/home/ubuntu/anaconda3/envs/qrnn/bin/python3 -u -m torch.distributed.launch \ --nproc_per_node=1 --nnodes=[number of instances] --node_rank=[rank of instance] --master_addr=""0.0.0.0"" \ --master_port=1235 main_signum.py --epochs 12 --nlayers 4 --emsize 400 --nhid 2500 --alpha 0 --beta 0 \ --dropoute 0 --dropouth 0.1 --dropouti 0.1 --dropout 0.1 --wdrop 0 --wdecay 0 --bptt 140 --batch_size 240 \ --optimizer signum --lr 1e-3 --momentum 0.5 --data data/wikitext-103 --save WT103.12hr.QRNN.pt --when 12 --model QRNN \ --world-size [number of instances] --dist-url [parameter sever's url] \ --save-dir ./ --distributed --multi_gpu --momentun_warm_up 

Training Adam

/home/ubuntu/anaconda3/envs/qrnn/bin/python3 -u -m torch.distributed.launch \ --nproc_per_node=1 --nnodes=[number of instances] --node_rank=[rank of instance] --master_addr=""0.0.0.0"" \ --master_port=1235 main_signum.py --epochs 12 --nlayers 4 --emsize 400 --nhid 2500 --alpha 0 --beta 0 \ --dropoute 0 --dropouth 0.1 --dropouti 0.1 --dropout 0.1 --wdrop 0 --wdecay 0 --bptt 140 --batch_size 240 \ --optimizer adam --lr 1e-3 --momentum 0.5 --data data/wikitext-103 --save WT103.12hr.QRNN.pt --when 12 --model QRNN \ --world-size [number of instances] --dist-url [parameter sever's url] \ --save-dir ./ --distributed --multi_gpu --momentun_warm_up 

QSGD Benchmark
Execute following commands on the directory of 'benchmark/QSGD'
Training Signum

ulimit -n 1000000
sudo /home/ubuntu/anaconda3/envs/fastai/bin/python3 -m torch.distributed.launch \ --nproc_per_node=1 --nnodes=[number of instances] --node_rank=[rank of instance] --master_addr=""0.0.0.0"" \ --master_port=1235 benchmark_main.py ~/ILSVRC/Data/CLS-LOC -a resnet50 -b 128 --lr 1e-4 --seed 1 \ --epochs 90 --save-dir ./ --world-size [number of instances] --print-freq 50 \ --extra_epochs 0 --compress --signum --communication_method Signum \ --dist-url [parameter sever's url] 

Training QSGD

ulimit -n 1000000
sudo /home/ubuntu/anaconda3/envs/fastai/bin/python3 -m torch.distributed.launch \ --nproc_per_node=1 --nnodes=[number of instances] --node_rank=[rank of instance] --master_addr=""0.0.0.0"" \ --master_port=1235 benchmark_main.py ~/ILSVRC/Data/CLS-LOC -a resnet50 -b 128 --lr 0.1 --seed 1 \ --epochs 90 --save-dir ./ --world-size [number of instances] --print-freq 50 \ --extra_epochs 0 --compress --signum --communication_method QSGD --qsgd_level [the level of QSGD] [--enable_max, if enable max_norm] --all_reduce \ --dist-url [parameter sever's url] 

Krum Benchmark
Execute following commands on the directory of 'benchmark/Krum'
Training Signum

ulimit -n 1000000
sudo /home/ubuntu/anaconda3/envs/fastai/bin/python3 -m torch.distributed.launch \ --nproc_per_node=1 --nnodes=[number of instances] --node_rank=[rank of instance] --master_addr=""0.0.0.0"" \ --master_port=1235 benchmark_main.py ~/ILSVRC/Data/CLS-LOC -a resnet50 -b 128 --lr 1e-3 \ --epochs 90 --save-dir ./ --world-size 7 --print-freq 50 \ --extra_epochs 0 --compress --signum --communication_method Signum \ --enable_adversary --adversary_num [the number of adversaries] [--enable_minus_adversary, enable minus adversary or it will be random one] \ --dist-url [parameter sever's url] 

Training Krum

ulimit -n 1000000
sudo /home/ubuntu/anaconda3/envs/fastai/bin/python3 -m torch.distributed.launch \ --nproc_per_node=1 --nnodes=[number of instances] --node_rank=[rank of instance] --master_addr=""0.0.0.0"" \ --master_port=1235 benchmark_main.py ~/ILSVRC/Data/CLS-LOC -a resnet50 -b 128 --lr 1e-1 \ --epochs 90 --save-dir ./ --world-size 7 --print-freq 50 \ --extra_epochs 0 --compress --signum --communication_method Signum \ --enable_krum --krum_f [the number of F] --enable_adversary --adversary_num [the number of adversaries] \ --dist-url [parameter sever's url] 

",46
LCTT/TranslateProject,Shell,"






ç®ä»
LCTT æ¯âLinux ä¸­å½âï¼https://linux.cn/ï¼çç¿»è¯ç»ï¼è´è´£ä»å½å¤ä¼ç§åªä½ç¿»è¯ Linux ç¸å³çææ¯ãèµè®¯ãææç­åå®¹ã
LCTT å·²ç»æ¥æå ç¾åæ´»è·æåï¼å¹¶æ¬¢è¿æ´å¤ç Linux å¿æ¿èå å¥æä»¬çå¢éã


LCTT å®ç½ï¼ https://linux.cn/lctt/
LCTT ç¶æï¼ https://lctt.github.io/

å å¥æä»¬
è¯·é¦åå å¥ç¿»è¯ç»ç QQ ç¾¤ï¼ç¾¤å·æ¯ï¼198889102ï¼å ç¾¤æ¶è¯·è¯´ææ¯âå¿æ¿èâã
å å¥çæåï¼è¯·ï¼

ä¿®æ¹ä½ ç QQ ç¾¤åçä¸ºâè¯è-æ¨ç_GitHub_IDâã
éè¯» WIKI äºè§£å¦ä½å¼å§ã
éå°ä¸è§£ä¹å¤ï¼è¯·å¨ç¾¤ååé®ã

å¦ä½å¼å§
è¯·éè¯» WIKIãå¦éè¦åå©ï¼è¯·å¨ç¾¤ååé®ã
åå²

2013/09/10 å¡è®®å¹¶å¾å°äºå¤§å®¶çç§¯æååºï¼æç«ç¿»è¯ç»ã
2013/09/11 éç¨ GitHub è¿è¡ç¿»è¯åä½ï¼å¹¶å¼å§è¿è¡éé¢ç¿»è¯ã
2013/09/16 å¬å¼åå¸äºç¿»è¯ç»æç«æ¶æ¯åï¼åææ°çæåç³è¯·å å¥äºãå¹¶ä»æ­¤å»ºç«è§ä¹ æåå¶åº¦ã
2013/09/24 é´äºå¤§å®¶ä½¿ç¨ GitHub çæ°´å¹³ä¸ä¸ï¼å®¹æå¯¼è´ä¸»ä»åºçä¸äºéè¯¯ï¼å æ­¤æ¢æäºå¸¸è§ç fork+PR çæ¨¡å¼æ¥è¿è¡ç¿»è¯æµç¨ã
2013/10/11 æ ¹æ®å¯¹ LCTT çè´¡ç®ï¼ååäº Core Translators ç»ï¼æåçå å¥æåæ¯ vito-L å tinyeyeserã
2013/10/12 åæ¶å¯¹ LINUX.CN æ³¨åç¨æ·çå³èï¼å¨ QQ ç¾¤åãæç« åé½éç¨ GitHub çæ³¨å IDã
2013/10/18 æ­£å¼å¯å¨ man ç¿»è¯è®¡åã
2013/11/10 ä¸¾è¡ç¬¬ä¸æ¬¡åäº¬çº¿ä¸èä¼ã
2014/01/02 å¢å äº Core Translators æå: geekpiã
2014/05/04 æ´æ¢äºæ°ç QQ ç¾¤ï¼198889102
2014/05/16 å¢å äº Core Translators æå: will.qianãvizvã
2014/06/18 ç±äº GOLinux ä»¤äººæå¹çç¿»è¯éåº¦åä¸éçç¿»è¯è´¨éï¼åçº§ä¸º Core Translators æåã
2014/09/09 LCTT ä¸å¨å¹´ï¼åä¸å¹´æ»ç»ãå¹¶å°æ¾ä»» CORE çæååç»ä¸º Seniorï¼ä»¥è¡¨å½°ä»ä»¬çè´¡ç®ã
2014/10/08 æå bazz2 ä¸º Core Translators æåã
2014/11/04 æå zpl1025 ä¸º Core Translators æåã
2014/12/25 æå runningwater ä¸º Core Translators æåã
2015/04/19 åèµ· LFS-BOOK-7.7-systemd é¡¹ç®ã
2015/06/09 æå ictlyh å dongfengweixiao ä¸º Core Translators æåã
2015/11/10 æå strugglingyouthãFSSlcãVic020ãalim0x ä¸º Core Translators æåã
2016/02/18 ç±äºéé¢ DeadFire éçï¼ä»»å½ oska874 æ¥æéé¢å·¥ä½ã
2016/02/29 éé¢ DeadFire çéã
2016/05/09 æå PurlingNayuki ä¸ºæ ¡å¯¹ã
2016/09/10 LCTT ä¸å¨å¹´ã
2016/12/24 æå® LCTT Core è§åï¼å¹¶å¢å æ°ç Core æåï¼ ucasFLãmartin2011qiï¼åè°æ´ä¸äºç»ã
2017/03/13 å¶ä½äº LCTT ä¸»é¡µãæååè¡¨åæåä¸»é¡µï¼LCTT ä¸»é¡µå°ç§»å¨è³ https://linux.cn/lctt ã
2017/03/16 æå GHLandyãbestonyãrusking ä¸ºæ°ç Core æåãåå»º Comic å°ç»ã
2017/04/11 å¯ç¨å¤´è¡å¶ï¼ä¸ºåä½éè¦æåé¢åå¤´è¡ã
2017/11/21 é´äº qhwdw å¿«éèä¸ä½³çç¿»è¯è´¨éï¼æå qhwdw ä¸ºæ°ç Core æåã
2017/11/19 wxy å¨ä¸æµ·äº¤å¤§ä¸¾åç 2017 ä¸­å½å¼æºå¹´ä¼ä¸åäºæ¼è®²ï¼ãå¦ä½ä»¥ç¿»è¯è´¡ç®åä¸å¼æºç¤¾åºãã
2018/01/11 æå lujun9972 æä¸ºæ ¸å¿æåï¼å¹¶å å¥éé¢ç»ã
2018/02/20 é­é DMCA ä»åºè¢«å°ã
2018/05/15 æå MjSeven ä¸ºæ ¸å¿æåã
2018/08/01 åå¸ Linux ä¸­å½éè¯ï¼LCCNã
2018/08/17 æå pityonline ä¸ºæ ¸å¿æåï¼æä»»æ ¡å¯¹ï¼å¹¶æ¥åä»çå»ºè®®éç¨ PR å®¡æ ¸æ¨¡å¼ã
2018/09/10 LCTT äºå¨å¹´ã
2018/10/25 éæäº CIï¼æè°¢ vizvãlujun9972ãbestonyã
2018/11/13 æç«äºé¡¹ç®ç®¡çå§åä¼ï¼PMCï¼ï¼åå§æåä¸ºï¼@wxy ï¼ä¸»å¸­ï¼ã@oska874ã@lujun9972ã@bestonyã@pityonlineã@geekpiã@qhwdwã

é¡¹ç®ç®¡çå§ååæ ¸å¿æå
LCTT ç°ç±é¡¹ç®ç®¡çå§åä¼ï¼PMCï¼è¿è¡ç®¡çï¼æåå¦ä¸ï¼

ð© ä¸»å¸­ @wxy
ð© éé¢ @oska874
ð© éé¢ @lujun9972
ð© ææ¯ @bestony
ð© æ ¡å¯¹ @pityonline
ð© è¯è @geekpi
ð© è¯è @qhwdw

ç®å LCTT æ ¸å¿æåæï¼

â¤ï¸ æ ¸å¿æå @vizv
â¤ï¸ æ ¸å¿æå @zpl1025
â¤ï¸ æ ¸å¿æå @runningwater
â¤ï¸ æ ¸å¿æå @FSSlc
â¤ï¸ æ ¸å¿æå @Vic020
â¤ï¸ æ ¸å¿æå @alim0x
â¤ï¸ æ ¸å¿æå @martin2011qi
â¤ï¸ æ ¸å¿æå @Locez
â¤ï¸ æ ¸å¿æå @ucasFL
â¤ï¸ æ ¸å¿æå @MjSeven

æ¾ç»ååºäºå·¨å¤§è´¡ç®çæ ¸å¿æåï¼è¢«åå¥è£èªæ¦ï¼

ð åä»»éé¢ @DeadFire
ð åä»»æ ¡å¯¹ @reinoir222
ð åä»»æ ¡å¯¹ @PurlingNayuki
ð åä»»æ ¡å¯¹ @carolinewuyan
ð åä»»æ ¡å¯¹ @jasminepeng
ð ååæå @tinyeyeser
ð ååæå @vito-L
ð ååæå @willqian
ð ååæå @GOLinux
ð ååæå @bazz2
ð ååæå @ictlyh
ð ååæå @dongfengweixiao
ð ååæå @strugglingyouth
ð ååæå @GHLandy
ð ååæå @rusking

å¨é¨æååè¡¨è¯·åè§ï¼ https://linux.cn/lctt-list/ ã
è°¢è°¢å¤§å®¶çæ¯æï¼
",1353
jdlingyu/ad-wars,None,"å¤§å£åå ä½¿ç¨å¸®å©
åºç¨ä¸è½½å°å(æèµ çæ¬éæ¿æ´»ç )

https://fir.im/adwars

éåå«æ/æç©º/åå§åè½ï¼ä¸æ¬¾å¤ç§å§¿å¿å»é¤å¹¿åçåºç¨...
å«æ é·å®ä¸è½½(åè´¹)

åå©æ éç¢æå¡ï¼éè¿æå­/ViewId/å±å¹åæ æ¥æ¨¡æç¹å»ï¼å¯ä»¥ç¨æ¥è·³è¿å¯å¨é¡µå¹¿åã

æç©º é·å®ä¸è½½(åè´¹)

åºäº Xposed æ¡æ¶ï¼å¨ä¸æ¹ååçå®è£åçåæä¸ï¼ç¨å¤ç§æ¦æªææ®µæ¶ç­å¯å¨å¹¿åã

åå§ é·å®ä¸è½½(åè´¹)

ãå«æããæç©ºãçè§åæ°æ®å±äº«ã

å¯»æ¾ç»ç»

Telegram(æå¼404çè¯ ä½ æç)
QQç¾¤ï¼559898993

ç®å½

æç©ºåå
å«æå©æ
å«æåæ 
å¤§å£FAQ
æ¬æµ®çªè§£ç 
ä¿æåºç¨åå°è®¾ç½®
æç©ºå é
æ¿æ¢è§å

",24
jdayllon/contratacionestado,None,"contratacionestado
El objetivo del proyecto es generar un dataset sobre contrataciÃ³n del sector pÃºblico para facilitar la reutilizaciÃ³n y el anÃ¡lisis de la informaciÃ³n que genera este tipo de contrataciÃ³n
Sobre la informaciÃ³n recogida


La informaciÃ³n en el repositorio procede de las pÃ¡ginas web de los organismos:

Junta de AndalucÃ­a (http://www.juntadeandalucia.es)
Generalitat de Catalunya. (https://contractaciopublica.gencat.cat/)



Las transformaciones aplicadas buscan facilitar el proceso de la informaciÃ³n o enriquecer la informaciÃ³n ofrecida por las plataformas anteriores.


La estructura de los datos se estÃ¡ adaptando a un modelo inspirado en CODICE 2.1 / UBL
** MÃ¡s informaciÃ³n en: https://contrataciondelestado.es/wps/portal/codice


Propiedad Intelectual
Junta de AndalucÃ­a
Tal y como se cita en el aviso legal del Portal de la Junta de AndalucÃ­a:
La Junta de AndalucÃ­a promueve el libre uso y reutilizaciÃ³n de los textos disponibles en el presente Portal sobre los que ostenta derechos de propiedad intelectual. Dichos textos estÃ¡n disponibles a travÃ©s de una licencia-tipo Creative Commons Reconocimiento 3.0.
De modo general, la Junta de AndalucÃ­a te autoriza a:

Copiar, redistribuir y comunicar pÃºblicamente los textos del Portal.
Hacer un uso comercial de los contenidos.
Generar obras derivadas.

He impone las siguientes obligaciones:

Reconocer explÃ­citamente la fuente de informaciÃ³n Identificada en el presente texto.
Incluir la misma obligaciÃ³n de reconocimiento en los tÃ©rminos de licencia de cualquier producto derivado que haga uso de esta informaciÃ³n. * Por lo que usuarios de esta informaciÃ³n deben tener presente esta obligaciÃ³n *
No desnaturalizar el sentido de la informaciÃ³n reproducida.
Evitar cualquier rasgo de presentaciÃ³n que sugiera que la Junta de AndalucÃ­a apoya o promueve el uso que se hace de la informaciÃ³n difundida. En ningÃºn caso estÃ¡ permitida la reproducciÃ³n de logotipos, escudos, sÃ­mbolos y marcas identificativas de la Junta de AndalucÃ­a sin autorizaciÃ³n expresa de la instituciÃ³n.

Generalitat de Catalunya
TODO
",2
pytorch/pytorch,C++,"

PyTorch is a Python package that provides two high-level features:

Tensor computation (like NumPy) with strong GPU acceleration
Deep neural networks built on a tape-based autograd system

You can reuse your favorite Python packages such as NumPy, SciPy and Cython to extend PyTorch when needed.

More about PyTorch
Installation

Binaries
From Source
Docker Image
Building the Documentation
Previous Versions


Getting Started
Communication
Releases and Contributing
The Team




System
2.7
3.5
3.6




Linux CPU


â


Linux GPU


â


Windows CPU / GPU
â

â


Linux (ppc64le) CPU

â



Linux (ppc64le) GPU

â




See also the ci.pytorch.org HUD.
More About PyTorch
At a granular level, PyTorch is a library that consists of the following components:



Component
Description




torch
a Tensor library like NumPy, with strong GPU support


torch.autograd
a tape-based automatic differentiation library that supports all differentiable Tensor operations in torch


torch.jit
a compilation stack (TorchScript) to create serializable and optimizable models from PyTorch code


torch.nn
a neural networks library deeply integrated with autograd designed for maximum flexibility


torch.multiprocessing
Python multiprocessing, but with magical memory sharing of torch Tensors across processes. Useful for data loading and Hogwild training


torch.utils
DataLoader and other utility functions for convenience



Usually one uses PyTorch either as:

a replacement for NumPy to use the power of GPUs.
a deep learning research platform that provides maximum flexibility and speed.

Elaborating further:
A GPU-Ready Tensor Library
If you use NumPy, then you have used Tensors (a.k.a ndarray).

PyTorch provides Tensors that can live either on the CPU or the GPU, and accelerates the
computation by a huge amount.
We provide a wide variety of tensor routines to accelerate and fit your scientific computation needs
such as slicing, indexing, math operations, linear algebra, reductions.
And they are fast!
Dynamic Neural Networks: Tape-Based Autograd
PyTorch has a unique way of building neural networks: using and replaying a tape recorder.
Most frameworks such as TensorFlow, Theano, Caffe and CNTK have a static view of the world.
One has to build a neural network, and reuse the same structure again and again.
Changing the way the network behaves means that one has to start from scratch.
With PyTorch, we use a technique called reverse-mode auto-differentiation, which allows you to
change the way your network behaves arbitrarily with zero lag or overhead. Our inspiration comes
from several research papers on this topic, as well as current and past work such as
torch-autograd,
autograd,
Chainer, etc.
While this technique is not unique to PyTorch, it's one of the fastest implementations of it to date.
You get the best of speed and flexibility for your crazy research.

Python First
PyTorch is not a Python binding into a monolithic C++ framework.
It is built to be deeply integrated into Python.
You can use it naturally like you would use NumPy / SciPy / scikit-learn etc.
You can write your new neural network layers in Python itself, using your favorite libraries
and use packages such as Cython and Numba.
Our goal is to not reinvent the wheel where appropriate.
Imperative Experiences
PyTorch is designed to be intuitive, linear in thought and easy to use.
When you execute a line of code, it gets executed. There isn't an asynchronous view of the world.
When you drop into a debugger, or receive error messages and stack traces, understanding them is straightforward.
The stack trace points to exactly where your code was defined.
We hope you never spend hours debugging your code because of bad stack traces or asynchronous and opaque execution engines.
Fast and Lean
PyTorch has minimal framework overhead. We integrate acceleration libraries
such as Intel MKL and NVIDIA (cuDNN, NCCL) to maximize speed.
At the core, its CPU and GPU Tensor and neural network backends
(TH, THC, THNN, THCUNN) are mature and have been tested for years.
Hence, PyTorch is quite fast â whether you run small or large neural networks.
The memory usage in PyTorch is extremely efficient compared to Torch or some of the alternatives.
We've written custom memory allocators for the GPU to make sure that
your deep learning models are maximally memory efficient.
This enables you to train bigger deep learning models than before.
Extensions Without Pain
Writing new neural network modules, or interfacing with PyTorch's Tensor API was designed to be straightforward
and with minimal abstractions.
You can write new neural network layers in Python using the torch API
or your favorite NumPy-based libraries such as SciPy.
If you want to write your layers in C/C++, we provide a convenient extension API that is efficient and with minimal boilerplate.
There is no wrapper code that needs to be written. You can see a tutorial here and an example here.
Installation
Binaries
Commands to install from binaries via Conda or pip wheels are on our website:
https://pytorch.org
NVIDIA Jetson platforms
Python wheels for NVIDIA's Jetson Nano, Jetson TX2, and Jetson AGX Xavier are available via the following URLs:

Stable binaries:

Python 2.7: https://nvidia.box.com/v/torch-stable-cp27-jetson-jp42
Python 3.6: https://nvidia.box.com/v/torch-stable-cp36-jetson-jp42


Rolling weekly binaries:

Python 2.7: https://nvidia.box.com/v/torch-weekly-cp27-jetson-jp42
Python 3.6: https://nvidia.box.com/v/torch-weekly-cp36-jetson-jp42



They requires JetPack 4.2 and above and are maintained by @dusty-nv
From Source
If you are installing from source, we highly recommend installing an Anaconda environment.
You will get a high-quality BLAS library (MKL) and you get a controlled compiler version regardless of your Linux distro.
Once you have Anaconda installed, here are the instructions.
If you want to compile with CUDA support, install

NVIDIA CUDA 7.5 or above
NVIDIA cuDNN v6.x or above

If you want to disable CUDA support, export environment variable NO_CUDA=1.
Other potentially useful environment variables may be found in setup.py.
If you are building for NVIDIA's Jetson platforms (Jetson Nano, TX1, TX2, AGX Xavier), Instructions to are available here
Install Dependencies
Common
conda install numpy ninja pyyaml mkl mkl-include setuptools cmake cffi typing

On Linux
# Add LAPACK support for the GPU if needed
conda install -c pytorch magma-cuda90 # or [magma-cuda80 | magma-cuda92 | magma-cuda100 ] depending on your cuda version
Get the PyTorch Source
git clone --recursive https://github.com/pytorch/pytorch
cd pytorch
# if you are updating an existing checkout
git submodule sync 
git submodule update --init --recursive
Install PyTorch
On Linux
export CMAKE_PREFIX_PATH=${CONDA_PREFIX:-""$(dirname $(which conda))/../""}
python setup.py install
On macOS
export CMAKE_PREFIX_PATH=${CONDA_PREFIX:-""$(dirname $(which conda))/../""}
MACOSX_DEPLOYMENT_TARGET=10.9 CC=clang CXX=clang++ python setup.py install
On Windows
At least Visual Studio 2017 Update 3 (version 15.3.3 with the toolset 14.11) and NVTX are needed.
If the version of Visual Studio 2017 is higher than 15.4.5, installing of ""VC++ 2017 version 15.4 v14.11 toolset"" is strongly recommended.
 If the version of Visual Studio 2017 is lesser than 15.3.3, please update Visual Studio 2017 to the latest version along with installing ""VC++ 2017 version 15.4 v14.11 toolset"".
 There is no guarantee of the correct building with VC++ 2017 toolsets, others than version 15.4 v14.11.
 ""VC++ 2017 version 15.4 v14.11 toolset"" might be installed onto already installed Visual Studio 2017 by running its installation once again and checking the corresponding checkbox under ""Individual components""/""Compilers, build tools, and runtimes"".
For building against CUDA 8.0 Visual Studio 2015 Update 3 (version 14.0), and the patch are needed to be installed too.
The details of the patch can be found here.
NVTX is a part of CUDA distributive, where it is called ""Nsight Compute"". For installing it onto already installed CUDA run CUDA installation once again and check the corresponding checkbox.
Be sure that CUDA with Nsight Compute is installed after Visual Studio 2017.
cmd
REM [Optional] The following two lines are needed for Python 2.7, but the support for it is very experimental.
set MSSdk=1
set FORCE_PY27_BUILD=1

REM [Optional] As for CUDA 8, VS2015 Update 3 is required; use the following line.
set ""CUDAHOSTCXX=%VS140COMNTOOLS%..\..\VC\bin\amd64\cl.exe""

set CMAKE_GENERATOR=Visual Studio 15 2017 Win64
set DISTUTILS_USE_SDK=1

REM Run ""Visual Studio 2017 Developer Command Prompt""
for /f ""usebackq tokens=*"" %i in (`""%ProgramFiles(x86)%\Microsoft Visual Studio\Installer\vswhere.exe"" -version [15^,16^) -products * -latest -property installationPath`) do call ""%i\VC\Auxiliary\Build\vcvarsall.bat"" x64 -vcvars_ver=14.11

python setup.py install

Docker Image
Dockerfile is supplied to build images with cuda support and cudnn v7. You can pass -e PYTHON_VERSION=x.y flag to specify which Python version is to be used by Miniconda, or leave it unset to use the default. Build from pytorch repo directory as docker needs to copy git repo into docker filesystem while building the image.
docker build -t pytorch -f docker/pytorch/Dockerfile .

You can also pull a pre-built docker image from Docker Hub and run with nvidia-docker,
but this is not currently maintained and will pull PyTorch 0.2.
nvidia-docker run --rm -ti --ipc=host pytorch/pytorch:latest

Please note that PyTorch uses shared memory to share data between processes, so if torch multiprocessing is used (e.g.
for multithreaded data loaders) the default shared memory segment size that container runs with is not enough, and you
should increase shared memory size either with --ipc=host or --shm-size command line options to nvidia-docker run.
Building the Documentation
To build documentation in various formats, you will need Sphinx and the
readthedocs theme.
cd docs/
pip install -r requirements.txt

You can then build the documentation by running make <format> from the
docs/ folder. Run make to get a list of all available output formats.
Previous Versions
Installation instructions and binaries for previous PyTorch versions may be found
on our website.
Getting Started
Three pointers to get you started:

Tutorials: get you started with understanding and using PyTorch
Examples: easy to understand pytorch code across all domains
The API Reference

Communication

forums: discuss implementations, research, etc. https://discuss.pytorch.org
GitHub issues: bug reports, feature requests, install issues, RFCs, thoughts, etc.
Slack: The PyTorch Slack hosts a primary audience of moderate to experienced PyTorch users and developers for general chat, online discussions, collaboration etc. If you are a beginner looking for help, the primary medium is PyTorch Forums. If you need a slack invite, please fill this form: https://goo.gl/forms/PP1AGvNHpSaJP8to1
newsletter: no-noise, one-way email newsletter with important announcements about pytorch. You can sign-up here: https://eepurl.com/cbG0rv

Releases and Contributing
PyTorch has a 90 day release cycle (major releases). Please let us know if you encounter a bug by filing an issue.
We appreciate all contributions. If you are planning to contribute back bug-fixes, please do so without any further discussion.
If you plan to contribute new features, utility functions or extensions to the core, please first open an issue and discuss the feature with us.
Sending a PR without discussion might end up resulting in a rejected PR, because we might be taking the core in a different direction than you might be aware of.
The Team
PyTorch is a community driven project with several skillful engineers and researchers contributing to it.
PyTorch is currently maintained by Adam Paszke, Sam Gross, Soumith Chintala and Gregory Chanan with major contributions coming from hundreds of talented individuals in various forms and means.
A non-exhaustive but growing list needs to mention: Trevor Killeen, Sasank Chilamkurthy, Sergey Zagoruyko, Adam Lerer, Francisco Massa, Alykhan Tejani, Luca Antiga, Alban Desmaison, Andreas Kopf, James Bradbury, Zeming Lin, Yuandong Tian, Guillaume Lample, Marat Dukhan, Natalia Gimelshein, Christian Sarofeen, Martin Raison, Edward Yang, Zachary Devito.
Note: this project is unrelated to hughperkins/pytorch with the same name. Hugh is a valuable contributor in the Torch community and has helped with many things Torch and PyTorch.
License
PyTorch is BSD-style licensed, as found in the LICENSE file.
",27940
meseta/git-together-0,Game Maker Language,"Make sure you read the Instructions note in the project
",7
startupengine/startupengine,HTML,"
Startup Engine
A beautiful & open-source platform for launching startups.



Key Features

 Publish & sell software/content subscriptions.
 Completely plug-and-play. Coding is optional.
 Supports any workflow, architecture, or framework.
 JSON API allows you integrate with external sites/apps.
 Completely open-source.
 1-Click Install.

Documentation
Documentation is available at https://www.startupengine.io/docs.
Deployment
Click the button below to deploy a new instance of Startup Engine to Heroku instantly.

Please reference Heroku's official guide for getting started with Laravel apps on Heroku.
Once you've installed the Heroku CLI, run the following commands on your instance:
First, generate an APP_KEY by locally running:
php artisan key:generate.
Then copy the newly generated key and run:
heroku config:set APP_KEY=APPKEYGOESHERE
The default user email is admin@example.com and the default password is password.
Change these after logging in.
Support
Found a bug? Submit an issue.
Security
If you discover a security vulnerability within Startup Engine, please send an e-mail to startupengine.io@domainsbyproxy.com
All security vulnerabilities will be promptly addressed.
License
Startup Engine is open-sourced software licensed under the MIT license.
",86
Lombiq/Smart-Notifications,C#,"Smart Notifications readme
Orchard CMS module that adds the ability to have closable (can be closed with an X in the corner like windows), fading (fades out in a few seconds) or persistent notifications (will be shown until the user closes them). The standard Notifier service is used so all existing notifications can be changed from site settings (and thus you can e.g. make all appearing notifications closable).
If you want to add closable, fading or persistent notifications from code explicitly just use the extension methods on INotifier added by the module.
The module's source is available in two public source repositories, automatically mirrored in both directions with Git-hg Mirror:

https://bitbucket.org/Lombiq/smart-notifications (Mercurial repository)
https://github.com/Lombiq/Smart-Notifications (Git repository)

Bug reports, feature requests and comments are warmly welcome, please do so via GitHub.
Feel free to send pull requests too, no matter which source repository you choose for this purpose.
This project is developed by Lombiq Technologies Ltd. Commercial-grade support is available through Lombiq.
",2
xaos-project/XaoS,C,"XaoS
Original Authors: Jan Hubicka and Thomas Marsh.
See CREDITS file for a complete list of contributors.
Introduction
XaoS is a realtime interactive fractal zoomer. This means that it lets you
zoom smoothly into any place in the fractal you choose without the long
calculation required by most other fractal generators. It has many other
features too, like different fractal types, autopilot, special coloring
modes, random palette generation, color cycling, etc.
Website
Visit the XaoS website
for the latest news and downloads.  Source code is available on
GitHub.
Documentation
Documentation is maintained on the GitHub Wiki.
User Support
XaoS is a community-supported free software project.
The xaos-users Google Group
provides a place for XaoS users to help each other get the most out of XaoS.
XaoS developers also monitor this discussion and answer questions from time to time.
You can browse the archives freely but to prevent spam, you must join the group
in order to post. Google Groups provides options for participation from a
traditional mailing list to a completely web-based forum, so you donât have to
get emails if you donât want to.
Reporting Bugs
Issues are tracked on GitHub.
If you think you have found a bug in XaoS or have an idea for a new feature,
please let us know about it.
XaoS is developed on a volunteer basis and the developers work on it in their spare time.
Therefore, we canât guarantee that issues will be addressed in a certain timeframe. If
you are able to fix a bug yourself, pull requests are very welcome.
Supported Platforms
XaoS is based on Qt, and supports Linux, Mac, and Windows.
License
Copyright (C) 1996-2019 XaoS Contributors
This program is free software; you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation; either version 2 of the License, or
(at your option) any later version.
This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.
You should have received a copy of the GNU General Public License
along with this program.  If not, see https://www.gnu.org/licenses/.
",99
openboxes/openboxes,Groovy,"




OpenBoxes
About
OpenBoxes is an Open Source Inventory and Supply Chain Management System. The initial implementation of OpenBoxes will occur at Partners In Health-supported facilities in Haiti.
License
Copyright (c) 2012 Partners In Health.  All rights reserved.
The use and distribution terms for this software are covered by the
Eclipse Public License 1.0 (http://opensource.org/licenses/eclipse-1.0.php)
which can be found in the file epl-v10.html at the root of this distribution.
By using this software in any fashion, you are agreeing to be bound by
the terms of this license.
You must not remove this notice, or any other, from this software.
Setup development environment
Install Dependencies
Required

Java 7 (must install Java 7)
MySQL 5.7
SDK Man
Grails 1.3.9
NPM

Optional

IntelliJ IDEA 14.1
Chrome

Basic setup instructions for developers
These instructions are for developers only.  If you are a user/implementer, please check out our
Installation documentation.
1. Install Dependencies
Install required dependencies above
2. Install Grails
Check that you have SDK Man installed properly (otherwise follow instructions on the skdman install page).
$ sdk version
SDKMAN 3.1.0

Install Grails 1.3.9
$ sdk install grails 1.3.9

3. Clone repository
If you are a core contributor:
git clone git@github.com:openboxes/openboxes.git      

If you are a not core contributor, fork openboxes git repository
and replace git url with the one of your forked repository
git clone git@github.com:<gitusername>/openboxes.git      

4. Create database
Create openboxes database
mysql -u root -p -e 'create database openboxes default charset utf8;'

Create openboxes user
mysql -u root -p -e 'grant all on openboxes.* to ""openboxes""@""localhost"" identified by ""openboxes"";'

5. Create Openboxes configuration file
Edit $HOME/.grails/openboxes-config.properties
# Database connection settings
# You can use dataSource.url when you are using a non-dev/non-test database (test-app may not run properly).
# If you want to run $ grails test-app you should comment out the dataSource.url below and create a new 
# openboxes_test database.  Eventually, we will move to an in-memory H2 database for testing, but we're 
# currently stuck with MySQL because I'm using some MySQL-specific stuff in the Liquibase changesets.  My bad.

dataSource.url=jdbc:mysql://localhost:3306/openboxes
dataSource.username=openboxes
dataSource.password=openboxes

# OpenBoxes mail settings (disabled by default)
grails.mail.enabled=false

NOTE: If you are running in development mode with a copy of an existing production database, you will need to
instruct the application to not setup test fixtures automatically by uncommenting the above property:
openboxes.fixtures.enabled=false

6. Install NPM dependencies
npm install

7. Build React frontend
You can build React frontend with this command, but it will be automatically build when starting the application.
npm run bundle

8. React frontend Hot-Reload
When using this command React fronted will be rebuild automatically after any change, you just need to refresh the
browser to see the effect.
npm run watch

9. Upgrade the project to the currently installed grails version
Either of the following actions (upgrade, compile, run-app) should generate the all important Spring configuration
(/WEB-INF/applicationContext.xml) and start the dependency resolution process.
grails upgrade

OR
grails compile

The grails compile step is not necessary since grails run-app will invoke the compilation step, but it doesn't
hurt anything.
If you see any errors, run the command again.
IMPORTANT That last line is important.  Because of some quirkiness with the way older versions of Grails resolve
dependencies and generates config files, you may need to run either of these commands multiple times in order to
resolve all dependencies and generate the config files.
Once the dependency resolution phase has completed, all dependencies will be stored in a local ivy cache (usually
under $USER_HOME/.grails/ivy-cache).  You do not have to worry about this, just know that the dependencies are now
on your machine and Grails will attempt to find them there before it tries to resolve them in a remote repository.
10. Start application in development mode
The application can be run in development mode.  This starts the application running in an instance of Tomcat within
the Grails console.
You may need to run 'grails run-app' several times in order to download all dependencies.
grails run-app

11. Open application in Google Chrome
http://localhost:8080/openboxes

12. Log into OpenBoxes
You can use the default accounts (manager:password OR admin:password). Once you are logged in as an admin, you can
create own account. Or you can use the signup form to create a new account.
13. React tests
To run new frontend (React) tests type:
npm test

14. React documentation
Start a style guide dev server:
npm run styleguide

View your style guide in the browser:
http://localhost:6060

Troubleshooting
How to Debug

Run Grails in debug mode
grails-debug run-app


In Intellij navigate to Run > Edit Configurations
Create a new Remote Debug Configuration

Name: openboxes-debug
Transport: Socket
Debugger mode: Attach
Host: localhost
Port: 5005


Command line arguments should look something like this:
-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5005



Problem
Caused by: java.io.FileNotFoundException: Could not open ServletContext resource [/WEB-INF/applicationContext.xml]

Solution
Execute the grails upgrade command in order to generate the files nece
$ grails upgrade

See the following stackoverflow article:
http://stackoverflow.com/questions/24243027/grails-spring-security-sample-application-not-working
",187
oestrich/grapevine,Elixir,"Grapevine

Grapevine is a MUD chat network.

MUD Coders Slack
Docs
Trello
Patreon
Discord

WebSocket Protocol
View the websocket details on Grapevine.
Server
Requirements
This is only required to run Grapevine itself, the server. These are not required to connect as a game. See the above websocket docs for connecting as a client.

PostgreSQL 10
Elixir 1.8.0
Erlang 21.2.6
node.js 10.13.0

Setup
mix deps.get
mix compile
cd assets && npm install && node node_modules/brunch/bin/brunch build && cd ..
mix ecto.reset
mix phx.server
This will start a web server on port 4100. You can now load http://localhost:4100/ to view the application.
Running Tests
MIX_ENV=test mix ecto.create
MIX_ENV=test mix ecto.migrate
mix test
Docker
docker-compose build grapevine
docker-compose up -d postgres
docker-compose run --rm grapevine migrate
docker-compose up grapevine
Telnet Web Client
For deployment the telnet application needs to be on its own erlang node. You can connect with something similar to:
config :grapevine,
  topologies: [
    local: [
      strategy: Cluster.Strategy.Epmd,
      config: [
        hosts: [
          :grapevine@localhost,
          :telnet@localhost,
        ]
      ]
    ]
  ]
Setting up a new Play CNAME

Game sets the CNAME to grapevine.haus
Game must have a homepage url
Game must have the web client enabled
Update game's record for their CNAME
Update nginx config for new domain
Run certbot for the new domain
Refresh CNAMEs in ETS Grapevine.CNAMEs.reload()

",49
indieweb/indieweb-chat-archive,PHP,"IndieWeb Chat Archive
This repo contains the full archive of IndieWeb chat log data files visible at https://chat.indieweb.org
Chat logs are added to this repo every 15 minutes.
File Format
Each channel's files can be read using QuartzDB. The files follow a simple format:
2017-12-01 23:15:06.218000 {""type"":""message"",""timestamp"":1512170106.218,""network"":""irc"",""server"":""freenode"",""channel"":{""uid"":""#indieweb"",""name"":""#indieweb""},""author"":{""uid"":""Loqi"",""nickname"":""Loqi"",""username"":""Loqi"",""name"":""Loqi"",""photo"":null,""url"":null,""tz"":""US\/Pacific""},""content"":""[@indiewebcamp] This week in the #indieweb https://indieweb.org/this-week/2017-12-01.html https://pbs.twimg.com/media/DP_z5rCVwAAGdTk.jpg (http://twtr.io/1Yx4r5CHSBC)"",""modes"":[]}


Each line begins with the timestamp.
There will always be 26 characters followed by a space.
The timestamp is UTC and has 6 digits of precision for the seconds.
The rest of the line is a JSON-encoded string representing the IRC message and who sent it.

Spam removal
For a guide on how we deal with spam in these logs, see IRC#Spam on the wiki.
",3
theabraxas/Battalion,Shell,"Battalion
Battalion is a tool designed to automate a huge portion of a standard pentest. By supplying only a domain name and website site Battalion goes through the various passive and active reconaissance tasks, enumerates publicly accessible sites and services, identifies potential misconfigurations or vulnerable technologies, discoves and identifies breached accounts, build reports, and much more.
Ultimately Battalion will automate beyond reconaissance and go so far as to trigger phishing campaigns, automatically exploit some discovered vulnerabilities, and come with post-exploitation options.
Try out Battalion and send us any feedback! https://github.com/eidolonpg and I are excited to build out this tool and make it as comprehensive and efficient as possible!
Installation
Battalion depends on a number of tools - please see the primary documentation in the Battalion Installation Guide for more information. This distribution also includes scripts for some system types in the install directory. The installation documentation provides more information on these scripts.
Using Battalion
Example: Scanning a Domain and Users
$ ./battalion.sh --name ""Test Scan"" --out /home/user/scans/company \
    --company ""My Company"" --domain ""company.com"" --nmap
This scan for My Company will produce results in the directory /home/user/scans/company. The domain scan would be based on the specified domain company.com, whereas the user scan is based upon the company name My Company. This scan also enables a light Nmap scan on the detected domains.
Required Parameters for All Scans

--name <scan name>: The scan name
--out  <directory>: The output directory (absolute path)

Required Parameters for Domain Scans

--domain <domain name>: The domain name to scan

Required Parameters for User Scans

--company <company name>: The company name per LinkedIn, used for user scraping

Optional Parameters

--email-domain <domain name>: Allows a different email domain to be configured. Use this if the primary domain is x.com but users receive mail at y.com addresses.
--subdomain-list <file>: Specify a file that provides potential subdomains, this is used by the dnsrecon tool. That tool provides some high-quality default lists.
--nmap: Enable light touch nmap scanning of subdomains
--nmap-aggressive: (Long running!) This is a VERY intense scan on each subdomain, approximately 10 minutes per subdomain.
--shodan <api key>: Specify a Shodan API key and enables a Shodan scan
--hunter <api key>: Sets a Hunter.io API Key and enables Hunter in the user scan. This will vastly speed up the user scan!
--timeout-http <seconds>: Specify a timeout in seconds for HTTP detection
--timeout-eyewitness <seconds>: Specify a timeout in seconds for EyeWitness individual scans

Disabling Major Scan Types

--disable-user: Disable the user scan
--disable-domain: Disable the domain scan

Scan Output
Battalion produces a number of directories which help categorize raw output. All of these directories will be created at the location specified by the --out parameter by the Battalion script.
Expected Scan Time (User)
The current default scan time for the user scan is rather large -- over 20 minutes. We recomment acquiring a Hunter API key to expidite this process.
Expected Scan Time (Domain)
Scans depend very much on the 'size' of the target, where the size is deteremined by the number of users and the number of detected domain records. Small targets usually take at least a few minutes to complete.
Disclaimer
This utility has been created purely for the purposes of research and for improving defense, and is not intended to be used to attack systems except where explicitly authorized. Project maintainers are not responsible or liable for misuse of the software. Use responsibly.
",43
NerdHubMC/Refined-Machinery,Java,"Refined Machinery Mod
",2
bacco007/HomeAssistant-Config,JavaScript,"TBSmartHome - Home Assistant Configuration

Here is the configuration and Documentation for my Home Assistant Setup - very much a work-in-progress
I'm from  so some of the stuff here will have limited use outside of the land downunder.

Table of Contents

Screenshots
Setup
Notes


Screenshots
A few screenshots - I'll add more as the other pages are improved


More Screenshots



Setup
Some Notes about my setup
Server

Lenovo ThinkCentre M73 Tiny (Intel Pentium G3240T, 4Gb RAM, 500Gb HDD)
Ubuntu Server 18.10


Hass.io

AppDaemon
Configurator
Glances
IDE
InfluxDB
MariaDB - Database Server
Node-RED
SSH & Web Terminal

Other Stuff I Run

Docker

Docker-Compose
Portainer
Dockermon for HA


My ""Download Stack""

Jackett
Lidarr
Radarr
SABnzbd
Sonarr
Transmission


Tautulli (Plex Reporting)
Traefik

Network
My Network isn't currently running as I would like it - mainly because I'm unable to deploy my Ubquiti gear in my current location - hopefully that will change soon and I'll update this section with a bit more detail

Notes
Lovelace UI
I've started to use the inbuilt Lovelace UI editor, so my lovelace_ui.yaml file is a backup (and JSON->YAML conversion) of the HA Storage file lovelace - there is a Python file in /custom_components/ called tb_lovelacebackup.py that does the conversion
",2
xaos-project/XaoS,C,"XaoS
Original Authors: Jan Hubicka and Thomas Marsh.
See CREDITS file for a complete list of contributors.
Introduction
XaoS is a realtime interactive fractal zoomer. This means that it lets you
zoom smoothly into any place in the fractal you choose without the long
calculation required by most other fractal generators. It has many other
features too, like different fractal types, autopilot, special coloring
modes, random palette generation, color cycling, etc.
Website
Visit the XaoS website
for the latest news and downloads.  Source code is available on
GitHub.
Documentation
Documentation is maintained on the GitHub Wiki.
User Support
XaoS is a community-supported free software project.
The xaos-users Google Group
provides a place for XaoS users to help each other get the most out of XaoS.
XaoS developers also monitor this discussion and answer questions from time to time.
You can browse the archives freely but to prevent spam, you must join the group
in order to post. Google Groups provides options for participation from a
traditional mailing list to a completely web-based forum, so you donât have to
get emails if you donât want to.
Reporting Bugs
Issues are tracked on GitHub.
If you think you have found a bug in XaoS or have an idea for a new feature,
please let us know about it.
XaoS is developed on a volunteer basis and the developers work on it in their spare time.
Therefore, we canât guarantee that issues will be addressed in a certain timeframe. If
you are able to fix a bug yourself, pull requests are very welcome.
Supported Platforms
XaoS is based on Qt, and supports Linux, Mac, and Windows.
License
Copyright (C) 1996-2019 XaoS Contributors
This program is free software; you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation; either version 2 of the License, or
(at your option) any later version.
This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.
You should have received a copy of the GNU General Public License
along with this program.  If not, see https://www.gnu.org/licenses/.
",99
openboxes/openboxes,Groovy,"




OpenBoxes
About
OpenBoxes is an Open Source Inventory and Supply Chain Management System. The initial implementation of OpenBoxes will occur at Partners In Health-supported facilities in Haiti.
License
Copyright (c) 2012 Partners In Health.  All rights reserved.
The use and distribution terms for this software are covered by the
Eclipse Public License 1.0 (http://opensource.org/licenses/eclipse-1.0.php)
which can be found in the file epl-v10.html at the root of this distribution.
By using this software in any fashion, you are agreeing to be bound by
the terms of this license.
You must not remove this notice, or any other, from this software.
Setup development environment
Install Dependencies
Required

Java 7 (must install Java 7)
MySQL 5.7
SDK Man
Grails 1.3.9
NPM

Optional

IntelliJ IDEA 14.1
Chrome

Basic setup instructions for developers
These instructions are for developers only.  If you are a user/implementer, please check out our
Installation documentation.
1. Install Dependencies
Install required dependencies above
2. Install Grails
Check that you have SDK Man installed properly (otherwise follow instructions on the skdman install page).
$ sdk version
SDKMAN 3.1.0

Install Grails 1.3.9
$ sdk install grails 1.3.9

3. Clone repository
If you are a core contributor:
git clone git@github.com:openboxes/openboxes.git      

If you are a not core contributor, fork openboxes git repository
and replace git url with the one of your forked repository
git clone git@github.com:<gitusername>/openboxes.git      

4. Create database
Create openboxes database
mysql -u root -p -e 'create database openboxes default charset utf8;'

Create openboxes user
mysql -u root -p -e 'grant all on openboxes.* to ""openboxes""@""localhost"" identified by ""openboxes"";'

5. Create Openboxes configuration file
Edit $HOME/.grails/openboxes-config.properties
# Database connection settings
# You can use dataSource.url when you are using a non-dev/non-test database (test-app may not run properly).
# If you want to run $ grails test-app you should comment out the dataSource.url below and create a new 
# openboxes_test database.  Eventually, we will move to an in-memory H2 database for testing, but we're 
# currently stuck with MySQL because I'm using some MySQL-specific stuff in the Liquibase changesets.  My bad.

dataSource.url=jdbc:mysql://localhost:3306/openboxes
dataSource.username=openboxes
dataSource.password=openboxes

# OpenBoxes mail settings (disabled by default)
grails.mail.enabled=false

NOTE: If you are running in development mode with a copy of an existing production database, you will need to
instruct the application to not setup test fixtures automatically by uncommenting the above property:
openboxes.fixtures.enabled=false

6. Install NPM dependencies
npm install

7. Build React frontend
You can build React frontend with this command, but it will be automatically build when starting the application.
npm run bundle

8. React frontend Hot-Reload
When using this command React fronted will be rebuild automatically after any change, you just need to refresh the
browser to see the effect.
npm run watch

9. Upgrade the project to the currently installed grails version
Either of the following actions (upgrade, compile, run-app) should generate the all important Spring configuration
(/WEB-INF/applicationContext.xml) and start the dependency resolution process.
grails upgrade

OR
grails compile

The grails compile step is not necessary since grails run-app will invoke the compilation step, but it doesn't
hurt anything.
If you see any errors, run the command again.
IMPORTANT That last line is important.  Because of some quirkiness with the way older versions of Grails resolve
dependencies and generates config files, you may need to run either of these commands multiple times in order to
resolve all dependencies and generate the config files.
Once the dependency resolution phase has completed, all dependencies will be stored in a local ivy cache (usually
under $USER_HOME/.grails/ivy-cache).  You do not have to worry about this, just know that the dependencies are now
on your machine and Grails will attempt to find them there before it tries to resolve them in a remote repository.
10. Start application in development mode
The application can be run in development mode.  This starts the application running in an instance of Tomcat within
the Grails console.
You may need to run 'grails run-app' several times in order to download all dependencies.
grails run-app

11. Open application in Google Chrome
http://localhost:8080/openboxes

12. Log into OpenBoxes
You can use the default accounts (manager:password OR admin:password). Once you are logged in as an admin, you can
create own account. Or you can use the signup form to create a new account.
13. React tests
To run new frontend (React) tests type:
npm test

14. React documentation
Start a style guide dev server:
npm run styleguide

View your style guide in the browser:
http://localhost:6060

Troubleshooting
How to Debug

Run Grails in debug mode
grails-debug run-app


In Intellij navigate to Run > Edit Configurations
Create a new Remote Debug Configuration

Name: openboxes-debug
Transport: Socket
Debugger mode: Attach
Host: localhost
Port: 5005


Command line arguments should look something like this:
-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5005



Problem
Caused by: java.io.FileNotFoundException: Could not open ServletContext resource [/WEB-INF/applicationContext.xml]

Solution
Execute the grails upgrade command in order to generate the files nece
$ grails upgrade

See the following stackoverflow article:
http://stackoverflow.com/questions/24243027/grails-spring-security-sample-application-not-working
",187
oestrich/grapevine,Elixir,"Grapevine

Grapevine is a MUD chat network.

MUD Coders Slack
Docs
Trello
Patreon
Discord

WebSocket Protocol
View the websocket details on Grapevine.
Server
Requirements
This is only required to run Grapevine itself, the server. These are not required to connect as a game. See the above websocket docs for connecting as a client.

PostgreSQL 10
Elixir 1.8.0
Erlang 21.2.6
node.js 10.13.0

Setup
mix deps.get
mix compile
cd assets && npm install && node node_modules/brunch/bin/brunch build && cd ..
mix ecto.reset
mix phx.server
This will start a web server on port 4100. You can now load http://localhost:4100/ to view the application.
Running Tests
MIX_ENV=test mix ecto.create
MIX_ENV=test mix ecto.migrate
mix test
Docker
docker-compose build grapevine
docker-compose up -d postgres
docker-compose run --rm grapevine migrate
docker-compose up grapevine
Telnet Web Client
For deployment the telnet application needs to be on its own erlang node. You can connect with something similar to:
config :grapevine,
  topologies: [
    local: [
      strategy: Cluster.Strategy.Epmd,
      config: [
        hosts: [
          :grapevine@localhost,
          :telnet@localhost,
        ]
      ]
    ]
  ]
Setting up a new Play CNAME

Game sets the CNAME to grapevine.haus
Game must have a homepage url
Game must have the web client enabled
Update game's record for their CNAME
Update nginx config for new domain
Run certbot for the new domain
Refresh CNAMEs in ETS Grapevine.CNAMEs.reload()

",49
indieweb/indieweb-chat-archive,PHP,"IndieWeb Chat Archive
This repo contains the full archive of IndieWeb chat log data files visible at https://chat.indieweb.org
Chat logs are added to this repo every 15 minutes.
File Format
Each channel's files can be read using QuartzDB. The files follow a simple format:
2017-12-01 23:15:06.218000 {""type"":""message"",""timestamp"":1512170106.218,""network"":""irc"",""server"":""freenode"",""channel"":{""uid"":""#indieweb"",""name"":""#indieweb""},""author"":{""uid"":""Loqi"",""nickname"":""Loqi"",""username"":""Loqi"",""name"":""Loqi"",""photo"":null,""url"":null,""tz"":""US\/Pacific""},""content"":""[@indiewebcamp] This week in the #indieweb https://indieweb.org/this-week/2017-12-01.html https://pbs.twimg.com/media/DP_z5rCVwAAGdTk.jpg (http://twtr.io/1Yx4r5CHSBC)"",""modes"":[]}


Each line begins with the timestamp.
There will always be 26 characters followed by a space.
The timestamp is UTC and has 6 digits of precision for the seconds.
The rest of the line is a JSON-encoded string representing the IRC message and who sent it.

Spam removal
For a guide on how we deal with spam in these logs, see IRC#Spam on the wiki.
",3
theabraxas/Battalion,Shell,"Battalion
Battalion is a tool designed to automate a huge portion of a standard pentest. By supplying only a domain name and website site Battalion goes through the various passive and active reconaissance tasks, enumerates publicly accessible sites and services, identifies potential misconfigurations or vulnerable technologies, discoves and identifies breached accounts, build reports, and much more.
Ultimately Battalion will automate beyond reconaissance and go so far as to trigger phishing campaigns, automatically exploit some discovered vulnerabilities, and come with post-exploitation options.
Try out Battalion and send us any feedback! https://github.com/eidolonpg and I are excited to build out this tool and make it as comprehensive and efficient as possible!
Installation
Battalion depends on a number of tools - please see the primary documentation in the Battalion Installation Guide for more information. This distribution also includes scripts for some system types in the install directory. The installation documentation provides more information on these scripts.
Using Battalion
Example: Scanning a Domain and Users
$ ./battalion.sh --name ""Test Scan"" --out /home/user/scans/company \
    --company ""My Company"" --domain ""company.com"" --nmap
This scan for My Company will produce results in the directory /home/user/scans/company. The domain scan would be based on the specified domain company.com, whereas the user scan is based upon the company name My Company. This scan also enables a light Nmap scan on the detected domains.
Required Parameters for All Scans

--name <scan name>: The scan name
--out  <directory>: The output directory (absolute path)

Required Parameters for Domain Scans

--domain <domain name>: The domain name to scan

Required Parameters for User Scans

--company <company name>: The company name per LinkedIn, used for user scraping

Optional Parameters

--email-domain <domain name>: Allows a different email domain to be configured. Use this if the primary domain is x.com but users receive mail at y.com addresses.
--subdomain-list <file>: Specify a file that provides potential subdomains, this is used by the dnsrecon tool. That tool provides some high-quality default lists.
--nmap: Enable light touch nmap scanning of subdomains
--nmap-aggressive: (Long running!) This is a VERY intense scan on each subdomain, approximately 10 minutes per subdomain.
--shodan <api key>: Specify a Shodan API key and enables a Shodan scan
--hunter <api key>: Sets a Hunter.io API Key and enables Hunter in the user scan. This will vastly speed up the user scan!
--timeout-http <seconds>: Specify a timeout in seconds for HTTP detection
--timeout-eyewitness <seconds>: Specify a timeout in seconds for EyeWitness individual scans

Disabling Major Scan Types

--disable-user: Disable the user scan
--disable-domain: Disable the domain scan

Scan Output
Battalion produces a number of directories which help categorize raw output. All of these directories will be created at the location specified by the --out parameter by the Battalion script.
Expected Scan Time (User)
The current default scan time for the user scan is rather large -- over 20 minutes. We recomment acquiring a Hunter API key to expidite this process.
Expected Scan Time (Domain)
Scans depend very much on the 'size' of the target, where the size is deteremined by the number of users and the number of detected domain records. Small targets usually take at least a few minutes to complete.
Disclaimer
This utility has been created purely for the purposes of research and for improving defense, and is not intended to be used to attack systems except where explicitly authorized. Project maintainers are not responsible or liable for misuse of the software. Use responsibly.
",43
NerdHubMC/Refined-Machinery,Java,"Refined Machinery Mod
",2
bacco007/HomeAssistant-Config,JavaScript,"TBSmartHome - Home Assistant Configuration

Here is the configuration and Documentation for my Home Assistant Setup - very much a work-in-progress
I'm from  so some of the stuff here will have limited use outside of the land downunder.

Table of Contents

Screenshots
Setup
Notes


Screenshots
A few screenshots - I'll add more as the other pages are improved


More Screenshots



Setup
Some Notes about my setup
Server

Lenovo ThinkCentre M73 Tiny (Intel Pentium G3240T, 4Gb RAM, 500Gb HDD)
Ubuntu Server 18.10


Hass.io

AppDaemon
Configurator
Glances
IDE
InfluxDB
MariaDB - Database Server
Node-RED
SSH & Web Terminal

Other Stuff I Run

Docker

Docker-Compose
Portainer
Dockermon for HA


My ""Download Stack""

Jackett
Lidarr
Radarr
SABnzbd
Sonarr
Transmission


Tautulli (Plex Reporting)
Traefik

Network
My Network isn't currently running as I would like it - mainly because I'm unable to deploy my Ubquiti gear in my current location - hopefully that will change soon and I'll update this section with a bit more detail

Notes
Lovelace UI
I've started to use the inbuilt Lovelace UI editor, so my lovelace_ui.yaml file is a backup (and JSON->YAML conversion) of the HA Storage file lovelace - there is a Python file in /custom_components/ called tb_lovelacebackup.py that does the conversion
",2
Library-of-Kaeon/Library-of-Kaeon,Java,"Library of Kaeon
Philosophy
The Library of Kaeon (pronounced ""KAI-on"") is a suite of documents and utilities.
The core documents within the library describe a philosophy referred to as Angaianism,
and the rest of the documents and utilities serve as resources for various projects.
Principles
All of the documents within the Library of Kaeon are stored in a system of folders.
The subfolders of each folder are numbered.
Angaianism
The whole of the Angaianism can be summed up through the following dialogue:
Make all that ought to be into reality.

Sentient entities shall never be destroyed, shall always be in a state of maximum joy, and shall
never be manipulated, and it is good to create sentient entities.

What will you do?

The word ""Kaeon"",
which means ""the way up"",
refers to the first line in the above dialogue,
""Make all that ought to be into reality.""
Kaeon is the core principle of Angaianism.
The word ""Angaia"" means ""the whole world"".
Sections
Canon
The Canon section holds documents specifying information that defines the core principles that the rest of the library expands upon.
These documents are written in ONE,
which itself is established in one of said documents.
Chronicle
The Chronicle section holds multiple folders containing documents on various subjects.
These documents are written in ONE+,
which itself is established in one of said documents.
Collection
The Collection section holds several miscellaneous utilities.
",3
LambdaSchool/React-UI-Components,HTML,"React-UI-Components

This repository is designed to be your first exposure into the world of ReactJS. There are 2 projects to complete in this repository. Project 1 is all about implementing a Social Card in ReactJS. On Project 2 you'll be implementing a Calculator. We've given you the file structure and have gone ahead and added all the files you'll need to be set up for success for each project.

Initializing the application.

This project was put together using create-react-app (CRA). You will not need to install CRA in order to make this project work
Each project has it's own package.json file in it, we'll chat more about this later. So it's already set up for you to install some dependencies that are needed for you to be able to work within the React Ecosystem.
To start the Social Card project, you'll need to cd into Project-1-Social-Card and then into social-card and run yarn install to retrieve all the dependencies.
Inside of ../../social-card you'll then need to run yarn start to open up a React Development Server that can take your .js files as components and bundle them up to work in your new environment.
You'll repeat this last two steps for the calculator project, but you'll need to make sure that you're inside of ../../calculator directory to make this work.

Instructions

For the first project you'll work on the project found in Project-I-Social-Card.
For the second project you'll work on the project found in Project-II-Calculator.
Use the design files to build out your User Interfaces.
All components can be built out using the provided html files found in their respective directories.
Each file has been set up to work within a react.js environment. Pay attention to the notes found within each project.
Don't forget about className vs class on your JSX elements!!

Project I - Social Card

We're going to break down this assignment in terms of how you should be starting to think in react. Remember that everything is a component.
All the files you'll need for this project are found in Project-I-Social-Card/social-card/src/components. You can find all the component files you should need in their respective directory. i.e. inside of the HeaderComponents directory you should see a few .js files and a .css file.
Feel free to add any files for any extra components you may feel the need to build.
Any of the styles you write in your respective .css file should be available for your the components where the .css file is being imported.
We have drawn boxes around possible areas that could be components.

The outer box will represent the App.js file.
The red box around the header could represent the header directory with a few nested components inside, the thumbnail image and the header content.
You could go so far as to break down the header content into a header and body component.
The next box around the social card represents the React Banner image and some copy found underneath.
And then of course the footer (Stretch Problem 1) which contains your icons, could be a container for all of your icon components.




Project 1 MVP requirements


Create a <HeaderContainer /> container component that will hold your header components.

Create an <ImageThumbnail /> component using this image url https://tk-assets.lambdaschool.com/1c1b7262-cf23-4a9f-90b6-da0d3c74a5c6_lambdacrest.png as it's img src.
Create a <HeaderTitle /> component that displays the Lambda School header text, @LambdaSchool handle and timestamp.
Create a <HeaderContent /> component that displays the copy provided in the headers content.



Create a <CardContainer/ > container component that will hold your card components.

Create a <CardBanner /> component that will display this image as it's background: https://tk-assets.lambdaschool.com/fcd75197-7d12-46ec-bc9e-4130f34822fa_reactbackground.png
Create a <CardContent /> component that displays the card copy provided.
The entire <CardContainer /> should take a user to https://www.reactjs.org when clicked.



Project 1 Stretch Problems

Create a <Footer/> component that pulls in the icons and displays them properly.

Build out the functionality so that a user can click on the icons and have them react to events.


Ensure that your product is as pixel perfect as possible using any tools that you were introduced to in previous weeks.
Look up the moment.js library and figure out how to format your time-stamp in your header to be todays date.

Project II - React Calculator

For this project you're not going to be given any tips on how to break down the image file into components. Now that you've had some practice with the social card, this should be something you can start doing on your own. Just think about the image, and what potentially looks like a component.
For the MVP the calculator just needs to be displayed properly. Functionality will be a part of the stretch requirement.
All the files you'll need for this project are found in Project-II-Calculator/calculator/src/components. You can find all the component files you should need in their respective directory. i.e. inside of the ButtonComponents directory you should see a couple .js files and a .css file.
Feel free to add any files for any extra components you may feel the need to build.
Here is what your calculator should look like:



BEFORE YOU DO ANYTHING ELSE READ This
This is the time to stop and break down this image in terms of components. Each container on the screen should give you an idea of what your components should be. You're now about to begin your journey into learning how to think in React.

Project 2 MVP requirements

Create a <NumberButton /> component that can accept props and display any number/symbol passed down as text.

Example your component should be able to render a dynamic prop called text:
Your button button should also be able to accept dynamic props buttonStyle for styling



<button className={props.buttonStyle}>{props.text}</button>

Create an <ActionButton /> component that will be used for the zero character and the clear button.
Create a <CalculatorDisplay /> component that will be used as the calculator display

Project 2 Stretch Problems


Re-factor your App.js file to be a classical component that can hold state on it's constructor. (There is some documentation in training kit on how this works).

On your state object be sure to include a property for the total that can be passed down to your <CalculatorDisplay /> component.



Create some handler functions that can take in some information from an, onClick and use that information to update the total on the App state.

this.setState will be your best friend here :)

GOOD LUCK!


",9
Randrian45/pylustrator,Python,"Pylustrator
 
 

Visualisations of data are at the core of every publication of scientific research results. They have to be as clear as
possible to facilitate the communication of research. As data can have different formats and shapes, the visualisations
often have to be adapted to reflect the data as well as possible. We developed Pylustrator, an interface to directly
edit python generated matplotlib graphs to finalize them for publication. Therefore, subplots can be resized and dragged
around by the mouse, text and annotations can be added. The changes can be saved to the initial plot file as python code.
Keywords: python, matplotlib, draggable subplots, texts, annotations, code generation
Please refer to our Documentation for more information and instructions on installing it.
",4
tanepiper/ngx-tinynodes,TypeScript,"Ngx-Tinynodes
This repository is a collection of Angular components and demos with full documentation.
See the Changelog for the development diary of this site, or visit the documentation of libraries.
You can also find a fully searchable API documentation for all @tinynode components.
Links

Repository
Documentation
Demo Application Site
NPM Collection

Libraries
@tinynodes/ngx-editorjs
This project provides a set of features for using EditorJS within Angular 7+ - including a directive, component and service

Readme
Changelog
Demo
Project Folder

Development Information
This repository is run by Tane Piper and was generated using Nx.
",3
gusdnd852/Social-Robot-Bao,Python,"Social-Robot-Bao
Artificial Intelligence Cure Robot for Children with Autism


Design

",6
mirceapasoi/erc725-735,JavaScript,"ERC 725 + 735
This is an attempt at an implementation of ERC 725 v1 and ERC 735, following the specs as closely as possible. It uses the Truffle framework and Ganache CLI for testing.
Overview
The smart contract implements the following features:

deploy contract using initial set of keys (Identity.sol)
add/remove keys to identity (KeyManager.sol)
get key data, in multiple ways (KeyGetters.sol)
""proxy contract"" execution on the blockchain (MultiSig.sol)
multi-signature mechanism for MANAGEMENT_KEY and EXECUTION_KEY (MultiSig.sol)
add/remove claims to identity (ClaimManager.sol)
get claim data, in multiple ways (ClaimManager.sol)
refresh claims in identity (ClaimManager.sol)
ability to pause/unpause the contract, potentially with multi-sig (Pausable.sol)
ability to destroy the contract and return funds, potentially with multi-sig (Destructible.sol)

Architecture
The implementation tries to make extensive use of Solidity patterns for modular code i.e. libraries, abstract contracts and multiple inheritence. Here's how the class diagram looks:
                +--------------+         +------------+
                |              |         |            |
                |    ERC 165   |         | KeyStore** |
                |              |         |            |
                +---+--------+-+         +----+-------+
                    |        |                |
               +----v-----+ +v---------+ +----v-----+
               |          | |          | |          |
 +-------------+ ERC 735* | | ERC 725* | | KeyBase* |
 |             |          | |          | |          |
 |             +----------+ ++-+----+--+ +--+-------+------+--------------+
 |                           | |    |       |              |              |
 |                           | |    |       |              |              |
 |   +-----------------------+ |    | +-----+-----+  +-----v-----+ +------v-------+
 |   |                         |    | |           |  |           | |              |
 |   |                 +-------|----|-+  Pausable |  | KeyGetter | | Destructible |
 |   |    +--------------------|----|-+           |  |           | |              |
 |   |    |            |       |    | +--+--------+  +-+---------+ +--+-----------+
 |   |    |            |  +----+    |    |             |              |
 |   |    |            |  |         |    |             |              |
 |   |    |            |  |         |    |             |              |
 |   |    |            |  |         |    |             |              |
+v---v----v---+ +------v--v---+  +--v----v--+          |              |
|             | |             |  |          |          |              |
|ClaimManager | | KeyManager  |  | MultiSig |          |              |
|             | |             |  |          |          |              |
+---+---------+ ++------------+  +--+-------+          |              |
    |            |                  |                  |              |
    |            |                  |                  |              |
    |            |        +---------v------------------v---+          |
    |            |        |                                <----------+
    |            +-------->            Identity            |
    |                     |        (ERC 725 + 735)         |
    +--------------------->                                |
                          +--------------------------------+

* = Abstract contract
** = Library

Tests
Truffle tests exists for each contract, in separate files in the test/ folder. Each tests tries to count how much gas it's using for setup and during the test. Also, at the end I'm printing out
total gas used for all tests.
$ ganache-cli --allowUnlimitedContractSize -l 10000000
...
$ truffle test
...
  â should be paused/unpaused by management keys (86435 gas)
	  Test only: 59,944 gas

  54 passing (1m)

Currently missing unit tests for events being emitted.
Open issues

uri is not included in the signature and could theoretically be changed without changing a claim signature. Is this intentional or not?
Claim IDs are generated using keccak256(address issuer + uint256 _topic), which doesn't work great for self-claims i.e. issuer is address(this) and we might want multiple self-claims with the same topic
Added an ExecutionFailed event in ERC725 which isn't part of the standard
For execution requests, I'm using the multi-sig threshold at the time of request, not the one at the time of execution - is that a good idea? (e.g. you request an execution, threshold is X, wait for approvals, threshold is increased to Y, initial execution is approval with X approvals)
Using ERC 165 pseudo-introspection to check if an address implements ERC 725 or 735. Is this the best pattern for that?
Added a PROFILE_TOPIC claim topic which isn't part of the standard. The intended use is to store a plain-text profile URL in data (social media, blogs, etc.). As a convention, uri should be equal to data.
Added a LABEL_TOPIC claim topic which isn't part of the standard. The intended use is to store a plain-text label in data (real name, business name, nick name, brand name, alias, etc.).
The ""proxy contract"" only supports .call, doesn't support .delegateacall or creating a new contract on behalf of the identity.

",42
ABadCandy/BaiDuBigData19-URFC,Python,"BaiDuBigData19-URFC
my two networks solution with 0.67 accuracy for 9 classification.
ä¸»è¦ä¸ºäºç¨Pytorchå¤ç° https://github.com/czczup/UrbanRegionFunctionClassification è¿ä½å¤§ç¥çtensorflowå®ç°çååæ¯ç½ç»baselineï¼
åæ¶visitæ°æ®çè½¬æ¢åé¾æ¥ä¸­visit2array.pyææä¸è´ï¼å³è½¬ä¸º7Ã26Ã24(å¤©Ãå¨Ãå°æ¶)çç¹å¾ç©éµã
ä¸åç¹ï¼

æ°æ®é¢å¤çï¼é¤äºç®åçå¹³ç§»æè½¬éåªå¤è¿äºåå»é¤äºå¨é»åå¨ç½å¾çãå»é¾ãç´æ¹å¾åè¡¡åç­ï¼å©ä½è®­ç»éå¾çæ°ä¸º39730å¼ ã
å¾çç½ç»ï¼éç¨åå§3Ã100Ã100çå°ºå¯¸è¾å¥ï¼å©ç¨imagenetçé¢è®­ç»æ¨¡åse_resnext101_32x4dè¿è¡å¾®è°ã
visitç½ç»ï¼è¾å¥å°ºå¯¸ä¸º7Ã26Ã24ï¼ä¸è¿ä¸tfçæ¬ä¸åä¹å¤ä¸ºåèå°24ä½ä¸ºééæ°ï¼è¯¥çæ¬å°7ä½ä¸ºééæ°ï¼è¿æ ·é¿å®½åºæ¬ä¸è´ï¼å¯ä»¥å©ç¨cifar10æcifar100
çé¢è®­ç»ResNetç³»åæ¨¡åè¿è¡å¾®è°ï¼è¿ééç¨çæ¯æ é¢è®­ç»çdpn26ç½ç»ã
ç¹å¾èåï¼å¾çç½ç»æåä¸å±çç¹å¾åéç»´åº¦ä¸º256ï¼visitç½ç»æåç¹å¾ç»´åº¦ä¸º64ï¼concatåä¸º320ï¼æåæ¥9ä¸ªèç¹çå¨è¿æ¥å±è¿è¡åç±»ã

ä½¿ç¨è¯´æï¼

é¢å¤çæ°æ®ä¸è½½é¾æ¥ï¼https://pan.baidu.com/s/1Pil1LCesVy4m6Fsb02Ggow  æåç ï¼q5vp

å¨å½åç®å½ä¸æ°å»ºdataæä»¶å¤¹ï¼å°ä¸è½½å¥½çæ°æ®è§£åè³è¯¥ç®å½ä¸ï¼æåå¯ä»¥çå°dataæä»¶å¤¹ä¸ænpy,train.testä¸ä¸ªå­æä»¶å¤¹ï¼
å¶ä¸­npyéå­æè½¬æ¢å¥½çtrain_visitåtest_visitï¼trainåtestä¸¤ä¸ªå­æä»¶å¤¹éåå«å­æ¾äºç­éåé¢å¤çåç39730å¼ è®­ç»å¾çï¼ä»¥ååå§ç1wå¼ æµè¯å¾çã


æ§è¡ pip install -r requirements.txt å®è£å¿è¦çè¿è¡åºã


æ§è¡ python multimain.py å³å¯å¼å§è®­ç»åæµè¯ï¼å¶ä¸­ä¸äºè¶åæ°å¦epoch,batch_sizeç­å¯å¨config.pyä¸­ä¿®æ¹ã


ç­ç¬¬3æ­¥æ§è¡å®åä¼å¨sumbitæä»¶å¤¹ä¸çæcsvæ ¼å¼çé¢æµç»æï¼ä¸ºäºä¸æäº¤ç³»ç»è¦æ±ä¿æä¸è´éè¦åè¿è¡ python submission.pyï¼æç»å¨submitæä»¶å¤¹ä¸å¾å°submit.txtå³å¯æäº¤ã


æäº¤ç»æå¦å¾ï¼

",5
Unity-Technologies/EditorXR,C#,"EditorXR
Author XR in XR - Initial public release was on December 15, 2016 via blogpost
Experimental Status
Itâs important to note that EditorXR is an experimental feature. As such, there is no formal support (e.g. FogBugz, support@unity3d.com, Premium Support, etc.) offered, so please do not use these channels. Instead, take your questions, suggestions, comments to our dedicated forum.
To help ensure you have a good experience, and to help us answer your questions (hey, weâre a small team!), we encourage you to try it out first with a small VR-ready scene. Please use life-sized objects, nothing too big or small. Dive in and have fun just playing around, instead of trying to use your existing project.
As with any experimental/preview/alpha/beta build, it is always a good idea to make a backup of your project before using the build.
Experimental means this:

We're still adding features!
The current menus, tools, workspaces, actions, etc. are not the end-all-be-all. Each of these have individual designs that will change as we experiment with what works best for UX. EditorXR was designed in such a way that we plan on you being able to replace all of these defaults, too, if you so desire.
Namespaces, classes, software architecture, prefabs, etc. can change at any point. If you are writing your own tools, then you might need to update them as these things change.
There wonât always be an upgrade path from one release to the next, so you might need to fix things manually, which leads to the next point...
Stuff can and will break (!)
Thereâs no guarantee that this project will move out of experimental status within any specific timeframe.
As such, there is no guarantee that this will remain an actively supported project.

Getting Started
If you've made it here, but aren't accustomed to using GitHub, cloning repositories, etc. and are simply looking to give EditorXR a spin, then take a look at the Getting Started Guide. Once you're up and running we recommend you join the discussion on the EditorXR forum.
For Software Developers
If you're a developer, we recommend that you take a look at the Getting Started Guide and the companion document Extending EditorXR. You'll need to clone the repository into an existing project using the instructions below.
Git Dependencies

git-lfs
git-submodule

Project Asset Dependencies

Textmesh Pro
Legacy Input Helpers (2019.1+)

Users of 2018.3 do not need Legacy Input Helpers



Cloning

Create a new Unity project or use an existing one
From the command line change directory to your project's Assets directory.
Run git lfs clone --recursive -b development https://github.com/Unity-Technologies/EditorXR (Use HTTPS!)

Updating
Because this project uses git-submodule, you'll need to execute git submodule update after pulling whenever a submodule is updated. You could execute this command always just to be safe or if you notice that a submodule is showing as modified after pulling changes.
Optionally, you could add a git hook for post-checkout or use a GUI (e.g. SourceTree) that does this automatically for you.
Project Settings
If you plan on making changes to EditorXR and/or contributing back, then you'll need to set the Asset Serialization property under Edit->Project Settings->Editor to Force Text.
Assembly Definitions
In order to support a variety of platform configurations, and to optionally strip its code out of player builds, EditorXR uses assembly definitions. Some of EditorXR's dependencies do not include assembly definitions in their current forms, so after importing EditorXR (in Unity 2018.3 and below), you must add them.
For easy set-up, EditorXR includes a .unitypackage (Patches/Dependencies_asmdef.unitypackage) containing an assembly definition for the PolyToolkit and UnityEngine.SpatialTracking, which are referenced by EditorXR. Simply import it via Assets > Import Package > Custom Package...
This is not required for Unity versions 2019.1 and above, though you will need to add an assembly definition in order to reference PolyToolkit.
All contributions are subject to the Unity Contribution Agreement (UCA)
By making a pull request, you are confirming agreement to the terms and conditions of the UCA, including that your Contributions are your original creation and that you have complete right and authority to make your Contributions.
",634
LibreOffice/core,C++,"LibreOffice
 
LibreOffice is an integrated office suite based on copyleft licenses
and compatible with most document formats and standards. Libreoffice
is backed by The Document Foundation, which represents a large
independent community of enterprises, developers and other volunteers
moved by the common goal of bringing to the market the best software
for personal productivity. LibreOffice is open source, and free to
download, use and distribute.
A quick overview of the LibreOffice code structure.
Overview
You can develop for LibreOffice in one of two ways, one
recommended and one much less so. First the somewhat less recommended
way: it is possible to use the SDK to develop an extension,
for which you can read the API docs here
and here.
This re-uses the (extremely generic) UNO APIs that are also used by
macro scripting in StarBasic.
The best way to add a generally useful feature to LibreOffice
is to work on the code base however. Overall this way makes it easier
to compile and build your code, it avoids any arbitrary limitations of
our scripting APIs, and in general is far more simple and intuitive -
if you are a reasonably able C++ programmer.
The build chain and runtime baselines
These are the current minimal operating system and compiler versions to
run and compile LibreOffice, also used by the TDF builds:

Windows:

Runtime: Windows 7
Build: Cygwin + Visual Studio 2017


macOS:

Runtime: 10.10
Build: 10.13.2 + Xcode 9.3


Linux:

Runtime: RHEL 6 or CentOS 6
Build: either GCC 7.0.0; or Clang 5.0.2 with libstdc++ 7.3.0


iOS (only for LibreOfficeKit):

Runtime: 11.4 (only support for newer i devices == 64 bit)
Build: Xcode 9.3 and iPhone SDK 11.4



If you want to use Clang with the LibreOffice compiler plugins, the minimal
version of Clang is 5.0.2. Since Xcode doesn't provide the compiler plugin
headers, you have to compile your own Clang to use them on macOS.
You can find the TDF configure switches in the distro-configs/ directory.
To setup your initial build environment on Windows and macOS, we provide
the LibreOffice Development Environment
(LODE) scripts.
For more information see the build instructions for your platform in the
TDF wiki.
The important bits of code
Each module should have a README file inside it which has some
degree of documentation for that module; patches are most welcome to
improve those. We have those turned into a web page here:
https://docs.libreoffice.org/
However, there are two hundred modules, many of them of only
peripheral interest for a specialist audience. So - where is the
good stuff, the code that is most useful. Here is a quick overview of
the most important ones:



Module
Description




sal/
this provides a simple System Abstraction Layer


tools/
this provides basic internal types: 'Rectangle', 'Color' etc.


vcl/
this is the widget toolkit library and one rendering abstraction


framework
UNO framework, responsible for building toolbars, menus, status bars, and the chrome around the document using widgets from VCL, and XML descriptions from /uiconfig/ files


sfx2/
legacy core framework used by Writer/Calc/Draw: document model / load/save / signals for actions etc.


svx/
drawing model related helper code, including much of Draw/Impress



Then applications



Module
Description




desktop/
this is where the 'main' for the application lives, init / bootstrap. the name dates back to an ancient StarOffice that also drew a desktop


sw/
Writer


sc/
Calc


sd/
Draw / Impress



There are several other libraries that are helpful from a graphical perspective:



Module
Description




basegfx/
algorithms and data-types for graphics as used in the canvas


canvas/
new (UNO) canvas rendering model with various backends


cppcanvas/
C++ helper classes for using the UNO canvas


drawinglayer/
View code to render drawable objects and break them down into primitives we can render more easily.



Rules for #include directives (C/C++)
Use the ""..."" form if and only if the included file is found next to the
including file. Otherwise, use the <...> form. (For further details, see the
mail Re: C[++]: Normalizing include syntax ("""" vs
<>).)
The UNO API include files should consistently use double quotes, for the
benefit of external users of this API.
loplugin:includeform (compilerplugins/clang/includeform.cxx) enforces these rules.
Finding out more
Beyond this, you can read the README files, send us patches, ask
on the mailing list libreoffice@lists.freedesktop.org (no subscription
required) or poke people on IRC #libreoffice-dev on irc.freenode.net -
we're a friendly and generally helpful mob. We know the code can be
hard to get into at first, and so there are no silly questions.
",630
Ogg-Technologies/warframe-database,None,"warframe-database
Contains data about warframe
",2
CreatorFan/Unipus-Helper,JavaScript,"Liberator of the oppressed by Unipus

ä¸­æç


Introduction
It is a Chrome Extension whose purpose is to liberate broad Chinese college students who suffer oppression by Unipus. Liberate them from boring blank filling and Unipus's devils talons.
Functions

Fill the blank with correct answer automatically.
Generate mistakes to mislead the evil Unipus's system automatically.
Submit all automatically.(developing)
Hang up online 2 hours everyday.(developing)

How to use it

It is easy to use. Just load the unzip file under developer mode on your Chrome.
If you don't use Chrome, you can use it in the same way with a Chromium core browser.

About us
We are a group of college students who are tired of filling the blank on Unipus in vain. We want to liberate students who suffer oppression by Unipus with use our technological capability.
Join us
We need you!
No matter you can code and be a developer or just help us to format key files. History will witness your contribution and all the user will never forget your distinctive contribution.
To contribute

Document of ""To Contribute""
""å¦ä½è´¡ç®""ä¸­æç

",3
aliyunfe/weekly,None,"é¿éäºåç«¯ææ¯å¨å
å½ä¸ï¼åç«¯ææ¯è¬ååå±ï¼ä» jQuery å°ä¸å¤§æ¡æ¶ï¼ä» RNãWeex å°å°ç¨åºï¼ä»¥åéè¿ Node.js ä¸ºæä»¬æå±æ´å¤§ççåï¼åç±»ææ¯å±åºä¸ç©·ãè¿å°±éè¦æä»¬ææ£çå¥½å¥å¿å»æ¢ç´¢å­¦ä¹ ï¼å¼éææ¯è§éï¼å æ·±ææ¯å¹¿åº¦åæ·±åº¦ãäºèç½ä¸çèµæºè½å¤ä½ä¸ç²¾ï¼å æ­¤å¸æå°ä¼è´¨çå­¦ä¹ èµæºè¿è¡æ´åï¼ãé¿éäºåç«¯ææ¯å¨åãå¨æ°å¯èªï¼
æ¬å¨åç±é¿éäºæºè½åä¸ä¸­å°ä½éªææ¯å¢éæ´çç¼åï¼å¸æè½ç»ç¤¾åºå¸¦æ¥æ´å¤æä»·å¼çåå®¹ï¼è¿æ¥äºä¸çå¤§åç«¯æ¶ä»£ï¼
ç¥ä¹ï¼é¿éäºä¸­å°åç«¯/å¨æ å¢éä¸æ 
Githubï¼é¿éäºåç«¯ææ¯å¨å
ç¿»è¯å°ç»ï¼é¿éäºç¿»è¯å°ç»
å¦ä½æç¨¿
å¦ä½è®¢éæ¬å¨å
ä¸æ´å¤åè¡äº¤æµ
ç®å½
ãé¿éäºåç«¯ææ¯å¨åãç¬¬ä¸æ
ãé¿éäºåç«¯ææ¯å¨åãç¬¬äºæ
ãé¿éäºåç«¯ææ¯å¨åãç¬¬ä¸æ
ãé¿éäºåç«¯ææ¯å¨åãç¬¬åæ
å³äºæä»¬
æä»¬æ¯é¿éäºæºè½åä¸ä¸­å°ä½éªææ¯å¢é è¯¦æ
å¦æå´è¶£å å¥æä»¬ï¼ç®å/æ²éè¯·è³ï¼ ranmo.cy@alibaba-inc.com/yeshu.lrt@alibaba-inc.com
",606
t-edson/PicPas,Pascal,"Donate to the project

PicPas 0.8.8
Multi-platform Pascal cross-compiler for Microchip 8 bits PIC microcontrollers.

PicPas is a Pascal compiler and IDE, written in Lazarus, which generates executable code for Baseline and Mid-range PIC microcontrollers.
No additional libraries or software required to compile. PicPas generates the *.hex file directly.
PicPas works with a simplified version of the Pascal language, that has been adapted to work with limited resources small devices.
Currently, it only supports basic types.
It includes a complete IDE/debugger/simulator to facilitate the development.
The PicpPas compiler includes advanced optimization options so the code obtained is generally more compact than the obtained with other compilers.
Installation
PicPas doesn't need installation, and have not dependencies, except the commons of the operative system, where it's runnig.
To run, it's only needed to download the folder from GitHub. There is compiled binaries for Windows-64 version (PicPas-win64.exe), Ubuntu version (PicPas-linux) and a Mac version (PicPas-Mac.dmg).
If it's required other platform, it need to be compiled from the source code.
When starting, PicPas could generate warning messsages, if not needed folders exist.
Hello World
As an example the following code, is to blink a LED on port B:
{Sample program to blink a Led on PORTB.7}
program BlinkLed;
uses PIC16F84A;
{$FREQUENCY 8MHZ}
var
  pin: bit absolute PORTB.7;
begin                          
  TRISB := 0;   //all outputs
  while true do 
    delay_ms(1000);
    pin := not pin;
  end;
end.

The processor target is defined including the correspondent unit in the USES section.
The CPU clock is defined using the directive {$FREQUENCY } and must be after the USES section.
Devices supported
Almost all the Mid-range and Baseline PIC devices are supported:
BASELINE DEVICES:
PIC10F200 PIC10F200 PIC10F202 PIC10F204 PIC10F206 PIC10F220 PIC10F222
PIC12F508 PIC12F509 PIC12F510 PIC12F519
PIC16F505 PIC16F506 PIC16F526 PIC16F527 PIC16F54 PIC16F57 PIC16F59
MID-RANGE DEVICES:
PIC10F320 PIC10F322
PIC12F609 PIC12F615 PIC12F617 PIC12F629 PIC12F635 PIC12F675 PIC12F683
PIC12F752
PIC16F73 PIC16F74 PIC16F76 PIC16F77 PIC16F83 PIC16F84 PIC16F87 PIC16F88
PIC16F610 PIC16F616 PIC16F627 PIC16F627A PIC16F628 PIC16F628A PIC16F630
PIC16F631 PIC16F636 PIC16F639 PIC16F648A PIC16F676 PIC16F677 PIC16F684
PIC16F685 PIC16F687 PIC16F688 PIC16F689 PIC16F690
PIC16F707 PIC16F716 PIC16F720 PIC16F721 PIC16F722 PIC16F722A PIC16F723
PIC16F723A PIC16F724 PIC16F726 PIC16F727 PIC16F737 PIC16F747 PIC16F753
PIC16F767 PIC16F777 PIC16F785
PIC16F818 PIC16F819 PIC16F870 PIC16F871 PIC16F872 PIC16F873 PIC16F874
PIC16F874A PIC16F876 PIC16F877 PIC16F882 PIC16F883 PIC16F884 PIC16F886
PIC16F887
PIC16F913 PIC16F914 PIC16F916 PIC16F917 PIC16F946
Support are implemented using units. So if we need compile to the PIC16f628A, we write:
program anything;
uses PIC16F628A; 
begin
  ...
end. 

There is not yet support for Enhanced Mid-range, or the PIC18 High-preformance families of PIC.
IDE
PicPas includes an IDE integrated to the compiler, to help on developing the programs.
Some features of the IDE are:
â¢	Cross-platform.
â¢	Multiple editors windows.
â¢	Syntax highlighting, code folding, word, and line highlighting for Pascal and ASM.
â¢	Code completion, and templates for the common structures IF, REPEAT, WHILE, â¦
â¢	Shows the assembler code and the resources used.
â¢	Support for themes (skins).
â¢	Code tools for completion and navigation.
â¢	Check syntax in REAL TIME!!!.
â¢	Several setting options.
â¢	Translated to english, french, spanish and german.



Debugger/Simulator
PicPas includes a graphical debugger/simulator for instructions of the Mid-Range core:

To control the execution, the following keys can be used:
F5 -> Set a breakpoint in the current position of  the assembler code.
F6 -> Reste the device.
F7 -> Step by step into subroutine.
F8 -> Step by step over subroutine.
F9 -> Run the program in real time.
Optimization Comparison
PisPas has been compared in two code optimization competition against the best profesional compilers for PIC microcontrollers, obtaining the first place in both.
Firts competition
Compiling a simple light sequence:
https://github.com/AguHDz/PicPas-Librerias_y_Programas/tree/master/Comparacion%20PicPas-Otros%20Compiladores
Result:

Second competition
Compiling a digital clock using I2C and the DS1307:
https://www.facebook.com/groups/electronicaymicrocontroladores/permalink/1812269192135162/
Result

Language Reference
Program structure
program <Name>;  //optional
uses
  //Units declarations

const
  //Constants declarations

var
  //Variables declarations

//<Procedures declaration>

begin
  //Main program body
end.

Unit structure
unit <name>;
interface
uses
  //units declaration
const
  //Constant declaration
var
  //Variable declaration

//Procedures declaration

implementation

uses
  //units declaration
const
  //Constant declaration
var
  //Variable declaration

//Procedures implementation

end.

Operators
Operator            Precedence
=================== ==========
 NOT, sign â-â         6
 *, DIV, MOD, AND      5
 +, -, OR, XOR         4
 =, <>, <, <=, >, >=   3
 := +=                 2

Types
Type           Size
============== ==========
 bit           1 bit
 boolean       1 bit
 byte          1 byte
 char          1 byte
 word          2 bytes
 dword         4 bytes

Numerical types are all unsigned.
Variables
Variables are defined with the VAR keyword:
var
  var1 : byte;
  var2 : bit;
  large_name_variable: boolean;

Variables can be defined too, at an absolute memory address:
var
  PORTB: BYTE absolute $06;
  pin0: bit; absolute $06.0;
  pin1: boolean; absolute PORTB.bit1;

Bit access can be performed too, using fields:
  var_byte.bit0 := 1;
  var_byte.bit7 := 0;

Specific byte of a word, can be access using fields:
  word_var.Low := $ff;
  word_var.High := $ff;

Control structures
PicPas doens't follow the common Pascal syntax. Instead, a new Modula-2, style syntax is implemented.
The common control structures have the following forms:
IF <condition> THEN 
  <block of code>
END;

IF <condition> THEN 
  <block of code>
ELSE
  <block of code>
END;

IF <condition> THEN 
  <block of code>
ELSIF <condition> THEN 
  <block of code>
ELSE
  <block of code>
END;

WHILE <condition> DO
  <block of code>
END;

REPEAT
  <block of code>
UNTIL <condition>;

FOR  <variable> := <start-value> TO <end-value> DO 
  <block of code>
END;

System Functions
System functions are always available in code. They don't need to be defined or included in a unit.
FUNCTION       DESCRIPTION
============== =================================================
delay_ms()	   Generate a time delay in miliseconds, from 0 to 65536.
Inc()          Increase a variable.
Dec()          Decrease a varaible.
SetBank()      Set the current RAM bank.
Exit()         Exit from a procedure or end the program.
Ord()          Convert a char to a byte.
Chr()          Convert a byte to a char.
Bit()          Convert an expression to a bit expression.
Byte()         Convert an expression to a byte expression.
Word()         Convert an expression to a word expression.
DWord()        Convert an expression to a dword expression.
SetAsInput()   Set a 8-bits port or a pin as an input.
SetAsOutput()  Set a 8-bits port or a pin as an output.

Procedure and Functions
PicPas use the Modula-2 syntax for procedures and functions:
Proedures are declared in the common Pascal syntax:
  procedure proc2(par1: byte);
  begin
    if par1 = 0 then 
      exit;
    else
      par1 := 5;
    end;  
  end;

Functions are declared the same, but indicating the type to return:
procedure TheNext(par1: byte): byte;
begin
  exit(par1 + 1);
end;

The return value is indicated with the exit() instruction.
When using in procedures parameters, a REGISTER parameter can be included:
procedure QuickParameterProc(register regvar: byte);
begin
  //Be carefull if put some code here
  PORTB := regvar;
end;

REGISTER parameters are fast, because they use the W register, so only one REGISTER parameter can be used.
As REGISTER parameter is stored in W register, any operation using the W register, could lose its value, so the first operation in a procedure, using a REGISTER parameter must be read this parameter.
Interrupts
To manage interrupts, PicPas let us to define a special kind of Procedure:
  procedure My_ISR; interrupt;
  begin

    //ISR code

  end;

The name of the procedure is not important, but the declaration must be followed but the reserved word INTERRUPT.
Only one INTERRUPT procedure is allowed in a program.
When PicPas compile an INTERRUPT procedure, some special criterias are considered:

Are always compiled starting in the address 0x0004.
A RETFIE instruction is added to the end of the routine.
No additional bank switching instructions are generated at the beginning of the procedure. It is the responsibility of the programmer to properly handle the banks within the routine.

INTERRUPT procedures don't save the value of registers or the control flags. This should be done manually.
ASM blocks
PicPas have a complete support for inserting ASM code inside the Pascal source.
ASM blocks must be included between the delimiters ASM and END:
procedure DoSomething;
begin
  x := 10;
  asm
    ;Add 2 to the address $20 
    MOVLW 2
    ADDWF $20, F
  end
end;

ASM blocks are not instructions, that's why they are not finished with "";"". It lets the ASM block, to be included in almost any place of the source code, like a comment.
WARNING: Changing the RAM bank, inside an ASM block, can generate errors in compilation or in the code compiled. PicPas know always the current RAM bank, when compiling, but is not aware of the changes can be made inside ASM blocks.
Absolute and relative Labels can be used too:
asm 
  GOTO $+1   ;jump one position forward
end

asm 
  ;infinite loop
label:
  NOP
  GOTO label
end

Program variables can be accessed, using his common name:
var 
 byte1: byte; 
 car1: char; 
 bit1: bit;
 bol1: boolean; 
 word1: word;
 dword1: dword;
begin
  //Low level clear
  asm 
    CLRF byte1
    CLRF car1
    BCF bit1
    BCF bol1
    CLRF word1.Low
    BCF word1.high.bit1
	CLRF dword1.low
	CLRF dword1.high
	CLRF dword1.extra
	CLRF dword1.ultra
  end
end.

Constant can be accessed too, using the same way.
It's possible to use the directive ORG inside a ASM block, too:
  asm 
    org $-2
  end
  vbit := 1;

The address in ORG, can be absolute or relative.
WARNING: Changing the PC pointer with ORG, can generate errors in the compilation or in the code compiled.
Pointers
Pointers are supported in PicPas, only for addresses going from $00 to $FF (1 byte size), thus they can cover only the RAM memory in banks 0 and 1.
Pointers must be declared usin first, a type declaration in the common Pascal style:
type
  ptrByte: ^Byte;
  ptrByte: ^Word;
var
  pbyte: ptrByte;
  pword: ptrWord;

Pointers can be assigned like variables or using addresses form others varaibles:
type
  ptrByte: ^Byte;
var
  pbyte: ptrByte;
  m    : byte;
begin
  pbyte := @m;    //Assign address
  pbyte^ := $ff;  //Write value
  //Now âmâ is  $ff
end.

The operator ""@"" return the address of a variable.
Pointers support some basic operations:
Assign   :	p1 := p2;
Compare  : 	if p1 = p2 then ...
Increment:	Inc(p);
Decrement:	Dec(p);
Add      :	p1 + p2 + 1
Subtrac  :	p1 - 5
Directives
Directives are special instructions inserted in the source code that are interpreted and executed by the compiler when compiling the source code (in compilation time).
Directive Programming Language
Directives have their own programmig language. It's a simple and interpreted language (with instructions, variables, operators and conditional structures) what is different from Pascal.
Some features of this programming language are:

It's case insensitive, like Pascal is.
Instructions are contained in one single line and are delimited by {$ â¦ }
It's not a typed language. Variables can change their type and value in execution and different type variables can be assigned.
Variables don't need to be defined before using.
There are only two types for variables: strings and numbers.

Variables
Variables are assigned with the instruction $SET:
{$SET x = 1}
{$SET y = 1 + x}
{$SET x = 'I'm now a string'}

$SET, is not a declaration, but an assignment. First time a variable is assigned, it's created.
Content of a variable, can be shown using instructions like $MSGBOX oo $INFO:
{$MSGBOX 'x is:' + x}
System Variables
There are some system variables, accessible from the directives language. They are:
{$MSGBOX PIC_MODEL} -> Shows the PIC model defined.
{$MSGBOX PIC_FREQUEN} -> Shows the Clock frequency.
{$MSGBOX PIC_MAXFREQ} -> Shows the Max Clock frequency for the device.
{$MSGBOX PIC_NUMBANKS} -> Shows the RAM banks number for the device.
{$MSGBOX SYN_MODE} -> Shows the syntax Mode of the compiler.
{$MSGBOX CURRBANK} -> Shows the current RAM bank.
(*) To see the complete list, check the User Manual.
List of Directives
The next directives are supported by PicPas:
$PROCESSOR
Specify the target device model of the microcontroller. Example:
{$PROCESSOR PIC16F628A}

The devices supported using $PROCESSOR directive are:
Baseline: PIC10F200 PIC10F202 PIC10F204 PIC10F206
Mid-Range: PIC16C63 PIC16CR63 PIC16C65 PIC16C65A PIC16CR65 PIC16F72 PIC16F83 PIC16CR83 PIC16F84 PIC16CR84 PIC16F84A PIC16F870 PIC16F871 PIC16F872 PIC16F873 PIC16F873A PIC16F874 PIC16F874A PIC16F876 PIC16F876A PIC16F877 PIC16F877A PIC16F887 PIC16F627A PIC16F628A PIC16F648A
This directive is a short form to define a device, however it's preferred to define devices using directives, like $SET_STATE_RAM, $SET_MAPPED_RAM, $CLEAR_STATE_RAM.
$FREQUENCY
Specify the clock frequency, in MHz or KHz. Example:
{$FREQUENCY 10Mhz}

Frequency information is used for:

The compiler, when needed to generate delays.
The simulator, for Real Time simulation.

If delays are used in the program, only some frequencies are supported. They are:
1MHz, 2Mhz, 4Mhz, 8MHz, 10MHz, 12MHz, 16MHz or 20MHz.
If frequency is not specified, the default value is 4MHz.
$MODE
Specify the syntax mode, used by the compiler. The allowed values are:
{$MODE PICPAS} -> Default mode. Use the new syntax for the control structures.
{$MODE PASCAL} -> Clasic Pascal mode. Use the common Pascal syntax for the control structures.
$MSGBOX
Shows a text message in the screen:
{$MSGBOX 'Hello World'} -> Shows the message 'Hello World' in the screen.
{$MSGBOX PIC_MODEL} -> Shows the system variable PIC_MODEL, that is the PIC model defined.
{$MSGBOX PIC_FREQUEN} -> Shows the Clock frequency.
{$MSGBOX 'clock=' + PIC_FREQUEN}  -> Shows the message: ""clock=8000000"" (if the Frequency was set to 8MHz).
$MSGERR
Shows a text message in the screen, with an error icon.
$MSGWAR
Shows a text message in the screen, with a warning icon.
$CONFIG
Sets the configuration bits of the device.
{$CONFIG $3FFD}

{$define _CP_ON       =     0x000F}
{$define _CP_OFF      =     0x3FFF}
{$define _WDT_OFF     =     0x3FFB}
{$define _LP_OSC      =     0x3FFC}
{$define _XT_OSC      =     $3FFD}

{$CONFIG _CP_OFF, _XT_OSC, _WDT_OFF }

{$CONFIG _CP_OFF _XT_OSC _WDT_OFF }

$INCLUDE
Includes the contents of a external file, into de source code:
{$INCLUDE aaa.pas}
{$INCLUDE d:\temp\aaa.txt}
x := {$INCLUDE expression.txt};

$OUTPUTHEX
Defines the name of the output binary file *.hex.
{$OUTPUTHEX myoutput.hex}  // Relative path
{$OUTPUTHEX d:\temp\myoutput.hex}  //Absolute path

When relative path is used, the file will be created in the same folder the Pascal program is.
If it's not defined the name of the *.hex file, it will be used the name of the program/unit compiled. So if the program is called ""myprogram"" (and the file is ""myprogram.pas""), then the *.hex file will be ""myprogram.hex"".
Directive {$OUTPUTHEX}, can be placed in any part of the source code and can be used several times. If so, the output file will be the defined by the last directive.
$DEFINE
Define symbols or macros
To define a symbol we can do:
{$define MY_SYMBOL}

Once defined, it can be tested using $IFDEF directive.
To define a macro we can do:
{$DEFINE macro=Hello}

Then we can expand a macro, in the code, using the way:
{$macro}
Following, there a sample code:
{$DEFINE pin_out=PORTB.0}
uses PIC16F84A;
begin
  SetAsOutput({$pin_out});
  {$pin_out} := 1;
end.

$SET
Set a value for a variable. If variables doesn't exist, it will be created.
{$SET pin_out='PORTB.0'}
uses PIC16F84A;
begin
  SetAsOutput({$pin_out});
  {$pin_out} := 1;
end.

Variables can be numbers or string.
Variables supports expresions:
{$SET a_var = 1 + 2 * another_var + 2 ^ sin(0.5)}

Unlike macros, variables values are solved when assigned. Macros values, are solved when macro is referenced.
$IFDEF, $ELSE, $ENDIF
This directives let us to define conditional compilation blocks:
Directive $IFDEF check the existence of some macro or variable and according to that, compile or not some blocks of code.
It has two forms:
{$IFDEF <identifier>} 
... 
{$ENDIF}

{$IFDEF <identifier>} 
... 
{$ELSE}
... 
{$ENDIF}

The next code is an example of use:
{$DEFINE MyPinOut=PORTB.0}
uses PIC16F84A;
begin
{$IFDEF MyPinOut}
{$ELSE}
  {$DEFINE MyPinOut=PORTB.1}
{$ENDIF}
  SetAsOutput({$MyPinOut});
  {$MyPinOut} := 1;
end.

$IFNDEF
This directive is the opposite version of $IFDEF.
{$DEFINE MyPinOut=PORTB.0}
uses PIC16F84A;
begin
{$IFNDEF MyPinOut}
  {$DEFINE MyPinOut=PORTB.1}
{$ENDIF}
  SetAsOutput({$MyPinOut});
  {$MyPinOut} := 1;
end.

$IF
This directives let us to define conditional compilation blocks, using expressions:
Directive $IF evaluates an expression, and according to the result, compile or omit some blocks of code.
The common syntax is:
{$IF <expression>} 
... 
{$ENDIF}

A long way can be used too:
{$IF <expression>} 
... 
{$ELSE}
... 
{$ENDIF}

The following code shows an example of use:
{$IF value>255}
var x: word;
{$ELSE}
var x: byte;
{$ENDIF}

As there is not a boolean type, a boolean expression returns the number 1 when the expression is TRUE and 0 when the expression is FALSE.
On the other side, instruction {$IF} will consider as TRUE, any number different from 0, or any string not empty.
$IFNOT
It's the opposite version of $IF.
{$IFNOT value>255}
var x: byte;
{$ELSE}
var x: word;
{$ENDIF}

$SET_STATE_RAM
Set the state of the RAM memory for the current device.
The state of a byte of RAM can have 3 values:

SFR: Special Function Register, like STATUS or TRISB.
GPR: General Purpose Register. Used as free memory for the user.
NIM: Not implemented cell.

$SET_STATE_RAM, let us to define the state of the RAM using a range of addresses.
The syntax of $SET_STATE_RAM is:
{$SET_STATE_RAM <list of commands>}

COmmands are separaed by commas. One command have teh syntax:
-:
One valid example, for this directive, would be:
{$SET_STATE_RAM '000-00B:SFR'};

That indicates the bytes in RAM from $000 to $00B are SFR.
Addresses are expressed always in hexadecimal.
Other example are:
//Multiple commands in one directive
{$SET_STATE_RAM '000-00B:SFR, 00C-04F:GPR'}  
//Set state for all banks
{$SET_STATE_RAM '000-00C:SFR:ALL'}  
//Set state for all banks and map them to bank 0
{$SET_STATE_RAM '000-00C:SFR:ALLMAPPED'}  

$SET_MAPPED_RAM
Define mapped regions of the RAM memory, for the current device.
RAM memory can be implemented as independent or mapped RAM. Mapped RAM usually points to other RAM bank. One register can be mapped in several banks. That's the case of registers like STATUS or INTCON, mapped in all the banks of the RAM.
$SET_MAPPED_RAM, can map ranges of RAM in register GPR and SFR. It has not sense to map unimplemented RAM.
The syntax for $SET_MAPPED_RAM is:
{$SET_MAPPED_RAM <list of commands>}

Commands are separated by commas. One command have the form:
Start address>-<End address>:<Target bank>

Target bank can be:
bnk0, bnk1, bnk2 or bnk3 for the Mid-Range PIC core devices (14 bits instruction).
bnk0, bnk1, bnk2, bnk3, bnk4, bnk5, bnk6 or bnk7 for the Baseline PIC core devices (12 bits).
A valid example, for a Mid-Range PIC would be:
{$SET_MAPPED_RAM ' 080-080:bnk0'};
This instruction defines the RAM address $080 as a register mapped at the bank 0, corresponding to the address 0x00.
Addresses are expresed always as a 3 digit hexadecimal number.
$CLEAR_STATE_RAM
USed to define the initial state of RAM memory.
$CLEAR_STATE_RAM, set the state of all the RAM as unimplemented, clearing all previous setting.
It's used before of starting to define the RAM for a device, using the directives $SET_STATE_RAM and $SET_MAPPED_RAM.
$RESET_PINS
Clear all the configuration for the pines defined in the microcontroller.
{$RESET_PINS}

This directive is generally used before of defining the microcontollers pins with the directive {$SET_PIN_NAME}
$SET_PIN_NAME
Define the name for a specified pin of the microcontroller.
The syntax is:
{$SET_PIN_NAME <pin number>:<name>}

One example would be:
{$SET_PIN_NAME '2:VDD'}

This definition would make the label ""VDD"" will appear in the pin 2 of the graphic representation of the PIC, when using the debugger.,
$MAP_RAM_TO_PIN
Assign some bits of the RAM, to physical pins of a microcontroller. This is used to map the registers GPIO, PORTA, PORTB, â¦, to pins of the device.
This assignment is needed to a have a better visual effect in the simulation of the PIC, when using the debugger. This way we will see the pin highlighted when it has a high level (bit set to 1).
The syntax of $MAP_RAM_TO_PIN is:
{$MAP_RAM_TO_PIN <address>:<list of associations>}

Associations are separated by commas. One association have the form:
<number of bit>-<number of pin>

One valid example would be:
{$MAP_RAM_TO_PIN '005:0-17,1-18,2-1,3-2,4-3'};

This instruction indicates the bits  0, 1, 2, 3 and 4, of the address $05, are mapped to the pins 17, 18, 1, 2 y 3 respectively.
Values for number of bit and pins are in decimal.
$SET_UNIMP_BITS
Defines bits not implemented in some specific positions of the RAM.
This setting is used to model the RAM in a accurate way (to the bit level) in order to have a better and realistic simulation of the device.
The syntax of $SET_UNIMP_BITS is:
{$SET_UNIMP_BITS <list of commands>}

The commands are separated by commas. One command have the form:
<address>:<mask>

The address and the mask are expressed in hexadecimal using 3 and 2 digits respectively.
One valid example would be:
{$SET_UNIMP_BITS '005:1F'};

And indicates the bits 5, 6 and 7, of the position $005 (PORTA) are not implemented in the hardware and will be read always as 0.
$SET_UNIMP_BITS1
Defines bits not implemented in some specific positions of the RAM.
This instruction works in the same way of $SET_UNIMP_BITS, but the unimplemented bits will be read always as 1, instead of 0.
One valid example would be:
{$SET_UNIMP_BITS1 '004:E0'};
And indicates the bits 5, 6 and 7, of the position $004 are not implemented in the hardware and will be read always as 1.
(*) For more information about directives, check the User Manual.
Defining custom devices
PicPas have complete support to define the hardware of microcontrollers, using directives.
Practically all devices from Baseline and Mid-Range families can be defined in this way.
Following, there is an example of defining a microcontoller similar to the  PIC16F84:
//Define hardware
{$SET PIC_MODEL='MY_PIC'}
{$SET PIC_MAXFREQ = 1000000}
{$SET PIC_NPINS = 18}
{$SET PIC_NUMBANKS = 2}
{$SET PIC_NUMPAGES = 1}
{$SET PIC_MAXFLASH = 1024}
//Clear memory state
{$SET_STATE_RAM '000-1FF:NIM'}
//Define RAM state
{$SET_STATE_RAM '000-00B:SFR, 00C-04F:GPR'}
{$SET_STATE_RAM '080-08B:SFR, 08C-0CF:GPR'}
//Define mapped RAM
{$SET_MAPPED_RAM '080-080:bnk0, 082-084:bnk0, 08A-08B:bnk0'}
{$SET_MAPPED_RAM '08C-0CF:bnk0'}
//Define unimplemented bits in RAM
{$SET_UNIMP_BITS '003:3F,083:3F,005:1F,085:1F,00A:1F,08A:1F'}

To see more examples of definig devices, check the folders /devices10 and /devices16.
PicPas Limitations
â¢	Only basic types are implemented: bit, byte, char, boolean, word an dword(limited support).
â¢	Cannot declare arrays or records.
â¢	No recursion implemented, Because of the limited hardware resources, available in PIC devices.
â¢	No float point implemented.
Some of these limitations must be solved in next versions.
Development
PicPas is a free software (GPL license) and it's opened for the collaboration of anyone who is interested.
There is still, much work for development or documentation, so any help will be appreciated.
Source Code
The source code of the compiler is in the folder /Source.
To compile PicPas, it's needed to have the following libraries:

SynFacilUtils
MisUtils
MiConfig
PicUtils
t-Xpres
UtilsGrilla
ogEditGraf

All of them, must be availables on the GitHub. Check the versions used.
These libraries don't include package. They are only files in folders that need to be included when compiling PicPas.
PicPas has been compiled, using the version 1.8.0 of Lazarus. Tested in Windows, Ubuntu and Mac.
To have more information about the compiler, check the Technical Documentation (Only in spanish by now).
Libraries
PicPas is a new project and it's still in development and there are not dedicated libraries for the compiler.
The best repository for libraries and useful code is in: https://github.com/AguHDz/PicPas-Librerias_y_Programas
",39
nkonev/blog,Java,"



Features

Zero-downtime update deployment
Fast page loading due client-side rendering
Fulltext search by posts
Updating posts through web STOMP on main page
Draft posts that visible only for author and administrator
User locking
User deletion (with migrating posts to special deleted user)
Pages prerendering for crawlers with rendertron
Dynamically setting header, subheader and background image without server restart
Auto cleaning ""orphanned"" images from PostgreSQL, and ""orphaned"" posts from Elasticsearch
Cluster out from the box - simple scale it with docker service scale BLOGSTACK_blog=4
Login through Facebook, Vkontakte OAuth2 providers
Binding several OAuth2 account to same blog account
Simply installation with docker swarm
Applications like Vkontakte/Facebook apps. Example store application on Go
Self-sufficient frontend asset. No CDN used.

Requirements
Run

Docker 18.06.0+

Development

JDK 12
docker-compose 1.16.1 +
Google Chrome (as default browser for webdriver-test). Just dnf install chromium in latest Fedora.

FAQ
Q: Can I run it without docker ?
A: Yes, you can achieve it by manually install PostgreSQL, RabbitMQ, Redis, Elasticsearch and configure it's connections in config or through commandline. See Spring Boot documentation https://docs.spring.io/spring-boot/docs/2.1.1.RELEASE/reference/html/boot-features-external-config.html.
Q: How to build frontend if I am backend developer ?
A:
./mvnw -P frontend generate-resources
Q: How to build full jar (with static) ?
A:
./mvnw -P frontend clean package
It will download java dependencies and nodejs with frontend dependencies.
Q: Why does blog wait for PostgreSQL, Elasticsearch, Redis, RabbltMQ port availability on boot?
A: Primarily for deploy tests runned inside Travis. When there isn' t these waits, I had spirously tests fails due inpredictable time of Elasticsearch boot.
Embedded API documentation
Embedded documentation are available at http://127.0.0.1:8080/docs/index.html
Request version info
This will available after full package, e. g. after resource filtering of git.template.json and renaming result in target/classes/static dir to git.json
curl -i http://127.0.0.1:8080/git.json

Running on Windows without docker
First you should install Redis, PostgreSQL, Rabbit MQ, Elasticsearch
and manually setup them (create database, schema, user for PostgreSQL, install web stomp plugin and create user for RabbitMQ).
Redis Windows x86 which works on my PC (Windows 7 x86)
http://bitsandpieces.it/redis-x86-32bit-builds-for-windows
2.8.2104 http://fratuz610.s3.amazonaws.com/upload/public/redis-builds/x86/redis-windows-x86-2.8.2104.zip - requires enabled swapfile.
run
redis-server.exe --maxheap 8Mb

Next you should use localhost IP addresses and disable asciidoctor:
mvnw -P local -Dasciidoctor.skip=true clean test

Demo Run / Installation
cd docker
./swarm-init.sh
I strongly recommend copy and rename docker-compose.template.yml to docker-compose.stack.yml.
Next I'll use renamed file.
Copy files on your server:
scp -r /path/to/blog/docker/* user@blog.test:/path/to/blog/
chmod 600 traefik/acme.json
Manual changes
Let' s assume cd docker.
a) ./swarm-init.sh
b) In docker-compose.template.yml or docker-compose.stack.yml:.
Change tag in service blog image: nkonev/blog:current-test -> image: nkonev/blog:latest
Also you can remove demo profile
c) Change next properties:
      - SPRING_MAIL_HOST=smtp.yandex.ru
      - CUSTOM_EMAIL_FROM=username@yandex.ru
      - SPRING_MAIL_USERNAME=username
      - SPRING_MAIL_PASSWORD=password
      - CUSTOM_BASE-URL=http://blog.test
 

And remove explicit ports definition where it's don't need - postgres, redis, rabbit, because of docker publishes ports by add it to iptables chain.
If you very want, you can skip setting these properties, but you'll have non-working email, wrong links in emails and so on.
d) Generating monitoring grafana & prometheus password
sudo yum install -y httpd-tools
# generate login and hash with replaced $ with $$ sign for able to copy-paste to docker-compose.stack.yml
htpasswd -nb admin admin | sed -e 's/\$/\$\$/g'
e) Set journald logging with appropriate tag for all services
    logging:
      driver: ""journald""
      options:
        tag: blog
f) Uncomment & change SSL setting in ./traefik/traefik.toml
g) Configure notifications in ./alertmanager/alert.yml
i) For able to http(s) request your domain registrar name with curl from container
ensure that
cat /proc/sys/net/ipv4/ip_forward
returns non-zero
next
Option a)
firewall-cmd --permanent --zone=public --add-port=80/tcp
firewall-cmd --permanent --zone=public --add-port=443/tcp
firewall-cmd --reload
Check
firewall-cmd --list-all-zones
iptables -t nat --line-numbers --numeric --list
Option b) insert iptables rule
iptables -I INPUT -i docker_gwbridge -p tcp -m multiport --dports 80,443 -j ACCEPT
If all ok, you should do it persistent by
chmod +x /etc/rc.local
vim /etc/rc.local
iptables -I INPUT -i docker_gwbridge -p tcp -m multiport --dports 80,443 -j ACCEPT
echo ""Successful inserted docker_gwbridge rule""
Starting with docker swarm
Next you can
docker stack deploy --compose-file docker-compose.stack.yml BLOGSTACK
docker service scale BLOGSTACK_blog=4
docker service ls
See postgres volume
docker volume inspect BLOGSTACK_postgresql_blog_dev_data_dir
See logs of jars
via journalctl (see applied tags in docker-compose.stack.yml):
journalctl -f CONTAINER_TAG=blog
journalctl -f CONTAINER_TAG=blog -o verbose
journalctl -f CONTAINER_TAG=blog CONTAINER_TAG=postgresql CONTAINER_TAG=redis CONTAINER_TAG=rabbitmq
or via docker
docker service logs -f BLOGSTACK_blog
Remove
docker stack rm BLOGSTACK
Remove exited containers
docker rm $(docker ps -aq -f name=BLOGSTACK_blog -f status=exited)
Test on local machine
curl
curl -H ""Host: blog.test"" http://127.0.0.1:8088
curl -H ""Host: grafana.blog.test"" -u ""admin:admin"" http://127.0.0.1:8088
curl -H ""Host: prometheus.blog.test"" -u ""admin:admin"" http://127.0.0.1:8088
curl -H ""Host: alertmanager.blog.test"" -u ""admin:admin"" http://127.0.0.1:8088
Browser
We add domains to /etc/hosts for browser sends correct Host header
sudo tee --append /etc/hosts <<'EOF'
127.0.0.1 blog.test
127.0.0.1 grafana.blog.test
127.0.0.1 prometheus.blog.test
127.0.0.1 alertmanager.blog.test
EOF
Maintenance
docker ps -aq | xargs docker rm
docker volume ls -q | xargs docker volume rm
docker images -q -a | xargs  docker rmi
Open PostgreSQL
docker exec -it $(docker ps --filter label=com.docker.swarm.service.name=BLOGSTACK_postgresql -q) psql -U blog
docker exec -it $(docker ps --filter label=com.docker.swarm.service.name=TESTBLOGSTACK_postgresql -q) psql -U blog
Open blog
docker exec -it $(docker ps --filter label=com.docker.swarm.service.name=BLOGSTACK_blog -q | head -n 1) bash
SEO
First configure custom.rendertron.serviceUrl - setup correct url of Rendertron installation. See also dockerized build.
How to add SEO metrics scripts
Just prepend file: location which contains index.html, and copy modified index.html to there folder.
spring.resources.static-locations: file:/var/www/, file:backend/src/main/resources/static/, classpath:/static/
So firstly Spring Mvc will looking in /var/www, next in $PWD/backend/src/main/resources/static/...
If your search(Yandex Metrics for example) checks for existence script - request will passed through rendertron, which wipes <script> tags.
In order to solve it, use custom.seo.script=file:/var/www/seo.html - Rendertron filter will inject content of
this file before closing </head>.
Grafana
Fix disk usage in https://grafana.com/dashboards/1860
Set query
100 - ((node_filesystem_avail_bytes{mountpoint=""/rootfs""} * 100) / node_filesystem_size_bytes{mountpoint=""/rootfs""})
Set Instant
TODO

re-implement buttons css
sitemap for SEO
edit metainfo for SEO by user
change post owner by admin
change comment owner by admin
LDAP
Google OAuth2 login
search by comments

",5
Pathoschild/StardewMods,C#,"This repository contains my SMAPI mods for Stardew Valley. See the individual mods for
documentation and release notes.
Mods
Active mods:


Automate (source)
Place a chest next to a machine (like a furnace or crystalarium), and the machine will
automatically pull raw items from the chest and push processed items into it. Connect multiple
machines with a chest to create factories.


Chests Anywhere (source)
Access your chests from anywhere and organise them your way. Transfer items without having to
run around, from the comfort of your bed to the deepest mine level.


Content Patcher (source)
Load content packs that change the game's images and data without replacing XNB files. Unlike
XNB mods, these content packs get automatic update checks and compatibility checks, are easy to
install and uninstall, and are less likely to break due to game updates.


Crops Anytime Anywhere (source)
Lets you grow crops in any season and location, including on grass/dirt tiles you normally
couldn't till.


Data Layers (source)
Overlays the world with visual data like accessibility, bee/Junimo/scarecrow/sprinkler coverage,
etc. It automatically includes data from other mods if applicable.


Debug Mode (source)
Press a button to view debug information and unlock the game's built-in debug commands
(including teleportation and time manipulation).


Fast Animations (source)
Speed up many animations in the game (currently eating, drinking, milking, shearing, and
breaking geodes). Optionally configure the speed for each animation.


Lookup Anything (source)
See live info about whatever's under your cursor when you press F1. Learn a villager's favourite
gifts, when a crop will be ready to harvest, how long a fence will last, why your farm animals
are unhappy, and more.


Noclip Mode (source)
Toggle noclip mode at the press of a button,
letting you walk through anything (even map boundaries).


Rotate Toolbar (source)
Rotate the top inventory row for the toolbar by pressing Tab (configurable).


Skip Intro (source)
Skip straight to the title screen or load screen (configurable) when you start the game. It also
skips the screen transitions, so starting the game is much faster.


Small Beach Farm (source)
Replaces the riverlands farm with a fertile pocket beach, suitable for slower or challenge runs.


Tractor Mod (source)
Lets you buy a tractor to more efficiently till/fertilize/seed/water/harvest crops, clear rocks, etc.


Inactive mods:


No Debug Mode
(deleted) Disables SMAPI's F2 debug mode, which can cause unintended effects like skipping an
entire season or teleporting into walls. No longer needed after SMAPI 1.0.


The Long Night (source)
Disables collapsing. You just stay awake forever and the night never ends (until you go to bed).
Broke permanently in Stardew Valley 1.3.20.


Translating the mods
The mods can be translated into any language supported by the game, and SMAPI will automatically
use the right translations.
(â = untranslated, â» = partly translated, â = fully translated)



Â 
Chests Anywhere
Data Layers
Debug Mode
Lookup Anything
Noclip Mode
Tractor Mod




Chinese
â
â
â
â» partial
â
â


French
â» partial
â» partial
â
â» partial
â
â


German
â
â
â
â» partial
â
â


Hungarian
â
â
â
â
â
â


Italian
â
â
â
â
â
â


Japanese
â» partial
â» partial
â
â» partial
â
â


Korean
â
â
â
â» partial
â
â


Portuguese
â» partial
â» partial
â
â» partial
â
â


Russian
â
â
â
â» partial
â
â


Spanish
â
â» partial
â
â» partial
â
â


Turkish
â
â
â
â
â
â



Contributions are welcome! See Modding:Translations
on the wiki for help contributing translations.
Compiling the mods
Installing stable releases from Nexus Mods is recommended for most users. If you really want to
compile the mod yourself, read on.
These mods use the crossplatform build config
so they can be built on Linux, Mac, and Windows without changes. See the build config documentation
for troubleshooting.
Compiling a mod for testing
To compile a mod and add it to your game's Mods directory:

Rebuild the project in Visual Studio or MonoDevelop.
This will compile the code and package it into the mod directory.
Launch the project with debugging.
This will start the game through SMAPI and attach the Visual Studio debugger.

Compiling a mod for release
To package a mod for release:

Switch to Release build configuration.
Recompile the mod per the previous section.
Upload the generated bin/Release/<mod name>-<version>.zip file from the project folder.

",140
Lombiq/Helpful-Libraries,C#,"Helpful Libraries Orchard module Readme
Project Description
Libraries that can be handy when developing for Orchard.
Includes:

Contents Libraries with dynamic pages
Authentication Libraries
Dependency Injection Libraries
Key Value Store
Parallel Extensions Extras
Serialization Libraries
Service Validation Libraries
Tasks Libraries and Jobs
Utilities

You can download an install the module from the Orchard Gallery.
Documentation
This module needs at least Orchard 1.8!
Libraries
The module consists of the following independent libraries (all in their own features):

Authentication Libraries
Contents Libraries
Dependency Injection Libraries
Key Value Store
Parallel Extensions Extras is an exception, as it isn't a feature
Serialization Libraries
Service Validation Libraries
Tasks Libraries
Utilities

You can use these libraries as described on the above pages. Don't forget to add a reference to the Piedone.HelpfulLibraries project from your project. Also correctly list the feature of the used libraries as a dependency in your module's Module.txt.
Public APIs are always documented so please always read method comments.
The module is also available for DotNest sites.
See the Version history.
The module's source is available in two public source repositories, automatically mirrored in both directions with Git-hg Mirror:

https://bitbucket.org/Lombiq/helpful-libraries (Mercurial repository)
https://github.com/Lombiq/Helpful-Libraries (Git repository)

Bug reports, feature requests and comments are warmly welcome, please do so via GitHub.
Feel free to send pull requests too, no matter which source repository you choose for this purpose.
This project is developed by Lombiq Technologies Ltd. Commercial-grade support is available through Lombiq.
",6
jhu-cs-uima-sp19/uniporter_app,Java,"Sprint 2 ------>
User accounts:
username: beary@jhu.edu
password: beary
username:jessy@jhu.edu
Password: password
Username: john@jhu.edu
Password: password
Username: madhu@jhu.edu
Password: madhu
For sprint 2, we added the ability for a user to delete their pending ride. We added a confirmation message before they delete for error prevention on the user end. If a user cancels their pending ride 24 hours before or earlier than their preferred leaving time then the code will reoptimize all the groups so that the other users can still save as much money as possible on their ubers. If the user cancels the ride within the 24 hours before their leaving time then the ride shares are not reoptimized and the group loses one person from their group. We also added a confirmation page that reviews all the information that a user put into the add new ride sequence so that the user can check that all their information is correct before submitting the ride request. We also updated the pending rides page into a sectioned recycler view so that it groups the rides based on whether they are past or upcoming rides. The pending rides are also sorted and presented so that the most recent and upcoming rides are at the top. We also added the feature to enter the date in the scheduled rides page so that the user can easily filter through their rides without having to scroll. We also decided to make it so that a user can only see the share rides they are a part of and not all the existing share ride groups in the database. We also added input restrictions so that users cannot input new rides in past dates and only to future dates. This ensures that the share rides are finalized 24 hours before the time they want to leave. We also added a feature to message the other people within your ride share group so the users can communicate their exact locations and whether they are running a little late. This was built using Firebase. We still need to improve the stylistic design of the chatroom. We also included a notifications feature that we created using Firebase. At the moment we are still sending notifications manually and we still have to integrate notifications within messages. We also decided to add some color to the nav drawer since it was completely white before. We made the top portion have a have a blue and green gradient background but kept the rest of it white to keep the simplicity. We also reduced the amount of things in the nav drawer to log out, scheduled rides, pending rides, and add new ride so that it was simple and the user canât get lost and stay focused on the main features of the app. We also changed the animations so that it was less abrupt. The card view animation was changed into a smooth fade. The backend algorithm checks to make sure that all the userâs luggage can fit into the uber or uberXL if needed. The main priority was to check that the user did not miss their flight so we made sure the user left early enough. We made sure the user never had to walk further than they wanted to. The user information, rides, and preferences are all stored in the Postgres user database. The optimization algorithm of the ride share groups is done on the Uniporter compute server separate from other processing.

SPRINT 1 ---->
README: As a part of Sprint 1 in terms of back end, we first created a Postgres Database to store the following: User accounts, User past preference inputs for their rides, User past share rides. We integrated Postgres with Django and Django Rest Framework to create API-endpoints. We also set up serializers, view-sets, and migration models for the following, and use the Django ORM to map these nested data points to Postgres RDBMS.:Users, Preferences, Tags, Rides and set up authentication and correct association between them. Our servers were linked to the app backend with APIâs (RetrofitClientRides, RetrofitClientSharerides, RetrofitClientUser)
In terms of front end, we created the main landing page, the register page, the log-in page, and pages to add a new ride. We have made it so that once you log-in once, you are always logged into the app. Once you are on the main landing page, you can open click on the hamburger to open the nav drawer. From there we have included three options: âNew Rideâ, âPending Ridesâ, and âLog outâ. You can add a new ride by clicking on âNew Rideâ. This will take you to the first page in a sequence of pages (you can see what part of the step you are on based on the circles at the bottom). There is the flight information page where you can put in your airline (from a spinner with all airlines at BWI) and the flight number and we will make an API call to get the date information and time of the flight. If we can't find it or you would rather prefer, you can enter the flight time manually (this will be done in the second sprint since we were not able to get the right format). The second page ask where you live on campus. This spinner drops down to show a list of all the common residences on campus. We took out the option for them to manually enter an address since it would involve a lot of working converting the address to GPS coordinates we use to calculate the optimal meeting location. The third page takes you to where you can customize how much you are willing to walk to meet with your group. The fourth page is for how much luggage you are bringing. Since we cannot account for every type of large luggage we made a spinner that will enable the user to give us an approximate size of the special item based on a scale we created and explained in a short paragraph. The last page is how early the user is willing to leave (in hours) before their flight. We added an x button in the corner of every page to exit the add a ride process. In the second sprint we want to add a pop-up that tells the user that they will lose the data they have entered up to this point. We have a final confirmation page after which their request is submitted and all the information is sent to the database backend.
Some sample users and passwords for testing purposes:
Username: madhu@jhu.edu, password: madhu
Username: lilian@jhu.edu, password: heehee
Username: tyang28@jhu.edu, password: R35YVR9S!
",2
gnodipac886/MatebookXPro-hackintosh,Shell,"Matebook X Pro Hackintosh
This is the guide to install macOS onto the Huawei Matebook X Pro.
Feel free to help a broke student out at the bottom of the page. :)
English | ä¸­æ| EspaÃ±ol
DISCLAIMER
The project is still in its beta/testing state.
Proceed at your own risk, I shall not take responsibility for any damages caused.
My Matebook X Pro's Hardware Configuration:

CPU: i7-8550U @ 1.8GHz
16GB RAM
Nvidia GTX MX 150 / Intel UHD 620
3K display @ 3000x2000
512 Gb Toshiba SSD
USB Wifi: Edimax N150
Builtin Bluetooth: Intel Wireless Bluetooth 8265

What works:

Intel UHD 620 Graphics Acceleration
Brightness
Sleep
Realtek alc256 Audio via AppleALC
Keyboard with Volume Controls and Brightness controls (via VoodooPS2)
Camera support up to 10.14.3
Trackpad and Native Gestures via Custom VoodooI2C
Touchscreen with multi-touch capabilities (think of it as a large trackpad)
Battery Percentage
Bluetooth (Reboot from Widows required - should persist after single reboot)
Power Management - I'm getting around 8-9 hours.
Wifi via USB dongle
Liton SSDs are now supported.
HDMI 2.0 support, up to theoretically 4K @60Hz. (Only 4K @30 tested due to equipment limitations)

What doesn't Work:

dGPU (Nvidia Optimus not supported on MacOS)
eGPU (not tested)
Fingerprint Sensor
Intel Wifi (soldered onto the motherbaord)

Let's Get Started
What you need:

Huawei Matebook X Pro (either i7 or i5 model)
macOS or OS X downloaded from the Mac App Store
8GB USB stick
External USB Wifi Dongle
USB C dock (for connecting to external mouse for initial setup)

BIOS Settings

f2 is for booting into BIOS
f12 is for boot override
Any version of the BIOS is good, but I'm on version 1.26
Restore Defaults
Disable Secure boot
Matebook's BIOS is rewrite protected, EFI tool is useless against this BIOS.

Pre-Install:
Prior to installing macOS, it is a good idea to backup any important files on Windows.


You can also leave Windows intact, but it can get tricky. Read here for more information:


This guide for creating USB and installing using Clover UEFI works well for this laptop:


For the installation purposes, please use the HD620 plist that rehabman provides in his guide for your installation USB.


Set config.plist/Graphics/ig-platform-id=0x12345678 for installation.
I ended up wiping windows and installing it afterwards, if you do so, fingerprint sensor will stop working, please follow the guide from this link:
Install macOS according to post 2 of this guide.
Post Installation
You should now be at your desktop.
Download

Clover Configurator Pro
USB Wi-fi Drivers
Newest Clover Bootloader, and install it to your boot disk

Mount EFI partition if not mounted already
Clone the repository via terminal or download it and swap the CLOVER folder downloaded for the one in your EFI directory.
IMPORTANT BrcmFirmwareRepo.kext is in /CLOVER/kexts/Other from this repository - make sure to move it to /Library/Extensions. These kexts will allow bluetooth to persist after a single reboot from Windows.
Note if you have the i5 version, or any other configurations of the laptop sold exclusively in China, you should:

For i5 models: you have to make a custom CPUFriendProvider for Power Management by following this guide:

DSDT fixes
Add the VoodooI2C patches (One for the SKL+ one for Windows 10 Patch)
Add the following code to your DSDT.aml to fix brightness keys.
into method label _Q0A replace_content
begin
// Brightness Down\n
    Notify(\_SB.PCI0.LPCB.PS2K, 0x0405)\n
end;
into method label _Q0B replace_content
begin
// Brightness Up\n
    Notify(\_SB.PCI0.LPCB.PS2K, 0x0406)\n
end;

Reboot
Updates
5/1/2019: Most Important Update Yet

Native brightness is now working
macOS is able to automatically adjust the brightness accroding to the ambient light sensor
Native Sleep is now working, not more glitchy screen after computer comes out from sleep, fixed by injecting custom EDID values
Native graphics: we are now using KBL graphics, we had to change the maximum link rate to HBR in order for the screen to work
Better audio: speakers are now louder, you can always just use voodooHDA but you will lose headphone detection
WhatEverGreen updated to version 1.2.8
VoodooI2C kext updated
Note* you still need to patch your DSDT for trackpad to work, and brightness keys to work.

4/11/2019: New LiteOn Patch

If you have problems updating to 10.14.4 (seeing a prohibited sign), its likely that the problem is caused by your liteon drive, please replace the following patch in your config.plist before you update.

      <dict>
        <key>Comment</key>
        <string>IONVMeFamily: Ignore FLBAS bit:4 being set - for Plextor/LiteOn/Hynix</string>
        <key>Disabled</key>
        <false/>
        <key>Name</key>
        <string>IONVMeFamily</string>
        <key>Find</key>
        <data>SBr2wRAPhQ==</data>
        <key>Replace</key>
        <data>SBr2wQAPhQ==</data>
      </dict>

4/2/2019: Config for Updating/Installing

Added New config-install/update.plist in CLOVER folder for installing purposes. You may choose this config in the boot screen of Clover: options - configs - config-install/update.plist

4/1/2019: 10.14.4 & New Power Management Kexts

New CPUFriend and CPUFriendProvider kexts for better battery life. (~9 hrs)
Run the following code if you would like to make a custom version of the power management kexts to your liking, then install the kexts located at your desktop to Clover. Source

    sh -c ""$(curl -fsSL https://raw.githubusercontent.com/daliansky/XiaoMi-Pro/master/one-key-cpufriend/one-key-cpufriend.sh)""



Undervolt the CPU/GPU/Cache via a shell: Place the new ""voltageshift"" file into your downloads folder and run the ""voltageset.command"" script to undervolt, and the ""voltageinfo.command"" to check your results. Furthermore, you can also set custom values to what you would like to undervolt to based on your hardware (i5 vs i7) by editing the script. Source
WhatEverGreen updated to version 1.2.7
Lilu updated to version 1.3.5
New config.plist in CLOVER comes with 10.14.4 graphics patch in kexttopatch (credit gnodipac886)
New 10.14.4 graphics patch

Comment: CFL patch for MateBook X Pro (10.14.4 credit gnodipac886)
Name: AppleIntelCFLGraphicsFramebuffer
Find: <48ff0557 f607008b 96c02500 008a8e95>
Replace: <b8040000 008986bc 25000031 c05dc395>

    <dict>
        <key>Comment</key>
        <string>CFL patch for MateBook X Pro (10.14.4 credit gnodipac886)</string>
        <key>Find</key>
        <data>SP8FV/YHAIuWwCUAAIqOlQ==</data>
        <key>Name</key>
        <string>AppleIntelCFLGraphicsFramebuffer</string>
        <key>Replace</key>
        <data>uAQAAACJhrwlAAAxwF3DlQ==</data>
        <key>Disabled</key>
        <false/>
    </dict>

2/1/2019 : 10.14.3

New Virtural SMC replacing FakeSMC
Added support for 4K video output with HDMI audio support
Added tools.zip for editing system files such as config.plist or DSDT
Support for firevault2 (In theory, never tested)
Added vanilla 10.14.3 framebuffer graphics kext, if you have replaced the kext before with a custom version, please swap it out in /System/Library/Extension and then use kextutility in tools.zip to rebuild permissions then reboot with 10.14.3 config.plist.
Added ""Configs"" for past config.plists and plists for KBL or SKL graphics (NEED HELP)
Other tweaks to CLOVER folder to support VituralSMC kext.
Updated NoTouchID.kext to newest versions for Mojave support which elimates any lags when promted for user password
Remember to apply brightness key patches to you DSDT.aml so you can play with them for no reason
New config.plist in CLOVER comes with 10.14.3 graphics patch in kexttopatch (credit gnodipac886)
Reports of Thunderbolt eGPU was able to work when booted with eGPU plugged in, no hotplug support yet
Support for Liteon SSDs confirmed with new config.plist in CLOVER and in Configs folder

1/23/2019 : 10.14.3 Update Graphics

New 10.14.3 graphics patch

CFL patch for MateBook X Pro (10.14.3 credit gnodipac886)
Name: AppleIntelCFLGraphicsFramebuffer
Find: <48ff0589 4d07008b 96c02500 008a8e95>
Replace: <b8040000 008986bc 25000031 c05dc395>

			<dict>
				<key>Comment</key>
				<string>CFL patch for MateBook X Pro (10.14.3 credit gnodipac886)</string>
				<key>Find</key>
				<data>SP8FiU0HAIuWwCUAAIqOlQ==</data>
				<key>Name</key>
				<string>AppleIntelCFLGraphicsFramebuffer</string>
				<key>Replace</key>
				<data>uAQAAACJhrwlAAAxwF3DlQ==</data>
				<key>Disabled</key>
				<false/>
			</dict>

1/21/2019

New Whatevergreen replaced old custom version
Lilu updated
New Applealc to support native audio codec
Custom version of I2C trackpad kexts for better support
Added KBL and SKL config.plists for people who are interested to help out. Main issue: Blackscreen/ internal screen not recognized
config.plist minor fixes

Credits:

Darren_Pan on reddit
midi and Maemo on discord
Chinese Matebook X Pro Hackintosh community
Spanish Matebook X Pro Hackintosh community
All the developers who developed the kexts used in this guide.

Help a broke student out:

PayPal
Venmo

QR Codes:



PayPal
Venmo.
WeChat
æ¯ä»å®











Good Luck!
",74
ozikot/AtCoder,C++,"AtCoder
Strage box of AtCoder code
åãã¡ã¤ã«åã®README.mdã«è§£æ³ã¨ã³ã¼ããè¼ãå§ãã¾ãã(2019/1/14~)
åå¿é²
next_permutation()ã¯sortæ¸ã¿ã®vector or éåãä½¿ç¨
ã«ãã´ãªã¼å¥
https://ozikot.github.io/cp-categorize/
",3
belowthetree/MiniProgram,JavaScript,"MiniProgram
ç§»å¨å¼åï¼å¾®ä¿¡å°ç¨åºé¡¹ç®ï¼
",3
bsiddiqui/hapi-router,JavaScript,"hapi-router
    
Route loader for hapi.
Hapi v17
hapi-router requires Hapi v18.

Hapi 18, hapi-router@5
Hapi 17, hapi-router@4
Hapi <= 16, hapi-router@3

Install
// If you're using Hapi v18
$ npm i -S hapi-router@5

// If you're using Hapi v17
$ npm i -S hapi-router@4

// If you're using < Hapi v17
$ npm i -S hapi-router@3.5.0
Usage
try {
  await server.register({
    plugin: require('hapi-router'),
    options: {
      routes: 'src/**/*Route.js' // uses glob to include files
    }
  })
} catch (err) {
  // Handle err
  throw err
}
Options
routes
Required 
Type: string / array
The glob pattern you would like to include
ignore
Type: string / array
The pattern or an array of patterns to exclude
cwd
Type: string
The current working directory in which to search (defaults to process.cwd())
Specifying Routes
Any files that match your routes glob will be loaded
Example route file:
module.exports = [
  {
    path: '/test1',
    method: 'GET',
    handler: function (request, reply) {
      reply('hello');
    }
  },
  {
    path: '/test2',
    method: 'GET',
    handler: function (request, reply) {
      reply('hello');
    }
  }
]
Glob Primer
Example globs:
'routes/*.js'    // match all js files in the routes directory
'routes/**/*.js' // recursively match all js files in the routes directory
'**/*Route.js'   // match all js files that end with 'Route'
From isaacs:
""Globs"" are the patterns you type when you do stuff like ls *.js on
the command line, or put build/* in a .gitignore file.
The following characters have special magic meaning when used in a
path portion:

* Matches 0 or more characters in a single path portion
? Matches 1 character
[...] Matches a range of characters, similar to a RegExp range.
If the first character of the range is ! or ^ then it matches
any character not in the range.
!(pattern|pattern|pattern) Matches anything that does not match
any of the patterns provided.
?(pattern|pattern|pattern) Matches zero or one occurrence of the
patterns provided.
+(pattern|pattern|pattern) Matches one or more occurrences of the
patterns provided.
*(a|b|c) Matches zero or more occurrences of the patterns provided
@(pattern|pat*|pat?erN) Matches exactly one of the patterns
provided
** If a ""globstar"" is alone in a path portion, then it matches
zero or more directories and subdirectories searching for matches.
It does not crawl symlinked directories.

",70
Lombiq/Git-Hg-Mirror-Common,JavaScript,"Git-hg Mirror Common readme
Orchard CMS module serving as the frontend of the two-way Git-Mercurial repository syncing service Git-hg Mirror.  The service component is Git-Hg Mirror Daemon.
This is a C# project that you'll need Visual Studio to work with. Commits in the master/default branch represent deployments, i.e. the latest commit in that branch shows the version currently running in production.
The project's source is available in two public source repositories, automatically mirrored in both directions with Git-hg Mirror itself:

https://bitbucket.org/Lombiq/git-hg-mirror-daemon-common (Mercurial repository)
https://github.com/Lombiq/Git-hg-Mirror-Common (Git repository)

Bug reports, feature requests and comments are warmly welcome, please do so via GitHub. Feel free to send pull requests too, no matter which source repository you choose for this purpose.
This project is developed by Lombiq Technologies Ltd. Commercial-grade support is available through Lombiq.
Developer overview
To work with the module locally you'll need to put it in an Orchard solution among the modules in a folder named exactly ""GitHgMirror.Common"". You'll need the same Orchard version as it's stated in the Module.txt file.
After enabling the module you'll see the same UI to create mirroring configurations than on githgmirror.com (note that it won't exactly look the same since the theme component of the website is not open source, since it's of little use to anybody else).
",2
HL7/PDDI-CDS,HTML,"PDDI-CDS
Documents and code related to the CDS and Pharmacy WG sponsored implementation guide for potential drug-drug interaction clinical decision support.
CI Build
Commits to this repository will automatically trigger a build which is pushed to the following location:
http://build.fhir.org/ig/HL7/PDDI-CDS/index.html
Project Wiki Page
http://wiki.hl7.org/index.php?title=PDDI_CDS
Who do I talk to?

Project Facilitators

Richard Boyce boycerd@upmc.edu
Guilherme Del Fiol guilherme.delfiol@utah.edu
Local Build
java -jar ""org.hl7.fhir.igpublisher.jar"" -ig ig.json

ig publisher GUI
Please read more about the implementation guide publishing process here: http://wiki.hl7.org/index.php?title=IG_Publisher_Documentation
Running the publisher""
    java -jar org.hl7.fhir.igpublisher.jar

Then, execute ig.json from the GUI. This will render webpages with html files in output folder (e.g., index.html).
",2
clockworkpi/CPI,None,"CPI
version control info.
",3
SourMesen/Mesen-S,C++,"Mesen-S
Mesen-S is a cross-platform SNES emulator for Windows & Linux built in C++ and C#.
If you want to support this project, please consider making a donation:

Development Builds
Development builds of the latest commit are available from Appveyor. For release builds, see the Releases tab on GitHub.
Warning: These are development builds and may be unstable. Using them may also increase the chances of your settings being corrupted, or having issues when upgrading to the next official release. Additionally, these builds are currently not optimized via PGO and will typically run 20-30% slower than the official release builds.
Windows: 
Linux: 
Roadmap
Mesen-S is very early in its development and some features are still missing.
The following should be added over time (in no particular order):

Movies
Netplay
Cheats
Additions/improvements in the debugging tools
Lua scripting
Support for the enhancement chips used in some games
Libretro core (once the emulation core is stable/accurate enough)

Compiling
See COMPILING.md
License
Mesen is available under the GPL V3 license.  Full text here: http://www.gnu.org/licenses/gpl-3.0.en.html
Copyright (C) 2019 M. Bibaud
This program is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.
This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.
You should have received a copy of the GNU General Public License
along with this program.  If not, see http://www.gnu.org/licenses/.
",81
xieyuheng/cicada,TypeScript,"Cicada
Aims

Libraries and tools for topological and geometric modeling

Community

We enforce C4 as collaboration protocol -- The C4 RFC
Style Guide -- observe the style of existing code and respect it
Code of Conduct
Source code -- github, gitlab
cicada-rs -- an old version of the same project written in rust
IRC -- #cicada-language
CI -- gitlab-ci

Docs

A Recursive Combinatorial Description of cell-complex

A paper about the definition of cell-complex in this project



Modules


npm install cicada-lang


API Docs


Try examples


Contents:

int
num
euclid
combinatorial-game
cell-complex
homology
cicada-core
cicadascript



int int
examples/int-module.js:
let assert = require (""assert"")

let ut = require (""cicada-lang/lib/util"")
let int = require (""cicada-lang/lib/int"")

{
  /**
   * generic `row_canonical_form`
   *   i.e. `hermite_normal_form` for integers
   */

  let A = int.matrix ([
    [2, 3, 6, 2],
    [5, 6, 1, 6],
    [8, 3, 1, 1],
  ])

  let B = int.matrix ([
    [1, 0, -11, 2],
    [0, 3, 28, -2],
    [0, 0, 61, -13],
  ])

  assert (
    A.row_canonical_form () .eq (B)
  )
}

{
  /**
   * generic `diag_canonical_form`
   *   i.e. `smith_normal_form` for integers
   */

  let A = int.matrix ([
    [2, 4, 4],
    [-6, 6, 12],
    [10, -4, -16],
  ])

  let S = int.matrix ([
    [2, 0, 0],
    [0, 6, 0],
    [0, 0, -12],
  ])

  assert (
    A.diag_canonical_form () .eq (S)
  )
}

{
  /**
   * solve linear diophantine equations
   */

  let A = int.matrix ([
    [1, 2, 3, 4, 5, 6, 7],
    [1, 0, 1, 0, 1, 0, 1],
    [2, 4, 5, 6, 1, 1, 1],
    [1, 4, 2, 5, 2, 0, 0],
    [0, 0, 1, 1, 2, 2, 3],
  ])

  let b = int.vector ([
    28,
    4,
    20,
    14,
    9,
  ])

  let solution = A.solve (b)

  if (solution !== null) {
    solution.print ()

    assert (
      A.act (solution) .eq (b)
    )
  }
}
num num

with config-able epsilon for numerical stability

examples/num-linear-algebra.js:
let assert = require (""assert"")

let ut = require (""cicada-lang/lib/util"")
let num = require (""cicada-lang/lib/num"")

{
  /**
   * `reduced_row_echelon_form` is like `row_canonical_form`
   *   it reduces pivots to one
   *   while respecting `epsilon` for numerical stability
   */

  let A = num.matrix ([
    [1, 3, 1, 9],
    [1, 1, -1, 1],
    [3, 11, 5, 35],
  ])

  let B = num.matrix ([
    [1, 0, -2, -3],
    [0, 1, 1, 4],
    [0, 0, 0, 0],
  ])

  A.reduced_row_echelon_form () .print ()
  A.row_canonical_form () .print ()

  assert (
    A.reduced_row_echelon_form () .eq (B)
  )
}
eu euclid

module theory over euclidean ring

for generic matrix algorithms



cg combinatorial-game

a game engine for n-player perfect information games
example games:

tic-tac-toe
hackenbush -- demo



cx cell-complex

cell-complex based low dimensional algebraic topology library
docs/a-recursive-combinatorial-description-of-cell-complex.md

gh graph

[TODO]
graph theory -- one dimensional cell-complex

hl homology

cellular homology of cell-complex

examples/four-ways-to-glue-a-square.js:

let cx = require (""cicada-lang/lib/cell-complex"")
let hl = require (""cicada-lang/lib/homology"")
let ut = require (""cicada-lang/lib/util"")

class sphere_t extends cx.cell_complex_t {
  constructor () {
    let builder = new cx.cell_complex_builder_t ()
    let [south, middle, north] = builder.attach_points (3)
    let south_long = builder.attach_edge (south, middle)
    let north_long = builder.attach_edge (middle, north)
    let surf = builder.attach_face ([
      south_long,
      north_long,
      north_long.rev (),
      south_long.rev (),
    ])
    super (builder)
  }
}

class torus_t extends cx.cell_complex_t {
  constructor () {
    let builder = new cx.cell_complex_builder_t ()
    let origin = builder.attach_point ()
    let toro = builder.attach_edge (origin, origin)
    let polo = builder.attach_edge (origin, origin)
    let surf = builder.attach_face ([
      toro,
      polo,
      toro.rev (),
      polo.rev (),
    ])
    super (builder)
  }
}

class klein_bottle_t extends cx.cell_complex_t {
  constructor () {
    let builder = new cx.cell_complex_builder_t ()
    let origin = builder.attach_point ()
    let toro = builder.attach_edge (origin, origin)
    let cross = builder.attach_edge (origin, origin)
    let surf = builder.attach_face ([
      toro,
      cross,
      toro.rev (),
      cross,
    ])
    super (builder)
  }
}

class projective_plane_t extends cx.cell_complex_t {
  constructor () {
    let builder = new cx.cell_complex_builder_t ()
    let [start, end] = builder.attach_points (2)
    let left_rim = builder.attach_edge (start, end)
    let right_rim = builder.attach_edge (end, start)
    let surf = builder.attach_face ([
      left_rim, right_rim,
      left_rim, right_rim,
    ])
    super (builder)
  }
}

calculate homology groups:

let report = {
  ""sphere"": hl.report (new sphere_t ()),
  ""torus"": hl.report (new torus_t ()),
  ""klein_bottle"": hl.report (new klein_bottle_t ()),
  ""projective_plane"": hl.report (new projective_plane_t ()),
}

ut.log (report)

let expected_report = {
  sphere:
   { '0': { betti_number: 1, torsion_coefficients: [] },
     '1': { betti_number: 0, torsion_coefficients: [] },
     '2': { betti_number: 1, torsion_coefficients: [] },
     euler_characteristic: 2 },
  torus:
   { '0': { betti_number: 1, torsion_coefficients: [] },
     '1': { betti_number: 2, torsion_coefficients: [] },
     '2': { betti_number: 1, torsion_coefficients: [] },
     euler_characteristic: 0 },
  klein_bottle:
   { '0': { betti_number: 1, torsion_coefficients: [] },
     '1': { betti_number: 1, torsion_coefficients: [ 2 ] },
     '2': { betti_number: 0, torsion_coefficients: [] },
     euler_characteristic: 0 },
  projective_plane:
   { '0': { betti_number: 1, torsion_coefficients: [] },
     '1': { betti_number: 0, torsion_coefficients: [ 2 ] },
     '2': { betti_number: 0, torsion_coefficients: [] },
     euler_characteristic: 1 }
}

Pictures by Guy Inchbald, a.k.a. Steelpillow

cc cicada-core

[TODO]
a dependently-typed programming language
game semantics
logic programming interface

cs cicadascript

[TODO]
js syntax frontend of cicada-core

License

GPLv3

",10
clockworkpi/CPI,None,"CPI
version control info.
",3
SourMesen/Mesen-S,C++,"Mesen-S
Mesen-S is a cross-platform SNES emulator for Windows & Linux built in C++ and C#.
If you want to support this project, please consider making a donation:

Development Builds
Development builds of the latest commit are available from Appveyor. For release builds, see the Releases tab on GitHub.
Warning: These are development builds and may be unstable. Using them may also increase the chances of your settings being corrupted, or having issues when upgrading to the next official release. Additionally, these builds are currently not optimized via PGO and will typically run 20-30% slower than the official release builds.
Windows: 
Linux: 
Roadmap
Mesen-S is very early in its development and some features are still missing.
The following should be added over time (in no particular order):

Movies
Netplay
Cheats
Additions/improvements in the debugging tools
Lua scripting
Support for the enhancement chips used in some games
Libretro core (once the emulation core is stable/accurate enough)

Compiling
See COMPILING.md
License
Mesen is available under the GPL V3 license.  Full text here: http://www.gnu.org/licenses/gpl-3.0.en.html
Copyright (C) 2019 M. Bibaud
This program is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.
This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.
You should have received a copy of the GNU General Public License
along with this program.  If not, see http://www.gnu.org/licenses/.
",81
xieyuheng/cicada,TypeScript,"Cicada
Aims

Libraries and tools for topological and geometric modeling

Community

We enforce C4 as collaboration protocol -- The C4 RFC
Style Guide -- observe the style of existing code and respect it
Code of Conduct
Source code -- github, gitlab
cicada-rs -- an old version of the same project written in rust
IRC -- #cicada-language
CI -- gitlab-ci

Docs

A Recursive Combinatorial Description of cell-complex

A paper about the definition of cell-complex in this project



Modules


npm install cicada-lang


API Docs


Try examples


Contents:

int
num
euclid
combinatorial-game
cell-complex
homology
cicada-core
cicadascript



int int
examples/int-module.js:
let assert = require (""assert"")

let ut = require (""cicada-lang/lib/util"")
let int = require (""cicada-lang/lib/int"")

{
  /**
   * generic `row_canonical_form`
   *   i.e. `hermite_normal_form` for integers
   */

  let A = int.matrix ([
    [2, 3, 6, 2],
    [5, 6, 1, 6],
    [8, 3, 1, 1],
  ])

  let B = int.matrix ([
    [1, 0, -11, 2],
    [0, 3, 28, -2],
    [0, 0, 61, -13],
  ])

  assert (
    A.row_canonical_form () .eq (B)
  )
}

{
  /**
   * generic `diag_canonical_form`
   *   i.e. `smith_normal_form` for integers
   */

  let A = int.matrix ([
    [2, 4, 4],
    [-6, 6, 12],
    [10, -4, -16],
  ])

  let S = int.matrix ([
    [2, 0, 0],
    [0, 6, 0],
    [0, 0, -12],
  ])

  assert (
    A.diag_canonical_form () .eq (S)
  )
}

{
  /**
   * solve linear diophantine equations
   */

  let A = int.matrix ([
    [1, 2, 3, 4, 5, 6, 7],
    [1, 0, 1, 0, 1, 0, 1],
    [2, 4, 5, 6, 1, 1, 1],
    [1, 4, 2, 5, 2, 0, 0],
    [0, 0, 1, 1, 2, 2, 3],
  ])

  let b = int.vector ([
    28,
    4,
    20,
    14,
    9,
  ])

  let solution = A.solve (b)

  if (solution !== null) {
    solution.print ()

    assert (
      A.act (solution) .eq (b)
    )
  }
}
num num

with config-able epsilon for numerical stability

examples/num-linear-algebra.js:
let assert = require (""assert"")

let ut = require (""cicada-lang/lib/util"")
let num = require (""cicada-lang/lib/num"")

{
  /**
   * `reduced_row_echelon_form` is like `row_canonical_form`
   *   it reduces pivots to one
   *   while respecting `epsilon` for numerical stability
   */

  let A = num.matrix ([
    [1, 3, 1, 9],
    [1, 1, -1, 1],
    [3, 11, 5, 35],
  ])

  let B = num.matrix ([
    [1, 0, -2, -3],
    [0, 1, 1, 4],
    [0, 0, 0, 0],
  ])

  A.reduced_row_echelon_form () .print ()
  A.row_canonical_form () .print ()

  assert (
    A.reduced_row_echelon_form () .eq (B)
  )
}
eu euclid

module theory over euclidean ring

for generic matrix algorithms



cg combinatorial-game

a game engine for n-player perfect information games
example games:

tic-tac-toe
hackenbush -- demo



cx cell-complex

cell-complex based low dimensional algebraic topology library
docs/a-recursive-combinatorial-description-of-cell-complex.md

gh graph

[TODO]
graph theory -- one dimensional cell-complex

hl homology

cellular homology of cell-complex

examples/four-ways-to-glue-a-square.js:

let cx = require (""cicada-lang/lib/cell-complex"")
let hl = require (""cicada-lang/lib/homology"")
let ut = require (""cicada-lang/lib/util"")

class sphere_t extends cx.cell_complex_t {
  constructor () {
    let builder = new cx.cell_complex_builder_t ()
    let [south, middle, north] = builder.attach_points (3)
    let south_long = builder.attach_edge (south, middle)
    let north_long = builder.attach_edge (middle, north)
    let surf = builder.attach_face ([
      south_long,
      north_long,
      north_long.rev (),
      south_long.rev (),
    ])
    super (builder)
  }
}

class torus_t extends cx.cell_complex_t {
  constructor () {
    let builder = new cx.cell_complex_builder_t ()
    let origin = builder.attach_point ()
    let toro = builder.attach_edge (origin, origin)
    let polo = builder.attach_edge (origin, origin)
    let surf = builder.attach_face ([
      toro,
      polo,
      toro.rev (),
      polo.rev (),
    ])
    super (builder)
  }
}

class klein_bottle_t extends cx.cell_complex_t {
  constructor () {
    let builder = new cx.cell_complex_builder_t ()
    let origin = builder.attach_point ()
    let toro = builder.attach_edge (origin, origin)
    let cross = builder.attach_edge (origin, origin)
    let surf = builder.attach_face ([
      toro,
      cross,
      toro.rev (),
      cross,
    ])
    super (builder)
  }
}

class projective_plane_t extends cx.cell_complex_t {
  constructor () {
    let builder = new cx.cell_complex_builder_t ()
    let [start, end] = builder.attach_points (2)
    let left_rim = builder.attach_edge (start, end)
    let right_rim = builder.attach_edge (end, start)
    let surf = builder.attach_face ([
      left_rim, right_rim,
      left_rim, right_rim,
    ])
    super (builder)
  }
}

calculate homology groups:

let report = {
  ""sphere"": hl.report (new sphere_t ()),
  ""torus"": hl.report (new torus_t ()),
  ""klein_bottle"": hl.report (new klein_bottle_t ()),
  ""projective_plane"": hl.report (new projective_plane_t ()),
}

ut.log (report)

let expected_report = {
  sphere:
   { '0': { betti_number: 1, torsion_coefficients: [] },
     '1': { betti_number: 0, torsion_coefficients: [] },
     '2': { betti_number: 1, torsion_coefficients: [] },
     euler_characteristic: 2 },
  torus:
   { '0': { betti_number: 1, torsion_coefficients: [] },
     '1': { betti_number: 2, torsion_coefficients: [] },
     '2': { betti_number: 1, torsion_coefficients: [] },
     euler_characteristic: 0 },
  klein_bottle:
   { '0': { betti_number: 1, torsion_coefficients: [] },
     '1': { betti_number: 1, torsion_coefficients: [ 2 ] },
     '2': { betti_number: 0, torsion_coefficients: [] },
     euler_characteristic: 0 },
  projective_plane:
   { '0': { betti_number: 1, torsion_coefficients: [] },
     '1': { betti_number: 0, torsion_coefficients: [ 2 ] },
     '2': { betti_number: 0, torsion_coefficients: [] },
     euler_characteristic: 1 }
}

Pictures by Guy Inchbald, a.k.a. Steelpillow

cc cicada-core

[TODO]
a dependently-typed programming language
game semantics
logic programming interface

cs cicadascript

[TODO]
js syntax frontend of cicada-core

License

GPLv3

",10
runningcheese/RunningCheese-Firefox,JavaScript,"RunningCheese Firefox V10
RunningCheese Firefox æ¯ä¸æ¬¾æ¨å¨æé«Firefoxæç¨æ§çæµè§å¨ï¼çé¢ä¼ç¾åè½å¼ºå¤§ï¼æä½ç®åå®¹æä¸ææ¯å®çç¹è²ï¼ä¸ºä½ å¨å·¥ä½å­¦ä¹ ä¸æä¾æå¤§çä¾¿å©ãVç³»åFirefox å°åå®å°æè¿ä¸ªæ¹ååè¿ï¼åæ±ç®æ´æç¨ï¼è®©æ´å¤çäººå å¥ Firefox éµè¥ã

å¼åååç»å4å¹´ç RunningCheese Firefox V10 æ­£å¼çåå¸äºï¼å¨æ°ç Firefox Quantum æ¶æè®© Firefox çåäºç¬¬äºæ¥ï¼æå²ä»¥æ¥ææ£ç Firefoxï¼é«éæµçï¼ä¸å«å¡é¡¿ãå¨éåº¦æ¯è© Chrome æµè§å¨çåæ¶ï¼è¿ä¿çäº Firefox çå¼ºå¤§åè½ï¼æ­£å¼çV10å·²ç»å¯ä»¥å®å¨æ¿ä»£ä¼ ç»æ¶æçV9ï¼å¦æä½ è¿½æ±çæ¯ç®æ´é«æï¼é£ä¹è¿æ¬¾ Firefox æµè§å¨ä¸å®éåä½ ï¼
æ´æ°åå®¹ï¼

åºäºå¨æ° Firefox Quantum æ¶æ ï¼Firefox 64ï¼ï¼éåº¦æ¯ççå¿«~
Firefox Quantum æ¯å²ä¸ææ£ç Firefoxï¼V10ä¹æ¯ Vç³»å Firefox ä¸­æå¥½ç¨çã
å®åäºä¸»é¢çé¢ï¼ä¼ååç§ç»èï¼ä¿®æ¹å·²ç¥çé®é¢ï¼å®å¨å¯ä»¥åä¸ºä¸»åæµè§å¨ä½¿ç¨ã
éç½®ä¸é®èªå¨æ´æ°ï¼çå»äºä¸åæè¾çç¦æ¼ï¼åºç°é®é¢éè¦ä¿®å¤ä¹å¯ä»¥ä¸é®ä¿®å¤ã

ä¸è½½å°åï¼
é«éä¸è½½ï¼https://firefox.runningcheese.com 
ç¾åº¦ç½çï¼https://pan.baidu.com/s/1nvGrYbR 
è¾è®¯ç½çï¼https://share.weiyun.com/5pjDbnL 
è°·æ­ç½çï¼https://drive.google.com/drive/folders/19DUhiuNxoPciVSIZwkQjPz_tbuHT1dPO
é®é¢åé¦ï¼https://www.runningcheese.com/v10
ä½¿ç¨æåï¼https://www.runningcheese.com/firefox-usage
å¼åæåï¼https://www.runningcheese.com/firefox-development
å¦æè§å¾å¥½ç¨ï¼å¯ä»¥æä¸æ¹ç âStar å¸®å©æ´å¤çæååç°è¿ä¸ªé¡¹ç®ã
",313
socketry/protocol-websocket,Ruby,"Protocol::WebSocket
Provides a low-level implementation of the WebSocket protocol according to RFC6455. It only implements the latest stable version (13).

Installation
Add this line to your application's Gemfile:
gem 'protocol-websocket'
And then execute:
$ bundle

Or install it yourself as:
$ gem install protocol-websocket

Usage
Here is a basic WebSocket client:
stream = # connect to remote system
framer = Protocol::WebSocket::Framer.new(stream)

frame = framer.read_frame
Contributing

Fork it
Create your feature branch (git checkout -b my-new-feature)
Commit your changes (git commit -am 'Add some feature')
Push to the branch (git push origin my-new-feature)
Create new Pull Request

License
Released under the MIT license.
Copyright, 2019, by Samuel G. D. Williams.
Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the ""Software""), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
",2
ppriyank/Bert-Coref-Resolution-Lee-,Python,"Bert-Coref-Resolution-Lee-
A replicate of Official github of End-to-end Neural Coreference Resolution
(https://arxiv.org/pdf/1707.07045.pdf)
Use  this for setting  up the requrements and preparing  glove vectors/Elmo(https://github.com/kentonl/e2e-coref)
For setting up the prince cluster to  support running the scripts : follow : https://github.com/ppriyank/Prince-Set-UP
bert_end_2_end.py & train-bert_end2end.py
Replaced bert model to generate embedings at run time to replace glove vectors and  elmo vectors in original paper
Since Bert works in sequences, and original code is written using sentences as chunks, the sequence is converted into run time  splits of sesntences.  For detailed explanation go  to line  #323.
For easier explanation of tensorflow code go to  https://stackoverflow.com/questions/34970582/using-a-variable-for-num-splits-for-tf-split/56015552#56015552 (my own answer)
",2
lydzhng/lydzhng.github.io,HTML,"lydzhng.github.io
my website
",3
cms-sw/cms-sw.github.io,JavaScript,"CMSSW work pages
They include:

Actual documentation.
Various scripts to import log files sparse in /afs to the git repository.

Importing log files to the repository.
A reasonable amount of processed log files, usually in json format, can be
stored in this git repository and not cause scalability issues, since git
is extremely good at compressing similar files.
This allows us to serve integration builds results via Github
Pages
In order to populate the data directory:
git clone cms-sw.github.com
cd cms-sw.github.com
./process-logs --logdir <path-to-your-toplevel-log-directory>
make -j 20
git commit data -m'Results updated'
git push origin master

Contributing to repository.
This repository contains two branches - master and code. All user submitted changes should go to code branch which will then be merged into master branch. Auto-generated data such as JSON files submitted by Cms Bot should go directly in to master. This should solve PR issues like this.
",6
ppriyank/Bert-Coref-Resolution-Lee-,Python,"Bert-Coref-Resolution-Lee-
A replicate of Official github of End-to-end Neural Coreference Resolution
(https://arxiv.org/pdf/1707.07045.pdf)
Use  this for setting  up the requrements and preparing  glove vectors/Elmo(https://github.com/kentonl/e2e-coref)
For setting up the prince cluster to  support running the scripts : follow : https://github.com/ppriyank/Prince-Set-UP
bert_end_2_end.py & train-bert_end2end.py
Replaced bert model to generate embedings at run time to replace glove vectors and  elmo vectors in original paper
Since Bert works in sequences, and original code is written using sentences as chunks, the sequence is converted into run time  splits of sesntences.  For detailed explanation go  to line  #323.
For easier explanation of tensorflow code go to  https://stackoverflow.com/questions/34970582/using-a-variable-for-num-splits-for-tf-split/56015552#56015552 (my own answer)
",2
lydzhng/lydzhng.github.io,HTML,"lydzhng.github.io
my website
",3
cms-sw/cms-sw.github.io,JavaScript,"CMSSW work pages
They include:

Actual documentation.
Various scripts to import log files sparse in /afs to the git repository.

Importing log files to the repository.
A reasonable amount of processed log files, usually in json format, can be
stored in this git repository and not cause scalability issues, since git
is extremely good at compressing similar files.
This allows us to serve integration builds results via Github
Pages
In order to populate the data directory:
git clone cms-sw.github.com
cd cms-sw.github.com
./process-logs --logdir <path-to-your-toplevel-log-directory>
make -j 20
git commit data -m'Results updated'
git push origin master

Contributing to repository.
This repository contains two branches - master and code. All user submitted changes should go to code branch which will then be merged into master branch. Auto-generated data such as JSON files submitted by Cms Bot should go directly in to master. This should solve PR issues like this.
",6
keywish/keywish-panther-tank,C++,"Please Contact Us
Technical support email: abbott@emakefun.com 
Sales email: ken@keywish-robot.com
The latest information download address: https://github.com/keywish/keywish-panther-tank
The branch switch method

Panther-tank

Product Introduce
""Tank"" is ATMEGA328P-PU as the main control chip, and TB6612FGN is used as a multi-functional
crawler car for motor drive chip. Compared with the traditional car, ""Tank"" is also equipped with wireless
control (Bluetooth, infrared remote control). It can automatically avoid obstacles. Of course, Maker can also
add or subtract other functions through its own Idea, such as adding automatic tracking, PS2 gamepad,
adding wifi control, robotic arm, etc.
""Tank"" is equipped with all kinds of materials, technical manuals, routines, etc., and teaches you from
entry to proficiency. Every electronic enthusiast can easily get started and realize the functions they want.
Feature
ïµ*	High power all metal geared motor
ïµ*	Integral stamping molding kit,easier Installation,tighter
ïµ*	2400mAH,7.4v ,rechargeable li-battery,longer battery life,and more dynamic
ïµ*	2 RGB turn lights
ïµ*	Buzzer Turn around reminder
ïµ*	Infrared remote control
ïµ*	Android App control
Required Best Buy Links
Buy on Amazon 
Buy on Aliexpress
Video Links
Component Introduce
Assembly
Function
Download method

",2
Lombiq/Tidy-Orchard-Development-Toolkit,C#,"Tidy Orchard Development Toolkit Readme
The Tidy Orchard Development Toolkit allows you to develop Orchard-based applications in a way that you own code (e.g. extensions, configuration) is completely separated from the core Orchard source.
This makes Orchard development not only tidier but it also allows you to:

Manage your extensions better: e.g. now you can keep all your modules under a single repository (with subrepositories for other modules) instead of having all your modules in separate repositories.
Updating or upgrading the Orchard source is a matter of pulling in the latest changes from the Orchard repository.
You can even keep a single (or just a few) folders on your computer with the Orchard source that you link to from each of your solutions, thus minimizing storage space usage and build time.

Keep in mind that this toolkit is purely experimental! It can in no way support a production scenario. Also the aim was to get Orchard working in its basics: it fully runs. Other areas like deplyoment wasn't explored yet.
Creating a Tidy Orchard solution
There is a sample solution with all of the below tasks already done: see the Tidy Orchard Development Quick Start. This solution has all the details just referenced here.

Create a folder in the root for your web project (e.g. âOrchard.Webâ but the name is not mandatory) and copy the contents of Orchard.Web there (the Web csproj can also have an arbitrary name). Modify the Web.config as in the sample.
Add the Toolkit to the Lombiq.TidyOrchardDevelopmentToolkit under your web project's folder.
Add the full Orchard source to the Web project's folder under a folder called ""Orchard"". This should be the full Orchard source (e.g. with the lib and src folders in the root). Please note that you have to remove the Web.config from Orchard.Web.
Copy the Orchard solution file to the root (and optionally rename it).
Change all project references of the solution to point to the new web project's content (assuming your web project's folder is called Orchard.Web):

Replace ""Orchard\ with ""Orchard.Web\Orchard\src\Orchard\ (including the quotes).
Replace Orchard.Tests\ with Orchard.Web\Orchard\src\Orchard.Tests.
Replace Orchard.Web.Tests\ with Orchard.Web\Orchard\src\Orchard.Web.Tests.
Replace ""Orchard.Web\ with ""Orchard.Web\Orchard\src\Orchard.Web\ (including the quotes).
Replace Orchard.Tests.Modules\ with Orchard.Web\Orchard\src\Orchard.Tests.Modules.
Replace Orchard.Core.Tests\ with Orchard.Web\Orchard\src\Orchard.Core.Tests.
Replace Orchard.WarmupStarter\ with Orchard.Web\Orchard\src\Orchard.WarmupStarter.
Replace ""Tools\ with ""Orchard.Web\Orchard\src\Tools\ (including the quotes).
Replace Orchard.Specs\ with Orchard.Web\Orchard\src\Orchard.Specs.
Replace Orchard.Profile\ with Orchard.Web\Orchard\src\Orchard.Profile.
Replace Orchard.Web\Orchard\src\Orchard.Web\Orchard.Web.csproj back to Orchard.Web\Orchard.Web.csproj.


Copy over the contents of the original Orchard.Web folder to your own web folder except the Core, Modules, Media and Themes folders.
Adjust Orchard.Web.csproj:

Replace ....\lib\ with Orchard\lib.
Replace ProjectReference Include=""..\ with ProjectReference Include=""Orchard\src.
Replace ProjectReference Include=""Core\ with ProjectReference Include=""Orchard\src\Orchard.Web\Core.


Add the Toolkit's project to the solution and reference it from the web project.
Register the Toolkit's Autofac module in the HostComponents.config file.
Register the TidyDevelopmentHttpModule in the Web.config and change the handlers declaration to use the appropriate accessPolicy.
Add your own themes and modules under the Web project's folder under ""Modules"" and ""Themes"" folders, respectively.
Modify module project files according to the Orchard App Host documentation so they support the new solution structure.

Instead of copying you can always create symlinks with mklink instead.
The module's source is available in two public source repositories, automatically mirrored in both directions with Git-hg Mirror:

https://bitbucket.org/Lombiq/tidy-orchard-development-toolkit (Mercurial repository)
https://github.com/Lombiq/Tidy-Orchard-Development-Toolkit (Git repository)

Bug reports, feature requests and comments are warmly welcome, please do so via GitHub.
Feel free to send pull requests too, no matter which source repository you choose for this purpose.
This project is developed by Lombiq Technologies Ltd. Commercial-grade support is available through Lombiq.
",3
digital-flowers/react-animated-css,JavaScript,"react-animated-css
React component to show or hide elements with animations using Animated.css


demo
https://digital-flowers.github.io/react-animated-css.html
install
npm i react-animated-css --save
Note You have to include Animated.css in your html page, this component is just a wrapper for it.
<head>
  <link rel=""stylesheet"" href=""https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.5.2/animate.min.css"">
</head>
how to use
very easy to use, just wrap your content with the animated component
import {Animated} from ""react-animated-css"";

<Animated animationIn=""bounceInLeft"" animationOut=""fadeOut"" isVisible={true}>
    <div>
        hello world ;)
    </div>
</Animated>

then you can just toggle the  isVisible property to see the animation.
Properties

animationIn animation in name, default ""fadeIn""
animationOut animation out name, default ""fadeOut""
animationInDelay animation in delay, default 0
animationOutDelay animation out delay, default 0
animationInDuration animation in delay, default 1000
animationOutDuration animation out delay, default 1000
style react style property for the inner component
isVisible if the component is visible or not, default true
innerRef react ref property for the inner component
className react className property for the inner component
animateOnMount apply animationIn on mount or not, default true

List of animation
All the following animation from animated.css are supported.



ï»¿Animation Name




bounce


flash


pulse


rubberBand


shake


headShake


swing


tada


wobble


jello


bounceIn


bounceInDown


bounceInLeft


bounceInRight


bounceInUp


bounceOut


bounceOutDown


bounceOutLeft


bounceOutRight


bounceOutUp


fadeIn


fadeInDown


fadeInDownBig


fadeInLeft


fadeInLeftBig


fadeInRight


fadeInRightBig


fadeInUp


fadeInUpBig


fadeOut


fadeOutDown


fadeOutDownBig


fadeOutLeft


fadeOutLeftBig


fadeOutRight


fadeOutRightBig


fadeOutUp


fadeOutUpBig


flipInX


flipInY


flipOutX


flipOutY


lightSpeedIn


lightSpeedOut


rotateIn


rotateInDownLeft


rotateInDownRight


rotateInUpLeft


rotateInUpRight


rotateOut


rotateOutDownLeft


rotateOutDownRight


rotateOutUpLeft


rotateOutUpRight


hinge


jackInTheBox


rollIn


rollOut


zoomIn


zoomInDown


zoomInLeft


zoomInRight


zoomInUp


zoomOut


zoomOutDown


zoomOutLeft


zoomOutRight


zoomOutUp


slideInDown


slideInLeft


slideInRight


slideInUp


slideOutDown


slideOutLeft


slideOutRight


slideOutUp



note:
From React 17.x.x componentWillReceiveProps will be deprecated and a different strategy is introduced.
",64
rudty/nodekell,TypeScript,"nodekell
Functional library for nodejs






almost all functions support currying
supports parallel functions
supports async generator
supports lazy evaluation
typescript support (ver:3.4, target:es2018)

Installation
npm install nodekell
Import Module
const F = require(""nodekell"");
Quick Example
const v = await F.run(
    F.range(Infinity),//[0,1,2...]
    F.filter(e => e % 2 == 0), //[0,2,4...] 
    F.map(e => e + 1), //[1,3,5...]
    F.take(5), // [1,3,5,7,9]
    F.reduce((acc, e) => acc + e)); // 1+3+5+7+9
console.log(v);//25
const v = await F.run(
    F.repeat(2), //[2,2,2,..]
    F.map(e => e + 1), //[3,3,3...]
    F.take(5), // [3,3,3,3,3]
    F.distinct, // [3]
    F.collect); // generator to array
console.log(v);//[3]
Functions / Examples
currying

run
pipe
compose
curry

functional

filter
map
take
takeWhile
fmap          [change]
flatMap    [change]
flat
dflat
reverse
forEach
zip
zipWith
drop
dropWhile
emptyThen
errorThen
distinct
distinctBy
splitBy
innerJoin
leftInnerJoin
rightInnerJoin
outerJoin
leftOuterJoin
rightOuterJoin
then
tap
concat
union
scanl
scanl1
buffer

functional / parallel

parallel_set_fetch_count
pfilter
pmap
pfmap
pcalls

generator

range
seq
rangeOf [deprecated]
repeat
rangeInterval
iterate

aggregate

foldl
foldl1
reduce
foldr
foldr1
collect
collectMap
collectSet
maxBy
minBy
max
min
some
every
count
sum
average
groupBy
orderBy
sortBy
order
sort

util / else

sleep
head
tail
interval
timeout
withTimeout
notNil [deprecated]
isNil
cond
otherwise


run
combination left to right functions
first arguments received second functions argument
from second received combine functions
returns promise
const v = await F.run(
            F.range(10),//[0~9]
            F.filter(e => e % 2 == 0), //[0,2,4,6,8] 
            F.map(e => e + 1), //[1,3,5,7,9]
            F.reduce((acc, e) => acc + e)) // 1+3+5+7+9
console.log(v + 1); // 25 + 1
this expands to
const v = await F.reduce((acc, e) => acc + e, // 1+3+5+7+9
                    F.map(e => e + 1, //[1,3,5,7,9]
                        F.filter(e => e % 2 == 0, //[0,2,4,6,8]
                            F.range(10)))); //[0~9]
pipe
combination left to right functions
only first function can use multiple arguments.
return value is promise.
see also compose
const rs = F.pipe(
    e => e.sort(), //[1,2,3,4,5]
    F.reverse, //[5,4,3,2,1]
    F.collect); //generator to array
const a = [1,5,4,3,2];
const result = await rs(a);//call
console.log(result); //[5,4,3,2,1]
const double1 = F.pipe(
    F.map(e => e + e), //[2,4,6,8]
    F.collect);
const a = [1,2,3,4];
const r1 = await double1(a);
console.log(r1); // [2,4,6,8]
const double2 = F.pipe(
    t => t.map(e => e + e)); // Array.map

const a = [1,2,3,4];
const r2 = await double2(a); // return promise
console.log(r2); // [2,4,6,8]
compose
combination right to left functions
only last function can use multiple arguments.
return value is promise.
see also pipe
const rs = F.compose(
    F.collect, //generator to array
    F.reverse, //[5,4,3,2,1]
    e => e.sort() //[1,2,3,4,5]
);
const a = [1,5,4,3,2];
const result = await rs(a);//call
console.log(result); //[5,4,3,2,1]
const double1 = F.compose(
    F.collect,
    F.map(e => e + e) //[2,4,6,8]
);
const a = [1,2,3,4];
const r1 = await double1(a);
console.log(r1); // [2,4,6,8]
const double2 = F.compose(
    t => t.map(e => e + e)); // Array.map

const a = [1,2,3,4];
const r2 = await double2(a); // return promise
console.log(r2); // [2,4,6,8]
curry
if all arguments are not given for the function,
it returns the function that stored the argument
const myAdd = F.curry((a,b,c) => a + b + c);
const myAdd1 = myAdd(1);
const myAdd2 = myAdd1(2);
const myAdd3 = myAdd2(3);//<- real call
console.log(myAdd3); // print 6
const myAdd = F.curry((a,b,c) => a + b + c);
const r = myAdd(1,2,3); // <- real call
console.log(r); // print 6
filter
const a = [1,2,3,4,5];
const filtered = F.filter(e=> e % 2 == 0, a)
for await (const e of filtered) {
    console.log(e);
}
//print
//2
//4
const r = await F.run(
       [1,2,3,4,5], 
       F.filter(e => e % 2 == 0));

for await (const e of r) {
    console.log(e);
}
//print 
//2
//4
map
const a = [1,2,3,4,5];
for await (const e of F.map(e=> e * 2, a)) {
    console.log(e);
}
//print 2 4 6 8 10
const v = await F.run([1,2,3,4,5],
            F.map(e => e + 1),
            F.collect);
console.log(v);
//print 2 3 4 5 6        
take
const a = [1,2,3,4,5];
const t = F.take(3, a);
console.log(await F.collect(t)); // print 1 2 3
const v = await F.run(
    F.range(Infinity),
    F.take(2),
    F.collect
);
console.log(v); // print 0 1
takeWhile
const a = [1,2,3,1,2,3];
const t = F.takeWhile(e => e < 3, a);
console.log(await F.collect(t)); // print 1, 2
fmap
change
support for an iterable with non-iterable elements is deprecated.
example) F.fmap(e => e, [[1],[2],3,4,5])
current: [1,2,3,4,5]
after: throw Error
use F.flat or F.map instead.
const a = [[1],[2],[3],[4],[5]];
const f = F.fmap(e => e, a);
console.log(await F.collect(f)); // print [1,2,3,4,5]
const a = [ 
        [Promise.resolve(1)],
        Promise.resolve([2]),
        [3],
        [4],
        [5]];
const f = F.fmap(e => e, a);
console.log(await F.collect(f)); // print [1,2,3,4,5]
flatMap
same as fmap
flat
const a = [ 
        [Promise.resolve(1)],
        Promise.resolve([2]),
        [3],
        4,
        5];
const f = F.flat(a);
console.log(await F.collect(f)); // print [1,2,3,4,5]
dflat
Similar to flat, but works recursively
const r = F.dflat([[[1],[2]]],[[3]],[4]);
const c = await F.collect(r);
console.log(c);//print [1,2,3,4]
const r = F.dflat(""HELLO"");
const c = await F.collect(r);
console.log(c);//print [""H"",""E"",""L"",""L"",""O""]
reverse
const a = [1,2,3,4,5];
const t = F.reverse(a);
console.log(await F.collect(t)); // print 5,4,3,2,1
forEach
const beginTime = Date.now();
await F.run(
    F.range(100), 
    F.forEach(async e => {
        await F.sleep(100)
    }));
const endTime = Date.now();
console.log(endTime - beginTime); 
// print 121
// works concurrency
zip
const a = [1,2,3,4,5];
const b = [6,7,8,9,10];
const z = F.zip(a, b);
const arr = await F.collect(z);
for (const e of arr) {
    console.log(e);
    //print
    //[1,6]
    //[2,7]
    //[4,9]
    //[5,0]
}
zipWith
const a = [{id:1}, {id:2}];
const b = [{name:""a""}, {name:""b""}];

const myZip = (f, s) => {
    return [f.id, s.name];
};

const z = F.zipWith(myZip,a, b);
const arr = await F.collect(z);
for (const e of arr) {
    console.log(e);
}
//print
//[1,""a""]
//[2,""b""]
drop
const a = [1,2,3,4,5];
const r = F.drop(3, a)
const result = await F.collect(r);
console.log(result); // print [4, 5]
const a = [1,2,3,4,5];
const r = F.drop(Infinity, a)
const result = await F.collect(r);
console.log(result); // print []
dropWhile
const a = [1,2,3,4,1];
const r = F.dropWhile(e=> e < 3, a)
const result = await F.collect(r);
console.log(result); // print [3,4,1]
const a = [Promise.resolve(1),2,3,4,1];
const r = F.dropWhile(e=> e < 3, a)
const result = await F.collect(r);
console.log(result); // print [3,4,1]
emptyThen
const v = await F.run(F.range(Infinity),
            F.take(0), // take 0 
            F.emptyThen([1,2,3,4,5]), // new array
            F.map(e => e + 1), // 2,3,4,5,6
            F.collect);
console.log(v); // 2,3,4,5,6
const v = await F.run(F.range(Infinity),
    F.take(0),// take 0
    F.emptyThen(()=> { return [1,2,3] }), // new array from function
    F.map(e => e + 1), // 2,3,4
    F.collect) 
console.log(v);// 2,3,4
const v = await F.run(F.range(Infinity),
    F.take(3), // [0,1,2]
    F.emptyThen(([9,9,9]),//not work
    F.map(e => e + 1), //[1,2,3]
    F.collect);
console.log(v); //2,3,4
errorThen
catch error
const v = await F.run([1,2,3,4,5],
    F.filter(e =>{
        if (e > 2) {
            throw new Error(""hello"")
        }
        return e;
    }), // [1, 2 error! 
    F.errorThen([9,8]),//catch and return 9,8
    F.collect); // 
console.log(v);
//print 1,2,9,8
const v = await F.run([1,2,3,4,5],
    F.filter(e =>{
        if (e > 2) {
            throw new Error(""hello error"");
        }
        return e;
    }), // [1, 2 error! 
    F.errorThen((reason) => {
        console.log(reason); //hello error
        return [9,8];
    }),//catch and return 9,8
    F.collect); // 
console.log(v);
//print 
//hello error 
//callstack... 
//1,2,9,8
distinct
const a = [1,2,1,2,2,3];
const r = F.distinct(a);
const result = await F.collect(r);
console.log(result); // print 1,2,3
distinctBy
const a = [{num:1}, {num:1}, {num:2}];
const r = F.distinctBy(e=>e.num, a);
const result = await F.collect(r);
for (const m of result) {
    console.log(m);
}
//print
//{num:1}
//{num:2}
splitBy
to iterable from any
const helloWorld = ""hello world"";
const r = await F.splitBy(e=>e.split("" ""), helloWorld);
for await(const e of r) {
    console.log(e);
}
//print 
//hello
//world
innerJoin
same as leftInnerJoin
leftInnerJoin
support Map, Object({})
const a = [{id:1, name:""foo""}, {id: 2, name:""bar""}, {id: 3, name:""hoo""}];
const b = [{id:1, value:3}, {id: 2, value: 4}];
const j = await F.innerJoin((v1,v2) => v1.id === v2.id , a, b);
const r = await F.collect(j);
console.log(r);
// print
// [{id:1, name:""foo"", value:3},
// {id:2, name:""bar"", value:4}]
rightInnerJoin
support Map, object({})
the result is the same as innerJoin, but the output order is right iterator
const a = [{id:1, value:3}]; 
const b = [{id:1, name:""foo""}, {id: 2, name:""bar""}, {id: 3, name:""hoo""}];
const j = await F.rightInnerJoin((v1,v2) => v1.id === v2.id , a, b);
const r = await F.collect(j);
console.log(r);
//  print
// [{id:1, name:""foo"", value:3}]
outerJoin
same as leftOuterJoin
leftOuterJoin
support Map, object({})
const a = [{id:1, name:""foo""}, {id: 2, name:""bar""}, {id: 3, name:""hoo""}];
const b = [{id:1, value:3}, {id: 2, value: 4}];
const j = await F.outerJoin((v1,v2) => v1.id === v2.id, a, b);
const r = await F.collect(j)
console.log(r);
// print
// [{id:1, name:""foo"", value:3},
// {id:2, name:""bar"", value:4},
// {id:3, name:""hoo""}]
rightOuterJoin
support Map, object({})
const a = [{id:1, value:3}]; 
const b = [{id:1, name:""foo""}, {id: 1, name:""bar""}, {id: 1, name:""hoo""}];
const j = await F.rightOuterJoin((v1,v2) => v1.id === v2.id , a, b);
const r = await F.collect(j);
console.log(r);
// print
// [{id:1, name:""foo"", value:3},
// {id:1, name:""bar"", value:3},
// {id:1, name:""hoo"", value:3}]
then
like promise then
see also tap
const v = await F.run([1,2,3,4,5],
    F.then(async function*(iter) {
        for await(const e of iter) {
            console.log(e);
            yield e;
        }
    }),
    F.map(e => e + 1),
    F.collect);
console.log(v);
//print
//1
//2
//3
//4
//5
//[2,3,4,5,6]
const v = await F.run([1,2,3,4,5],
    F.then(iter => {
        return iter; //do nothing
    }),
    F.collect);
console.log(v);
// print
// [1,2,3,4,5]
tap
call first argument with second argument
then returns the second argument
return promise wrap
see also then
const v = await F.run([1,2,3,4,5],
    F.tap(console.log), //print and return Promise([1,2,3,4,5])
    F.map(e => e + 1),
    F.collect);
concat
merge 2 ranges
const c = F.concat([1,2,3],[4,5,6]);
for await(const e of c) {
    console.log(e);
}
//print [1,2,3,4,5,6]
const v = await F.run(
    F.concat([1,2,3],[4,5,6]),
    F.collect);
console.log(v);
//print [1,2,3,4,5,6]
union
same as concat
scanl
const s = F.scanl((a,b) => a + b, 0, [1,2,3]);
const r = await F.collect(s);
console.log(r);
//print [0,1,3,6]
const r = F.scanl((a, b) => a/b, 64, [4,2,1]);
const r = await F.collect(s);
console.log(r);
//print [64,16,8,8]
scanl1
const s = F.scanl((a,b) => a + b, [1,2,3]);
const r = await F.collect(s);
console.log(r);
//print [1,3,6]
const r = F.scanl1((a, b) => a/b, [64,4,2,1]);
const r = await F.collect(s);
console.log(r);
//print [64,16,8,8]
buffer
creates a list by dividing the iterator at specified interval
const b = F.buffer(1, [1,2,3,4,5]);
const c = await F.collect(b);
console.log(c); //print [[1],[2],[3],[4],[5]]
const b = F.buffer(2, [1,2,3,4,5]);
const c = await F.collect(b);
console.log(c); //print [[1,2],[3,4],[5]]
parallel_set_fetch_count
Set the fetch count of the parallel functions.
after setting, the parallel function is called by count at the same time.
default fetch count is 100
F.parallel_set_fetch_count(3);

await F.run(
    F.range(Infinity),
    F.pmap(async e =>{
        console.log(e);
        return e + 1;
    }),
    F.take(1),
    F.collect);
//print
//0
//1
//2
F.parallel_set_fetch_count(200);

await F.run(
    F.range(Infinity),
    F.pmap(async e =>{
        console.log(e);
        return e + 1;
    }), // fetch and execute first [0..199]
    F.take(1), // take 0 and execute 200. in pmap:[3..102]
    F.collect);
//print
//0
//1
//2
//3
//4
//5
//...
//...
//198
//199
//200
pfilter
Same as filter, but calls a fetch count of functions concurrently.
useful for async function or return promise.
//F.parallel_set_fetch_count(100);  default is 100
const v = await F.run(
    F.range(Infinity),
    F.pfilter(async e =>{
        console.log(e);

        //somthing async work...

        return e % 2 === 0;
    }),// fetch and execute first [0..99]
    F.take(2),// take 2 and execute 100, 101, 102 in pmap:[3..102]
    F.collect);
console.log(v);
//print
//1
//2
//3
//...
//...
//99
//[0,2]
pmap
Same as map, but calls a fetch count of functions concurrently.
useful for async function or return promise.
//F.parallel_set_fetch_count(100); default is 100
const v = await F.run(
    F.range(Infinity),
    F.pmap(async e =>{
        console.log(e);

        //somthing async work...

        return e + 1;
    }), // fetch and execute first [0..99]
    F.take(2), // fetch 0, 1, excute 100, 101 in pmap:[2..101]
    F.collect);
console.log(v);
//print
//0
//1
//2
//...
//...
//99
//100
//101
//[1,2]
pfmap
Same as fmap, but calls a fetch count of functions concurrently.
useful for async function or return promise.
// F.parallel_set_fetch_count(100); default is 100
const v = await F.run(
    F.range(Infinity),  //0,1,2,...
    F.map(e=> [e]),     //[0],[1],[2]...
    F.pfmap(async e =>{
        console.log(e); //print [0] ...

        //somthing async work...

        e.push(42);     // [0,42],[1,42],[2,42]... 
        return e ;
    }),
    F.take(5),          //[0,42,1,42,2]
    F.collect);         //iterator to array
console.log(v);
//print
//[0]
//[1]
//[2]
//...
//...
//[99]
//[0,42,1,42,2]
pcalls

async function generator

const gfn2 = async function* () {
    yield _ => Promise.resolve(1);
    yield _ => 2;
    yield async _ => await Promise.resolve(3);
    yield async _ => await 4;
};
const c = F.pcalls(gfn2());
const r = await F.collect(c);
console.log(r);
//print [1,2,3,4]

call vaarg async functions

/*same as */Promise.all([fn1(),fn2(),fn3(),fn4()])
const fn1 = () => {
    return 1;
};
const fn2 = () => {
    return Promise.resolve(2);
};
const fn3 = async () => {
    return 3;
};
const fn4 = async () => {
    return Promise.resolve(4);
};
const c = F.pcalls(fn1, fn2, fn3, fn4);
const r = await F.collect(c);
console.log(r); //print [1,2,3,4]
range
for (const e of F.range(10)) {
    console.log(e);
}
//print 0 ~ 9

for (const e of F.range(10, 0, -1)) {
    console.log(e);
}
//print 10 ~ 1
seq
make iterable(array, set, map, iteratorObject) to asyncIterator
const a = [1,2,3,4,5];
for await(const e of F.seq(a)) {
    console.log(e);
}
//print 1,2,3,4,5
const a = new Map([[1,2],[3,4]]);
for await(const e of F.seq(a)) {
    console.log(e);
    //print 
    //[1,2]
    //[3,4]
}
rangeOf
deprecated
deprecated. use flat or dflat instead.
repeat
const r = F.repeat(3);
for await(const e of r) {
    console.log(e);
}
//print 
//3
//3
//3
//....
const v = await F.run(
    F.repeat(1), //[1,1,1....]
    F.map(e => e + 1), //[2,2,2....]
    F.take(5), //[2,2,2,2,2]
    F.collect); //generator => array
console.log(v);
//print [2,2,2,2,2]
const r = F.repeat(()=>{return 3;});
for await(const e of r) {
    console.log(e);
}
//print 
//3
//3
//3
//....
rangeInterval
first argument is set to the repeat interval
for await (const e of F.rangeInterval(100, 5)) {
    console.log(e);
}
//print
// [sleep 100]
// 0
// [sleep 100]
// 1
// [sleep 100]
// 2
// [sleep 100]
// 3
// [sleep 100]
// 4
// [sleep 100]
for await (const e of F.rangeInterval(100, 5, 0, -1)) {
    console.log(e);
}
//print
// [sleep 100]
// 5
// [sleep 100]
// 4
// [sleep 100]
// 3
// [sleep 100]
// 2
// [sleep 100]
// 1
// [sleep 100]
iterate
apply a function to an argument to produce a sequence
const r = await F.run(
            F.iterate(F.inc, 1),
            F.take(5),
            F.collect);
console.log(r);
//print 
//[1,2,3,4,5]
const fibo = (a) => [a[1], a[0] + a[1]];
const r = await F.run(
    F.iterate(fibo, [0, 1]),//[0, 1], [1, 1], [1, 2], [2, 3] ...
    F.map(F.head),//[0,1,1,2 ... 
    F.take(10),//[0,1,1,2,3,5,8,13,21,34]
    F.collect);//generator to array
console.log(r);
//print
//[0,1,1,2,3,5,8,13,21,34]
foldl
const a = [1,2,3,4,5];
const sum = await F.foldl((acc, e) => acc + e, 0, a); 
console.log(sum); // print 15
const a = [""w"",""o"",""r"",""l"",""d""];
const sum = await F.foldl((acc, e) => acc + e, ""hello"", a); 
console.log(sum); // print ""helloworld""
foldl1
take 1 items and call foldl
const a = [1,2,3,4,5];
const sum = await F.foldl1((acc, e) => acc + e, a); 
console.log(sum); // print 15;
reduce
same as foldl1
const a = [1,2,3,4,5];
const sum = await F.reduce((acc, e) => acc + e, a); 
console.log(sum); // print 15;
foldr
const arr = [1,2,3,4,5];
const r = await F.foldr((a, b) => a + b, 0, arr);
console.log(r); // print 15
const arr = [64,2,1];
const r = await F.foldr((a, b) => a / b, 1, arr);
console.log(r); // print 32
const arr = [""1"",""2"",""3"",""4""];
const r = await F.foldr((a, b) => a + b, ""5"", arr);
console.log(r); // print 12345
foldr1
const arr = [1,2,3,4,5];
const r = await F.foldr1((a, b) => a + b, 0, arr);
console.log(r); // print 15
const arr = [64,2,1];
const r = await F.foldr1((a, b) => a / b, arr);
console.log(r); // print 32
const arr = [""1"",""2"",""3"",""4"",""5""];
const r = await F.foldr1((a, b) => a + b, arr);
console.log(r); // print 12345
collect
iterator or asyncIterator to Array
const mapped = F.map(e => e + 1, a); 
console.log(mapped); // print asyncGenerator
const collected = await F.collect(mapped);
console.log(collected); //print [2,3,4,5,6]
const v = await F.run(
    F.range(Infinity),//[0,1,2....]
    F.filter(e => (e % 3) === 0), //[0,3,6...] 
    F.map(e => e + 1), //[1,4,7...]
    F.take(5), // generator([1,4,7,10,13])
    F.collect);  // generator => array
console.log(v); //[1,4,7,10,13]
collectMap
const a = [[1,2],[3,4]];
const m = await F.collectMap(a); // new Map([[1,2],[3,4]])
for(const [k,v] of m) {
    console.log(k, v);
}
//print 
//1 2
//3 4
collectSet
const a = [1,2,3,1,2,3];
const m = await F.collectSet(a); //new Set([1,2,3])
for(const e of m) {
    console.log(e);
}
//print 
//1
//2
//3
const a = ""hello world"";
const m = await F.collectSet(a); //new Set(""helo wrd"")
for(const e of m) {
    console.log(e);
}
//print 
//helo wrd
maxBy
const a = [10,9,8,7];
const r = await F.maxBy(e => e, a);
console.log(r); // print 10;
const a = [1,10,9,8,7,11];
const r = await F.maxBy(e => Math.floor(e/10), a) //compare [0,1,0,0,0,1]
console.log(r); // print 10
minBy
const a = [0,10,9,8,7];
const r = await F.minBy(e => e, a);
console.log(r); // print 0
const a = [7,10,9,8,1,11];
const r = await F.minBy(e => Math.floor(e/10), a) //compare [0,1,0,0,0,1]
console.log(r); // 7
max
const a = [Promise.resolve(10),9,8,7];
const r = await F.max(a);
console.log(r);
//print 10
min
const a = [10,9,8,Promise.resolve(7)];
const r = await F.min(a);
console.log(r);
//print 7
some
const a = [1,2,3,4,5];
const r = await F.some(e=> e % 2 == 0, a); //found '2' return
console.log(r); // true
const r = await F.run(
    F.range(Infinity), //[0...Infinity]
    F.some(e=> Promise.resolve(e > 100)) // found '101' return
);
console.log(r); // true
every
const a = [1,2,3,4,5];
const r = await F.every(e=> e  >= 0, a); // all elem >= 0 return true
console.log(r); // true
const a = [1,2,3,4,5];
const r = await F.every(e=> Promise.resolve(e < 3), a); 
//1 ok, 2 ok, 3 no return false
console.log(r); // false
count
const a = [1,2,3,4,5];
const n = await F.count(a);
console.log(n); // print 5
sum
const a = [1,2,3,4,5];
const n = await F.sum(a);
console.log(n); // print 15
const a = ""abcde"";
const n = await F.sum(a);
console.log(n); // print abcde
average
const a = [1,2,3,4,5];
const s = await F.average(a);
console.log(s); // print 3
const a = [1.0,2.0,3.0,4.0,5.5];
const s = await F.average(a)
console.log(s); //print 3.1
groupBy
returns a Map that is aggregated through a function.
key is the return value of the function, and value is the source.
const a = [
    {type: ""tea"",
        price: 1},
    {type: ""tea"",
        price: 2},
    {type: ""phone"",
        price: 3},
    {type: ""phone"",
        price: 4},
];
//returns new Map(... )
const r = await F.groupBy(e => e.type, a);
console.log(r.get(""tea""));
//print [ { type: 'tea', price: 1 }, { type: 'tea', price: 2 } ]
console.log(r.get(""phone""));
//print [ { type: 'phone', price: 3 }, { type: 'phone', price: 4 } ]
orderBy
same as sortBy
sortBy
const a = [{ year: 1990 }, { year: 2005 }, { year: 1958 }];

const ASC = 'ASC'; // or 'asc'
const DESC = 'desc'; // or 'DESC'

const sortedByASC0 = F.sortBy(e => e.year, F.asc, a);
const sortedByASC1 = F.sortBy(e => e.year, ASC, a);
const sortedByDESC0 = F.sortBy(e => e.year, F.desc, a);
const sortedByDESC1 = F.sortBy(e => e.year, DESC, a);

await F.collect(sortedByASC0);
// [{ year: 1958 }, { year: 1990 }, { year: 2005 }]
await F.collect(sortedByDESC1);
// [{ year: 2005 }, { year: 1990 }, { year: 1958 }]
const a = [3, 6, 2, 3, 7, 10, 23, 21, 22, 16, 13, 14, 17, 20];

const sortedByASC = F.sortBy(e => e, F.asc, a);
const sortedByDESC = F.sortBy(e => e, F.desc, a);

await F.collect(sortedByASC);
// [2, 3, 3, 6, 7, 10, 13, 14, 16, 17, 20, 21, 22, 23]
await F.collect(sortedbyDESC);
// [23, 22, 21, 20, 17, 16, 14, 13, 10, 7, 6, 3, 3, 2]
const a = 'Haskell Brooks Curry';

const sortedByASC = F.sortBy(e => e, F.asc, a);
const sortedByDESC = F.sortBy(e => e, F.desc, a);

await F.collect(sortedByASC).then(e => [e.join('')]);
// ['  BCHaekklloorrrssuy']
await F.collect(sortedByDESC).then(e => [e.join('')]);
// ['yussrrroollkkeaHCB  ']
order
same as sort
sort
const a = [3, 6, 2, 3, 7, 10, 23, 21, 22, 16, 13, 14, 17, 20];

const sortedByASC = F.sort(F.asc, a);
const sortedByDESC = F.sort(F.desc, a);

await F.collect(sortedByASC);
// [2, 3, 3, 6, 7, 10, 13, 14, 16, 17, 20, 21, 22, 23]
await F.collect(sortedbyDESC);
// [23, 22, 21, 20, 17, 16, 14, 13, 10, 7, 6, 3, 3, 2]
const a = 'Haskell Brooks Curry';

const sortedByASC = F.sort(F.asc, a);
const sortedByDESC = F.sort(F.desc, a);

await F.collect(sortedByASC).then(e => [e.join('')]);
// ['  BCHaekklloorrrssuy']
await F.collect(sortedByDESC).then(e => [e.join('')]);
// ['yussrrroollkkeaHCB  ']
sleep
like other language
const beginDate = Date.now();
await F.sleep(1000);
const endDate = Date.now();
console.log(endDate - beginDate); // print 1009
head
get first element
warning: if use head for generator, result is not the same
const a = [1,2,3,4,5];
console.log(await F.head(a)); //print 1
console.log(await F.head(a)); //print 1
const a = F.seq([10,9,8,7]); // make generator
console.log(await F.head(a)); //print 9
console.log(await F.head(a)); //print 8
console.log(await F.head(a)); //print 7
const a = [];
try{
    await F.head(a);
}catch(e) {
    console.log(e);
} 
//print empty iter 
tail
get from the second
warning: if use tail for generator, result is not the same
const a = [1,2,3,4,5];
const t = F.tail(a);
console.log(await F.collect(t)); // print 2 3 4 5
const a = F.seq([10,9,8,7]); //make generator
for await (const e of F.tail(a)){
    console.log(e);
}
for await (const e of a) {
    //a is empty...
    console.log(""a is empty"");
}
//print 
//9
//8
//7
interval
works like built-in function setInterval

timer works same time start of the function
available async function.
only one function is executed at a time.

F.interval(1000, async () => {
    await F.run(
        F.range(5),
        F.then(async _ =>{
            await F.sleep(100);
            console.log(""WORK!"");
        }));
});
///print 
//WORK!
// 1 sec 
//WORK!
// 1 sec
//... 
F.interval(10, async () => {
    await F.run(
        F.range(5),
        F.then(async _ =>{
            await F.sleep(1000);
            console.log(""WORK!"");
        }));
});
///print 
//WORK!
// 1 sec 
//WORK!
// 1 sec
//... 
timeout
@changed iterator timeout use withTimeout instead.
const foo = async () => {
    await F.sleep(1);/*something work*/
    return 1;
};
const v = await F.timeout(40, foo());
console.log(v);
//print 1;
try{
    await F.timeout(40, async ()=>{
        await F.sleep(1000);
    });
} catch(e) {
   console.log(e); 
}
//print
//timeout error
//callstack...
withTimeout
it is effective to use timeout at the bottom of the run
const res = [];
try{
    const iter = await F.run(
        F.range(Infinity),
        F.map(e => e + 1),
        F.map(async e => {
            await F.sleep(5);
            return e;
        }),
        F.take(10)
        F.withTimeout(40));
    
    for await (const e of iter) {
        res.push(e);
    }
} catch(ex) {
    console.log(ex);
}
console.log(res);
//print 
//timeout error
//callstack...
//[1,2,3,4,5,6]
try{
    const a = [1,2,3,4,5];
    const t = F.withTimeout(50, 
        F.map(async e => {
            await F.sleep(5);
            return e;
        }, a));
    const v = await F.collect(t);
    console.log(v);
}catch(ex) {
    console.log(ex);
}
//print 
//timeout error
//callstack....
notNil
deprecated
use isNil instead.
return false null, undefined, NaN true otherwise
console.log(F.notNil(NaN)); // false
console.log(F.notNil(undefined)); //false
console.log(F.notNil(null)); //false
console.log(F.notNil(""null"")); // true
console.log(F.notNil(""NaN"")); //true
console.log(F.notNil(0)); // true
console.log(F.notNil(false)); // true
isNil
return false null, undefined, NaN true otherwise
console.log(F.isNil(NaN)); // true
console.log(F.isNil(undefined)); //true
console.log(F.isNil(null)); //true
console.log(F.isNil(""null"")); // false 
console.log(F.isNil(""NaN"")); //false
console.log(F.isNil(0)); // false
console.log(F.isNil(false)); // false
console.log(F.isNil([])); // false
console.log(F.isNil({})); // false
cond
Requires an even number of arguments
if the first argument is true, it returns the second argument
const r = await F.cond( 
    false, ""ff"",
    true, ""tt"",
    F.otherwise, ""oo""
);
console.log(r); // ""tt""
const r = await F.cond( 
    Promise.resolve(false), ""ff"",
    Promise.resolve(true), ""tt"",
    F.otherwise, ""oo""
);
console.log(r); // ""tt""
otherwise
if (F.otherwise) {
    console.log(""WORK!"");
}
if (F.otherwise()) {
    console.log(""WORK!"");
}
//print 
//WORK!
//WORK!
License

",3
clodonil/Python-Fundamentals,Python,"Python Fundamentals (Python 3)
Objetivo
Capacitar estudantes com nenhum ou prÃ©vio conhecimento na linguagem Python a desenvolver aplicaÃ§Ãµes ricas com acesso a banco de dados e interface WEB
Carga HorÃ¡ria
O curso tem carga horÃ¡ria de 40 horas
Metodologia
ConteÃºdo

MÃ³dulo 1
MÃ³dulo 2
MÃ³dulo 3
MÃ³dulo 4
MÃ³dulo 5

Temos um grupo no whatsapp para tirar as suas dÃºvidas:

click aqui para entrar no grupo

By:

Autor   = ['Clodonil Honorio Trigo','clodonil@nisled.org']
linkdin = 'https://www.linkedin.com/in/clodonil-trigo-4155722a'
Blog    = 'http://www.devops-sys.com.br'
",4
sqlmapproject/sqlmap,Python,"sqlmap
     
sqlmap is an open source penetration testing tool that automates the process of detecting and exploiting SQL injection flaws and taking over of database servers. It comes with a powerful detection engine, many niche features for the ultimate penetration tester and a broad range of switches lasting from database fingerprinting, over data fetching from the database, to accessing the underlying file system and executing commands on the operating system via out-of-band connections.
The sqlmap project is sponsored by Netsparker Web Application Security Scanner.
Screenshots

You can visit the collection of screenshots demonstrating some of features on the wiki.
Installation
You can download the latest tarball by clicking here or latest zipball by clicking  here.
Preferably, you can download sqlmap by cloning the Git repository:
git clone --depth 1 https://github.com/sqlmapproject/sqlmap.git sqlmap-dev

sqlmap works out of the box with Python version 2.6, 2.7 and 3.x on any platform.
Usage
To get a list of basic options and switches use:
python sqlmap.py -h

To get a list of all options and switches use:
python sqlmap.py -hh

You can find a sample run here.
To get an overview of sqlmap capabilities, list of supported features and description of all options and switches, along with examples, you are advised to consult the user's manual.
Links

Homepage: http://sqlmap.org
Download: .tar.gz or .zip
Commits RSS feed: https://github.com/sqlmapproject/sqlmap/commits/master.atom
Issue tracker: https://github.com/sqlmapproject/sqlmap/issues
User's manual: https://github.com/sqlmapproject/sqlmap/wiki
Frequently Asked Questions (FAQ): https://github.com/sqlmapproject/sqlmap/wiki/FAQ
Twitter: @sqlmap
Demos: http://www.youtube.com/user/inquisb/videos
Screenshots: https://github.com/sqlmapproject/sqlmap/wiki/Screenshots

Translations

Bulgarian
Chinese
Croatian
French
Greek
Indonesian
Italian
Japanese
Polish
Portuguese
Russian
Spanish
Turkish
Ukrainian

",14120
algolia/algolia.github.io,CSS,"Algolia Community website
This is the source code of https://community.algolia.com/. The deployment to this live website is automated
when changes are pushed to the source branch.
Local setup
Requirements
To run this project, you will need:

Node.js >= 9.80, via nvm - install instructions
Yarn >= 1.5.1 - install instructions (""Alternatives"" tab): curl -o- -L https://yarnpkg.com/install.sh

Pro tip: Remove any brew installed/globall system installed Node.js and Yarn, just use nvm and Alternatives installation, they works perfectly.
Then:
nvm install
nvm use
Dev
To develop on this project, do:
yarn
yarn dev
Deploy
The deploy steps are directly handled by Gulp.js in the gulpfile.
yarn build
yarn deploy
Updating the underlying index
The current appId storing the data is latency (accessible for writes by Algolia employees).
If you want to update the data, first test it on a new index: modify algolia-projects.json and run:
appId= adminApiKey= yarn update-index
Once you are sure this is the right config, then run the same command using latency credentials.
You may encounter issues while running yarn deploy, you can fix it by following this GH thread
",10
dktr0/estuary,Haskell,"Estuary is a platform for collaboration and learning through live coding. It enables you to create sound, music, and visuals in a web browser. Key features include:

built-in tutorials and reference materials
a growing collection of different interfaces and live coding languages
support for networked ensembles (whether in the same room or distributed around the world)
text localization to an expanding set of natural languages
visual customization via themes (described by CSS)

The development of Estuary is the result of ongoing collaborative work that has been supported by two grants from Canada's Social Sciences and Humanities Research Council (SSHRC) - initially for the project ""Projectional interfaces for musical live coding"", and more recently as part of the project ""Platforms and practices for networked, language-neutral live coding"". Estuary builds upon, and depends on, the work of many others, including but not limited to all those who contribute to Reflex , TidalCycles, and other languages and projects. Estuary is free and open source software, released under the terms of the GNU Public License (version 3).
You don't need to install or build anything to start using Estuary - you can just point your web browser to an existing deployment of it, and start making things! Please note that Chrome or Chromium are strongly recommended as the preferred browsers for use with Estuary. At the time of writing, a stable, recent version of Estuary is online 24/7 at a test server belonging to the research group at McMaster University that is working
on Estuary - you can try it out anytime at the following URL (and if you have
questions take them either to the #estuary channel on talk.lurk.org
or the ""estuary"" Google group): http://intramuros.mcmaster.ca:8002
If you do want to build Estuary from source yourself, please refer to the instructions in BUILDING.md. Note that building Estuary depends on a rather complex tool-chain and can be time-consuming. Don't hesitate to reach out on the lurk or Google group channels mentioned above for assistance.
",29
enChenging/android_posthouse,None,"ðandroidé©¿ç«ð

ä¸ºæ¹ä¾¿ä½¿ç¨androidå¼æºåºï¼æä»¥æ¬äººèè´¹å¤§éæ¶é´è¿è¡æ´çãå¦ææ¶å½çé¡¹ç®æéè¯¯æèä½ ç¥éææ¯è¾å¥½çå¼æºé¡¹ç®ï¼å¯ä»¥éè¿Issuesåé¦ç»æï¼æå°å°½å¿«çæ´æ°å°androidé©¿ç«ä¸­ï¼å¸æandroidé©¿ç«å¯ä»¥æä¸ºandroidå¼åèå¨å¼åè¿ç¨ä¸­çå®ç¨å·¥å·ãé¡¹ç®Staræ°ä¸è¬1ä¸ªæä¼æ´æ°ä¸æ¬¡ï¼æ­¤å¼æºåºæ´çä¼ä¸æ­æ´æ°ï¼ä½ çç¹èµðå°æ¯æä¸æ­æ´æ°çæå¤§å¨åã

âï¸âï¸âï¸âï¸âï¸âï¸âï¸âï¸âï¸âï¸âï¸âï¸âï¸âï¸âï¸âï¸âï¸âï¸âï¸âï¸âï¸âï¸âï¸âï¸âï¸âï¸âï¸âï¸âï¸âï¸âï¸

ç®å½

1----------------------------------------------RecycleView(åç§ç±»ååè¡¨) ð (43)
2----------------------------------------------Refresh(ä¸æå·æ°) ð (12)
3----------------------------------------------TabLayout ð (8)
4----------------------------------------------ProgressBar(è¿åº¦æ¡) ð (53)
5----------------------------------------------ViewPager ð (18)
6----------------------------------------------Button(æé®) ð (31)
7----------------------------------------------Menu(èåãæµ®å¨èå) ð (27)
8----------------------------------------------Dialog(å¯¹è¯æ¡)ð (12)
9----------------------------------------------ImageView(å¾ç)ð (57)
10---------------------------------------------Splash(å¯å¨é¡µãå¼å¯¼é¡µ)ð (16)
11---------------------------------------------TextViewð (23)
12---------------------------------------------EditTextð (5)
13---------------------------------------------Banner(è½®æ­å¾)ð (10)
14---------------------------------------------BottomNavigation(åºé¨å¯¼èª)ð (12)
15---------------------------------------------Toolbarð (9)
16---------------------------------------------Chart(å¾è¡¨)ð (10)
17---------------------------------------------WebViewð (5)
18---------------------------------------------Layout(å¸å±)ð (17)
19---------------------------------------------Picker(éæ©å¨)ð (15)
20---------------------------------------------Calendar(æ¥åæ¶é´)ð (12)
21---------------------------------------------Cardð (11)
22---------------------------------------------Blur(æ¨¡ç³ææ)ð (12)
23---------------------------------------------ThemeãStatusBar(ä¸»é¢æ ·å¼ãç¶ææ )ð (13)
24---------------------------------------------Notify(éç¥)ð (5)
25---------------------------------------------Badge(å¾½ç« )ð (7)
26---------------------------------------------Login(è¡¨å)ð (15)
27---------------------------------------------Timeline(æ¶é´è½´)ð (4)
28---------------------------------------------Spinnerð (3)
29---------------------------------------------SearchView(æç´¢è§å¾)ð (14)
30---------------------------------------------TagView(æ ç­¾)ð (9)
31---------------------------------------------MaterialDesign(MDé£æ ¼)ð (11)
32---------------------------------------------Toastð (7)
33---------------------------------------------SeekBarð (3)
34---------------------------------------------ScrollViewð (6)
35---------------------------------------------SwipeBack(æ»å¨è¿å)ð (8)
36---------------------------------------------RatingBar(è¯åæ§ä»¶)ð (7)

",2
ppengtang/pcl.pytorch,Python,"PCL: Proposal Cluster Learning for Weakly Supervised Object Detection
By Peng Tang, Xinggang Wang, Song Bai, Wei Shen, Xiang Bai, Wenyu Liu, and Alan Yuille.
This is a PyTorch implementation of our PCL. The original Caffe implementation of PCL is available here.
We embed the trick proposed in our ECCV paper for better performance.
The final performance of this implementation is mAP 49.2% and CorLoc 65.0% on PASCAL VOC 2007 using a single VGG16 model. The results are comparable with the recent state of the arts.
Introduction
Proposal Cluster Learning (PCL) is a framework for weakly supervised object detection with deep ConvNets.

It achieves state-of-the-art performance on weakly supervised object detection (Pascal VOC 2007 and 2012, ImageNet DET, COCO).
Our code is written based on PyTorch, Detectron.pytorch, and faster-rcnn.pytorch.

The original paper has been accepted by CVPR 2017. This is an extened version.
For more details, please refer to here and here.
Comparison with other methods
(a) Conventional MIL method;
(b) Our original OICR method with newly proposed proposal cluster generation method;
(c) Our PCL method.


Architecture



Visualizations
Some PCL visualization results.



Some visualization comparisons among WSDDN, WSDDN+context, and PCL.



License
PCL is released under the MIT License (refer to the LICENSE file for details).
Citing PCL
If you find PCL useful in your research, please consider citing:
@article{tang2018pcl,
    author = {Tang, Peng and Wang, Xinggang and Bai, Song and Shen, Wei and Bai, Xiang and Liu, Wenyu and Yuille, Alan},
    title = {{PCL}: Proposal Cluster Learning for Weakly Supervised Object Detection},
    journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
    volume = {},
    number = {},
    pages = {1--1},
    year = {2018}
}

@inproceedings{tang2017multiple,
    author = {Tang, Peng and Wang, Xinggang and Bai, Xiang and Liu, Wenyu},
    title = {Multiple Instance Detection Network with Online Instance Classifier Refinement},
    booktitle = {IEEE Conference on Computer Vision and Pattern Recognition},
    pages = {3059--3067},
    year = {2017}
}

Contents

Requirements: software
Requirements: hardware
Basic installation
Installation for training and testing
Extra Downloads (Models trained on PASCAL VOC)
Usage
TODO

Requirements: software
Tested under python3.

python packages

pytorch==0.4.1
torchvision>=0.2.0
cython
matplotlib
numpy
scipy
opencv
pyyaml==3.12
packaging
pycocotools  â also available from pip.
tensorboardX  â for logging the losses in Tensorboard
sklearn


An NVIDAI GPU and CUDA 8.0 or higher. Some operations only have gpu implementation.
NOTICE: different versions of Pytorch package have different memory usages.

Requirements: hardware

NVIDIA GTX 1080Ti (~11G of memory)

Installation

Clone the PCL repository

git clone https://github.com/ppengtang/pcl.pytorch.git & cd pcl.pytorch

Compile the CUDA code:

cd $PCL_ROOT/lib
sh make.sh
Installation for training and testing

Download the training, validation, test data and VOCdevkit

wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar
wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar
wget http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCdevkit_18-May-2011.tar

Extract all of these tars into one directory named VOCdevkit

tar xvf VOCtrainval_06-Nov-2007.tar
tar xvf VOCtest_06-Nov-2007.tar
tar xvf VOCdevkit_18-May-2011.tar


Download the COCO format pascal annotations from here and put them into the VOC2007/annotations directory


It should have this basic structure


$VOC2007/                           
$VOC2007/annotations
$VOC2007/JPEGImages
$VOC2007/VOCdevkit        
# ... and several other directories ...

Create symlinks for the PASCAL VOC dataset

cd $PCL_ROOT/data
ln -s $VOC2007 VOC2007
Using symlinks is a good idea because you will likely want to share the same PASCAL dataset installation between multiple projects.


[Optional] follow similar steps to get PASCAL VOC 2012.


You should put the generated proposal data under the folder $PCL_ROOT/data/selective_search_data, with the name ""voc_2007_trainval.pkl"", ""voc_2007_test.pkl"". You can downlad the Selective Search proposals here.


The pre-trained models are available at: Dropbox, VT Server. You should put it under the folder $PCL_ROOT/data/pretrained_model.


Download models trained on PASCAL VOC
Models trained on PASCAL VOC can be downloaded here.
Usage
Train a PCL network. For example, train a VGG16 network on VOC 2007 trainval
CUDA_VISIBLE_DEVICES=0 python tools/train_net_step.py --dataset voc2007 \
  --cfg configs/baselines/vgg16_voc2007.yaml --bs 1 --nw 4 --iter_size 4
Note: The current implementation has a bug on multi-gpu training and thus does not support multi-gpu training.
Test a PCL network. For example, test the VGG 16 network on VOC 2007:
On trainval
python tools/test_net.py --cfg configs/baselines/vgg16_voc2007.yaml \
  --load_ckpt Outputs/vgg16_voc2007/$MODEL_PATH \
  --dataset voc2007trainval
On test
python tools/test_net.py --cfg configs/baselines/vgg16_voc2007.yaml \
  --load_ckpt Outputs/vgg16_voc2007/$model_path \
  --dataset voc2007test
Test output is written underneath $PCL_ROOT/Outputs.
Note: Add --multi-gpu-testing if multiple gpus are available.
Evaluation
For mAP, run the python code tools/reval.py
./tools/reeval.py $output_dir/detections.pkl \
  --dataset voc2007test --cfg configs/baselines/vgg16_voc2007.yaml
For CorLoc, run the python code tools/reval_discovery.py
./tools/reeval.py $output_dir/discovery.pkl \
  --dataset voc2007trainval --cfg configs/baselines/vgg16_voc2007.yaml
What we are going to do

 Add PASCAL VOC 2012 configurations.
 Upload trained models.
 Support multi-gpu training.

",13
Jackarunda/gmod,Lua,"The Garry's Mod Additions Pack!
Huzzah!
The Plan
We're taking all of Jackarunda's past addons and resurrecting them into a single big community project to re-upload to the workshop.
Once most of the content is copied, converted and working, Jackarunda will split the content of this repo up and upload mutliple Workshop items so that everyone can enjoy this content once again and use it on their servers bug-free. Maintenance and additions will continue from there and Jackarunda will handle the workshop aspect of things. If you help as a playtester, you will be mentioned in the credits for the packs if you wish. If you help as a coder or file-folder organizer/converter in any way, you will be added as a co-publisher to the workshop items if you wish. This is a community project.
Contributing
We don't really need hardcore functional programming to make this work. If we do, jackarunda will do it. What we really need right now is:

move all of these files from X folder to Y folder


combine the content of these files into one file and put it in Z folder


take the content of this file and put it in a section of another file and delete this file


see what resources are needed from these files and copy the resources into the new folder


rename this file and then rename all usages of it in all the other files


rename this sound file and then replace any usages of it in these files


look through this folder for any large texture files, and if you find them, downsize them in GIMP or something and replace


look throgh this folder for large sound files and if you find them, then convert them to MP3 in Audacity or something and replace

If you think you can help, let Jackarunda know in the gmod Discord.
Setup
You must have a github account, first. You can make one for free.
Ask Jackarunda in the Discord to be added as a collaborator (tell him your github name), and he will find your github account and add you. Then you go back to github into your profile and accept the collaboration invite. Being a collaborator is important because it will allow you to push/pull without needing to fork (which is more complicated). Note that being a collaborator is a trusted position, because you will have the ability to mess up the repo (though if you do, Jackarunda will revoke your permissions and revert the changes).
If you're just edting the wiki file or the bugs file, you can just click the little edit buttons here on the github website to edit the files in-browser. Simple.
If, however, you're going to be moving/organizing content, then you need to have Git and know how to use it.
If you don't know anything about Git, then skip down and read the Git Noob section before continuing.
Clone this repo into your local gmod/addons directory. It will work just fine in gmod right from there, because this repo is orgnized exactly like a Gmod Legacy Addon. You can make changes directly right there, test them in gmod automatically (lua auto-reload ftw), and then push them up into git. Simple.
All the old addons can be found for download here:
FunGuns: https://www.dropbox.com/s/kxxbex74acct06r/FunGuns.7z?dl=0
Homicide: https://www.dropbox.com/s/qoegratt6amsxdl/Homicide.7z?dl=0
Defense Solutions: https://www.dropbox.com/s/ac8xg6tibl1gxfr/JIDS.7z?dl=0
OpSquads: https://www.dropbox.com/s/2k54kb7lq8ikw5o/OpSquads.7z?dl=0
Explosives: https://www.dropbox.com/s/8inhop8y3panltc/JIEX.7z?dl=0
SENTs: https://www.dropbox.com/s/7yc1gz3yw8oe88r/SENTs.7z?dl=0
BFS 2114: https://www.dropbox.com/s/qrpwohdcwypmbvr/JIBFS2114.7z?dl=0
Old BFS 2114 Wiki: http://jibfs.wikia.com/wiki/JIBFS_Wiki
Git Noob?
Git is a source control system, which is a system that allows multiple people to work together on a software project and not step on eachother's toes. Mostly. Github.com is a website, one of many, that hosts Git Repositories, which are like living containers for projects (contain all the files and assets and records etc).
Note that Git is a tech industry standard across the whole entire world and there are hundreds of thousands of millions of billions of blogs, tutorials, guides, documents, questions, answers, etc. etc. etc all over the internet that can help you with Git.
To work on git projects and do more than just edit text files in-browser, you need to have Git and Git Bash installed on your machine.
https://git-scm.com/downloads download and install all this from here
Note that Github recently made a GUI program for doing git operations, but IMO it's kinda pointless since the moment anything goes wrong you have to use the git bash command-line anyways, so might as well not bother. But you can use it if you wish.
Once git and git bash are installed on your machine, start a git bash window (probably from the start menu). Then you need to move the window's operating location into your gmod addons folder, so enter a command that looks something like this:
cd ""C:/Users/DickBagMcGee/Program Files (x86)/Steam/steamapps/common/garrysmod/garrysmod/addons""
But obviously the path is unique for you. Note that when git installs they usually add shell extensions so you can right click or shift+right click and open a new git bash window anywhere in your Explorer, which is easier than CDing every time. Now clone this repo into a new folder into your addons folder by using the command:
git clone https://github.com/Jackarunda/gmod.git gmod-additions-pack
This will create the addon in your gmod. It'll take a while to download. Once this is done, you can literally play in gmod with the addon from right there. You can then make any changes you wish in that local folder, renaming things, adding things, editing files, etc. You only need to clone the repo once, ever, unless yours gets really badly messed up and you need to delete and re-clone. But that should never happen.
Before you make any changes, always make sure to do the command: git pull origin master, because this will pull down the latest version of the repo into your local folder. You always want to be up-to-date.
When you've made changes you want to commit, do the following, in order:


make a new branch with
git checkout -b my_new_unique_branch_name
usually you make a branch name that contains your name and something relating to the work you did


stage all the changes you've made with
git add .


commit the changes to your new local branch you just made, with a comment, by entering
git commit -m ""fixing some bugs and adding more hookers""


push your branch up to the repo with
git push origin my_new_unique_branch_name


go to your browser, to the github repo page, and click the pull request button for the branch you just made


tell jackarunda about it in discord. We'll look at it, maybe fix a few things, and merge it into the master branch. All done.


then you should go back locally and git checkout master and then git pull origin master to get the latest content right from master. Then you can make more changes and start from step 1.


For more complicated operations regarding git, you can consult the wealth of information on the internet and/or ask jackarunda.
ToDo:
Include content from all the previous addons.
OpSquads has been included already. Next on the list is JI Defense Solutions.


download JIDS source from dropbox


copy whatever entities/weapons you like from JIDS into this repo, along with all dependent other entities and effects


convert all entities/weapons to single-file format if not already


take the sounds from JIDS and copy them into this repo's sound folder (sound/snds_jack_gmod), then replace all instances of their use in the entity/weapon files


copy all needed materials and textures from JIDS into respective folders in this repo, keeping the organization scheme the same and renaming if necessary (and replacing usage calls in code if necessary)


do the same for models and particle effects


test in gmod


Jackarunda will handle most of the fixing/optimizing of the code.
Custom Additions
If you're a glua coder and want to add new features or items to the pack, let Jackarunda know and make a PR. Custom contributions to the pack are welcome if they are of a quality and style similar to or surpassing that of existing content.
Bugs
If you find a bug, put it in the bugs.txt file here or tell Jackarunda about it in the gmod channel.
",3
regro/libcfgraph,None,"libcfgraph
Cron Status: 
Graph Data for Conda Forge Library
This repository houses metadata for all of conda-forge's artifacts and is updated hourly.
It is intendeded to be used in conjunction with libcflib which can convert the mountains
of json into something a little nicer to work with
",5
lightyen/react-app-typescript,TypeScript,"react app typescript Â· 
éæ¯ä¸åæå­¸ç¿ typescript & react ç¨çéç¼ç°å¢ç¯æ¬ï¼ä½¿ç¨èªè¨ç¾©ç webpack è¨­å®ï¼çµå redux, react-router, Sass ç­ç¸éæè¡éï¼éç®±å³ç¨ä¸è·¨å¹³å°ãï¼ä¸å®ææ´æ°ï¼
å®è£ä»¥ä¸éç¼ç°å¢








å®è£å®å¾æª¢æ¥ç°å¢æ¯å¦æ­£ç¢ºéä½
code -v
node -v
yarn -v
å®è£ç¸é Visual Studio Code æ´ååä»¶

Debug for Firefox
Debug for Chrome
TSLint
Awesome Typescript Problem Matcher
Prettier
Format Files
EditorConfig for VS Code

å¶ä»æå¸¸ç¨ç

GitLens
Material Icon Theme
Markdown All in One
TODO Highlight
Fira Code (å­å)

Build å»ºç½®
# clone this repo
git clone https://github.com/lightyen/react-app-typescript.git

# é²å¥å°æ¡è³æå¤¾
cd react-app-typescript

# æª¢æ¥æä¸è¼ dependencies
yarn

# éå§ï¼
yarn dev

# or å»ºç½® production
yarn build
Debug
å¨ vscode ä¸­æä¸ F5 å¾ launch browser é²è¡èª¿è©¦ï¼æèç´æ¥å¨çè¦½å¨ä½¿ç¨éç¼èå·¥å·(F12)

Firefox éè¦å» about:debugging å¾é¸ Enable debugging of add-ons æå¯ä»¥ä½¿ç¨

è©³ç´°è³è¨æè¿°å¨ï¼.vscode/launch.json
æ¶äººå


ç¨å¼ç¢¼é¢¨æ ¼
ç´å®ç¨å¼ç¢¼é¢¨æ ¼ï¼

string ä»¥éå¼è "" è¡¨ç¤º
statement é¤éç¹ä¾ï¼å¦åçµå°¾ä¸ä½¿ç¨åè ;
ç¸®æ 4 åç©ºæ ¼

editorconfig, prettier ç¨å¼ç¢¼é¢¨æ ¼
æ F1 > Start Format Files: Workspace å¯ä»¥æ ¼å¼åææçç¨å¼ç¢¼é¢¨æ ¼

ä¸åæ­¡æé¢¨æ ¼çæåå¯ä»¥èªè¡ä¿®æ¹ .editorconfig, .prettierrc, tslint.json

å¶ä»ç¥è­åè


https://reactjs.org/


https://www.typescriptlang.org/


React Beginners Tutorial


Getting Started With TypeScript


React With TypeScript


React Hook


Awesome


broswerlist

https://browserl.ist/

",4
notadd/notadd,TypeScript,"
Overview
ä¸­æææ¡£
Notadd is an open source, Nest.js framework-based microservice development architecture that allows you to build a microservices system using the right modules and addons for different business needs. Notadd officially provides an abstract public service layer. Within the service layer, each module provides the Grpc interface for the Notadd main program to call. For example, a CMS system, you can use the officially provided nt-module-cms and nt-module-user modules as the underlying service layer. Then use the Notadd main program to write your API layer code according to the protobuf message protocol defined by the service layer.
Features

[Microservice] Supports stand-alone deployment and microservice
[High Performance] Asynchronous high-performance applications, tens of thousands of concurrent
[Easy to maintain] Developed with Typescript, intelligent code hints and compile-time code checking mechanisms
[Pluggable] modular development system, according to business needs, select the appropriate module, build the API layer

Technology stack

Typescript
Nest.js
GraphQL
TypeORM
Grpc
Redis

System Architecture

Modular design
Enterprise Official Website: CMS module + neditor plug-in, message board plugin
Information release: CMS module, user module + CMS multi-user plugin, Neditor plugin
WeChat Mall: User module, Mall module, WeChat module + WeChat big turntable, payment plug-in, offline verification plug-in
Dining plan: User module, Mall module, WeChat module + ordering plugin, scan code payment plug-in, passenger flow monitoring plug-in ... + infrared sensor development, WiFi probe expansion
Hotel Program: User module, Hotel module, WeChat module + booking plugin, payment plug-in, smart WiFi plugin + WiFi probe expansion, door card system expansion
CRM system: User module, CRM module ...
More to imagine ...
Quick Start

Clone Rpc sample service to the local nt-rpc-demo
Clone the user service to the local nt-module-user
Start the microservice according to the instructions of nt-rpc-demo and nt-module-user
Clone this project to your local
Installation depends on yarn install
Start yarn start
Open a browser and go to localhost:5000/graphql
Test GraphQL API


Note: The Notadd main program provides demo code at this stage, and does not rule out the removal of all graphql api code later.

Module list

nt-module-user user module
nt-module-cms  CMS module

Addon list

nt-addon-pay payment addon
nt-addon-wechatapi wechatapi addon

Contribution
Welcome to Pull requests. For major changes, please file a Issue and discuss with us what you want to change.
Contributors
Thanks to all those who have contributed to notadd!

Communication
Tencent QQ Groupï¼322247106
Forum: Under construction
Blog: Under construction
Excellent Repositories

Swoft Modern High performance AOP and Coroutine PHP Framework, base on Swoole 2
ThinkSNS Plus Use of Laravel framework to achieve the user ecosystem.
Neditor A modern editor based on the Ueditor.

Sponsor
We would like to thank the following sponsors for funding the development of our Notadd. If you are interested in becoming a sponsor, please visit Notadd's Gitee Page:

China Xian Â· Benchu Network
China Hanzhou Â· upyun
China Xian Â· Mada Network

(Please ask your company to support this open source project by becoming a sponsor)

Backer
Thank you to all our backers! Become a backer

License
The Notadd is open-sourced software licensed under the Apache 2.0 license.

TODO

 Internationalization (i18n) support
 Public services such as cmsãpayãconfigãstorageãlogger, etc.
 Service governance, fuse, downgrade, load, registration and discovery
 Support PWA technology, implement off-screen reminders, web-off form saving, webpage offline message push

",1872
eshaibu/react-todo,JavaScript,"React Todo
Instructions

Clone the project
If cloning for the first time, create a .env file(if not created already), copy the contents .env.example into the new .env file
Update your .env file with the appropriate values

Set the environment value for
REACT_APP_API_BASE_URL: The base url of the API, the default value is http://localhost:8000/api/v1

Install dependencies => npm install
To start the application run npm start
To run test run npm test

",2
keywish/keywish-hummer-bot-v2.0,C++,"Please Contact Us
Technical support email: abbott@emakefun.com
Sales email: ken@keywish-robot.com
The latest information download address: https://github.com/keywish/keywish-hummer-bot-v2.0

Hummer-bot

Introduction
Hummer-Bot is a multi-function car, it is based on the Arduino UNO and the L298N motor drive module. You can freely install various sensor modules such as servo, ultrasonic, infrared obstacle avoidance, infrared tracking, etc. It can trace and avoid obstacles automatically, and it supports multiple remote control methods: infrared remote control, Bluetooth APP, PS2 handle (optional). And we will provide CD with the best tutorial including the programs and codes which bring you to the robot car world. It is the best choice for electronics enthusiasts, makers, and Arduino enthusiasts.
Feature

3-channel infrared tracking modules 
2 sets of infrared obstacle avoidance modules 
ultrasonic obstacle avoidance with servo 
2-channel DC motor drive 
2 rechargeable lithium batteries:3000mZh/3.7v, longer battery life 
Real-time battery power detection 
Infrared remote control 
Bluetooth app control 
PS2 handle control (optional) 

Required Best Buy Links
Buy on Amazon 
Buy on AliExpress
Video Links
Component introduction 
Function 
Assembly 
Download Method

",4
G-little/priest,JavaScript,"priest
dubbo mybatis springboot base soa rest api framework with customer code generator
åè¨
åè¿å ä¸ªè½¯ä»¶é¡¹ç®å¼åçäººï¼å¯è½æå¤æå°é½ä¼åç°ï¼é¤å»é¡¹ç®æ¬èº«ä¸å¡ç»èçåºå«ï¼é¡¹ç®ä¸é¡¹ç®ä¹é´è¿æ¯æå¤§éçåè½éå¤ï¼
å¦ç¨æ·ä¸­å¿ãæ¥å£è°ç¨æéè®¤è¯ãæ¯ä»ä¸­å¿ãè´¦æ·é±åãèå¤©æ¶æ¯ãç®¡çåå°çæéåèåç®¡çï¼å ä¹æ¯æ¯ä¸ªé¡¹ç®ä¼ç¨å°çåºç¡æ¨¡
åï¼æ¬é¡¹ç®æ¨å¨ä»¥priest é¡¹ç® (priest é¡¹ç®æ¯ä¸ä¸ªä»¥ incubator-dubbo - Spring Boot - Mybatis3 ä¸ºåºç¡çSOAå¼æºå¼åæ¡æ¶)
ä¸ºåºç¡ï¼å°å¸¸ç¨çéç¨éä¸å¡æ¨¡åç¬ç«ç»ä»¶åï¼è®©æ°çä¸å¡é¡¹ç®ç åå¦ç§¯æ¨ç»è£ä¸æ ·ç®åï¼è®©å¼åäººåçå¨é¨æ¾å°ä¸å¡ç»èçå¿«é
å®ç°ä¸ï¼è®©é¡¹ç®åä¸çäººåéç½®ç®ååï¼ææ¬æå°åã
é¡¹ç®ä»ç»
priesté¡¹ç®åºäºspringboot+dubbo+mybatisçåå¸å¼ææ·å¼åæ¡æ¶ï¼å° JSR303 hibernate-validate éªè¯ä½ç³»å®ç¾èådubboæå¡æ¡æ¶ãå¹¶ä»¥æ­¤ä¸ºåºç¡å¼åäºmaven-code-generator æä»¶ï¼è®©ç åäººåä»éå¤çå¢å æ¹æ¥å·¥ä½ä¸­å½»åºè§£è±ã
æ¬é¡¹ç®ä¸ºåç»­å¼æºçææé¡¹ç®çåºç³é¡¹ç®ï¼åç»­è®¡åéç»­çå¼æºé¡¹ç®å°ä¼æ ç¨æ·ä¸­å¿ æ¯ä»ä¸­å¿ æ¬è¯·æå¾ï¼
æ´æ°æ¥å¿
2019-04-17


ç¨æ·æ¨¡åå¾®ä¿¡OAuth2ç»å½æ¯æ


æ¯ä»æ¨¡åç¨æ·è´¦æ·æ¯æ


2019-04-09


å¢å äºç¨æ·æ¨¡å

ç­ä¿¡æ³¨å
ç¨æ·ä¿¡æ¯è¡¥å
è·åç¨æ·ä¿¡æ¯
restApi æ¥å£è°ç¨è®¤è¯
token è¿æå·æ°
ç¨æ·ä¸»å¨ç»åº



å¢å åå°ç®¡çæ¨¡å

æéç®¡ç
èåç®¡ç
ç®¡çåç®¡ç
ä»£ç çædemo



ä»£ç çææä»¶

åå°ç®¡çjspä»£ç çææ¯æ
ä»£ç çæ list attribute æ ç­¾æ¯æ



é¡¹ç®è®¡å



æ¨¡å
åè½æè¿°
å®æåº¦




priest-pay
æ¯ä»å®æ¯ä»
Â ð


priest-pay
å¾®ä¿¡æ¯ä»
Â ð


priest-pay
ç¨æ·è´¦æ·
Â ð


dubbo-extend
æ¹ä¸ºdubbo åçJSR303 åæ°éªè¯
Â ð


priest-user
token çæ
Â âï¸


priest-user
restApi token éªè¯
Â âï¸


priest-generator
ç®¡çåå°é¡µé¢èªå¨çæ
Â âï¸



ç»ç»ç»æ
âââ dubbo
âÂ Â  âââ assembly     --dubbo æåç¸å³éç½®
âÂ Â  âââ bin          --dubbo å¯å¨èæ¬
âââ dubbo-extend     --dubbo æ©å±æ¯ædubboæ¥å£åæ°æ ¡éª
âââ plugin-test      --ä»£ç çææä»¶æµè¯é¡¹ç®
âââ priest-admin     --ç®¡çåå°é¡¹ç®
âÂ Â  âââ priest-admin-api     --ç®¡çåå°apié¡¹ç®
âÂ Â  âââ priest-admin-common  --ç®¡çåå°å¬ç¨æ¨¡å
âÂ Â  âââ priest-admin-dao     --ç®¡çåå°æ°æ®åºè®¿é®å±
âÂ Â  âââ priest-admin-http    --ç®¡çåå°WEBçé¢
âÂ Â  âââ priest-admin-service --ç®¡çåå°dubboæå¡
âââ priest-common            --priest é¡¹ç®å¬ç¨æ¨¡å
âââ priest-common-web        --priest é¡¹ç®å¬ç¨WEBæ¨¡å
âââ priest-demo              --priest æå¡åæ ·ä¾é¡¹ç®
âÂ Â  âââ priest-demo-api      --priest æå¡åæ ·ä¾apié¡¹ç®
âÂ Â  âââ priest-demo-dao      --priest æå¡åæ ·ä¾daoé¡¹ç®
âÂ Â  âââ priest-demo-http     --priest æå¡åæ ·ä¾httpé¡¹ç®
âÂ Â  âââ priest-demo-service  --priest æå¡åæ ·ä¾dubboæå¡é¡¹ç®
âââ priest-generator         --priest ä»£ç çææä»¶é¡¹ç®
âââ priest-user              --ç¨æ·é¡¹ç®
âÂ Â  âââ priest-user-api      --ç¨æ·apié¡¹ç®
âÂ Â  âââ priest-user-dao		 --ç¨æ·æ°æ®åºè®¿é®å±
âÂ Â  âââ priest-user-http     --ç¨æ·WEBæ¥å£
âÂ Â  âââ priest-user-service  --ç¨æ·dubboæå¡
âÂ Â  âââ priest-user-token    --ç¨æ·tokençææ¨¡å
âââ wiki_images              --wiki å¼ç¨å¾ç
  
Getting Started

é¡¹ç®ä¾èµ

mysql æ°æ®åº
zookeeper æ³¨åæå¡
maven
jdk 1.8+

é¡¹ç®ç¼è¯


è¿å¥é¡¹ç®æ ¹ç®å½


æå¼é¡¹ç® priest-demo/priest-demo-dao/src/main/resources/demo.sql å»ºç«åå»ºæµè¯æ°æ®åºåè¡¨


ä¿®æ¹ priest-demo/priest-demo-dao/pom.xml develop profile å³äºjdbcçéç½®è§ä¸å¾



ä¿®æ¹ æ ¹ç®å½pom.xml develop profile å³äºzookeeperéç½®è§ä¸å¾



è¿å¥é¡¹ç®æ ¹ç®å½


mvn clean install -Pdevelop


é¡¹ç®è¿è¡

dubbo service å¯å¨

è¿è¡  priest-demo/priest-demo-service/src/test/java/com/little/g/demo/TestDubbo.java main


http å¯å¨

è¿å¥priest-demo/priest-demo-http é¡¹ç®ç®å½
æ§è¡ mvn spring-boot:run  ï¼è§å¯æ§å¶å°æ¥å¿è¾åºï¼åºç°å¦ä¸æ¥å¿ï¼ä¾¿æ¯å¯å¨æåäºã




æ¥å£è®¿é®æµè¯


curl http://127.0.0.1:8888/user/test
å¼åæµç¨
æ°æ®åºå»ºè¡¨
æ¬ä¾ä»¥orderè¡¨ä¸ºä¾å­å»ºè¡¨è¯­å¥å¦ä¸:
	
CREATE TABLE `order` (
  `id` int(11) unsigned NOT NULL AUTO_INCREMENT,
  `uid` int(11) DEFAULT NULL COMMENT 'ç¨æ·ID',
  `money` bigint(15) DEFAULT NULL COMMENT 'éé¢',
  `create_time` bigint(15) DEFAULT NULL COMMENT 'åå»ºæ¶é´',
  `status` tinyint(4) DEFAULT NULL COMMENT 'ç¶æ',
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;
	
dao çæ

æå¼priest-demo/priest-demo-dao/src/test/resources/generatorConfig.xmlè¿½å å¦ä¸éç½®

<table tableName=""order"" delimitIdentifiers=""true"" >
            <generatedKey column=""id""  sqlStatement=""JDBC"" />
</table>     



è°ç¨priest-demo-daoç mybatis-generatoræä»¶ç  mybatis-generator:generate ä»»å¡,æ§è¡ç»æå¦ä¸:



å³äºmybatis-generatorçè¯¦ç»éç½®åææ¡£å¯åè§ MyBatis Generator


api çæ

æ·è´ com.little.g.demo.model.Order è³ priest-demo-api é¡¹ç®ç com.little.g.demo.api.dto éå½åä¸º OrderDTO
æå¼priest-demo/priest-demo-api/src/main/conf/GenerateConfig.xml è¿½å å¦ä¸éç½®

<generateFile packagePath=""/com/little/g/demo/api"" templateName=""Service.tpl"" fileName=""OrderService.java"">
        <property name=""entityName"" value=""Order"" />
</generateFile>




è°ç¨priest-demo-apiç generatoræä»¶ç generator:generate ä»»å¡,æ§è¡ç»æå¦ä¸:



å³äºgenerator æä»¶çè¯¦ç»éç½®åææ¡£å¯åè§


service çæ

æå¼priest-demo/priest-demo-service/src/main/conf/GenerateConfig.xml è¿½å å¦ä¸éç½®

<generateFile packagePath=""/com/little/g/demo/service"" templateName=""ServiceImpl.tpl"" fileName=""OrderServiceImpl.java"">
        <property name=""entityName"" value=""Order"" />
</generateFile>




è°ç¨priest-demo-serviceç generatoræä»¶ç generator:generate ä»»å¡,æ§è¡ç»æå¦ä¸:



priest-demo-service dubbo-config.xml è¿½å dubbo service æ¥å£æ´é²
<dubbo:service interface=""com.little.g.demo.api.OrderService"" ref=""orderService""/>


å³äºgenerator æä»¶çè¯¦ç»éç½®åææ¡£å¯åè§ priest generator


http çæ

æå¼priest-demo/priest-demo-http/src/main/conf/GenerateConfig.xml è¿½å å¦ä¸éç½®

<generateFile packagePath=""/com/little/g/demo/web"" templateName=""Controller.tpl"" fileName=""OrderController.java"">
        <property name=""entityName"" value=""Order"" />
</generateFile>




è°ç¨priest-demo-httpç generatoræä»¶ç generator:generate ä»»å¡,æ§è¡ç»æå¦ä¸:



priest-demo-http dubbo-consume.xml è¿½å dubbo service å¼ç¨
<dubbo:reference id=""orderService"" interface=""com.little.g.demo.api.OrderService"" />


å³äºgenerator æä»¶çè¯¦ç»éç½®åææ¡£å¯åè§ priest generator


ç®¡çåå°ä»£ç çæ
ç®¡çåå°çdaoãapiåservice ççæä¸restApiççæé»è¾æ¬è´¨æ²¡æå¤ªå¤§åºå«ï¼åªæ¯å¨æ¥å£åæé»è¾çåºç¡ä¸å¢å äºåé¡µé»è¾ï¼å¯¹äºæ¢ææ¥å£é»è¾åæåå°ç®¡ççæ¨¡åï¼å¯ä»¥éç¨ç®¡çåå°ç apiãserviceæ¨¡æ¿
è¿è¡çæï¼ä¸é¢åªåç¬ååº admin ç®¡çé¡µé¢çä»£ç çæéç½®ï¼

æå¼priest-admin/priest-admin-http/src/main/conf/GenerateConfig.xml è¿½å å¦ä¸éç½®

æ³¨æ :é»è®¤çwebæä»¶çæè·¯å¾ä½äº WEB-INF/jsp+${webPath} è¥è¦ä¿®æ¹webæä»¶çæè·¯å¾ï¼ç´æ¥ä¿®æ¹æä»¶çwebSourceéç½®

<!-- Controller çæéç½® -->
<generateFile packagePath=""/com/little/g/admin/web/controllers/test"" templateName=""Controller.tpl"" fileName=""BookController.java"">
        <property name=""packageName"" value=""com.little.g.admin.web.controllers.test"" />
        <property name=""basePackage"" value=""com.little.g.admin"" />
        <property name=""entityName"" value=""Book"" />
        <property name=""module"" value=""BOOK"" />
        <property name=""uri"" value=""/book"" />
    </generateFile>
    
<!-- list.jsp çæéç½® -->
<generateFile webPath=""/book"" templateName=""list.tpl"" fileName=""book-list.jsp"">
        <property name=""uri"" value=""/book"" />
        <property name=""module"" value=""å¾ä¹¦"" />
        <list name=""attributes"">
            <attribute name=""name"" required=""true"" comment=""ä¹¦å"" />
            <attribute name=""price"" required=""false"" comment=""ä»·æ ¼"" />
            <attribute name=""author"" required=""false"" comment=""ä½è"" />
            <attribute name=""publisher"" required=""false"" comment=""åºçå"" />
        </list>
    </generateFile>

<!-- edit.jsp çæéç½® -->
<generateFile webPath=""/book"" templateName=""edit.tpl"" fileName=""book-edit.jsp"">
        <property name=""uri"" value=""/book"" />
        <property name=""paramName"" value=""book"" />
        <property name=""module"" value=""å¾ä¹¦"" />
        <list name=""attributes"">
            <attribute name=""name"" required=""true"" comment=""ä¹¦å"" />
            <attribute name=""price"" required=""false"" comment=""ä»·æ ¼"" />
            <attribute name=""author"" required=""false"" comment=""ä½è"" />
            <attribute name=""publisher"" required=""false"" comment=""åºçå"" />
        </list>
    </generateFile>



è°ç¨priest-admin-httpç generatoræä»¶ç generator:generate ä»»å¡,æ§è¡ç»æå¦ä¸:



priest-admin-http dubbo-consume.xml è¿½å dubbo service å¼ç¨
<dubbo:reference id=""orderService"" interface=""com.little.g.demo.api.BookService"" />


è®¿é®adminé¡¹ç®å¢å èå




admin çæçé¢æææªå¾

åè¡¨é¡µ:

ä¿®æ¹é¡µ:


å³äºgenerator æä»¶çè¯¦ç»éç½®åææ¡£å¯åè§ priest generator

æ¹éçæèæ¬
æ¨ä¹å¯ä»¥å¨éç½®å®æåï¼ç´æ¥æ§è¡æ¹éçæèæ¬ï¼å®æä¸è¿°æææ­¥éª¤
èæ¬ä½äº priest-demo æ ¹ç®å½
	sh	code_generate.sh
	
æåé¡¹ç®éæ°ç¼è¯è¿è¡ï¼æ°å¼åçæ¥å£å°±å¯ä»¥æµè¯äº
",31
pandas-dev/pandas,Python,"



pandas: powerful Python data analysis toolkit

 Â 

Latest Release














Package Status







License







Build Status















Coverage






Downloads







Gitter







What is it?
pandas is a Python package providing fast, flexible, and expressive data
structures designed to make working with ""relational"" or ""labeled"" data both
easy and intuitive. It aims to be the fundamental high-level building block for
doing practical, real world data analysis in Python. Additionally, it has
the broader goal of becoming the most powerful and flexible open source data
analysis / manipulation tool available in any language. It is already well on
its way towards this goal.
Main Features
Here are just a few of the things that pandas does well:

Easy handling of missing data (represented as
NaN) in floating point as well as non-floating point data
Size mutability: columns can be inserted and
deleted from DataFrame and higher dimensional
objects
Automatic and explicit data alignment: objects can
be explicitly aligned to a set of labels, or the user can simply
ignore the labels and let Series, DataFrame, etc. automatically
align the data for you in computations
Powerful, flexible group by functionality to perform
split-apply-combine operations on data sets, for both aggregating
and transforming data
Make it easy to convert ragged,
differently-indexed data in other Python and NumPy data structures
into DataFrame objects
Intelligent label-based slicing, fancy
indexing, and subsetting of
large data sets
Intuitive merging and joining data
sets
Flexible reshaping and pivoting of
data sets
Hierarchical labeling of axes (possible to have multiple
labels per tick)
Robust IO tools for loading data from flat files
(CSV and delimited), Excel files, databases,
and saving/loading data from the ultrafast HDF5 format
Time series-specific functionality: date range
generation and frequency conversion, moving window statistics,
moving window linear regressions, date shifting and lagging, etc.

Where to get it
The source code is currently hosted on GitHub at:
https://github.com/pandas-dev/pandas
Binary installers for the latest released version are available at the Python
package index and on conda.
# conda
conda install pandas
# or PyPI
pip install pandas
Dependencies

NumPy: 1.13.3 or higher
python-dateutil: 2.5.0 or higher
pytz: 2015.4 or higher

See the full installation instructions
for recommended and optional dependencies.
Installation from sources
To install pandas from source you need Cython in addition to the normal
dependencies above. Cython can be installed from pypi:
pip install cython
In the pandas directory (same one where you found this file after
cloning the git repo), execute:
python setup.py install
or for installing in development mode:
python setup.py develop
Alternatively, you can use pip if you want all the dependencies pulled
in automatically (the -e option is for installing it in development
mode):
pip install -e .
See the full instructions for installing from source.
License
BSD 3
Documentation
The official documentation is hosted on PyData.org: https://pandas.pydata.org/pandas-docs/stable
Background
Work on pandas started at AQR (a quantitative hedge fund) in 2008 and
has been under active development since then.
Getting Help
For usage questions, the best place to go to is StackOverflow.
Further, general questions and discussions can also take place on the pydata mailing list.
Discussion and Development
Most development discussion is taking place on github in this repo. Further, the pandas-dev mailing list can also be used for specialized discussions or design issues, and a Gitter channel is available for quick development related questions.
Contributing to pandas 
All contributions, bug reports, bug fixes, documentation improvements, enhancements and ideas are welcome.
A detailed overview on how to contribute can be found in the contributing guide. There is also an overview on GitHub.
If you are simply looking to start working with the pandas codebase, navigate to the GitHub ""issues"" tab and start looking through interesting issues. There are a number of issues listed under Docs and good first issue where you could start out.
You can also triage issues which may include reproducing bug reports, or asking for vital information such as version numbers or reproduction instructions. If you would like to start triaging issues, one easy way to get started is to subscribe to pandas on CodeTriage.
Or maybe through using pandas you have an idea of your own or are looking for something in the documentation and thinking âthis can be improvedâ...you can do something about it!
Feel free to ask questions on the mailing list or on Gitter.
",19467
KenanSulayman/heartbeat,None,"GCM R 20/0c/400 L 20/0c/400
DL8V8IJ03h7Gakgzy9MWgMsFIR8bBuoGMZkr2wAwcqwr40UYBHZ0ABxhdzE=W+oOj4PAtrfX7QB2xw2rB2spuZiF6OasThsTcfcpsv+7655zwM+lxR0yohDNzgjpzmEgjcJ8njLL4f0p...
iod1vs2qQInUGYgNBspJuTwswUm6LC7JGA+BjmTJxgoJlmog5iL+Izmq15s=lWq2Q1IZmzx4A25qIkdic87q4vw5hiVRRcLJx/XN7H5LzTKPk2Ho7IrggTQcN5nQ/8u/n6n1ykQk+Sub...
",13
algolia/places,JavaScript,"
    
Algolia Places provides a fast, distributed and easy way to use an address search autocomplete JavaScript library on your website.
See the website for more information.
Read the blog post introducing Algolia Places.
Fill the Google form to report any irrelevant results.
Demo
Watch more examples on the website.

Getting started
To use Algolia Places, all you need is an <input> and some JavaScript code that will load
and use the places.js library.
CDN <script>
Our JavaScript library is available on the jsDelivr CDN and also on  cdnjs.
<script src=""https://cdn.jsdelivr.net/npm/places.js@1.16.4""></script>
 is the latest version.
Here's a small example using it:
<input type=""search"" id=""address-input"" placeholder=""Where are we going?"" />

<script>
  var placesAutocomplete = places({
    appId: <YOUR_PLACES_APP_ID>,
    apiKey: <YOUR_PLACES_API_KEY>,
    container: document.querySelector('#address-input')
  });
</script>
Using npm
Algolia Places is also available on npm.
Install the module:
npm install places.js --save
Put an <input> in your html page:
<input type=""search"" id=""address-input"" placeholder=""Where are we going?"" />
Initialize the places.js library:
var places = require('places.js');
var placesAutocomplete = places({
  appId: <YOUR_PLACES_APP_ID>,
  apiKey: <YOUR_PLACES_API_KEY>,
  container: document.querySelector('#address-input')
});
Full documentation is available on the Algolia Places website.
Contributing
Wanna contribute? Awesome, please read the contributing guide.
",4722
duck8823/duci,Go,"duci
      
duci [zushi] (Docker Under Continuous Integration) is a simple ci server.
DSL is Unnecessary For CI
Let's define the task in the task runner.
Let's define the necessary infrastructure for the task in the Dockerfile.
duci just only execute the task in docker container.
Features

Execute the task in Docker container
Execute the task triggered by GitHub pull request comment or push
Execute tasks asynchronously
Create GitHub commit status
Store and Show logs

How to use
Target Repository
The target repository must have Dockerfile in repository root or .duci/Dockerfile.
If there is .duci/Dockerfile, duci read it preferentially.
In Dockerfile, I suggest to use ENTRYPOINT.
e.g.
ENTRYPOINT [""mvn""]
CMD [""compile""]
ENTRYPOINT [""fastlane""]
CMD [""build""]
When push to github, duci execute mvn compile / fastlane build.
And when comment ci test on github pull request, execute mvn test / fastlane test.
Using host environment variables
If exists ARG instruction in Dockerfile, override value from host environment variable.
ARG FOO=default
ARG BAR
and you can use as envrionment variable in command.
ARG FOO=default
ENV FOO=$FOO
Runtime configuration
volumes
You can use volumes options for external dependency, cache and etc.
Set configurations in .duci/config.yml
volumes:
  - '/path/to/host/dir:/path/to/container/dir'
environment variable
You can set environment variables in docker container.
Add the following to .duci/config.yml
environments:
  - ENVIRONMENT_VAIRABLE=value
Server Settings
Installation
# binary will be $(go env GOPATH)/bin/duci
curl -sfL https://raw.githubusercontent.com/duck8823/duci/master/install.sh | sh -s -- -b $(go env GOPATH)/bin
duci version
You can also install a specific version. (replace vX.Y.Z with the specific version from the releases page):
# binary will be $(go env GOPATH)/bin/duci
curl -sfL https://raw.githubusercontent.com/duck8823/duci/master/install.sh | sh -s -- -b $(go env GOPATH)/bin vX.Y.Z
duci version
Setting SSH (optional)
If target repository is private, You can use SSH key to clone repository from github.com.
Please set the public key of the pair at https://github.com/settings/keys.
Add Webhooks to Your GitHub repository
duci start to listen webhook with port 8080 (default) and endpoint /.
In GitHub target repository settings (https://github.com/<owner>/<repository>/settings/hooks),
Add endpoint of duci to Payload URL and application/json to Content type respectively.
Run Server
$ duci server
Server Configuration file
You can specify configuration file with -c option.
The configuration file must be yaml format.
Possible values ââare as follows.
server:
  workdir: '/path/to/tmp/duci'
  port: 8080
  database_path: '$HOME/.duci/db'
github:
  # (optional) You can use SSH key to clone. ex. '${HOME}/.ssh/id_rsa'
  ssh_key_path: ''
  # For create commit status. You can also use environment variable
  api_token: ${GITHUB_API_TOKEN}
job:
  timeout: 600
  concurrency: 4 # default is number of cpu
You can check the configuration values.
$ duci config
Using Docker
You can use Docker to run server.
$ docker run -p 8080:8080 \
             -e GITHUB_API_TOKEN=<your toekn> \
             -v /var/run/docker.sock:/var/run/docker.sock \
             duck8823/duci

When you want to clone with SSH in container,
$ docker run -p 8080:8080 \
             -e GITHUB_API_TOKEN=<your toekn> \
             -e SSH_KEY_PATH=/root/.ssh/id_rsa \
             -v ~/.ssh:/root/.ssh:ro \ 
             -v /var/run/docker.sock:/var/run/docker.sock \
             duck8823/duci

Run with docker-compose
With docker-compose, you can also start ui and reverse proxy together.
$ git clone https://github.com/duck8823/duci.git
$ cd duci
$ docker-compose up -d
If you start up on another host, set your host name (default: localhost) to environment variable DUCI_HOST.
Read job log
GitHub send payload as webhook including X-GitHub-Delivery header.
You can read job log with the X-GitHub-Delivery value formatted UUID.
$ curl -XGET http://localhost:8080/logs/{X-GitHub-Delivery}
The endpoint returns NDJSON (Newline Delimited JSON) formatted log.
{""time"":""2018-09-21T22:19:42.572879+09:00"",""message"":""Step 1/10 : FROM golang:1.11-alpine""}
{""time"":""2018-09-21T22:19:42.573093+09:00"",""message"":""\n""}
{""time"":""2018-09-21T22:19:42.573494+09:00"",""message"":"" ---\u003e 233ed4ed14bf\n""}
{""time"":""2018-09-21T22:19:42.573616+09:00"",""message"":""Step 2/10 : MAINTAINER shunsuke maeda \u003cduck8823@gmail.com\u003e""}
{""time"":""2018-09-21T22:19:42.573734+09:00"",""message"":""\n""}
...

Health Check
This server has an health check API endpoint (/health) that returns the health of the service. The endpoint returns 200 status code if all green.
$ curl -XGET -I http://localhost:8080/health
HTTP/1.1 200 OK
Date: Wed, 31 Oct 2018 20:33:42 GMT
Content-Length: 0

The check items are as follows

Whether the Docker daemon is running or not

You can also check with health sub-command.
$ duci health
INFO[14/Jan/2019 07:17:38.864] ok.

License
MIT License
Copyright (c) 2018 Shunsuke Maeda
See LICENSE file
",34
mitchellkrogza/Phishing.Database,Shell,"
Phishing Domain Database
A Testing Repository for Phishing Domains, Web Sites and Threats.
Below are results of Domains that have been tested to be Active, Inactive or Invalid.
These Lists update every few minutes.

Version: V0.1.10158
ACTIVE Phishing Domains (Tested): 136982 (94 %)
INACTIVE Phishing Domains (Tested): 8153 (6 %)
INVALID Phishing Domains (Tested): 387 (0 %)

Total Phishing URL's Captured: 147709 âï¸ Large File

ACTIVE Phishing Domains (Current Tests): 136982 (94 %)
INACTIVE Phishing Domains (Current Tests): 8153 (6 %)
INVALID Phishing Domains (Current Tests): 387 (0 %)

Purpose of this repo?
This is just one of a number of extensive projects dealing with testing the status of harmful domain names and web sites. We test sources of Phishing attacks to keep track of how many of the domain names used in Phishing attacks are still active and functioning. We sort all domains from all sources into one list, removing any duplicates so that we have a clean list of domains to work with.

How do you test?
We make use of the awesome PyFunceble Testing Suite written by Nissar Chababy. Over 2 years in development this testing tool really provides us with a reliable source of active and inactive domains and through regular testing even domains which are inactive and may become active again are automatically moved back to the active list.

Contributing
If you have a source list of phishing domains why not contribute them to this project for testing? Simply send a PR adding your input source details and we will add the source.


Contributors

Mitchell Krog
Nissar Chababy


MIT License
Copyright (c) 2018 Mitchell Krog
https://github.com/mitchellkrogza
Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the ""Software""), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
",33
dustinpfister/blog_posts,JavaScript,"blog_posts
These are the markdown files that are used to build by website here at github pages at https://dustinpfister.github.io. The build process involves the use of the node.js powered static site generator called hexo.
1 - Setup
After setting up a new instance of hexo by calling hexo init, clone this repo down, then delete the _posts folder in the hexo folder and create a new symbloic link for _posts in place of it pointing to the _posts folder in this repo. Some of the posts do use custom hexo tags that can be found in my hexo_sitesource repo.
1.1 - Making a symbolic link in Windows 10
In windows I use the mklink command to make a symbolic link to the _posts folder in this repo.
mklink /d C:\path\to\hexo-project-folder\source\_posts C:\path\to\blog_posts\_posts

cmd.exe will need to be started with admin privileges, and the /d option will need to be used as this is a like to a directory.
1. 2 - Making a symbolic link in Linux
In linux systems I would use the ln command to make a soft link
$ ln -s /home/github/hexo-project/source/_posts /home/github/blog_posts/_posts

Other repos of interest that involve blog_posts

dustinpfister.github.io - the current deployment of my github pages site that is built with the markdown found here.
hexo_sitesource - This repo contains the instance of hexo that I am using, including the theme.

",2
Lombiq/HipChat-to-Microsoft-Teams-Migration-Utility,C#,"Lombiq HipChat to Microsoft Teams Migration Utility Readme
Utility to migrate Atlassian HipChat content to Microsoft Teams. You can use this instead of waiting for official support. We're testing this utility at Lombiq Technologies (a web development company working with Microsoft technologies) with a 4GB+ HipChat export package containing more than 200k messages (in rooms; a lot more with private chats). The tool is intended for very technical users and developers.
Currently the app can import rooms, messages and attachments from a HipChat export file into configured Teams channels or existing channels (in configured teams). Messages will appear under the user's name doing the import, but messages will include the name of the original user too. To overcome the rate limit of the Teams API multiple HipChat messages can be imported into a single Teams message. See the issue tracker on GitHub for missing features and bugs. HipChat /quote and /code commands are converted into their Teams equivalents.
Note that this being a utility with just temporary use simplicity of implementation was favored against long-term maintainability. Note that the guide assumes you're using Windows but everything should work equally well under any OS supported by .NET Core. However, released executables are available only for Windows 64b currently.
Running the app
If you're a .NET developer then grab the latest source and run the app from the source (you'll need at least VS 2017 and 2.2 of the .NET Core SDK). Otherwise download the latest release from GitHub and run the exe file in the zip. Be sure to check the full usage guide below.
Usage
Keep in mind that you need to be both a HipChat and a Teams admin in your company for this to work.

As a HipChat admin export your HipChat data from under you HipChat URL (e.g https://lombiq.hipchat.com), Group admin, Data export. Select to export every kind of data and the whole history. Use a password without any special characters or spaces! Save the file under a path without any special characters.
Download the OpenSSL binaries if your system doesn't have them already. Recommended is the 1.0.2a (not any other version!) x64 zip from here (direct link to file). Unzip it to a folder whose path doesn't contain any special characters or spaces, run openssl.exe and decrypt the export file with the following command: aes-256-cbc -d -in C:\path\to\export\file.tar.gz.aes -out C:\export.tar.gz -pass pass:password.
Use your favorite ZIP utility (7-Zip recommended) to extract the gz and tar so finally you'll end up with an unencrypted, unzipped export folder (this will contain folders like rooms and users and some further files like rooms.json and users.json). If you get a ""The parameter is incorrect"" error in 7-Zip then first unzip the gz archive to a folder, then unpack the tar file as a second step. While this decrypt-unzip could be automated it's a yak shaving of epic proportions (but feel free to contribute it if you wish!) but you'll have to do it once any way.
Go to the Graph Explorer and log in. Note that the user account you're logging in there will be visible as the author of the messages you import, so it's recommended to use a special user account for this (like ""HipChat Import""). Confirm the required permissions. Then acquire the necessary permissions as following:

Click on ""show more samples"", turn ""Microsoft Teams"" and ""Microsoft Teams (beta)"" on.
Try to run e.g. the Microsoft Teams / create channel operation. You'll get an error that you don't have the necessary permissions. Click on ""modify your permission"".

Select the following permissions: Group.ReadWrite.All, User.Read.All. You'll need to log in again.


Once the permissions are OK then run an API request (it can be any of the samples, even just /me. Copy the bearer token (just the token, without the ""Bearer"" text) used by the request into the AppSettings.json configuration file under the AuthorizationToken config. You can e.g. use Chrome DevTools (open with F12 in Chrome) to see this token in the Request headers:

Specify the rest of the configuration as well:

ExportFolderPath: The file system path to the folder where you unzipped the HipChat export package.
NumberOfHipChatMessagesToImportIntoTeamsMessage: You may be able to guess :). If it's greater than 1 then multiple HipChat messages will be imported into a single Teams message. You can use this to overcome Graph API throttling limitations. It seems that a safe general maximum is about 25 (suitable for rooms with many HTML bodied notifications too), with more HipChat messages the request will be too large (depends on how long messages usually are, that can vary a lot); go with lower if you want to be sure. If the value is too high you'll get ""Importing x HipChat messages into a Teams message resulted in a message too large."" errors. A good strategy is try the value 50 (or even 100), then lower it if you get a lot of errors to find out what suits your chat history best. The Teams API rate limit is at about 1800 requests a day, so you'll only be able to import 1800 messages if you don't use this option before throttling kicks in. Importing into multiple teams (see the HipChatRoomsToTeams option) may increase this overall limit.
ShortenLongMessagesToCharacterCount: HipChat messages can be longer than allowed by Teams, so importing some longer HipChat messages can fail. If this configuration is 0 then in such a case importing will fail and you'll need to manually shorten the message in the HipChat export package; otherwise the message will automatically be shortened to the given character count.
UploadAttachments: If set to true HipChat file attachments will be uploaded to the respective Teams channels, linked from (or in case of images, embedded into) their corresponding messages. Set to false if you don't want attachments to be uploaded.
HipChatRoomsToTeams: Map HipChat room names to team names in Teams, so their corresponding channels will be created there. This way you can configure under which team to create channels. Since channels can't be moved across teams you need this if you don't want all the channels under a single team. Configure multiple room name-team name pairs like this: ""HipChatRoomsToTeams"": { ""$Default"": ""Team 1"", ""$Archived default"":  ""Archive"", ""Room 1"": ""Team 2"" }. If no team is configured for a room then the one under $Default will be used; similarly the team under $Archived default will be used for archived rooms (if this config is missing then the team under $Default will be used for archived rooms too). If a given team is not found then it'll be created (for security reasons as a Private team, you can change this later).
HipChatRoomsToChannels: Map HipChat room names to channel names in Teams. This way you can import the content of HipChat rooms into existing Teams channels, like utilizing the default General channel. Uses the same syntax as HipChatRoomsToTeams. If there's no mapping for a given room then a channel will be created for it. Note that this works together with HipChatRoomsToTeams: so e.g. if you want to import multiple rooms into multiple teams' General channels, then first configure the teams for the rooms with HipChatRoomsToTeams, then configure the room (""General"" in this example) with HipChatRoomsToChannels.


Run the app and wait for the import to complete. In the console you'll see status and possibly error messages. Since not all errors can be resolved automatically, and the bearer token can expire too. So don't let the app run too long (about half an hour) without checking its status.

Notable features missing and bugs
See the issue tracker on GitHub.
Some implementation notes

Here's some information on the HipChat export's schema.
Some inspiration is taken from https://github.com/microsoftgraph/csharp-teams-sample-graph.

Contribution and Feedback
The module's source is available in two public source repositories, automatically mirrored in both directions with Git-hg Mirror:

https://bitbucket.org/Lombiq/hipchat-to-microsoft-teams-migration-utility/ (Mercurial repository)
https://github.com/Lombiq/HipChat-to-Microsoft-Teams-Migration-Utility (Git repository)

Bug reports, feature requests and comments are warmly welcome, please do so via GitHub. Feel free to send pull requests too, no matter which source repository you choose for this purpose.
This project is developed by Lombiq Technologies Ltd. Commercial-grade support is available through Lombiq.
",7
HillTopTRPG/quoridorn-vue-cli-3,Vue,"âãã®ãªãã¸ããª
Quoridorn Vue CLI 3 ç
âåã®è³æ
Quoridorn Vue CLI 2 ç
https://github.com/HillTopTRPG/quoridorn
quoridorn-vue-cli-3
Project setup
npm install

Compiles and hot-reloads for development
npm run serve

Compiles and minifies for production
npm run build

Run your tests
npm run test

Lints and fixes files
npm run lint

Customize configuration
See Configuration Reference.
",4
Lombiq/HipChat-to-Microsoft-Teams-Migration-Utility,C#,"Lombiq HipChat to Microsoft Teams Migration Utility Readme
Utility to migrate Atlassian HipChat content to Microsoft Teams. You can use this instead of waiting for official support. We're testing this utility at Lombiq Technologies (a web development company working with Microsoft technologies) with a 4GB+ HipChat export package containing more than 200k messages (in rooms; a lot more with private chats). The tool is intended for very technical users and developers.
Currently the app can import rooms, messages and attachments from a HipChat export file into configured Teams channels or existing channels (in configured teams). Messages will appear under the user's name doing the import, but messages will include the name of the original user too. To overcome the rate limit of the Teams API multiple HipChat messages can be imported into a single Teams message. See the issue tracker on GitHub for missing features and bugs. HipChat /quote and /code commands are converted into their Teams equivalents.
Note that this being a utility with just temporary use simplicity of implementation was favored against long-term maintainability. Note that the guide assumes you're using Windows but everything should work equally well under any OS supported by .NET Core. However, released executables are available only for Windows 64b currently.
Running the app
If you're a .NET developer then grab the latest source and run the app from the source (you'll need at least VS 2017 and 2.2 of the .NET Core SDK). Otherwise download the latest release from GitHub and run the exe file in the zip. Be sure to check the full usage guide below.
Usage
Keep in mind that you need to be both a HipChat and a Teams admin in your company for this to work.

As a HipChat admin export your HipChat data from under you HipChat URL (e.g https://lombiq.hipchat.com), Group admin, Data export. Select to export every kind of data and the whole history. Use a password without any special characters or spaces! Save the file under a path without any special characters.
Download the OpenSSL binaries if your system doesn't have them already. Recommended is the 1.0.2a (not any other version!) x64 zip from here (direct link to file). Unzip it to a folder whose path doesn't contain any special characters or spaces, run openssl.exe and decrypt the export file with the following command: aes-256-cbc -d -in C:\path\to\export\file.tar.gz.aes -out C:\export.tar.gz -pass pass:password.
Use your favorite ZIP utility (7-Zip recommended) to extract the gz and tar so finally you'll end up with an unencrypted, unzipped export folder (this will contain folders like rooms and users and some further files like rooms.json and users.json). If you get a ""The parameter is incorrect"" error in 7-Zip then first unzip the gz archive to a folder, then unpack the tar file as a second step. While this decrypt-unzip could be automated it's a yak shaving of epic proportions (but feel free to contribute it if you wish!) but you'll have to do it once any way.
Go to the Graph Explorer and log in. Note that the user account you're logging in there will be visible as the author of the messages you import, so it's recommended to use a special user account for this (like ""HipChat Import""). Confirm the required permissions. Then acquire the necessary permissions as following:

Click on ""show more samples"", turn ""Microsoft Teams"" and ""Microsoft Teams (beta)"" on.
Try to run e.g. the Microsoft Teams / create channel operation. You'll get an error that you don't have the necessary permissions. Click on ""modify your permission"".

Select the following permissions: Group.ReadWrite.All, User.Read.All. You'll need to log in again.


Once the permissions are OK then run an API request (it can be any of the samples, even just /me. Copy the bearer token (just the token, without the ""Bearer"" text) used by the request into the AppSettings.json configuration file under the AuthorizationToken config. You can e.g. use Chrome DevTools (open with F12 in Chrome) to see this token in the Request headers:

Specify the rest of the configuration as well:

ExportFolderPath: The file system path to the folder where you unzipped the HipChat export package.
NumberOfHipChatMessagesToImportIntoTeamsMessage: You may be able to guess :). If it's greater than 1 then multiple HipChat messages will be imported into a single Teams message. You can use this to overcome Graph API throttling limitations. It seems that a safe general maximum is about 25 (suitable for rooms with many HTML bodied notifications too), with more HipChat messages the request will be too large (depends on how long messages usually are, that can vary a lot); go with lower if you want to be sure. If the value is too high you'll get ""Importing x HipChat messages into a Teams message resulted in a message too large."" errors. A good strategy is try the value 50 (or even 100), then lower it if you get a lot of errors to find out what suits your chat history best. The Teams API rate limit is at about 1800 requests a day, so you'll only be able to import 1800 messages if you don't use this option before throttling kicks in. Importing into multiple teams (see the HipChatRoomsToTeams option) may increase this overall limit.
ShortenLongMessagesToCharacterCount: HipChat messages can be longer than allowed by Teams, so importing some longer HipChat messages can fail. If this configuration is 0 then in such a case importing will fail and you'll need to manually shorten the message in the HipChat export package; otherwise the message will automatically be shortened to the given character count.
UploadAttachments: If set to true HipChat file attachments will be uploaded to the respective Teams channels, linked from (or in case of images, embedded into) their corresponding messages. Set to false if you don't want attachments to be uploaded.
HipChatRoomsToTeams: Map HipChat room names to team names in Teams, so their corresponding channels will be created there. This way you can configure under which team to create channels. Since channels can't be moved across teams you need this if you don't want all the channels under a single team. Configure multiple room name-team name pairs like this: ""HipChatRoomsToTeams"": { ""$Default"": ""Team 1"", ""$Archived default"":  ""Archive"", ""Room 1"": ""Team 2"" }. If no team is configured for a room then the one under $Default will be used; similarly the team under $Archived default will be used for archived rooms (if this config is missing then the team under $Default will be used for archived rooms too). If a given team is not found then it'll be created (for security reasons as a Private team, you can change this later).
HipChatRoomsToChannels: Map HipChat room names to channel names in Teams. This way you can import the content of HipChat rooms into existing Teams channels, like utilizing the default General channel. Uses the same syntax as HipChatRoomsToTeams. If there's no mapping for a given room then a channel will be created for it. Note that this works together with HipChatRoomsToTeams: so e.g. if you want to import multiple rooms into multiple teams' General channels, then first configure the teams for the rooms with HipChatRoomsToTeams, then configure the room (""General"" in this example) with HipChatRoomsToChannels.


Run the app and wait for the import to complete. In the console you'll see status and possibly error messages. Since not all errors can be resolved automatically, and the bearer token can expire too. So don't let the app run too long (about half an hour) without checking its status.

Notable features missing and bugs
See the issue tracker on GitHub.
Some implementation notes

Here's some information on the HipChat export's schema.
Some inspiration is taken from https://github.com/microsoftgraph/csharp-teams-sample-graph.

Contribution and Feedback
The module's source is available in two public source repositories, automatically mirrored in both directions with Git-hg Mirror:

https://bitbucket.org/Lombiq/hipchat-to-microsoft-teams-migration-utility/ (Mercurial repository)
https://github.com/Lombiq/HipChat-to-Microsoft-Teams-Migration-Utility (Git repository)

Bug reports, feature requests and comments are warmly welcome, please do so via GitHub. Feel free to send pull requests too, no matter which source repository you choose for this purpose.
This project is developed by Lombiq Technologies Ltd. Commercial-grade support is available through Lombiq.
",7
HillTopTRPG/quoridorn-vue-cli-3,Vue,"âãã®ãªãã¸ããª
Quoridorn Vue CLI 3 ç
âåã®è³æ
Quoridorn Vue CLI 2 ç
https://github.com/HillTopTRPG/quoridorn
quoridorn-vue-cli-3
Project setup
npm install

Compiles and hot-reloads for development
npm run serve

Compiles and minifies for production
npm run build

Run your tests
npm run test

Lints and fixes files
npm run lint

Customize configuration
See Configuration Reference.
",4
toehmler/bt-seg,Python,"Automatic Brain Tumor Segmentation
Table Of Contents:

High Grade Gliomas
MRI Scans
Why do we need Automatic Segmentation?
Dataset
Convolutional Neural Networks
Our Model

High Grade Glioma Brain Tumors
Glioma tumors are the most common type of brain tumor, comprising approximately 33% of all brain tumors. These tumors originate in
different types of glial cells, which surround and provide support for neurons in the brain. Gliomas are classified from Grade I to
Grade IV by their various rates of growth. While Grade I gliomas are usually removable surgically with a promising survival rate,
high grade gliomas (glioblastomas) are one of the most deadly cancers, with only a 5% survival rate after 5 years. The current standard of
treatment for these tumors generally consists of some combination of surgery, radiation and chemotherapy. The early detection and diagnosis
of these tumors is crucial to long-term survival rate. This is generally done through brain imaging, including MRI, CT and PET scans.
Of these, the most commonly used imaging technique is the MRI scan, due to its ability to non-invasively provide accurate characterizations
of different tissue types.
MRI Scans
Magnetic resonance imaging (MRI) scans work by applying a strong magnetic field to align protons in the brain, before using radiofrequency
pulses to disturb the alignment. When the radiofrequency field is turned off, MRI's can measure the energy emission as protons return to
alignment with the magnetic field. MRI scans are particularly effective at imaging soft tissue, and organs like the brain and the heart.
MRI's visual the brain through taking a series of two-dimensional 'slices' (at 1mm increments) in one of three planes:
coronal, sagittal and axial. In these slices, each pixel represents a 1mm^3 voxel. For the purposes of our model,
we used slices in the axial plane because it is easier to visualize/IN BRATS DAtASET and the resolution is the HIGHEST??
Why do we need Automatic Segmentation?
Given the huge number of slices generated by these MRI scans (we have 620 for each patient), it is incredibly laborious for a radiologist to go
label the voxels (240x240) in each slice (155 slices). This is time radiologists can use to focus on other tasks. Thus, an effective automatic segmentation method
could provide a much more efficient alternative, saving the radiologist and the patient valuable time. Indeed, one state-of-the-art algorithm
published in 2017 can provide a segmentation between 25 seconds and 3 minutes (Havaei et al.), which is manually inconceivable.
Further, manually applying these labels require high level of expertise and are prone to human error. The use of a highly-trained convolutional
neural network might be able to pick up small contrasts and edges that are hard to detect with the human eye.
PICTURE OF DIFFERENT SLICES?
Dataset
All MRI brain scans were provided by the BRATS 2015 challenge database (https://www.smir.ch/BRATS/Start2015).
This dataset consists of 246 high-grade glioma cases and 54 low-grade glioma cases. Each scan consists of 155 slices in four different
modalities: T1, T1 with contrast, T2 and FLAIR (each of these uses a different pulse sequence to create different pixel contrasts in
a MR brain image). Thus, there are 620 MR images for each patient, and 186,000 images overall. Further, each patient has a fifth image
providing the 'ground truth' labels for each pixel. In this dataset, the labels are as follows: '0' is 'non-tumor;' '1' is 'necrosis';
'2' is 'edema'; '3' is 'non-enhancing tumor'; '4' is 'enhancing tumor.' There is a label for each pixel in each 240x240 voxel slice, generating
8,928,000 labels for each patient, and 2,678,400,000 labels in the dataset overall (300 patients). These ground truth segmentation labels are
manually provided by radiologists.
Convolutional Neural Networks
Convolutional Neural Networks (CNN) are deep learning algorithms that are commonly used for image processing, object detection and classification
tasks. Neural networks can 'learn' through the fine tuning of large numbers of weight and biases in the network to adapt to a specific task.
These networks are modelled after the structure of the human brain, as they consist of a series of complex layers of connections between
artificial 'neurons,' or perceptrons. The first CNN, entitled 'AlexNet,' was created in 2012 by Geoffrey Hinton and his colleagues at the
University of Toronto. Since then, they have been used extensively, but the application of CNN's to medical images is a very new development.
CNN's are a well-suited tool for our task of the automatic segmentation of tumors.
References
",2
commercialhaskell/all-cabal-metadata,Shell,"all-cabal-metadata
Current metadata for all cabal files on Hackage. Generated using the
all-cabal-tool
package.
",7
tengge1/ShadowEditor,JavaScript,"Shadow Editor
Language: ä¸­æ / ç¹é«ä¸­æ / English / æ¥æ¬èª / Le franÃ§ais / ÑÑÑÑÐºÐ¸Ð¹

åç§°ï¼Shadow Editor
çæ¬ï¼v0.2.1(å¼åä¸­)
ç®ä»ï¼åºäºthree.jsçåºæ¯ç¼è¾å¨ã

v0.2.1å³å°æ´æ°

æ´æ°ç¤ºä¾ç¨åºï¼ä¸»è¦æ¯ç¼è¾å¨äºç»´èåæ¼ç¤ºãç äº GitHub

v0.2.0æ´æ°

åå¸æ¥æï¼2019å¹´5æ3æ¥
æ´æ°æ¥å¿ï¼


é»è®¤ä¸åå è½½ammo.jsãåªæåºæ¯ä¸­å­å¨åä½ææè½¯ä½æ¶ï¼æå¨æ­æ¾æ¶èªå¨å è½½ammo.jsï¼æåç¼è¾å¨å¯å¨éåº¦åéç©çåºæ¯è¿è¡éåº¦ã
æ°å¢äºç»´èåï¼æé®ãæ ç­¾ãé¢æ¿ãæ°´å¹³çº¿ãæ¡å½¢å¾ãæ¶é´ãç«ç´çº¿ãæ¥æãæ¶é´åçãé®å¼æ ç­¾ãè¡¨åãä»ªè¡¨ãæ±ç¶å¾ãæçº¿å¾ãä¾§è¾¹æ ãæ±ç¶å¾2ãæ£ç¹å¾ãé¥¼ç¶å¾ãå¼¦å¾ãåå¯¼åå¾ãæ ç¶å¾ãéç¾¤å¾ãåå¾ãååºå¾ãå¯æå¨ãä¿å­ãè½½å¥ï¼å¯å¨æ­æ¾å¨ä¸­æ¥çãï¼å¼åä¸­ï¼ä»ä¾æµè¯ï¼

é¡¹ç®æªå¾

æ¸©é¦¨å°çªã(ä»ä¾åè)



ä¸ç»´å°çãGitee GitHub


ç¹å»æ­¤å¤æ¥çæ´å¤æªå¾ã


æºç 
GitHub
ç äº
ææ¡£
GitHub
ç äº


æ¼ç¤º
GitHub
ç äº
æ°æ®åºåèµæº
ç¾åº¦ç½ç20190116
æåç ï¼n8je


ä¸»è¦åè½

åºäºthree.js/WebGLç3Dåºæ¯å¨çº¿ç¼è¾å¨ï¼æå¡ç«¯ä½¿ç¨MongoDBä¿å­å¨ç»ãé³é¢ãç±»å«ãè§è²ãè´´å¾ãæè´¨ãç½æ ¼æ¨¡åãç²å­ãé¢è®¾ä½ãåºæ¯æ°æ®ã
åç½®å ä½ä½ï¼å¹³é¢ãæ­£æ¹ä½ãåãåæ±ä½ãçä½ãäºåé¢ä½ãè½®èãçº½ç»ãè¶å£¶ãéæ¯ãç²¾çµãææ¬ï¼çº¿æ®µãCatmullRomæ²çº¿ãäºæ¬¡è´å¡å°æ²çº¿ãä¸æ¬¡è´å¡å°æ²çº¿ãæ¤­åæ²çº¿ã
åç½®åæºï¼ç¯å¢åãå¹³è¡åãç¹åæºãèåç¯ãåçåãç©å½¢åã
æ¯æå¤ç§ä¸å3Dæ ¼å¼æ¨¡ååå¨ç»å¯¼å¥ãæ¯æ3dsã3mfãamfãassimp(anim)ãawdãbabylonãbinaryãbvh(anim)ãcolladaãctmãdracoãfbx(anim)ãgcodeãgltf(anim)ãjs(anim)ãjson(anim)ãkmzãlmesh(anim)ãmd2ãmmd(anim)ãnrrdãobjãpcdãpdbãplyãprwmãsea3d(anim)ãstlãvrmãvrmlãvtkãx 31ç§3Dæä»¶æ ¼å¼ï¼å¸¦animçè¡¨ç¤ºæ¯æå¨ç»ãå¤ç§3Dæä»¶åæ¶æ¯æjsonåäºè¿å¶æ ¼å¼ãmmdæä»¶åæ¶æ¯æpmdåpmxæ ¼å¼ï¼æ¯ævmdæ ¼å¼çæ¨¡ååç¸æºå¨ç»ãå®ä¹æ¯å¯ä¸æ¯ælmesh(lolkingç½ç«lolæ¨¡å)çç¼è¾å¨ã
åç½®æè´¨ï¼çº¿æ¡æè´¨ãèçº¿æè´¨ãåºæ¬æè´¨ãæ·±åº¦æè´¨ãæ³åéæè´¨ãå°ä¼¯ç¹æè´¨ãå¯æ°æè´¨ãç¹äºæè´¨ãæ åæè´¨ãç©çæè´¨ãç²¾çµæè´¨ãçè²å¨æè´¨ãåå§çè²å¨æè´¨ã
æ¯æçº¹çï¼é¢è²çº¹çãéæçº¹çãå¹å¸çº¹çãæ³çº¿çº¹çãä½ç§»çº¹çãéé¢çº¹çãç¯å¢çº¹çãåç§çº¹çãé®æ¡çº¹çãèªååçº¹çã
æ¯æè´´å¾ï¼å¾çãç«æ¹ä½è´´å¾ãè§é¢è´´å¾ã
åç½®ç»ä»¶ï¼èæ¯é³ä¹ãç²å­åå°å¨ãå¤©ç©ºãç«ç°ãæ°´ãçãå¸ç»ä»¶ã
å¯è§åä¿®æ¹åºæ¯ãç¸æºç­ç©ä½å±æ§ï¼æä¾40å¤ç§ä¸åä¿®æ¹é¢æ¿ã
å¨çº¿ç¼è¾jsèæ¬ãçè²å¨ç¨åºï¼å¸¦æºè½æç¤ºã
èªå¸¦æ­æ¾å¨ï¼å®æ¶æ¼ç¤ºåºæ¯å¨æææï¼æ¯æå¨å±åæ°çªå£æ­æ¾ï¼å¯ä»¥ç´æ¥åµå¥é¡¹ç®iframeä¸­ã
æ¯æè¡¥é´å¨ç»ãéª¨éª¼å¨ç»ãç²å­å¨ç»ãmmdå¨ç»ãlmeshå¨ç»ï¼lolkingç½ç«lolæ¨¡åï¼ã
æ¯æåºæ¯ãæ¨¡åãè´´å¾ãæè´¨ãé³é¢ãå¨ç»ãç²å­ãé¢è®¾ä½ãè§è²èµæºç®¡çï¼æ¯æèªå®ä¹åç±»ï¼æ ¹æ®æ±å­åæ¼é³å¿«éæç´¢ãå¶ä¸­ï¼ç²å­ãé¢è®¾ä½ãè§è²èµæºç®¡çææªå®ç°ç¸åºåè½ã
æ¯æç¬¬ä¸è§è§æ§å¶å¨ãé£è¡æ§å¶å¨ãè½¨éæ§å¶å¨ãæééå®æ§å¶å¨ãè½¨è¿¹çæ§å¶å¨5ç§æ§å¶å¨ã
æ¯æç¹éµåç¹æãé¢è²åç§»ç¹æãæ®å½±ç¹æãèæ¯èåãå¿«éè¿ä¼¼æé¯é½¿(FXAA)ãæ¯åºç¹æãåè²è°ç¹æãå¨å±æé¯é½¿(SSAA)ãåç´ ç¹æãå¯æ©å±ç¯å¢åé®æ¡(SAO)ãå¤ééæ ·æé¯é½¿(SMAA)ãå±å¹ç©ºé´ç¯å¢åé®è½(SSAO)ãæ¶é´æé¯é½¿(TAA)ã
æä¾åå²è®°å½åæ¥å¿åè½ï¼æ¯ææ¤éãéåã
æ¯æå¯¼åºgltfãobjãplyãstlæ¨¡åã
æ¯æbulletç©çå¼æãæ­£æ¹ä½ãåå½¢ãåæ±ä½ãäºåé¢ä½ãéæ¯ãå¹³é¢ãçä½ãè¶å£¶ãè½®èãçº½ç»åå è½½çæ¨¡åé½æ¯æåä½ç»ä»¶ãæ¯æå¯è§åè®¾ç½®ç¢°æä½å½¢ç¶ï¼æ­£æ¹ä½ãçä½ï¼ãè´¨éåæ¯æ§ã
å·æå¹³ç§»ãæè½¬ãç¼©æ¾ãå¨ç©ä½è¡¨é¢ç»å¶ç¹ãçº¿ãè´´è±çå·¥å·ï¼å®æ¶ç»è®¡åºæ¯ç§ç©ä½ãé¡¶ç¹ãä¸è§å½¢æ°éã
æ¯æåºæ¯ä¸é®å¯¼åºåè½ã
ä¸­è±æåè¯­æ¯æã
æ¯æè²è°æè½¬(hue-rotate)ãé¥±ååº¦ãäº®åº¦ãé«æ¯æ¨¡ç³(blur)ãå¯¹æ¯åº¦ãç°åº¦ãé¢è²åè½¬(invert)ãå¤å¤(sepia)æ»¤éã
æ¯æçæ¬æ§å¶ã

ä½¿ç¨æå
è¯¥é¡¹ç®ä»æ¯æWindowsç³»ç»ï¼çµèä¸éè¦å®è£.Net Framework 4.5ã
æ¨èä½¿ç¨ææ°çè°·æ­æµè§å¨ï¼ä¸ä¿è¯å¼å®¹å¶ä»æµè§å¨ã

å®è£NodeJsï¼å¨æå¤å±ç®å½ï¼æ§è¡ä»¥ä¸å½ä»¤ã

npm install
npm run build

ä¸è½½MongoDBï¼å®è£å¹¶å¯å¨MongoDBæå¡ãMongoDBæå¡çé»è®¤ç«¯å£ä¸º27017ã

mongod --dbpath=D:\mongodb\db --logpath=D:\mongodb\log\mongoDB.log --install --serviceName MongoDB
net start MongoDB

ç¼è¾æä»¶ShadowEditor.Web/Web.configï¼å°27017ä¿®æ¹ä¸ºä½ çµèä¸MongoDBæå¡çç«¯å£ã

<add key=""mongo_connection"" value=""mongodb://127.0.0.1:27017"" />


ä½¿ç¨Visual Studio 2017æå¼é¡¹ç®ï¼çæShadowEditor.Webé¡¹ç®ã


å°ShadowEditor.Webé¨ç½²å¨iisä¸å³å¯å¨æµè§å¨ä¸­è®¿é®ã


ä¸ºäºä¿å­åç§ç±»åæä»¶è½æ­£å¸¸ä¸è½½ï¼éè¦å¨iisä¸æ·»å ä»¥ä¸ä¸¤ä¸ªMIMEç±»åã





æä»¶æ©å±å
MIMEç±»å
è¯´æ




.*
application/octet-stream
åç§æ ¼å¼åç¼æä»¶


.
application/octet-stream
æ åç¼æä»¶




ç¼è¯ææ¡£ï¼è¯·å®è£gitbookã

npm install -g gitbook-cli
ç¶ååæ¢å°docs-devç®å½ï¼å®è£gitbookæä»¶ã
gitbook install
ç¶ååæ¢å°ä¸çº§ç®å½ï¼æ§è¡ä»¥ä¸å½ä»¤çæææ¡£ã
npm run build-docs
å¸¸è§é®é¢

ä¸ä¼ æ¨¡åæ¶ä¸ºä»ä¹é½æ¯ä¸ä¼ å¤±è´¥ï¼

éè¦ææ¨¡åè´´å¾ç­èµæºåç¼©æä¸ä¸ªzipåï¼èä¸å¥å£æä»¶ä¸è½åµå¥æä»¶å¤¹ãæå¡ç«¯ä¼è§£åä¸ä¼ çzipåæ¾å°~/Upload/Modelæä»¶ä¸ï¼å¹¶å¨MongoDB _Meshè¡¨éæ·»å ä¸æ¡æ°æ®ã

å¦ä½å°å¤ä¸ªæ¨¡åç»åå¨ä¸èµ·ï¼

åºæ¬å ä½ä½é½æ¯æå¤å±åµå¥ãå¯ä»¥æ·»å ä¸ä¸ªç»ï¼å¨å ä½ä½èåä¸­ï¼ï¼ç¶åå¨åºæ¯æ ç¶å¾ä¸ï¼å°å¤ä¸ªæ¨¡åæå¨å°ç»ä¸ã
æ´æ°æ¥å¿
v0.2.0

åå¸æ¥æï¼2019å¹´5æ3æ¥
æ´æ°æ¥å¿ï¼


é»è®¤ä¸åå è½½ammo.jsãåªæåºæ¯ä¸­å­å¨åä½ææè½¯ä½æ¶ï¼æå¨æ­æ¾æ¶èªå¨å è½½ammo.jsï¼æåç¼è¾å¨å¯å¨éåº¦åéç©çåºæ¯è¿è¡éåº¦ã
æ°å¢äºç»´èåï¼æé®ãæ ç­¾ãé¢æ¿ãæ°´å¹³çº¿ãæ¡å½¢å¾ãæ¶é´ãç«ç´çº¿ãæ¥æãæ¶é´åçãé®å¼æ ç­¾ãè¡¨åãä»ªè¡¨ãæ±ç¶å¾ãæçº¿å¾ãä¾§è¾¹æ ãæ±ç¶å¾2ãæ£ç¹å¾ãé¥¼ç¶å¾ãå¼¦å¾ãåå¯¼åå¾ãæ ç¶å¾ãéç¾¤å¾ãåå¾ãååºå¾ãå¯æå¨ãä¿å­ãè½½å¥ï¼å¯å¨æ­æ¾å¨ä¸­æ¥çãï¼å¼åä¸­ï¼ä»ä¾æµè¯ï¼

v0.1.9

åå¸æ¥æï¼2019å¹´4æ20æ¥
æ´æ°æ¥å¿ï¼


ä¿®å¤å±æ§é¢æ¿ä¿®æ¹åç§°æ¶ï¼æå­å ä½ä½æå­ä¸æ¹åbugã
ä¿®å¤å°å¾å¡é¡¿é®é¢ã
æ°å¢å°å¾ç»ä»¶ï¼å¨æåæ¢è°·æ­å°å¾ãå¿åºå°å¾ãå¤©å°å¾ã
ä½¿ç¨ç«ä½çº¹çä¸ºå°çå®ç°æç©ºèæ¯ã
å°å¾æ·»å å¤ªé³ç¹æã
å°å¾ä¿å­è½½å¥ã
å¨æ­æ¾å¨ä¸­æ­æ¾GISåºæ¯ã
æ°å¢ä¸ç»´GISæ¼ç¤ºãGitee GitHub
æ°å¢è¡¥é´å¨ç»æ¼ç¤ºãGitee GitHub
éå¶å°è½´ä¸yè½´çå¤¹è§å¨ä¸å®èå´åã

v0.1.8

åå¸æ¥æï¼2019å¹´4æ7æ¥
æ´æ°æ¥å¿ï¼


è®¾ç½®é¢æ¿æ¾å°éé¡¹èåä¸­ã
æ°å¢è²è°æè½¬(hue-rotate)ãé¥±ååº¦ãäº®åº¦ãé«æ¯æ¨¡ç³(blur)ãå¯¹æ¯åº¦ãç°åº¦ãé¢è²åè½¬(invert)ãå¤å¤(sepia)æ»¤éã
æ»¤éè®¾ç½®ä¿å­å¨åºæ¯éç½®ä¸­ï¼å¹¶å¨ç¼è¾å¨åæ­æ¾å¨è§£æã
åå»ºGISåºæ¯ã(æ¼ç¤º)
ä¿®å¤å½æ¨¡åæå¤å±æ¯Sceneæ¶ï¼å±æ§é¢æ¿æ¾ç¤ºç©ä½ç¯å¢ç»ä»¶ååç§åæå¤çç»ä»¶çbugã
åºæ¯å±æ¬¡æ ï¼èç¹åé¢æ·»å ä¸ä¸ªç©å½¢ï¼è¡¨ç¤ºè¯¥èç¹ç±»åã

v0.1.7

åå¸æ¥æï¼2019å¹´3æ23æ¥
æ´æ°æ¥å¿ï¼


ä¿®å¤ç©ä½æ¹ååï¼åºæ¯æ ç¶å¾æ æ³åæ¶ååºï¼æ æ³è®°ä½æ èç¹å±å¼ç¶æï¼æ èç¹é¡ºåºéä¹±çbugã
ç©ä½åç§°è¶é¿èªå¨æ¾ç¤ºçç¥å·ãé¼ æ ç§»å°èç¹ä¸ï¼æ¾ç¤ºå®æ´åç§°ã
æ°å¢å¨å±æ­æ¾åè½ãæ°çªå£æ­æ¾åè½ãæ­æ¾å¨åç¼è¾å¨å½»åºè§£é¤è¦åï¼æ­æ¾å¨å¯ç¬ç«è¿è¡ã
å¯å°ç¼è¾å¥½çåºæ¯åµå¥iframeè¿è¡ãå°åï¼/view.html?sceneID=sceneIDãå¯ä½¿ç¨æ°çªå£æ­æ¾åè½è·åè¯¥å°åã
ç©ä½éä¸­ææä¼åï¼ç­å®½æè¾¹ã
ä¿®å¤æ´çæ¨¡åå·¥å·ï¼å¤å¶æ¨¡åæ¶æªå¤å¶æä»¶å¤¹ä¸­æææä»¶çbugã
ææè®¾ç½®æ¹ä¸ºå­å¨å¨localStorageä¸­ï¼ä¸åä¿å­å¨åºæ¯éç½®ä¸­ã
éæå¹³è¡åå¸®å©å¨ãåçåå¸®å©å¨ãç¹åæºå¸®å©å¨ãç©å½¢åå¸®å©å¨ãèåç¯å¸®å©å¨ï¼éç¨äºä»¶é©±å¨æ¹å¼ï¼ä¸åå¯¹ç¼è¾å¨ä¸¥éä¾èµã
æ´çæä»¶å¤¹ç»æãéååå²é¢æ¿æ¨¡åï¼å½»åºå é¤è¦ååº¦é«çOutlineræ§ä»¶ã
è±æç¿»è¯ä¼åã
æ°å¢åºæ¯ä¸é®å¯¼åºåè½ï¼èªå¨åæåºæ¯æéæ¨¡ååèµæºï¼æææéèµæºæ¾å¨/temp/yyyyMMddHHmmssæä»¶å¤¹ã
å¯¼åºä¸å¸¦èµæºçç¼è¾å¨åè½ã
éæ°åå¸äºæ¼ç¤ºé¡¹ç®ï¼Gitee GitHub
ä¿®å¤æ¸²æå¨è®¾ç½®ä¸­ï¼é´å½±ãÎ³è¾å¥ãÎ³è¾åºãÎ³å å­è®¾ç½®æ æbugã
å¹³é¢ä¸ç¹ãçº¿ãå·æ¶å·¥å·ä¸æ¬¡åªè½ç»å¶ä¸ä¸ªã
ä¿®å¤è¡¥é´å¨ç»æ æ³æ­æ¾é®é¢ã

v0.1.6

åå¸æ¥æï¼2019å¹´3æ10æ¥
æ´æ°æ¥å¿ï¼


ä½¿ç¨xtype.jsï¼éç¨éä¾µå¥å¼å¼åæ¹å¼éæUIæ¡æ¶ã
ä¸»æ¡æ¶ä½¿ç¨ç»å¯¹å®ä½éæ°å¸å±ã
åºé¨é¢æ¿æ¯ææå¤§ååè¿åã
åºé¨é¢æ¿æ¾ç¤ºèµæºç»è®¡ä¿¡æ¯ã
æéæ´çå¤§éè´´å¾åæ¨¡åï¼å¹¶è¿è¡åç±»ã
æ´çè´´å¾å·¥å·ã
æ´çæ¨¡åå·¥å·ã
æ´çç¼©ç¥å¾å·¥å·ã
æ·»å ç¹åæºï¼é»è®¤ä¸åæ·»å åçååæã
æ·»å åçåï¼é»è®¤ä¸åæ·»å å¤©ç©ºçã
æ·»å ç©å½¢åï¼é»è®¤ä¸åæ·»å ç©å½¢ç½è²å±å¹ã
ç±äºåæ¥çéä¸­æææ¯ä½¿ç¨åæå¤çå®ç°çï¼äº§çäºä¸¥éæ§è½æèåé¯é½¿ãæä»¥ç¨æ³çº¿æ¤åºåæ¨¡æ¿æµè¯çæ¹æ³éæ°å®ç°éä¸­ææã
éååçéä¸­ææä¸åäº§çé¯é½¿ï¼ä¸é»è®¤å¼å¯å¿«éæé¯é½¿(FXAA)åè½ï¼æé«äºæ§è½ãæ§åºæ¯è¯·å¨åºæ¯å±æ§ä¸­åæ¶å¾éå¿«éè¿ä¼¼æé¯é½¿(FXAA)ï¼å¹¶éæ°ä¿å­ã
é»è®¤å¯ç¨æ¶ä¸åå è½½ä»»ä½åæå¤ç(postprocessing)ç¸å³çè²å¨åç¹æç±»åºï¼æé«å è½½éåº¦ã
ä¿®å¤åå»ºèæ¬æ³¨éæªæ±åbugã
æå åºé¨é¢æ¿åè½ã
éååºæ¯æ ç¶å¾æ§ä»¶ï¼æ¯ææå ãæå¨ãéä¸­ã
ç¹å»åºæ¯éä¸­æ¨¡åæ¶ï¼åºæ¯æ ç¶å¾ä¼åéä¸­æ´ä¸ªæ¨¡åï¼èä¸æ¯æ¨¡åçä¸é¨åï¼èä¸ä¼èªå¨å±å¼å¹¶æ»å¨å°æéæ¨¡åã

v0.1.5

åå¸æ¥æï¼2019å¹´2æ23æ¥
æ´æ°æ¥å¿ï¼


çº¿æ®µãCatmullRomæ²çº¿ãäºæ¬¡è´å¡å°æ²çº¿ãä¸æ¬¡è´å¡å°æ²çº¿ãæ¤­åæ²çº¿å¯è§åç¼è¾ãä¿å­åè½½å¥ã
ä¿®å¤æ¶é´è½´ä¸çå¨ç»æ æ³æå¨çbugã
ä¿®å¤æ æ³å¨åºæ¯æ ç¶è§å¾å°ç©ä½æå¨å°ç»ä¸çbugã
åºæ¬å ä½ä½é½æ¯æå¤å±åµå¥ï¼å¯ä»¥æ­£å¸¸ä¿å­è½½å¥ã
ä¿®å¤è§è§æ§ä»¶å°ºå¯¸è®¡ç®bugã
ä¿®å¤è§è§æ§ä»¶å¯è½è¢«å¶ä»ç©ä½é®æ¡çbugã

v0.1.4

åå¸æ¥æï¼2019å¹´2æ11æ¥
æ´æ°æ¥å¿ï¼


æ°å¢ä¸ä¸ªæç¤ºæ¹åçæ§ä»¶ã
æ°å¢çº¿æ®µãCatmullRomæ²çº¿ãäºæ¬¡è´å¡å°æ²çº¿ãä¸æ¬¡è´å¡å°æ²çº¿ãæ¤­åæ²çº¿ã(æä¸æ¯æä¿å­)

v0.1.3

åå¸æ¥æï¼2019å¹´1æ28æ¥
æ´æ°æ¥å¿ï¼


å¤è¯­è¨æ¯æï¼æ¯æä¸­æåè±æï¼æ¯æè¯­è¨å¨æåæ¢ã
æ°å¢æ²çº¿å ä½ä½ã

v0.1.2

åå¸æ¥æï¼2019å¹´1æ11æ¥
æ´æ°æ¥å¿ï¼


åºæ¯æ°å¢çæ¬æ§å¶ãåºæ¯è¡¨ä»ä¿å­ææ°åºæ¯ï¼åå²æ°æ®ä¿å­å¨ åºæ¯åç§°_historyè¡¨ä¸­ã
ä¿å­æè´¨èªå¨çææè´¨çç¼©ç¥å¾ã
ä¿å­è½½å¥æå¡ç«¯æ¨¡åä¿®æ¹åçæè´¨ã
æ­£æ¹ä½ãåå½¢ãåæ±ä½ãäºåé¢ä½ãéæ¯ãå¹³é¢ãçä½ãè¶å£¶ãè½®èãçº½ç»ãå è½½æ¨¡åé½æ¯æåä½ç»ä»¶ãæ¯æå¯è§åè®¾ç½®ç¢°æä½å½¢ç¶ï¼æ­£æ¹ä½ãçä½ï¼ãè´¨éåæ¯æ§ã
æ°å¢æ­£æ¹ä½åçä½ç©çå½¢ç¶å¸®å©å¨ã

v0.1.1

åå¸æ¥æï¼2018å¹´12æ30æ¥
æ´æ°æ¥å¿ï¼


ä¿®å¤mmdå¨ç»åé³é¢ä¸åæ­¥é®é¢ãæ¯æå¤ä¸ªmmdæ¨¡åä¸æ¨¡åå¨ç»ãç¸æºå¨ç»åæ­¥ã
æ°å¢ç¹éµåç¹æãé¢è²åç§»ç¹æãæ®å½±ç¹æãèæ¯èåãå¿«éè¿ä¼¼æé¯é½¿(FXAA)ãæ¯åºç¹æãåè²è°ç¹æãå¨å±æé¯é½¿(SSAA)ãåç´ ç¹æãå¯æ©å±ç¯å¢åé®æ¡(SAO)ãå¤ééæ ·æé¯é½¿(SMAA)ãå±å¹ç©ºé´ç¯å¢åé®è½(SSAO)ãæ¶é´æé¯é½¿(TAA)ã
æ°å¢ç²å­ãé¢è®¾ä½ãè§è²é¢æ¿ãï¼ææªå®ç°å·ä½åè½ï¼

v0.1.0

åå¸æ¥æï¼2018å¹´12æ15æ¥
æ´æ°æ¥å¿ï¼


éæ°æ¢³çæ¨¡åå¯¼å¥åè½ãç®åæ¯æ3dsã3mfãamfãassimp(anim)ãawdãbabylonãbvh(anim)ãcolladaãctmãdracoãfbx(anim)ãgcodeãgltf(anim)ãjs(anim)ãjson(anim)ãkmzãlmesh(anim)ãmd2ãmmd(anim)ãnrrdãobjãpcdãpdbãplyãprwmãsea3d(anim)ãstlãvrmãvrmlãvtkãx 31ç§3Dæä»¶æ ¼å¼ï¼å¸¦animçè¡¨ç¤ºæ¯æå¨ç»ãå¤ç§3Dæä»¶åæ¶æ¯æjsonåäºè¿å¶æ ¼å¼ãmmdæä»¶åæ¶æ¯æpmdåpmxæ ¼å¼ï¼æ¯ævmdæ ¼å¼çæ¨¡ååç¸æºå¨ç»ãå®ä¹æ¯å¯ä¸æ¯ælmesh(lolkingç½ç«lolæ¨¡å)çç¼è¾å¨ã
æ­æ¾å¨æ°å¢ç¬¬ä¸è§è§æ§å¶å¨ãé£è¡æ§å¶å¨ãè½¨éæ§å¶å¨ãæééå®æ§å¶å¨ãè½¨è¿¹çæ§å¶å¨5ç§æ§å¶å¨ï¼å¨ç¸æºé¢æ¿è®¾ç½®ã
åºæ¯é¢æ¿ï¼ç¼è¾åºæ¯åç±»ï¼æ ¹æ®ç±»å«ãåç§°ãå¨æ¼ãæ¼é³é¦å­æ¯å®æ¶è¿æ»¤ã
æ¨¡åé¢æ¿ï¼ç¼è¾æ¨¡ååç±»ï¼æ ¹æ®ç±»å«ãåç§°ãå¨æ¼ãæ¼é³é¦å­æ¯å®æ¶è¿æ»¤ã
è´´å¾é¢æ¿ï¼ç¼è¾è´´å¾åç±»ï¼æ ¹æ®ç±»å«ãåç§°ãå¨æ¼ãæ¼é³é¦å­æ¯å®æ¶è¿æ»¤ã
æè´¨é¢æ¿ï¼ç¼è¾æè´¨åç±»ï¼æ ¹æ®ç±»å«ãåç§°ãå¨æ¼ãæ¼é³é¦å­æ¯å®æ¶è¿æ»¤ã
é³é¢é¢æ¿ï¼ç¼è¾é³é¢åç±»ï¼æ ¹æ®ç±»å«ãåç§°ãå¨æ¼ãæ¼é³é¦å­æ¯å®æ¶è¿æ»¤ã
æè´¨ç»ä»¶ï¼æ°å¢ä¿å­æè´¨åä»æè´¨é¢æ¿éæ©æè´¨åè½ã
çº¹çãéæçº¹çãå¹å¸çº¹çãæ³çº¿çº¹çãç½®æ¢çº¹çãç²ç³çº¹çãéå±çº¹çãç¯å¢çº¹çãåç§çº¹çãé®æ¡çº¹çãååçº¹çä»è´´å¾é¢æ¿éæ©è´´å¾åè½ã
å é¤ä¸ä¸ªçæ¬åºæ¯çªå£ãæ¨¡åçªå£ãè´´å¾çªå£ãé³é¢çªå£ã

v0.0.9

åå¸æ¥æï¼2018å¹´11æ25æ¥
æ´æ°æ¥å¿ï¼


æ°å¢å¸æå¸¦å¨ç»ã
gltfæ¨¡åå¯¼å¥å¸¦å¨ç»ã
skinned morph(*.js)æ¨¡åå¯¼å¥å¸¦å¨ç»ã(æ°çthree.jsç¤ºä¾ä¸­å·²ç»ç§»é¤è¯¥æ¨¡åã)
å¹³é¢ç»ç¹å·¥å·ã
å¹³é¢ç»çº¿å·¥å·ã
å¹³é¢è´´è±å·¥å·ã
éä¸­ç©ä½ææä¼åã

v0.0.8

åå¸æ¥æï¼2018å¹´10æ27æ¥
æ´æ°æ¥å¿ï¼


ç¼è¾å¨ææ¡£æ´æ°ã
ç«ä½è´´å¾ä¸ä¼ æå¡ç«¯ï¼å¹¶å¯è®¾ç½®ä¸ºåºæ¯èæ¯ã
ææåºæ¯ä¸é®åå¸éæç½ç«ï¼ä¾¿äºé¨ç½²å°GitHub Pagesæå¡ä¸ã
ææå°å½¢ç»ä»¶ãåºåååååºååï¼å¹¶å¯å¨æ­æ¾å¨ä¸­å±ç¤ºã
ä¸ä¼ mp4è§é¢è´´å¾ï¼å¹¶å¯ä»¥è®¾ç½®å°æè´¨ä¸ï¼å¨ä¸ç»´åºæ¯ä¸­æ­æ¾è§é¢ã
å¢å æ°´ç»ä»¶ã

v0.0.7

åå¸æ¥æï¼2018å¹´10æ14æ¥
æ´æ°æ¥å¿ï¼


åºæ¯ãæ¨¡åãçº¹çãé³é¢ãmmdèµæºç¼è¾åè½ï¼å¯ä¸ä¼ é¢è§å¾ã
æè´¨çº¹çå±æ§ç¼è¾åè½ã
æ­æ¾å¨éæ°æ¶æã
ç²å­åå°å¨ãå¤©ç©ºãç«ç°ãçä¿å­ãè½½å¥ãæ­æ¾ä¼åã
åä½ç»ä»¶ä¸åé»è®¤æ·»å ï¼æ¹ä¸ºä»ç»ä»¶èåä¸­æå¨æ·»å ã

v0.0.6

åå¸æ¥æï¼2018å¹´9æ30æ¥
æ´æ°æ¥å¿ï¼


æä¾è¡¥é´å¨ç»æ¯æãå¯ä»¥å¨æ¶é´è½´ä¸å¯è§åä¿®æ¹è¡¥é´å¨ç»ï¼å¹¶å¨æ­æ¾å¨ä¸­æ­æ¾ã
æ°å¢ä¸ä¼ mmdæ¨¡åï¼pmdåpmxæ ¼å¼ï¼åmmdå¨ç»ï¼å¯ä»¥å¨æ­æ¾å¨ä¸­æ­æ¾ã
æ°å¢ä¸ä¼ lmeshæ¨¡åï¼å¯å¨æ­æ¾å¨ä¸­æ­æ¾ã
åºæ¬å ä½ä½ãåæºãå°å½¢å°è£ï¼ä¾¿äºè¿ä¸æ­¥å¼åã

v0.0.5

åå¸æ¥æï¼2018å¹´9æ16æ¥
æ´æ°æ¥å¿ï¼


å¸å±ä¿®æ¹ï¼å³ä¾§æ¹ä¸ºä¸¤æ ï¼å·¦è¾¹æ æä¾åºæ¯å±æ¬¡å¾åjsèæ¬ç®¡çåè½ï¼å³è¾¹æ æ¯å±æ§ãè®¾ç½®ååå²é¢æ¿ã
å¨ç¼è¾åºæ¯ä¸æ¹æ°å¢å¨ç»ç¼è¾ï¼æªå®æï¼ï¼å¹¶ææ¥å¿æ¥çç§»å¨å°è¿éã
å±æ§é¢æ¿ç»ä»¶åæ¹é ï¼æ°å¢åºæ¬ä¿¡æ¯ãç¸æºãå ä½ä½ãåæºãæè´¨ãç²å­åå°å¨ãç©çéç½®ãåºæ¯ãå½±å­ã
ä½ç§»ãé³é¢çå¬å¨ãèæ¯é³ä¹ç­å¤ä¸ªç»ä»¶ã
èæ¯é³ä¹æ¯æä¿å­è½½å¥ï¼æä¾é³é¢ç®¡çã
ä¿®å¤ç¼è¾çè²å¨ç¨åºåè½ï¼å®æ¶æ¥ççè²å¨ææã
æ°å¢è¶å£¶åæ°ç¼è¾ç»ä»¶ã
åç§å ä½ä½é½å¯ä»¥å¼å¯åå°ã

v0.0.4

åå¸æ¥æï¼2018å¹´9æ2æ¥
æ´æ°æ¥å¿ï¼



èæ¬ç¼è¾ä¼åï¼èæ¬ä¸åè·ç©ä½ç»å®ï¼å¯ä»¥è·åºæ¯ä¸èµ·ä¿å­è½½å¥ï¼æä¾javascriptãvertexShaderãfragmentShaderãprogramInfoç¤ºä¾èæ¬ãèªå®ä¹èæ¬æ¯æinitãstartãupdateãstopãonClickãonDblClickãonKeyDownãonKeyUpãonMouseDownãonMouseMoveã
onMouseUpãonMouseWheelãonResize 13ç§äºä»¶ã


èæ¯æ¯æçº¯è²ãèæ¯å¾çãç«ä½è´´å¾ä¸ç§ä¸åç±»åï¼å¯ä»¥ä¿å­è½½å¥ã


æ°å¢ç½æ ¼ãç¸æºãç¹åæºãå¹³è¡åãèåç¯ãåçåãç©å½¢åãå¸®å©å¨ãéª¨éª¼9ç§å¸®å©å¨çæ¾ç¤ºéèè®¾ç½®ã


æ°å¢æ¥å¿é¢æ¿ã


å¹³æ¿æ°å¢éé¢ç¹æã


v0.0.3

åå¸æ¥æï¼2018å¹´8æ15æ¥
æ´æ°æ¥å¿ï¼


ä½¿ç¨asp.netå¼åwebæå¡ç«¯ï¼ä½¿ç¨MongoDBä¿å­æ¨¡åååºæ¯æ°æ®ã
15ç§æ ¼å¼3Dæ¨¡åçä¸ä¼ ï¼å¹¶å¯ä»¥ä¿å­å°åºæ¯ã
åºæ¯çåå»ºãä¿å­ãè½½å¥ã
ç»ã12ç§åç½®å ä½ä½ã5ç§åæºå¯ä»¥ä¿å­åºæ¯å¹¶è½½å¥ã
85ç§three.jså¯¹è±¡çåºåååååºååã

v0.0.2

åå¸æ¶é´ï¼2018å¹´6æ9æ¥
æ´æ°æ¥å¿ï¼


ä½¿ç¨rollupéæthree.jsèªå¸¦ç¼è¾å¨çä»£ç ã

v0.0.1

åå¸æ¶é´ï¼2017å¹´6æ21æ¥
æ´æ°æ¥å¿ï¼


ä¸»è¦å®æthree.jsèªå¸¦ç¼è¾å¨çç¿»è¯ã

ç¸å³é¾æ¥

Three.jså®ç½ï¼https://threejs.org/
LOLæ¨¡åæ¥çå¨ï¼https://github.com/tengge1/lol-model-viewer
æ¨¡åä¸è½½1ï¼https://sketchfab.com/3d-models?features=downloadable
æ¨¡åä¸è½½2ï¼https://www.3dpunk.com/work/index.html?category=downloadable

",216
JustusAvramenko/delenda_est,JavaScript,"Check out 0ad.mod.io for the latest Delenda Est release for the official releases of 0 A.D.
This repository is a work in progress and is not guaranteed to work with the latest ""release"" of 0 A.D. Rather, it is more compatible with the ""SVN"" or ""Development"" version of the game, which is bleeding edge.
",18
jpd002/Play-,C++,"Play!
Play! is an attempt to create a PlayStation 2 emulator for Windows, macOS, UNIX, Android & iOS platforms.
Compatibility information is available on the official Compatibility Tracker. If a specific game
doesn't work with the emulator, please create a new issue there.
For more information, please visit purei.org.
Project Dependencies
External Libraries

boost

Repositories

Play! Dependencies
Play! Framework
Play! CodeGen
Nuanceur

Building
General Setup
You can get almost everything needed to build the emulator by using the Play! Build project. You can also checkout every repository individually if you wish to do so, but make sure your working copies share the same parent folder.
In the end, your setup should look like this:
C:\Projects

CodeGen
Dependencies
Framework
Nuanceur
Play

Common Building Instructions
First you'd need to clone Play-Build which provides you with the needed subprojects required to build Play!.
Then setup the submodules and the dependency submodule(s) too.
git clone https://github.com/jpd002/Play-Build.git
cd Play-Build
git submodule update -q --init --recursive
git submodule foreach ""git checkout -q master""
cd Dependencies
git submodule update --init
cd ..

Building for Windows
The Easiest way to build the project on windows is to open Qt Creator and directed it to the cmake file in /project/dir/Play-/CMakeLists.txt.
You can also build the project using Visual Studio or cmdline, for that you must follow these isnstruction:
To build for Windows you will need to have CMake installed on your system.
cd Play
mkdir build
cd build

# Not specifying -G would automatically generate 32-bit projects.
cmake .. -G""Visual Studio 15 2017 Win64"" -DCMAKE_PREFIX_PATH=""C:\Qt\5.10.1\msvc2017_64"" -DUSE_QT=YES

You can now build the project by opening the generated Visual Studio Solution or continue through cmdline:
cmake --build . --config Release

Note: --config can take any of Release/Debug/RelWithDebInfo
Building for macOS & iOS
If you don't have CMake installed on your system, you can install it using brew with the following command: brew install cmake.
There are two ways to generate a build for macOS, either by using makefiles or by using Xcode.
cd Play
mkdir build
cd build

# Not specifying -G would automatically pick Makefiles
cmake .. -G""Xcode"" -DCMAKE_BUILD_TYPE=Release -DCMAKE_PREFIX_PATH=~/Qt/5.1.0/clang_64/
cmake --build . --config Release
# OR
cmake .. -G""Unix Makefiles"" -DCMAKE_BUILD_TYPE=Release -DCMAKE_PREFIX_PATH=~/Qt/5.1.0/clang_64/
cmake --build .

To generate a build for iOS, you will need to add the following parameters to the CMake invocation:
-DCMAKE_TOOLCHAIN_FILE=../../../Dependencies/cmake-ios/ios.cmake -DTARGET_IOS=ON
iOS build doesnt use Qt so please omit -DCMAKE_PREFIX_PATH=...
Note: while iOS build can be generated with Makefiles, they will not be FAT binaries.
Example:
cmake .. -G""Xcode"" -DCMAKE_TOOLCHAIN_FILE=../../../Dependencies/cmake-ios/ios.cmake -DTARGET_IOS=ON
Building for UNIX
if you dont have cmake or openal lib installed, you'll also require Qt (preferably version 5.6) you can install it using your OS packaging tool, e.g ubuntu apt install cmake libalut-dev
on UNIX systems there is 3 ways to setup a build, using qt creator, makefile or Ninja


QT Creator

Open Project -> Play/CMakeLists.txt



Makefile/Ninja


cd Play
mkdir build
cd build

# Not specifying -G would automatically pick Makefiles
cmake .. -G""Unix Makefiles"" -DCMAKE_BUILD_TYPE=Release -DCMAKE_PREFIX_PATH=/opt/qt56/
cmake --build .
# OR
cmake .. -G""Ninja"" -DCMAKE_PREFIX_PATH=/opt/qt56/
cmake --build . --config Release

Note CMAKE_PREFIX_PATH refers to the qt directory containing bin/libs folder, the above example uses a backport repo to install qt5.6 on trusty, if you install qt from qt offical website, your CMAKE_PREFIX_PATH might look like this ~/Qt5.6.0/5.6/gcc_64/
Building for Android
Building for Android has been tested on macOS and UNIX environments.
Android can be built using Android Studio or through Gradle.

Android Studio:

Files->Open Projects->Directory To Play/build_android
Install NDK using sdk manager
edit/create Play/build_android/local.properties

OSX: add a newline ndk.dir=/Users/USER_NAME/Library/Android/sdk/ndk-bundle replacing USER_NAME with your macOS username
UNIX: add a newline ndk.dir=~/Android/Sdk/ndk-bundle
Windows: add a newline C:\Users\USER_NAME\AppData\Local\Android\sdk\ndk-bundle
Please Leave an empty new line at the end of the file





Note, these examples are only valid if you installed NDK through Android Studio's SDK manager.
Otherwise you must specify the correct location to Android NDK.
Once this is done, you can start the build.

Gradle: Prerequisite Android SDK & NDK (Both can be installed through Android Studio)

edit/create Play/build_android/local.properties

OSX:

add a newline sdk.dir=/Users/USER_NAME/Library/Android/sdk replacing USER_NAME with your macOS username
add a newline ndk.dir=/Users/USER_NAME/Library/Android/sdk/ndk-bundle replacing USER_NAME with your macOS username


UNIX:

add a newline sdk.dir=~/Android/Sdk
add a newline ndk.dir=~/Android/Sdk/ndk-bundle


Windows:

add a newline sdk.dir=C:\Users\USER_NAME\AppData\Local\Android\sdk
add a newline ndk.dir=C:\Users\USER_NAME\AppData\Local\Android\sdk\ndk-bundle


Please Leave an empty new line at the end of the file





Note, these examples are only valid if you installed NDK through Android Studio's SDK manager.
Otherwise you must specify the correct location to Android NDK.
Once this is done, you can start the build.
cd Play/build_android
sh gradlew assembleDebug

about Release/Signed builds.
Building through Android Studio, you have the option to âGenerate Signed APKâ.
Building through Gradle, you must create a text file Play/build_android/keystore.properties and add the following properties to it, storeFile,storePassword,keyAlias,keyPassword.
E.g of keystore.properties
storeFile=/location/to/my/key.jks
storePassword=mysuperhardpassword
keyAlias=myalias
keyPassword=myevenharderpassword

Please Leave an empty new line at the end of the file
cd Play/build_android
sh gradlew assembleRelease
# or on Windows
gradlew.bat assembleRelease

",690
openstack/openstack,Python,"OpenStack Tracking Repo
zuul gates all of the contained projects in an effective single
timeline. This means that OpenStack, across all of the projects, does
already have a sequence of combinations that have been explicitly
tested, but it's non-trivial to go from a single commit of a particular
project to the commits that were tested with it.
Gerrit's submodule tracking feature will update a super project every
time a subproject is updated, so the specific sequence created by zuul
will be captured by the super project commits.
This repo is intended to be used in a read-only manner. Any commit in this
repo will get a collection of commits in the other repos that have
explicitly been tested with each other, if that sort of thing is important
to you.
",3052
TravelMapping/UserData,None,"UserData
Repository for User Files
.list files for TravelMapping users are stored here, and are retrieved from here for site updates.
TM users are welcome to update their own lists by submitting pull requests through to this repository or to submit list file updates by email to travmap@teresco.org to be placed here by the site admins.
See http://travelmapping.net and http://forum.travelmapping.net/ for more information about Travel Mapping.
",8
openstack/nova,Python,"Team and repository tags



OpenStack Nova
OpenStack Nova provides a cloud computing fabric controller, supporting a wide
variety of compute technologies, including: libvirt (KVM, Xen, LXC and more),
Hyper-V, VMware, XenServer, OpenStack Ironic and PowerVM.
Use the following resources to learn more.

API
To learn how to use Nova's API, consult the documentation available online at:

Compute API Guide
Compute API Reference

For more information on OpenStack APIs, SDKs and CLIs in general, refer to:

OpenStack for App Developers
Development resources for OpenStack clouds


Operators
To learn how to deploy and configure OpenStack Nova, consult the documentation
available online at:

OpenStack Nova

In the unfortunate event that bugs are discovered, they should be reported to
the appropriate bug tracker. If you obtained the software from a 3rd party
operating system vendor, it is often wise to use their own bug tracker for
reporting problems. In all other cases use the master OpenStack bug tracker,
available at:

Bug Tracker


Developers
For information on how to contribute to Nova, please see the contents of the
CONTRIBUTING.rst.
Any new code must follow the development guidelines detailed in the HACKING.rst
file, and pass all unit tests.
Further developer focused documentation is available at:

Official Nova Documentation
Official Client Documentation


Other Information
During each Summit and Project Team Gathering, we agree on what the whole
community wants to focus on for the upcoming release. The plans for nova can
be found at:

Nova Specs

",2469
Ultimate-Hosts-Blacklist/adblock.mahakala.is,Python,"About adblock.mahakala.is


About Ultimate-Hosts-Blacklist
Ultimate-Hosts-Blacklist serve a place to test and keep a track on each input sources that are present into Ultimate Hosts Blacklist.
As Ultimate Hosts Blacklist grew up it became impossible to test the whole repository, as it takes weeks to finish. That's why we use the GitHub organization system in order to create different repository for each list that are present into Ultimate Hosts Blacklist.

About PyFunceble
PyFunceble like Funceble is A tool to check domains or IP availability by returning 3 possible status: ACTIVE, INACTIVE or INVALID.
It also has been described by one of its most active user as:

[An] excellent script for checking ACTIVE, INACTIVE and EXPIRED domain names.

If you need further informations about PyFunceble or Funceble please report to our Wiki page and/or if you don't find any answer feel free to create an issue into one of the Dead Hosts's or Py-Funceble's repositories.
About the status returned by PyFunceble
For an up to date version of this part please report to the Status section of our Wiki.
ACTIVE
This status is returned when one of the following cases is met:


We can extract the expiration date from Lookup().whois().

Please note that we don't check if the date is in the past.



Lookup().nslookup() don't return server can't find domain-name.me: NXDOMAIN.


HTTOCode().get() return one the following code [100, 101, 200, 201, 202, 203, 204, 205, 206].


INACTIVE
This status is returned when all the following cases are met:

We can't extract the expiration date from Lookup().whois().
Lookup().nslookup() return server can't find domain-name.me: NXDOMAIN.

INVALID
This status is returned when the following case is met:


Domain extension has an invalid format or is unregistered in IANA Root Zone Database.

Understand by this that the extension is not present into the iana-domains-db.json file.



",2
alexandradilja/MonsterHousing,HTML,"MonsterHousing
",2
villares/sketch-a-day,JavaScript,"
sketch-a-day
one visual idea a day
Hi! I'm Alexandre Villares, welcome!
I try to make one small program (sketch) a day. I usually put the code here: github.com/villares/sketch-a-day
Feel free to contact me regarding licenses to use my work, teaching opportunities, consulting or other projects.
You may also support my artistic work, open source teaching resources and research with donations :)
Get updates from my sort-of-weekly newsletter: [sketch-mail]

2018

2019


sketch_190511b [Py.Processing]


sketch_190510a [Py.Processing]


sketch_190509a [Py.Processing]
Ugly but works :)


sketch_190508a [code for Py.Processing]
Back unfolding solids... 2D faces missing.


Using pyp5jsto run on your browser
sketch_190507a [code for pyp5js]


Old sketch tweaked to port tomorrow.


Using pyp5js to run on your browser
sketch_190505a
[code for pyp5js]
[code for Py.Processing]


Using pyp5jsto run on your browser
sketch_190504a code:pyp5js


sketch_190503a [Py.Processing]


sketch_190502a [Py.Processing]


sketch_190501a [Py.Processing]


sketch_190430b [Py.Processing]


sketch_190429b [Py.Processing]


sketch_190428b [Py.Processing]
Mixing in my var_bar() circle/circle tangent shape


sketch_190427b [Py.Processing]
Now based on 4 quaternary digits (256 variations). Each digit can be 0, 1, 2, or 3. And zero means no shape drawn for that layer/position. Still influenced by @arjanvandermeij :)


sketch_190426b [Py.Processing]


sketch_190425b  [Py.Processing]


sketch_190424b [Py.Processing]
Inspired by ""trit"" grids of balanced ternary digits from @arjanvandermeij
(4 ternary digits -> 81 variations)


sketch_190424a [Py.Processing]


sketch_190423a [Py.Processing]
Now I drag any point, inclunding of holes, and remove points.
TODO: Add points; Drag polys.


sketch_190422a [Py.Processing]
Object Oriented remake of the poly editor in progress, in order to have multiple polygons with multiple holes each.


sketch_190421 [Py.Processing]
This clean up and tweak of studies of Design By Numbers alphabet designed by Peter Cho from last year will count as today's sketch :)
Check out the other pieces, pixel and scaleable fonts I created here: http://github.com/villares/DesignByNumbers-alphabet


sketch_190420a [Py.Processing]
Some refactoring and coordinate annotations that I'll use in my classes :)


sketch_190419a [Py.Processing]
Press space-bar to order outer_pts clockwise, and inner_pts anticlockwise (counterclockwise, in the US)


sketch_190418a [Py.Processing]


sketch_190417a [Py.Processing]
Back to the editor... dragging points.


sketch_190416a [Processing Java Mode]
Very simple 3D example


sketch_190415a [Py.Processing]


sketch_190414a [Py.Processing]
Let's unfold some simple extrudes


sketch_190413b [Py.Processing]


sketch_190412a [Py.Processing]


sketch_190411a [Py.Processing]
Now we are talking!
I've got the divided top right, brought back the tabs,
and also found a bug on 190408a (and fixed it)...


sketch_190410a [Py.Processing]
major re-org, still broken...


sketch_190409b [Py.Processing]
Subdivided top! (not quite there yet...)


sketch_190408a [Py.Processing]
With glue tabs!


sketch_190407a [Py.Processing]
Now I can change the base proportions.


sketch_190406a [Py.Processing]
First unfold version ready!


sketch_190405a [Py.Processing]
Almost done!


sketch_190404a [Py.Processing]
Study for a ""Terrain box"" a paper surface ""unit"".


sketch_190403a [Py.Processing]


sketch_190402a [Py.Processing]


sketch_190401b [Py.Processing]


sketch_190331a [Py.Processing]


sketch_190330a [Py.Processing]


sketch_190329a [Py.Processing]


sketch_190328a [Py.Processing]


sketch_190327a [Py.Processing]


sketch_190326a [Py.Processing]


sketch_190325a [Py.Processing]


sketch_190324a [Py.Processing]
A retake of sketch_190207a + work from sketch_190321 :)
Will stall sometimes...
as there is an unsafe while loop
selecting pointing nodes... (also present on 190323)


sketch_190323a [Py.Processing]


sketch_190322a [Py.Processing]


sketch_1903221b [Py.Processing]


sketch_190320a [Py.Processing]


sketch_190319a [Py.Processing]


sketch_190318a [Py.Processing]


sketch_190317a [Py.Processing]


sketch_190316a [Py.Processing]


sketch_190315a [Py.Processing]


sketch_190314a [Py.Processing]


sketch_190313a [Py.Processing]


sketch_190312a [Py.Processing]


sketch_190311a [Py.Processing]


sketch_190310a [Py.Processing]
Refactor and a not very good filling test


sketch_190309a [Py.Processing]
Deque collection for a dynamic history on Z


sketch_190308a [Py.Processing]


sketch_190307a [[Py.Processing](https://villare
s.github.io/como-instalar-o-processing-modo-python/index-EN)]
An graph much like the ones before this, but made invisible, is behind the (virtual) corners of this rounded poly.


sketch_190306a Py.Processing]


sketch_190305a [Py.Processing]
Mais grapholia ;)
Removi parte do cÃ³digo para controle com potenciÃ´metros pois infelizmente a comunicaÃ§Ã£o serial estÃ¡ quebrada neste momento no Processing Modo Python :((


sketch_190304a [Py.Processing]
Grapholia ;)
Retomando um sketch de grafos com 4 parÃ¢metros ajustaveis (via teclado ou potenciÃ´metros ligados em um Arduino)


sketch_190303a [Py.Processing]


sketch_190302a [Py.Processing]


sketch_190301a [Py.Processing]


sketch_190228a [Py.Processing]


sketch_190227a [Py.Processing]


sketch_1tus90226a [Py.Processing]


sketch_190225a [Py.Processing]


sketch_190224a [Py.Processing]


sketch_190223a [Py.Processing]


sketch_190222a [Py.Processing]


sketch_190221a [Py.Processing]


sketch_190220a [Py.Processing]


sketch_190219a [Py.Processing]


sketch_190218a [Py.Processing]


sketch_190217a [Py.Processing]


sketch_190216a [Py.Processing]


sketch_190215a [Py.Processing]


sketch_190214a [Py.Processing]


sketch_190213a [Py.Processing]


sketch_190212a [Py.Processing]


sketch_190211b [Py.Processing]


sketch_190211a [Py.Processing]


sketch_190210c [Py.Processing]
""a"" and ""b"" are Java and Python ports of a C# round corner.


sketch_190209a [Py.Processing]


sketch_190208a [Py.Processing]


sketch_190207a [Py.Processing]


sketch_190206b [Py.Processing]


sketch_190205a [Py.Processing]


sketch_190204a [Py.Processing]


sketch_190203a [Py.Processing]


sketch_190202a [Py.Processing]
Retake of sketch #57 180226 with the variable ""bar"" from yesterday.


sketch_190201a [Py.Processing]


sketch_190131a [Py.Processing]


sketch_190130a [Py.Processing]


sketch_190129a [Py.Processing]


sketch_190128b [Py.Processing]


sketch_190127a [Py.Processing]


sketch_190126a [Py.Processing]


sketch_190125a [Py.Processing]


sketch_190124a [Py.Processing]


sketch_190123a [Py.Processing]


sketch_190122a [Py.Processing]


sketch_190121a [Py.Processing]


sketch_190120a [Py.Processing]


sketch_190119a [Py.Processing]


sketch_190118a [Py.Processing]


sketch_190117b [Py.Processing]


sketch_190116a [Py.Processing]


sketch_190115a [Py.Processing]


sketch_190114a [Py.Processing]


sketch_190113a [Py.Processing]


sketch_190112a [Py.Processing]


sketch_190111a [Py.Processing]


sketch_190110a [Py.Processing]
sketch_190110b [Py.Processing]


sketch_190109a [Py.Processing]


sketch_190108a [Py.Processing]


sketch_190107a [Py.Processing]


sketch_190106a [Py.Processing]


sketch_190105a [Py.Processing]


sketch_190104a [Py.Processing]
Module tweaks


sketch_190103a [Py.Processing]
Made this today, thinking about my new newsletter: [sketch-mail]


[sketch_190102a]https://github.com/villares/sketch-a-day/tree/master/2019/sketch_190102a) [Py.Processing]


sketch_190101a [Py.Processing]
",24
zqlovejyc/SQLBuilder.Core,C#,"SQLBuilder.Core
é¡¹ç®ä»ç»
.NET Standard 2.0çæ¬SQLBuilder
ç äºå°å
https://gitee.com/zqlovejyc/SQLBuilder.Core
",2
powerje/NyanDroid,Java,"Live wallpaper celebrating Ice Cream Nyanwiches. Available on Google Play.
Nyan Droid created by Daniel Sandler.
MMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMM
MMMMMMMMMMMMMMMMNNNNMMMNNNNNNNNNNNNNNNNNNMMMNNNNMMMMMMMMMMMMMMMM
MMMMMMMMMMMMMMMMy++hMMd++++++++++++++++++dMMh++yMMMMMMMMMMMMMMMM
MMMMMMMMMMMMMMMMdyyhhhs//////////////////shhhyydMMMMMMMMMMMMMMMM
MMMMMMMMMMMMMMMMMMMy////////////////////////yMMMMMMMMMMMMMMMMMMM
MMMMMMMMMMMMMMMMyoo+//smmmmmd//////dmmmmms//+ooyMMMMMMMMMMMMMMMM
MMMMMMMMMMMMMMMMs/////ohhdMMN//////hhhNMMs/////sMMMMMMMMMMMMMMMM
MMMMMMMMMMMMMMMMs/////-  :MMN//////`  dMMs/////sMMMMMMMMMMMMMMMM
MMMMMMMMMMMMMyss+//////-:/sss//////:-:oss+/////+ssyMMMMMMMMMMMMM
MMMMMMMMMMMMMo////////////////////////////////////oMMMMMMMMMMMMM
MMMMMMMMMMMMMo////////////////////////////////////oMMMMMMMMMMMMM
MMMMMMMMMMMMMhyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyhMMMMMMMMMMMMM
MMMMNNNNNNMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMNNNNNNNMMMMMMNNNNNNMMMM
MMMNooooooNMMmmmmmmmmmmmmmmmmmmmmmmmmmmmmo/////ommmMMNooooooNMMM
MMMN//////NMMmddddddmmddddddddddmmmdddddd/...../ddmMMN//////NMMM
MMMN//////NMMmdddddNMMNdddddddddMMMdddddd:     :ddmMMN//////NMMM
MMMN//////NMMmddddddmmmdddddddddmmmdddddd:     :ddmMMN//////NMMM
MMMN//////NMMmddddddddddddddddddddddddddd:     :ddmMMN//////NMMM
MMMN//////NMMmdddddddddddmMMMdddddddddddd:     :ddmMMN//////NMMM
MMMN//////NMMmddddddddddddmmmdddddddddddd:     :ddmMMN//////NMMM
MMMN//////NMMmddddddddddddddddddddddddddd:     :ddmMMN//////NMMM
MMMN//////NMMmdddddmMMNdddddddddMMMdddddd:     :ddmMMN//////NMMM
MMMN//////NMMmdddddmNNmdddddddddNNNdddddd:     :ddmMMN//////NMMM
MMMN//////NMMmddddddddddddddddddddddddddd:     :ddmMMN//////NMMM
MMMMddddddMMMmddddddddddddNNNdddddddddddd:     :ddmMMMddddddMMMM
MMMMMMMMMMMMMmdddddddddddmNNNdddddddddddd:     :ddmMMMMMMMMMMMMM
MMMMMMMMMMMMMmddddddddddddddddddddddddddd:     :ddmMMMMMMMMMMMMM
MMMMMMMMMMMMMmdddddmNNmdddddddddNNNdddddd:     :ddmMMMMMMMMMMMMM
MMMMMMMMMMMMMmdddddmMMNdddddddddMMMdddddd:     :ddmMMMMMMMMMMMMM
MMMMMMMMMMMMMmddddddddddddddddddddddddddd+-----+ddmMMMMMMMMMMMMM
MMMMMMMMMMMMMmmmmmmmmmmmmmmmmmmmmmmmmmmmmyoooooymmmMMMMMMMMMMMMM
MMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMM
MMMMMMMMMMMMMMMMMMMdoooooyMMMMMMMMMMMMyooooodMMMMMMMMMMMMMMMMMMM
MMMMMMMMMMMMMMMMMMMh/////oMMMMMMMMMMMMo/////hMMMMMMMMMMMMMMMMMMM
MMMMMMMMMMMMMMMMMMMh/////oMMMMMMMMMMMMo/////hMMMMMMMMMMMMMMMMMMM
MMMMMMMMMMMMMMMMMMMh/////oMMMMMMMMMMMMo/////hMMMMMMMMMMMMMMMMMMM
MMMMMMMMMMMMMMMMMMMh+++++sMMMMMMMMMMMMs+++++hMMMMMMMMMMMMMMMMMMM
MMMMMMMMMMMMMMMMMMMNNNNNNNMMMMMMMMMMMMNNNNNNNMMMMMMMMMMMMMMMMMMM
MMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMM

Licensing
Nyan Droid source is released under the Apache 2.0 license.
dyan.mp3 (droid droid dr-dr-droid audio) created by Jeff Sharkey and released under the CC license.
",9
Lombiq/Lombiq-Orchard-Visual-Studio-Extension,C#,"Lombiq Orchard Visual Studio Extension readme

Visual Studio extension with many features and templates frequently used by  Lombiq developers. Contains Orchard-related as well as generic goodies.
Check out the extension's Readme for more info (it's there and not in the root of the repository so it's also accessible from inside VS).
The project's logo was created by Ulises TJ.
",6
larseggert/iana-assignments,XSLT,"IANA Assignments Mirror
Mirror of the IANA registries. Periodically updated via
rsync -avzH rsync.iana.org::assignments .

from https://www.iana.org/protocols.
For obvious reasons, pull requests are not (currently) accepted.
",3
C4G/BLIS,PHP,"BLIS
C4G Basic Laboratory Information System
How to run BLIS
Clone the repository onto your machine. Download the BLIS runtime files from: [http://blis.cc.gatech.edu/files/BLISRuntime.zip]
Unzip all files from BLISRuntime.zip into the the BLIS/  directory in your repository clone.
Run BLIS.exe to start BLIS.
",13
kazedayo/GaldenApp-v2,Swift,"1080-Green
HKGalden app for iOS written in Swift
This is the branch of my HKGalden app for the upcoming new HKGalden forum by abc(owner of na.cx)
App Store Available Now!
https://itunes.apple.com/us/app/1080-green/id1437419169?l=zh&ls=1&mt=8
Compile to try yourself
You can compile this project using XCode and try it on your iOS device. Before compiling please run 'pod install' command under project diretory. If you don't have cocapods installed in your Mac, please install it from here: https://cocoapods.org
Buy me a coffee
https://paypal.me/kazeteitoku
",2
GovReady/govready-q,Python,"GovReady-Q Compliance Server
The GovReady-Q Compliance Server is an open source GRC platform for highly automated, user-friendly, self-service compliance assessments and documentation. It's perfect for DevSecOps.
GovReady-Q solves the painful compliance bottleneck of needing months to authorize applications that deploy and redeploy in minutes.




ATTENTION!




GovReady-Q software is ""Beta"" software best suited for early adopters needing faster compliance for DevSecOps.



Documentation
Visit our Documentation at govready-q.readthedocs.io.
Read What You Most Need to Know About GovReady-Q.
Using Hosted GovReady-Q
There's nothing to install. Q.GovReady.com is the hosted, multi-tenant version of GovReady-Q.

Visit Q.GovReady.com
Fill out the form ""About your organization"" and ""About you"" to create your account
Don't worry about the Service Levels -- everything's available to everyone during the Beta phase
We'll contact you to help you get started

The hosted version is an excellent solution if have one project/system you are trying to get through NIST SP 800-53 or NIST SP 800-171 compliance, or you are have just trying to pull together a few specific compliance documents like your Privacy Policy or Rules of Behaivor. The hosted service operated by GovReadyÂ® PBC, the company behind GovReady-Q Compliance Server.
If you have questions about if hosted version, email info@govready.com.
Downloading GovReady-Q



Downloading
Where




Current release on Docker
https://hub.docker.com/r/govready/govready-q/


Nightly Build on Docker
https://hub.docker.com/r/govready/govready-q-nightly/


Clone the GitHub repo
https://github.com/govready/govready-q



Installing GovReady-Q



Deployment Guide




Installing on Workstations for Development


Deploying with Docker


Deploying on RHEL 7 / CentOS 7


Deploying on Ubuntu



Support
Join our mailing list and stay informed of developments.
Noteworthy
GovReady-Q is open source and incorporates the emerging OpenControl data standard for reusable compliance content.
License / Credits
This repository is licensed under the GNU GPL v3.

Emoji icons by http://emojione.com/developers/.
Generic server icon by Stock Image Folio from Noun Project.

",27
gdmarmerola/r-tesouro-direto,R,"r-tesouro-direto
ProjeÃ§Ãµes de Investimentos no Tesouro Direto com R
No perÃ­odo recente de alta da taxa de juros e inflaÃ§Ã£o crescente (2014-2015), o Tesouro Direto tem se mostrado uma boa opÃ§Ã£o de investimento. Visualizar a evoluÃ§Ã£o de diversas carteiras hipotÃ©ticas e comparÃ¡-las ao longo do tempo pode ajudar significativamente o investidor a fazer uma alocaÃ§Ã£o de recursos alinhada com seus objetivos. Este pacote usa alguns recursos de web scraping e o pacote grÃ¡fico ggplot2 do R para fazer algumas estimativas e projeÃ§Ãµes de investimentos no tesouro direto.

Modalidades implementadas:

Tesouro Prefixado (LTN)
Tesouro IPCA (NTN-B Principal)
Tesouro IPCA com Juros Semestrais (NTN-B)


NÃ£o-implementadas (to-do):

Tesouro Prefixado com Juros Semestrais (NTN-F)
Tesouro Selic (LFT)


Pacotes necessÃ¡rios:

quantmod: sÃ©ries temporais, modelagem financeira
ggplot2: grÃ¡ficos
rvest: web scraping
reshape2: formataÃ§Ã£o de dataframes
lubridate: trabalhar com datas



Funcionamento
O objetivo do pacote Ã© criar sÃ©ries temporais a partir de informaÃ§Ãµes de investimentos. SÃ£o utilizadas duas funÃ§Ãµes bÃ¡sicas:
proj_tesdir: criar sÃ©rie temporal de investimento
proj_tesdir(valor_ini, juros_anuais, data_ini, data_fim)


valor_ini: montante inicial do investimento
juros_anuais: nÃºmero que represente a mÃ©dia prevista dos juros no perÃ­odo, ou lista que associe um valor de juros por ano (mais na seÃ§Ã£o Funcionalidades)
data_ini, data_fim: datas de inÃ­cio e fim do investimento

calcular_cupons: calcular pagamento de cupons
calcular_cupons(serie_td, tx_cupom, data_ini, data_fim)


serie_td: sÃ©rie temporal do principal
juros_anuais: juros associados ao pagamento de cupons
data_ini, data_fim: datas de inÃ­cio e fim do investimento

Para entender melhor como essas funÃ§Ãµes sÃ£o utilizadas segue um exemplo de utilizaÃ§Ã£o.
Exemplo de utilizaÃ§Ã£o
Um script de exemplo Ã© fornecido no repositÃ³rio. Para comeÃ§ar a usar as funÃ§Ãµes, devemos compilar o script base:
# colocar aqui o working directory
# windows: usar barras duplas -> '\\'
setwd('your-path/r-tesouro-direto')

# compilar o script base
source('your-path/td-base.r')

Utilizando as funÃ§Ãµes mencionadas anteriormente, podemos estimar projeÃ§Ãµes para as modalidades disponÃ­veis de investimento.
Tesouro Prefixado
Uma maneira organizada de gerenciar as informaÃ§Ãµes Ã© criar um objeto list() e utilizar suas entradas como argumentos da funÃ§Ã£o proj_tesdir:
### Tesouro Prefixado (LTN) ###

# valor inicial: 3000, taxa prefixada 13% a.a.
# duracÃ£o do investimento: 1 ano (01-01-2016 atÃ© 01-01-2017)
prefix_2017 = list(montante_ini = 3000, 
                   tx_anual = 13,
                   data_ini = ""2016-01-01"",
                   data_venc = ""2017-01-01"")

# cria uma sÃ©rie temporal (xts) com a projecÃ£o do investimento
serie_prefix_2017 = proj_tesdir(prefix_2017[['montante_ini']],
                                prefix_2017[['tx_anual']],
                                prefix_2017[['data_ini']],
                                prefix_2017[['data_venc']])


Tesouro IPCA
Aqui Ã© utilizada a funÃ§Ã£o extrair_ipca() para buscar o valor (12 meses) do IPCA no site do Valor EconÃ´mico. Ã importante ressaltar que dessa forma existe a aproximaÃ§Ã£o que o IPCA nÃ£o mudarÃ¡ ao longo do investimento. PorÃ©m, Ã© possÃ­vel definir uma lista com um valor de IPCA por ano, para um ajuste mais fino (como mostrado na seÃ§Ã£o Funcionalidades).
### Tesouro IPCA (NTN-B Principal) ###

# vencimento em 2019, montante inicial de 10000, taxa de 6%
ipca_2019 = list(montante_ini = 10000, 
                 tx_anual = 6.00 + extrair_ipca(), # 6% rendimento real
                 data_ini = ""2016-01-01"",
                 data_venc = ""2019-05-15"")

# sÃ©rie temporal
serie_ipca_2019 = proj_tesdir(ipca_2019[['montante_ini']],
                              ipca_2019[['tx_anual']],
                              ipca_2019[['data_ini']],
                              ipca_2019[['data_venc']])

Tesouro IPCA com Juros Semestrais
Nesta modalidade hÃ¡ o pagamento de juros semestrais. Portanto, no objeto list() Ã© colocada uma entrada tx_cupom para representar os juros semestrais. Ao final, sÃ£o criadas duas sÃ©ries, uma representando o montante principal e outra o pagamento de cupons.
### Tesouro IPCA com cupons semestrais (NTN-B) ###

# supondo VNA de 3000 e compra de 2 unidades: 6000
vna_exemplo = 3000

ipca_2020 = list(montante_ini = 2*vna_exemplo,
                 tx_anual = extrair_ipca(),
                 tx_cupom = 6,
                 data_ini = ""2016-02-01"",
                 data_venc = ""2020-08-15""
                 )

# sÃ©rie temporal
serie_ipca_2020 = proj_tesdir(ipca_2020[['montante_ini']],
                              ipca_2020[['tx_anual']],
                              ipca_2020[['data_ini']],
                              ipca_2020[['data_venc']])

# calcula os cupons com base na sÃ©rie principal
ipca_2020_cups = calcular_cupons(serie_ipca_2020,
                                 ipca_2020[['tx_cupom']],
                                 ipca_2020[['data_ini']],
                                 ipca_2020[['data_venc']])

Fluxo de caixa
ApÃ³s criar as sÃ©ries temporais, podem ser criadas mais duas sÃ©ries de apoio:

imobilizado: representa o total investido
resgates: mostra o fluxo de pagamentos

Dessa forma, Ã© possÃ­vel visualizar uma estimativa do fluxo de caixa do investidor ao longo do tempo, informaÃ§Ã£o valiosa no ato de alocar recursos. No pacote isso Ã© feito da seguinte maneira:

## desempenho geral

# juntar projecÃµes em um Ãºnico dataframe
merged_proj = merge.xts(serie_prefix_2017, serie_ipca_2019, 
                        serie_ipca_2020, ipca_2020_cups) #[""/2015-09-04""]

# sÃ©rie que mostra o fluxo de pagamentos
fluxo_resgate = valor_de_resgate(merged_proj,
                                 ""2017-01-01"",
                                 ""2019-05-15"",
                                 ""2020-08-15"")
      
# sÃ©rie que mostra o total investido 
imobilizado = rowSums(merged_proj[,1:3], na.rm=TRUE)

# fluxo de pagamentos: removendo NAs
resgates = rowSums(merge.xts(merged_proj[,4], fluxo_resgate), na.rm=TRUE)


Gerar grÃ¡ficos
Antes de gerar os grÃ¡ficos, Ã© feita uma etapa de prÃ©-processamento de forma que as sÃ©ries estejam em um formato fÃ¡cil de ser utilizado com o ggplot.
# unindo os dataframes que serÃ£o plotados
to_plot = cbind(data.frame(merged_proj), 
                data.frame(imobilizado),
                data.frame(resgates),
                data.frame(dates = index(merged_proj)))

# formatando o dataframe na forma adequada para o ggplo2
plot_df = melt(to_plot, 'dates')

Finalmente, podemos plotar as sÃ©ries.
# criando o grÃ¡fico
plt = ggplot(plot_df,aes(x=dates,y=value,group=variable,color=variable)) 
plt + geom_line(aes(group=variable),size=1) + scale_x_date() + ggtitle(""Portfolio corrente"") 

Em azul escuro, Ã© mostrado o total investido e sua evoluÃ§Ã£o com o tempo. Em lilÃ¡s, o ""fluxo de caixa"" do investidor. Cada investimento Ã© representado por uma linha (se nÃ£o houver pagamento de cupons) ou duas (se houver pagamento de cupons).

Funcionalidades
Nesta seÃ§Ã£o sÃ£o mostradas algumas funcionalidades interessantes do pacote.
FunÃ§Ãµes de apoio
FunÃ§Ãµes simples e Ãºteis utilizadas para criar as sÃ©ries temporais.

### FuncÃµes Ãºteis ###

# 1) Extrair dias Ãºteis entre duas datas:
# (usa o arquivo ./data/dates.csv como base)
# formato deve ser 'YYYY-MM-DD'
print( get_workdays('2015-01-01', '2015-01-10') ) 

# 2) NÃºmero de dias entre duas datas (corridos)
print( get_n_dias('2015-01-10', '2015-01-01') )

# 3) Retornar fatia do IR correspondente ao intervalo de dias
print( get_fatia_ir(100) ) # 1a faixa
print( get_fatia_ir(200) ) # 2a faixa
print( get_fatia_ir(400) ) # 3a faixa
print( get_fatia_ir(800) ) # 4a faixa

# 4) Extrair IPCA do site Valor EconÃ´mico (12 meses) 
print( extrair_ipca() )

# 5) Extrair Selic do site Valor EconÃ´mico (12 meses)
print( extrair_selic() )


CÃ¡lculo automÃ¡tico do IR
O Imposto de Renda Ã© calculado e descontado automaticamente nas projeÃ§Ãµes, segundo as regras do tesouro direto. Nos momentos em que hÃ¡ mudanÃ§a de faixa na alÃ­quota de imposto Ã© possÃ­vel observar pequenos saltos na rentabilidade:
plot(serie_ipca_2019)


DefiniÃ§Ã£o de lista de juros anuais
Para sanar o problema de utilizar uma Ãºnica taxa de juros para todo o perÃ­odo de um investimento, Ã© possÃ­vel criar uma lista em que cada entrada corresponde Ã  uma taxa prevista para um ano. Vamos utilizar 3 exemplos:

IPCA constante ao longo do investimento
IPCA crescente ao longo do investimento
IPCA decrescente ao longo do investimento

Nota: a variaÃ§Ã£o das taxas sÃ£o um pouco exageradas de forma que as diferenÃ§as entre os exemplos sejam visÃ­veis.
IPCA constante
A projeÃ§Ã£o neste caso Ã© feita da mesma forma mostrada no script exemplo:
taxa_constante = 10

ipca_constante = list(montante_ini = 10000, 
                      tx_anual = taxa_constante,
                      data_ini =  ""2015-01-01"",
                      data_venc = ""2019-05-15"")

# sÃ©rie temporal
serie_ipca_constante = proj_tesdir(ipca_constante[['montante_ini']],
                                   ipca_constante[['tx_anual']],
                                   ipca_constante[['data_ini']],
                                   ipca_constante[['data_venc']])

plot(serie_ipca_constante)


IPCA crescente
Neste caso, vamos supor que o IPCA aumente no ritmo de 2% ao ano. Para representar isto, utilizamos um objeto do tipo list(), taxa_crescente.
# ipca aumentando 2% a cada ano
taxa_crescente = list('2015' = 10,
                      '2016' = 12,
                      '2017' = 14,
                      '2018' = 16,
                      '2019' = 18) 

ipca_crescente = list(montante_ini = 10000, 
                      tx_anual = taxa_crescente,
                      data_ini =  ""2015-01-01"",
                      data_venc = ""2019-05-15"")

# sÃ©rie temporal
serie_ipca_crescente = proj_tesdir(ipca_crescente[['montante_ini']],
                                   ipca_crescente[['tx_anual']],
                                   ipca_crescente[['data_ini']],
                                   ipca_crescente[['data_venc']])

plot(serie_ipca_crescente)


IPCA decrescente
Finalmente, aqui vemos o caso inverso do anterior, em que o IPCA cai 2% ao ano atÃ© o fim do investimento.
# fazer a projecÃ£o de um IPCA 2019 utilizando taxas previstas para cada ano

# ipca diminuindo 2% a cada ano 
taxa_decrescente = list('2015' = 10,
                        '2016' = 8,
                        '2017' = 6,
                        '2018' = 4,
                        '2019' = 2) 

ipca_decrescente = list(montante_ini = 10000, 
                        tx_anual = taxa_decrescente,
                        data_ini =  ""2015-01-01"",
                        data_venc = ""2019-05-15"")

# sÃ©rie temporal
serie_ipca_decrescente = proj_tesdir(ipca_decrescente[['montante_ini']],
                                     ipca_decrescente[['tx_anual']],
                                     ipca_decrescente[['data_ini']],
                                     ipca_decrescente[['data_venc']])

plot(serie_ipca_decrescente)


",7
KaidemonLP/Open-Fortress-Source,C++,"Open Fortress: Source Code
",25
fuhd/studynotes,None,"studynotes
å­¦ä¹ ç¬è®°
",5
ahf/dotfiles,Perl,"Alex's Dotfiles
This repository contains dotfiles for various programs that I use regularly.
The files are split into ""logical"" modules that are maintained with the GNU
Stow ""symlink farm manager"".
",2
zapret-info/z-i,None,"z-i
Register of Internet Addresses filtered in Russian Federation
",926
limintao/vue-calendars,CSS,"vue-calendars


A simple calendar selection component based on vue.js!You can customize which day is not optional, or you can define subscripts for each day (or days). Single or multiple(/interval) choice!

Getting Started
install
By npm
npm install vue-calendars --save

or download code and include it
<script src='dist/vue-calendars.js'></script>

Usage
Register component globally!
// Your entry main.js

import Vue from 'vue'
import App from './App.vue'
import vCalendar from ""vue-calendars""

Vue.use(vCalendar)
new Vue({
  el: '#app',
  render: h => h(App)
})

or register locally in your .vue file
Example
<template>
  <div class=""hello"">
    <div class=""chooseView"" @click=""openCalendar"">
        <span class=""item"">éæ©æ¥æï¼</span>
        <span class=""result"">å¼å§æ¶é´ï¼{{ selectDate[0] }}</span>
    </div>
    
    <v-calendar 
        :option=""option"" 
        :click-action=""setSelectDate""
        :multi-selection=""isMultiple""
        :interval-selection=""isInterval""
        :subscript=""subscript""
        :items-subscript=""itemsSubscript""
        ></v-calendar>
    
  </div>
</template>

<script>
export default {
  name: 'HelloWorld',
  data () {
    return {
        option: {
            open: false,  //æ¯å¦æå¼æ¥åðï¼
            aroud: 12, //æ¾ç¤ºå¤å°æçæ°æ®
            title: 'éæ©åºè¡æ¥æ'
        },
        selectDate: [],    //å½åéæ©çæ¥æ
        isMultiple: false, //æ¯å¦å¤éï¼falseåéãtrueå¤é
        isInterval: true,   // æ¯å¦æ¯åºé´éæ©
        subscript: ""å¯çº¦"",  //ææçæ¥æä¸æ æ é¢
        itemsSubscript:[    // èªå®ä¹åªå¤©ä¸å¯éåèªå®ä¹æ é¢
            {
                date: '2018-05-31',
                title: 'ä¸å¯ä¼',
            },
            {
                date: '2018/06/01',
                title: 'ä¸å¯ä¼',
            },
            {
                date: '2018,06,22',
                title: 'ä¸å¯ä¼',
            }
        ]
    }
  },
  
  methods:{
    openCalendar() {
        this.option.open = true;
    },
    setSelectDate(d) {   //è®¾ç½®ç¹å»çæ¥æ,è¿åçæ¯ä¸ä¸ªæ°ç»
        this.selectDate= d;
    }
  }
}
</script>
A sample screenshot is here,

Options



Option
Description




option
ä¼ å¥ä¸ç»object aroud(å½åæ¥æ),å¦å½åæ¥æä¸º2018/04/25 aroundä¸º3 åæ¾ç¤º2018/04 2018/05 2018/06 3ä¸ªæï¼open(æ¯å¦æ¾ç¤ºæ¥å)ï¼true(æ¾ç¤º) or falseï¼éèï¼; title(è¦æ¾ç¤ºçæ é¢), string


click-action
éæ©æ¥æä¹åæ§è¡çæ¹æ³ï¼å¯æ¥æ¹æ³åï¼è¿åçæ¯ä¸ä¸ªåå«æ¥æçæ°ç»


multi-selection
æ¯å¦å¤é,true(å¤é) or false(åé)


interval-selection
æ¯å¦åºé´éæ©ï¼ä¸å¤éå²çªï¼å¦æåæ¶è®¾trueåæå¤éæä½


subscript
æææ¥æçä¸æ 


items-subscrip
éæ©åªäºæ¥æä¸å¯éï¼æåªäºæ¥æçèªå®ä¹ä¸æ 




æä»ä¹é®é¢æ¬¢è¿éæ¶æIssuesï¼ð

",3
jacobnisnevich/overrustle-vods,JavaScript,"OverRustle VODs
OverRustle VODs is a simple web app that plays Destiny Twitch VODs with the destiny.gg/OverRustle chat along the side in real-time
Running the Project
OverRustle VODs requires Ruby to run properly. I've tested with Ruby 2.2.1p85 using rvm on Ubuntu 14.04. To build the project simply run
bundle install

to install all gem dependencies and then start the project with
ruby app.rb

",2
Lombiq/Orchard-Application-Host,C#,"Orchard Application Host Readme
Project Description
A light-weight framework that allows you to write arbitrary code (console or web applications, anything) empowered with Orchard.
Overview
The Orchard Application Host is a portable environment that lets you run your application inside a standalone Orchard shell. I.e. you can write any app with an Orchard developer experience, without using an Orchard web app. This enables you to use Orchard's features and services from any application (not just web applications), including:

Automatic dependency injection
Helpers and utilities
Data access services, including content management
Orchard-style events
Shapes
Caching
Localization
Logging
Background tasks

With Orchard Application Host you can create console applications, Windows services, desktop applications, cloud workers or any other type of app that uses Orchard's capabilities. No more low-level project start: you get an application framework that you can begin developing awesome software with, utilizing your Orchard knowledge and Orchard's power.
You can see a demo of the Orchard Application Host on the recording of the Orchard Community Meeting.
Among others Orchard Application Host powers the reverse proxy of the Hosting Suite and Hastlayer too.
The project's source is available in two public source repositories, automatically mirrored in both directions with Git-hg Mirror:

https://bitbucket.org/Lombiq/orchard-application-host (Mercurial repository)
https://github.com/Lombiq/Orchard-Application-Host (Git repository)

Bug reports, feature requests and comments are warmly welcome, please do so via GitHub.
Feel free to send pull requests too, no matter which source repository you choose for this purpose.
This project is developed by Lombiq Technologies Ltd. Commercial-grade support is available through Lombiq.
Using Orchard App Host as source in a solution

See examples in Lombiq.OrchardAppHost.Sample and for a full usage scenario with a non-Orchard solution in the Orchard Application Host Quick Start.
Disable SessionConfigurationCache otherwise you'll get ""The invoked member is not supported in a dynamic assembly."" exceptions that are harmless but prevent the session cache from being used anyway.
You'll get a ""The invoked member is not supported in a dynamic assembly."" exception during the first startup from AbstractDataServicesProvider but this is harmless.
Also from AbstractDataServicesProvider you'll get a ""Could not load file or assembly 'NHibernate.XmlSerializers ...' or one of its dependencies. The system cannot find the file specified."" exception that is also harmless.
If you want to use anything, even indirectly, from Orchard.Core, you have to add a project reference to it. E.g. even if you don't access anything from Orchard.Core but you use a service that gets ISiteService injected what in turn has an implementation in Orchard.Core then you indirectly depend on Orchard Core; thus, you have to add a project reference to it.
When using SQL CE you should add a reference to its assembly System.Data.SqlServerCe and set it as Copy Local = true.
Imported extensions don't need to declare a Module.txt but still can have features: by default they get a feature with the same name as the assembly's (short) name and also all OrchardFeature attribute usages will be processed and their values registered as features.
Note that starting Orchard App Host will currently take over ASP.NET MVC and Web API controller instantiation, see this Orchard issue.

Solution structure
The solution must follow this folder structure:

NuGet.config (see explanation below)
Lombiq.OrchardAppHost

Lombiq.OrchardAppHost.csproj


Orchard (a full Orchard source, i.e. the lib, src folder under it)
Arbitrarily named subfolder for 3rd party modules, e.g. Modules. Put your own modules here.

Module1

Module1.csproj





The Orchard Application Host Quick Start solution shows these conventions.
Configuring NuGet
A custom NuGet.config file is needed in the root of your solution so NuGet packages used by Orchard can be properly loaded. This should configure repositoryPath as following:
<?xml version=""1.0"" encoding=""utf-8""?>
<configuration>
  <config>
    <add key=""repositoryPath"" value=""Orchard\src\packages"" />
  </config>
</configuration>

Also see the example in the Orchard Application Host Quick Start.
Making assembly references compatible with different solution structures
3rd party modules may reference dlls from the Orchard lib folder or use the same NuGet packages as Orchard. By default these references will break since modules in an Orchard solution are under src/Orchard.Web/Modules, not above the Orchard folder (and thus paths differ). To make a module compatible with both standard Orchard solutions and Orchard App Host solutions add the following elements to the modules's csproj:
<!-- Orchard App Host (https://github.com/Lombiq/Orchard-Application-Host) compatibility start. Enabling the usage of a lib folder at a different location. -->
<ItemGroup>
  <LibReferenceSearchPathFiles Include=""..\..\Orchard\lib\**\*.dll"">
    <InProject>false</InProject>
  </LibReferenceSearchPathFiles>
  <NuGetReferenceSearchPathFiles Include=""..\..\Orchard\src\packages\**\*.dll"">
    <InProject>false</InProject>
  </NuGetReferenceSearchPathFiles>
</ItemGroup>
<Target Name=""BeforeResolveReferences"">
  <RemoveDuplicates Inputs=""@(LibReferenceSearchPathFiles->'%(RootDir)%(Directory)')"">
    <Output TaskParameter=""Filtered"" ItemName=""LibReferenceSearchPath"" />
  </RemoveDuplicates>
  <CreateProperty Value=""@(LibReferenceSearchPath);$(AssemblySearchPaths)"">
    <Output TaskParameter=""Value"" PropertyName=""AssemblySearchPaths"" />
  </CreateProperty>
  <RemoveDuplicates Inputs=""@(NuGetReferenceSearchPathFiles->'%(RootDir)%(Directory)')"">
    <Output TaskParameter=""Filtered"" ItemName=""NuGetReferenceSearchPath"" />
  </RemoveDuplicates>
  <CreateProperty Value=""@(NuGetReferenceSearchPath);$(AssemblySearchPaths)"">
    <Output TaskParameter=""Value"" PropertyName=""AssemblySearchPaths"" />
  </CreateProperty>
</Target>
<PropertyGroup Condition=""Exists('..\..\Orchard\lib')"">
  <ModulesRoot>..\..\Orchard\src\Orchard.Web\Modules\Orchard.Alias\</ModulesRoot>
</PropertyGroup>
<!-- Orchard App Host (https://github.com/Lombiq/Orchard-Application-Host) compatibility end. -->

Also make sure to prefix every project reference that points to one of Orchard's built-in projects with $(ModulesRoot) (assembly references don't need to be changed):
<ProjectReference Include=""$(ModulesRoot)..\..\..\Orchard\Orchard.Framework.csproj"">
  <Project>{2D1D92BB-4555-4CBE-8D0E-63563D6CE4C6}</Project>
  <Name>Orchard.Framework</Name>
</ProjectReference>
<ProjectReference Include=""$(ModulesRoot)..\..\..\Orchard\Orchard.Framework.csproj"">
  <Project>{2D1D92BB-4555-4CBE-8D0E-63563D6CE4C6}</Project>
  <Name>Orchard.Framework</Name>
  <Private>false</Private>
</ProjectReference>

",3
wx-chevalier/Web-Series,None,"
ä¸­æçæ¬ | English Version
ç°ä»£ Web å¼ååºç¡ä¸å·¥ç¨å®è·µ
Copyright Â© 2018 çä¸éæç
Web å¼åï¼å¥é¨æï¼æ·±åº¦é¾ï¼åä¸ºåçª¥é¨å¾ãç»å å¥å®¤ãèä¼è´¯éç­é¶æ®µãæ¬ä»åºå­æ¾ ITCS ææ¯ä½ç³»ä¸ç¥è¯å¾è°±-Web åç«¯ç¸å³é¢åç Web å¼ååºç¡ä¸å·¥ç¨å®è·µçç¸å³åå®¢ãç¤ºä¾ä»£ç ä¸å¼æºé¡¹ç®ãæ´çæçç³»åä¹¦ç±ç­åå®¹ï¼ç®åä¸ºäºæ´å¥½å°ä½ç³»åéè¯»ï¼ç¬èå°ææçåå®¹è§æ´å°äºä¸åçç³»åæç«  / ä¹¦ç±ä¸­ï¼ä»£ç ç­å®è·µæ¨¡æ¿è¯·åè fe-boilerplateã

Nav | å¯¼èª
å¦ææ¨æ³å¿«éæ£ç´¢ï¼é£ä¹å»ºè®®åå¾ xCompass/alfred-sg è¿è¡äº¤äºå¼å°æ£ç´¢ãæ¥æ¾éè¦çæç« /é¾æ¥/ä¹¦ç±/è¯¾ç¨ã
å¦ææ¨å¯¹äº JavaScript åºç¡è¯­æ³å°ä¸å®å¨äºè§£ï¼é£ä¹å»ºè®®æ¨é¦åæµè§ç°ä»£ JavaScript è¯­æ³åºç¡ä¸å·¥ç¨å®è·µæè JavaScript-CheatSheet ä»¥äºè§£åºç¡ç JavaScript è¯­æ³åå®è·µåºç¨ã
å¦ææ¨æ³å¿«éå°äºè§£ Web å¼åå®è·µï¼æèæ¯æ³æ¥éæäºæ¸åï¼é£ä¹å»ºè®®æ¨åå¾ Awesome-CheatSheets/Webï¼æèä» Specials å¼å§éè¯»ï¼å®ä¼åå« Web å¼åç®å²ä¸åè¿ï¼æ°æ®æµé©±å¨ççé¢ï¼æ¨¡ååä¸ç»ä»¶åï¼å·¥å·åä¸å·¥ç¨åï¼ååç«¯åç¦»ä¸å¨æ æ¶æï¼å¾®åç«¯ä¸å¤§åç«¯ï¼è¿è¡æºå¶ä¸æ§è½ä¼åï¼ç­åå®¹ã
æ¥ä¸æ¥ï¼æ¨å¯ä»¥éæ©ä»¥ä¸ç« èä¸­æå´è¶£çæ¨¡åè¿è¡æ·±åº¦éè¯»ï¼


åºç¡ç¯: å¯¹äº HTMLãCSSãDOM ç­ Web å¼åä¸­æ¶åçåºç¡ç¥è¯ä¸çå¿µçæ»ç»ä»ç»ã


å·¥ç¨å®è·µç¯: æå»ºå·¥å·ï¼æµè¯ï¼å®å¨ï¼WebAssemblyã


æ¶æä¼åç¯: ç»ä»¶åï¼ç¶æç®¡çï¼æ§è½ä¼åï¼PWAã


React ç¯ï¼è¿å¹´æ¥åç«¯é¢åç¾è±é½æ¾ï¼åç§ææ¯æ¹æ¡äºå¦æè³ï¼åé¢é£éªãæ¬ä¹¦ç«è¶³äºå¶ä¸­çä½¼ä½¼è Reactï¼æ·±å¥æµåºçä»ç» ReactãWebpack ã ES6ãRedux ã MobX ç­å¸¸è§åç«¯å¼åå·¥å·ä¸å¼ååºçç¨æ³ï¼å¸®å©åå­¦èè½å¤è¿éæä¸ºä¸ååæ ¼åç«¯å·¥ç¨å¸ãèæ¬ä¹¦ä¹ä¸ä»å±éäºå·¥å·ä½¿ç¨çå±é¢ï¼æ¢å¯»åç§ææ¯æ¹æ¡èåè´å«çè®¾è®¡ææ³ä¸æ¶ææ¨¡å¼ï¼ä»åç«¯å·¥ç¨åçè§åº¦è®¨è®ºåç«¯å¼åèå¨è¿é¶è¿ç¨ä¸­éè¦ææ¡çå·¥ç¨å®è·µãæ¨¡ååä¸ç»ä»¶åãè´¨éä¿éãæ§è½ä¼åç­ç¥è¯è¦ç¹ãæç»å¸®å©å¼åèå¨åç«¯å¼åä¸­è½å¤å å°å¶å®çæå®åçæ¹æ¡ï¼ä»¥å°½å¯è½å¿«çéåº¦å®ç°å¯ä¿¡èµçäº§åã


Vue ç¯ï¼æ¬é¨åç®åæ­£éæ­¥å¯å¨ï¼ç¬èçåè¡·æ¯å¸æè½å¤ä¿è¯æ¬ä¹¦ç« èä¸ React ä¸åç«¯å·¥ç¨åå®è·µå°½å¯è½ä¸è´ï¼ä»èæ´æ¹ä¾¿å°å»ä»ç»ä¸åææ¯æ ä¸ç¸éçè®¾è®¡çå¿µï¼ç®åæ¬ä¹¦çç®å½åªæ¯æ·è´èª React ä¸åç«¯å·¥ç¨åå®è·µï¼æªæ¥ç¬èä¼éæ­¥å®åã


Preface | åè¨
è¿æ¯ä¸ä¸ªæå¥½çæ¶ä»£ï¼ä¹æ¯æåçæ¶ä»£ï¼æä»¬äº²èº«ç»åçæ¿å¨äººå¿çåé©ï¼ä¹å¾å¾ä¼é·å¥éæ©çè¿·è«ãéçæµè§å¨çæ¬çé©æ°ä¸ç¡¬ä»¶æ§è½çæåï¼Web åç«¯å¼åè¿å¥äºé«æ­çè¿ï¼æ¥æ°æå¼çæ¶ä»£ï¼æ æ°çåç«¯å¼åæ¡æ¶ãææ¯ä½ç³»äºå¦æè³ï¼è®©å¼åèä»¬é·å¥å°æï¼ä¹è³äºæ æéä»ãç¹å«æ¯éçç°ä»£ Web åç«¯æ¡æ¶(AngularãReactãVue.js)çåºç°ï¼JavaScriptãCSSãHTML ç­è¯­è¨ç¹æ§çæåï¼å·¥ç¨åãè·¨å¹³å°ãå¤§åç«¯ç­çè®ºæ¦å¿µçæåºï¼Web åç«¯å¼åçææ¯æ ãç¤¾åºä¹æ¯ä¸æ­ä¸°å¯å®åã
ä»»ä½ä¸ä¸ªç¼ç¨çæé½ä¼ç»åä¸ä¸ªé¶æ®µï¼é¦åæ¯åå§æ¶æï¼ç±äºéè¦å¨è¯­è¨ä¸åºç¡ç API ä¸è¿è¡æ©åï¼è¿ä¸ªé¶æ®µä¼å¬çå¤§éçè¾å©å·¥å·ãç¬¬äºä¸ªé¶æ®µï¼éçåçä¸è¥¿çå¤æåï¼éè¦æ´å¤çç»ç»ï¼ä¼å¼å¥å¤§éçè®¾è®¡æ¨¡å¼åï¼æ¶ææ¨¡å¼çæ¦å¿µï¼è¿ä¸ªé¶æ®µä¼å¬çå¤§éçæ¡æ¶ãç¬¬ä¸ä¸ªé¶æ®µï¼éçéæ±çè¿ä¸æ­¥å¤æä¸å¢éçæ©åï¼å°±è¿å¥äºå·¥ç¨åçé¶æ®µï¼åç±»åå± MVCï¼MVPï¼MVVM ä¹ç±»ï¼å¯è§åå¼åï¼èªå¨åæµè¯ï¼å¢éååç³»ç»ï¼è¿ä¸ªé¶æ®µä¼åºç°å¤§éçå°èç¾çåºã
Web åç«¯å¼åå¯ä»¥è¿½æº¯äº 1991 å¹´èå§Â·ä¼¯çº³æ¯-æå¬å¼æå HTML æè¿°ï¼èå 1999 å¹´ W3C åå¸ HTML4 æ åï¼è¿ä¸ªé¶æ®µä¸»è¦æ¯ B/S æ¶æï¼æ²¡ææè°çåç«¯å¼åæ¦å¿µï¼ç½é¡µåªä¸è¿æ¯åç«¯å·¥ç¨å¸çé¡ºæä¹ä½ï¼æå¡ç«¯æ¸²ææ¯ä¸»è¦çæ°æ®ä¼ éæ¹å¼ãæ¥ä¸æ¥çå å¹´é´éçäºèç½çåå±ä¸ REST ç­æ¶ææ åçæåºï¼ååç«¯åç¦»ä¸å¯å®¢æ·ç«¯çæ¦å¿µæ¥æ¸ä¸ºäººè®¤åï¼æä»¬éè¦å¨è¯­è¨ä¸åºç¡ç API ä¸è¿è¡æ©åï¼è¿ä¸ªé¶æ®µåºç°äºä»¥ jQuery ä¸ºä»£è¡¨çä¸ç³»ååç«¯è¾å©å·¥å·ã
2009 å¹´ä»¥æ¥ï¼æºè½ææºå¼åæ®åï¼ç§»å¨ç«¯å¤§æµªæ½®å¿ä¸å¯æ¡ï¼SPA åé¡µåºç¨çè®¾è®¡çå¿µä¹å¤§è¡å¶éï¼ç¸å³èçåç«¯æ¨¡ååãç»ä»¶åãååºå¼å¼åãæ··åå¼å¼åç­ç­ææ¯éæ±çä¸ºè¿«åãè¿ä¸ªé¶æ®µå¬çäº Angular 1ãIonic ç­ä¸ç³»åä¼ç§çæ¡æ¶ä»¥å AMDãCMDãUMD ä¸ RequireJSãSeaJS ç­æ¨¡åæ åä¸å è½½å·¥å·ï¼åç«¯å·¥ç¨å¸ä¹æä¸ºäºä¸é¨çå¼åé¢åï¼æ¥æç¬ç«äºåç«¯çææ¯ä½ç³»ä¸æ¶ææ¨¡å¼ãèè¿ä¸¤å¹´é´éç Web åºç¨å¤æåº¦çæåãå¢éäººåçæ©åãç¨æ·å¯¹äºé¡µé¢äº¤äºåå¥½ä¸æ§è½ä¼åçéæ±ï¼æä»¬éè¦æ´å ä¼ç§çµæ´»çå¼åæ¡æ¶æ¥åå©æä»¬æ´å¥½çå®æåç«¯å¼åãè¿ä¸ªé¶æ®µæ¶ç°åºäºå¾å¤å³æ³¨ç¹ç¸å¯¹éä¸­ãè®¾è®¡çå¿µæ´ä¸ºä¼ç§çæ¡æ¶ï¼è­¬å¦ ReactãVue.jsãAngular 2 ç­ç»ä»¶æ¡æ¶åè®¸æä»¬ä»¥å£°æå¼ç¼ç¨æ¥æ¿ä»£ä»¥ DOM æä½ä¸ºæ ¸å¿çå½ä»¤å¼ç¼ç¨ï¼å å¿«äºç»ä»¶çå¼åéåº¦ï¼å¹¶ä¸å¢å¼ºäºç»ä»¶çå¯å¤ç¨æ§ä¸å¯ç»åæ§ãèéµå¾ªå½æ°å¼ç¼ç¨ç Redux ä¸åé´äºååºå¼ç¼ç¨çå¿µç MobX é½æ¯éå¸¸ä¸éçç¶æç®¡çè¾å©æ¡æ¶ï¼è¾å©å¼åèå°ä¸å¡é»è¾ä¸è§å¾æ¸²æå¥ç¦»ï¼æ´ä¸ºåçå°ååé¡¹ç®ç»æï¼æ´å¥½å°è´¯å½»åä¸èè´£ååä¸æåä»£ç çå¯ç»´æ¤æ§ãå¨é¡¹ç®æå»ºå·¥å·ä¸ï¼ä»¥ GruntãGulp ä¸ºä»£è¡¨çä»»å¡è¿è¡ç®¡çä¸ä»¥ WebpackãRollupãJSPM ä¸ºä»£è¡¨çé¡¹ç®æåå·¥å·åé¢é£éªï¼å¸®å©å¼åèæ´å¥½çæ­å»ºåç«¯æå»ºæµç¨ï¼èªå¨åå°è¿è¡é¢å¤çãå¼æ­¥å è½½ãPolyfillãåç¼©ç­æä½ã
çæ
 
ç¬èæææç« éµå¾ª ç¥è¯å±äº« ç½²å - éåä¸æ§ä½¿ç¨ - ç¦æ­¢æ¼ç» 4.0 å½éè®¸å¯åè®®ï¼æ¬¢è¿è½¬è½½ï¼å°éçæãå¦æè§å¾æ¬ç³»åå¯¹ä½ ææå¸®å©ï¼æ¬¢è¿ç»æå®¶å¸ä¸ä¹°ç¹çç²®(æ¯ä»å®æ«ç )~

",4356
InfiniteAdventures/ia-trilogy,HTML,"Infinite Adventures: zweiteiliger Doppelband
Â»Alle aussteigen, wir klauen jetzt einen A380.Â«
Eine frei lizenzierte Romanserie Ã¼ber ein witzig-verrÃ¼cktes Verbrecher-Quartett, schrÃ¤ge Raumpiraten, bÃ¶se Diktatoren und die Benutzung eines Helikopters als Raumschiff. Open Source, geschrieben in LaTeX (LuaTeX).  ð ð¡ ð£ ð»
German: Freely licensed novel series about absurd crime and science fiction, featuring crazy space pirates, evil dictators and a modified helicopter used as a spaceship. Open source, written in LaTeX (LuaTeX).
",3
GallVp/visualEEG,MATLAB,"visualEEG

visualEEG is a MATLAB/GUIDE based toolbox which can be used for very basic analysis of EEG/EMG data. The goal of this project is to develop a single window interactive tool.


Fig 1. The main GUI window of visualEEG which allows an interactive processing of data.

Source Code and Tutorials related to Publications

README for ""Automated Labeling of Movement-Related Cortical Potentials using Segmented Regression"", IEEE Transactions on Neural Systems and Rehabilitation Engineering, doi: 10.1109/TNSRE.2019.2913880

Compatibility
Currently visualEEG is being developed on macOS Mojave, MATLAB 2017b. However, in the past, it has been tested to work on OSX El Capitan MATLAB R2015b; Windows 7, MATLAB 2014a; and Linux (Ubuntu LTS 14.04), MATLAB 2012b.
Installation
Latest Version with Source Code (Matlab Required)

Clone the git repository using git. Or, download a compressed copy here.

$ git clone https://github.com/GallVp/visualEEG


From MATLAB file explorer, enter the visualEEG folder by double clicking it. Type visualEEG in the MATLAB command window and hit enter to run.

Binary Versions (Matlab Not Required)
Version 2.1: Windows installer, Mac installer
Wiki
A detailed documentation with tutorials is available here.
Third Party Libraries
visualEEG uses following third party libraries. The licenses for these libraries can be found next to source files in their respective libs/thirdpartlib folders.

barwitherr Copyright (c) 2014, Martina Callaghan. Source is available here.
export_fig Copyright (c) 2014, Oliver J. Woodford, Yair M. Altman. Source is available here.
pooledmeanstd Copyright (c) 2012, R P. Source is available here.

",2
Lombiq/Arithmetics,C#,"Unum - Proof of concept readme
This project was developed as part of Hastlayer, the .NET HLS tool that converts .NET programs into equivalent logic hardware implementations.
Its goal is to implement a Unum proof of concept: the number type and an example using it, all transformable with Hastlayer.
The project's source is available in two public source repositories, automatically mirrored in both directions with Git-hg Mirror:

https://bitbucket.org/Lombiq/arithmetics (Mercurial repository)
https://github.com/Lombiq/Arithmetics (Git repository)

Bug reports, feature requests and comments are warmly welcome, please do so via GitHub. Feel free to send pull requests too, no matter which source repository you choose for this purpose.
This project is developed by Lombiq Technologies Ltd. Commercial-grade support is available through Lombiq.
About Unum
Unum is a new number format invented by Dr. John L. Gustafson that can be used to store any number with exact precision (or known error). It can be used to achieve better range and accuracy than IEEE floating point formats while eliminating the algebraic errors that the IEEE floats are prone to.
For more about its advantages see: http://ubiquity.acm.org/article.cfm?id=2913029.
",6
koji/icTrainer,Python,"



icTrainer is a python module which allows users to train image classifier easily
Basically, this module is for python3
Install
$ pip install ictrainer

Also you can install manually.
clone repo
$ git https://github.com/koji/icTrainer.git
$ cd icTrainer/ictrainer
$ python setup.py install

How to Use
In this gude, we will create a dog/cat image classifier.
1.Collect Images
https://icrawler.readthedocs.io/en/latest/
$ ictrainer --mode collect --keyword dog -n 250
$ ictrainer --mode collect --keyword cat -n 250

You'll have dogs & cats images under dataset folder.
2. Resize images
In this step, we will change all images size for training. The current input size must be 320 x 180(required).
This step may be mess up images you collected, so you need to check all images manually. In the furture, there will be a function that save your time.
$ ictrainer --mode resize --target dog
$ ictrainer --mode resize --target cat

For people want to use resize mode for other thing, you can use reize images with the following command.
The folder structure should be the same the above.
$ ictrainer --mode resize --target cat --image_width 480 --image_height 320

3.Create folders for classes
This step, we'll need to create folders and distribute images to train & validation folder.
3-1. create folders
Create a couple of folders under dataset.
This step will be automated in the future.
 dataset
    âââ train
    âÂ Â  âââ cat
    âÂ Â  âââ dog
    âââ val
        âââ cat
        âââ dog

3-2. distribute images
Move images we got via image collect mode. In this case, probably we have 250 images for each other.
We will put 225 images for train and 25 images for validation so that train/dog has 225 images and validation/dog has 25 images. The cats should be the same.
4.Train Images
There are some options we need to put. The most important one is --classes which will be labels. In this case, we have dog & cat, so we need to put them as classes.
--batch: batch size default 16
--epoch: epoch default 30
--mname: output model name
--lr: learning rate default 1e-3
momentum: mementum default 0.9
We will use default settings.
$ ictrainer --mode train --classes ""cat"" ""dog"" --mname ""dogAndcat_""

5 Face detection
From 0.2.0 ictrainer allows you to use face detection. The command is following. This function is using OpenCV Cascade filter to detect front faces. When you successfully run this command, ictrainer creates output folder and there are faces and something which means still you need check all image by yourself.
--mode face
--target target folder
$ ictrainer --mode face --target dataset/celeb

video
image collecting mode
https://www.youtube.com/watch?v=k5r_xrW_cxE
pre-train model
smart device
https://github.com/koji/icTrainer/blob/master/model/smartdevice_epoch30.h5
classes = ['echo', 'echoplus', 'echoshow', 'googlehome', 'googlehomemini', 'nest']   

",4
nexus-uw/make-account-green,Shell,"make-account-green
Purpose
This is a lazy repo that will generate public activity for this account to game the contributions graph.
Why
Because any system can be gamed
Notes
(idea forked from http://zeke.sikelianos.com/npm-and-github-automation-with-heroku/)
",3
SourMesen/Mesen,C++,"Mesen
Mesen is a cross-platform NES/Famicom emulator for Windows & Linux built in C++ and C#.
If you want to support this project, please consider making a donation:

Website (https://www.mesen.ca)
Documentation (https://www.mesen.ca/docs)
Development Builds
Development builds of the latest commit are available from Appveyor. For stable release builds, see the Releases section below.
Warning: These are development builds and may be unstable. Using them may also increase the chances of your settings being corrupted, or having issues when upgrading to the next official release. Additionally, these builds are currently not optimized via PGO and will typically run 20-30% slower than the official release builds.
Windows: 
Linux: 
Releases
Windows
The latest version is available on the website.  Older releases are available from the releases tab on GitHub.
Ubuntu
The official releases (same downloads as the Windows builds above) also contain the Linux version of Mesen, built under Ubuntu 16 - you should be able to use that in most cases if you are using Ubuntu.
The Linux version is a standard .NET executable file and requires Mono to run - you may need to configure your environment to allow it to automatically run .exe files through Mono, or manually run Mesen by using mono (e.g: ""mono Mesen.exe"").
The following packages need to be installed to run Mesen:

mono-complete
libsdl2-2.0
gnome-themes-standard

Note: Mono 5.18 or higher is recommended, some older versions of Mono (e.g 4.2.2) have some stability and performance issues which can cause crashes and slow down the UI.
The default Mono version in Ubuntu 18.04 is 4.6.2 (which also causes some layout issues in Mesen).  To install the latest version of Mono, follow the instructions here: https://www.mono-project.com/download/stable/#download-lin
Arch Linux
Packages are available here: https://aur.archlinux.org/packages/mesen
Roadmap
Things that may or may not be added in the future, in no particular order:

Support for more UNIF boards and more NES/Famicom input devices
Shaders
TAS editor

Compiling
See COMPILING.md
License
Mesen is available under the GPL V3 license.  Full text here: http://www.gnu.org/licenses/gpl-3.0.en.html
Copyright (C) 2014-2019 M. Bibaud
This program is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.
This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.
You should have received a copy of the GNU General Public License
along with this program.  If not, see http://www.gnu.org/licenses/.
",411
sanderhelleso/project_bio,JavaScript,"project_bio ð¤³ð¼
Project Bio is a platform currently in development, serving as a ""middleman"" for social media influencers to increase sales of product and grow a bigger audience.






Status
In development
Copyright
Sander HellesÃ¸
",6
webx-top/echo,Go,"Echo
 
Echo is a fast and unfancy web framework for Go (Golang). Up to 10x faster than the rest.
This package need >= go 1.9
Features

Optimized HTTP router which smartly prioritize routes.
Build robust and scalable RESTful APIs.
Run with standard HTTP server or FastHTTP server.
Group APIs.
Extensible middleware framework.
Define middleware at root, group or route level.
Handy functions to send variety of HTTP responses.
Centralized HTTP error handling.
Template rendering with any template engine.
Define your format for the logger.
Highly customizable.

Quick Start
Installation
$ go get github.com/webx-top/echo
Hello, World!
Create server.go
package main

import (
	""net/http""
	""github.com/webx-top/echo""
	""github.com/webx-top/echo/engine/standard""
)

func main() {
	e := echo.New()
	e.Get(""/"", func(c echo.Context) error {
		return c.String(""Hello, World!"", http.StatusOK)
	})
	e.Run(standard.New("":1323""))
}
Start server
$ go run server.go
Browse to http://localhost:1323 and you should see
Hello, World! on the page.
Routing
e.Post(""/users"", saveUser)
e.Get(""/users/:id"", getUser)
e.Put(""/users/:id"", updateUser)
e.Delete(""/users/:id"", deleteUser)
Path Parameters
func getUser(c echo.Context) error {
	// User ID from path `users/:id`
	id := c.Param(""id"")
}
Query Parameters
/show?team=x-men&member=wolverine
func show(c echo.Context) error {
	// Get team and member from the query string
	team := c.Query(""team"")
	member := c.Query(""member"")
}
Form application/x-www-form-urlencoded
POST /save



name
value




name
Joe Smith


email
joe@labstack.com



func save(c echo.Context) error {
	// Get name and email
	name := c.Form(""name"")
	email := c.Form(""email"")
}
Form multipart/form-data
POST /save



name
value




name
Joe Smith


email
joe@labstack.com


avatar
avatar



func save(c echo.Context) error {
	// Get name and email
	name := c.Form(""name"")
	email := c.Form(""email"")

	//------------
	// Get avatar
	//------------
	_, err := c.SaveUploadedFile(""avatar"",""./"")
	return err
}
Handling Request

Bind JSON or XML payload into Go struct based on Content-Type request header.
Render response as JSON or XML with status code.

type User struct {
	Name  string `json:""name"" xml:""name""`
	Email string `json:""email"" xml:""email""`
}

e.Post(""/users"", func(c echo.Context) error {
	u := new(User)
	if err := c.MustBind(u); err != nil {
		return err
	}
	return c.JSON(u, http.StatusCreated)
	// or
	// return c.XML(u, http.StatusCreated)
})
Static Content
Server any file from static directory for path /static/*.
e.Use(mw.Static(&mw.StaticOptions{
	Root:""static"", //å­æ¾éææä»¶çç©çè·¯å¾
	Path:""/static/"", //ç½åè®¿é®éææä»¶çè·¯å¾
	Browse:true, //æ¯å¦å¨é¦é¡µæ¾ç¤ºæä»¶åè¡¨
}))
Middleware
// Root level middleware
e.Use(middleware.Log())
e.Use(middleware.Recover())

// Group level middleware
g := e.Group(""/admin"")
g.Use(middleware.BasicAuth(func(username, password string) bool {
	if username == ""joe"" && password == ""secret"" {
		return true
	}
	return false
}))

// Route level middleware
track := func(next echo.HandlerFunc) echo.HandlerFunc {
	return func(c echo.Context) error {
		println(""request to /users"")
		return next.Handle(c)
	}
}
e.Get(""/users"", func(c echo.Context) error {
	return c.String(""/users"", http.StatusOK)
}, track)
Cookie
e.Get(""/setcookie"", func(c echo.Context) error {
	c.SetCookie(""uid"",""1"")
	return c.String(""/setcookie: uid=""+c.GetCookie(""uid""), http.StatusOK)
})
Session
...
import (
	...
	""github.com/webx-top/echo/middleware/session""
	//boltStore ""github.com/webx-top/echo/middleware/session/engine/bolt""
	cookieStore ""github.com/webx-top/echo/middleware/session/engine/cookie""
)
...
sessionOptions := &echo.SessionOptions{
	Engine: `cookie`,
	Name:   `SESSIONID`,
	CookieOptions: &echo.CookieOptions{
		Path:     `/`,
		Domain:   ``,
		MaxAge:   0,
		Secure:   false,
		HttpOnly: true,
	},
}

cookieStore.RegWithOptions(&cookieStore.CookieOptions{
	KeyPairs: [][]byte{
		[]byte(`123456789012345678901234567890ab`),
	},
})

e.Use(session.Middleware(sessionOptions))

e.Get(""/session"", func(c echo.Context) error {
	c.Session().Set(""uid"",1).Save()
	return c.String(fmt.Sprintf(""/session: uid=%v"",c.Session().Get(""uid"")))
})
Websocket
...
import (
	...
	""github.com/admpub/websocket""
	""github.com/webx-top/echo""
	ws ""github.com/webx-top/echo/handler/websocket""
)
...

e.AddHandlerWrapper(ws.HanderWrapper)

e.Get(""/websocket"", func(c *websocket.Conn, ctx echo.Context) error {
	//push(writer)
	go func() {
		var counter int
		for {
			if counter >= 10 { //æµè¯åªæ¨10æ¡
				return
			}
			time.Sleep(5 * time.Second)
			message := time.Now().String()
			ctx.Logger().Info(`Push message: `, message)
			if err := c.WriteMessage(websocket.TextMessage, []byte(message)); err != nil {
				ctx.Logger().Error(`Push error: `, err.Error())
				return
			}
			counter++
		}
	}()

	//echo
	ws.DefaultExecuter(c, ctx)
	return nil
})
More...
Sockjs
...
import (
	...
	""github.com/webx-top/echo""
	""github.com/admpub/sockjs-go/sockjs""
	ws ""github.com/webx-top/echo/handler/sockjs""
)
...

options := ws.Options{
	Handle: func(c sockjs.Session) error {
		//push(writer)
		go func() {
			var counter int
			for {
				if counter >= 10 { //æµè¯åªæ¨10æ¡
					return
				}
				time.Sleep(5 * time.Second)
				message := time.Now().String()
				log.Info(`Push message: `, message)
				if err := c.Send(message); err != nil {
					log.Error(`Push error: `, err.Error())
					return
				}
				counter++
			}
		}()

		//echo
		ws.DefaultExecuter(c)
		return nil
	},
	Options: &sockjs.DefaultOptions,
	Prefix:  ""/websocket"",
}
options.Wrapper(e)
More...
Other Example
package main

import (
	""net/http""

	""github.com/webx-top/echo""
	// ""github.com/webx-top/echo/engine/fasthttp""
	""github.com/webx-top/echo/engine/standard""
	mw ""github.com/webx-top/echo/middleware""
)

func main() {
	e := echo.New()
	e.Use(mw.Log())

	e.Get(""/"", func(c echo.Context) error {
		return c.String(""Hello, World!"")
	})
	e.Get(""/echo/:name"", func(c echo.Context) error {
		return c.String(""Echo "" + c.Param(""name""))
	})
	
	e.Get(""/std"", func(w http.ResponseWriter, r *http.Request) {
		w.Write([]byte(`standard net/http handleFunc`))
		w.WriteHeader(200)
	})

	// FastHTTP
	// e.Run(fasthttp.New("":4444""))

	// Standard
	e.Run(standard.New("":4444""))
}
See other examples...
Middleware list



Middleware
Import path
Description




BasicAuth
github.com/webx-top/echo/middleware
HTTP basic authentication


BodyLimit
github.com/webx-top/echo/middleware
Limit request body


Gzip
github.com/webx-top/echo/middleware
Send gzip HTTP response


Secure
github.com/webx-top/echo/middleware
Protection against attacks


CORS
github.com/webx-top/echo/middleware
Cross-Origin Resource Sharing


CSRF
github.com/webx-top/echo/middleware
Cross-Site Request Forgery


Log
github.com/webx-top/echo/middleware
Log HTTP requests


MethodOverride
github.com/webx-top/echo/middleware
Override request method


Recover
github.com/webx-top/echo/middleware
Recover from panics


HTTPSRedirect
github.com/webx-top/echo/middleware
Redirect HTTP requests to HTTPS


HTTPSWWWRedirect
github.com/webx-top/echo/middleware
Redirect HTTP requests to WWW HTTPS


WWWRedirect
github.com/webx-top/echo/middleware
Redirect non WWW requests to WWW


NonWWWRedirect
github.com/webx-top/echo/middleware
Redirect WWW requests to non WWW


AddTrailingSlash
github.com/webx-top/echo/middleware
Add trailing slash to the request URI


RemoveTrailingSlash
github.com/webx-top/echo/middleware
Remove trailing slash from the request URI


Static
github.com/webx-top/echo/middleware
Serve static files


MaxAllowed
github.com/webx-top/echo/middleware
MaxAllowed limits simultaneous requests; can help with high traffic load


RateLimit
github.com/webx-top/echo/middleware/ratelimit
Rate limiting HTTP requests


Language
github.com/webx-top/echo/middleware/language
Multi-language support


Session
github.com/webx-top/echo/middleware/session
Sessions Manager


JWT
github.com/webx-top/echo/middleware/jwt
JWT authentication


Markdown
github.com/webx-top/echo/middleware/markdown
Markdown rendering


Render
github.com/webx-top/echo/middleware/render
HTML template rendering


ReverseProxy
github.com/webx-top/reverseproxy
Reverse proxy



Handler Wrapper list



Wrapper
Import path
Description




Websocket
github.com/webx-top/echo/handler/websocket
Example


Sockjs
github.com/webx-top/echo/handler/sockjs
Example


Oauth2
github.com/webx-top/echo/handler/oauth2
Example


Pprof
github.com/webx-top/echo/handler/pprof
-


MVC
github.com/webx-top/echo/handler/mvc
Example



Credits

Vishal Rana - Author
Hank Shen - Author
Nitin Rana - Consultant
Contributors

License
Apache 2
",17
vic64/nlpcraft,Scala,"

Â 
Â 

Overview
NLPCraft is an open source library for adding a natural language interface to any applications. Think Amazon
Alexa that is developer friendly, works with any private data source, has no hardware or software lock-in while
giving you more NLP powers:

Download and Maven/Grape/Gradle/SBT instructions
Documentation, Javadoc, and REST APIs
Example data models
Licensed under Apache 2.0 License with Commons Clause.

For any questions, feedback or suggestions:

Send us a note at support@nlpcraft.org
Post a question at Stack Overflow using nlpcraft tag
If you have a bug or an idea open new issue here on GitHub.

Copyright
Copyright (C) 2013-2019 DataLingvo Inc. All Rights Reserved.
",15
user1121114685/koolproxyR_rule_list,None,"koolproxyR_rule_list
æ¬é¡¹ç®åªæ¯æ¶ékprè´¡ç®è§åã
æ­¤é¡¹ç®ä»»ä½äººé½å¯ä»¥èªç±æäº¤ä¿®æ¹ï¼æ­¤åè¡¨å°å¸®å©æ´å¤äººä½¿ç¨Kprå»å¹¿åã
",5
Lombiq/Orchard-Login-as-Anybody,C#,"Login as Anybody readme
Project Description
Orchard module for administrators to be able to log in as any user.
Documentation
After enabling the module you'll see a new tab under Users. You can log in as any registered user there. This is useful if you want to see how your Orchard app behaves for certain users.
This feature is only available to site owners, thus it's not way to get around security.
The module's source is available in two public source repositories, automatically mirrored in both directions with Git-hg Mirror:

https://bitbucket.org/Lombiq/orchard-login-as-anybody (Mercurial repository)
https://github.com/Lombiq/Orchard-Login-as-Anybody (Git repository)

Bug reports, feature requests and comments are warmly welcome, please do so via GitHub.
Feel free to send pull requests too, no matter which source repository you choose for this purpose.
This project is developed by Lombiq Technologies Ltd. Commercial-grade support is available through Lombiq.
",2
dream-frame/Dream-Frame,CSS,"Dream-Frame

Bring a sexy translucent look to Discord with customizable options! BetterDiscord theme.
Downloads

Download for Powercord

Don't have a powerful computer? Try Dream Frame Lite!
Helpful Links

How to install Powercord: https://github.com/powercord-org/powercord/wiki/Installation

Donation
Donate: https://Paypal.me/CorbsEditor
Exploring Dream Frame

Why Dream Frame?
Dream Frame offers many options like changing colors, icons, sizes, and so on. There are more options are come, more advanced options to come as well if you're into that. This theme is the best translucent look to Discord, nothing can beat it!
All of the Options Offered by Dream Frame
The creator tries to add as many options as possible and without failing thanks to the fallback system from v2.2
The following is offered as of now:

Background
Background blur
Background opacity
Background scaling
Background Rotation
Emoji menu height
Emoji size
Home icon
Avatar in chat size
Status color changing
Accent text, accent color
Font, font size
Border radius options
Custom background for your own profile
Server indicator color
Titlebar icons(Windows)
Titlebar button colors(macOS)

More is to come!
",4
muesli/telephant,QML,"Telephant!
A lightweight but modern Mastodon client, written in Go & QML.

Features

 Live feed via Mastodon's Streaming API
 Multi pane support
 Linux/macOS/Windows (Android & iOS should be working, but aren't tested yet)
 Media previews
 Shortened URL resolving
 System notifications
 Multiple accounts (work-in-progress)
 Support for more networks

Installation
Packages & Installers

Windows 64bit
Linux Static 64bit

From Source
Make sure you have a working Go environment (Go 1.8 or higher is required).
See the install instructions.
You will also need Qt5 and its development headers installed.
Dependencies
Before you can build Telephant you need to install the Go/Qt bindings.
Qt5 dependencies (Ubuntu example)
apt-get --no-install-recommends install build-essential libglib2.0-dev libglu1-mesa-dev libpulse-dev
apt-get --no-install-recommends install libqt*5-dev qt*5-dev qt*5-doc-html qml-module-qtquick*

Qt Bindings
export QT_PKG_CONFIG=true
go get -u -v github.com/therecipe/qt/cmd/...
$(go env GOPATH)/bin/qtsetup -test=false

Building Telephant
mkdir -p $(go env GOPATH)/src/github.com/muesli
cd $(go env GOPATH)/src/github.com/muesli
git clone https://github.com/muesli/telephant.git

cd telephant
go get -u -v
$(go env GOPATH)/bin/qtdeploy build desktop .

Within a Docker container
Follow the build instructions above, but instead of the last command, run:
$(go env GOPATH)/bin/qtdeploy -docker build linux

Run it
./deploy/linux/telephant


Development



",85
wx-chevalier/Distributed-Infrastructure-Series,None,"
æ·±å¥æµåºåå¸å¼åºç¡æ¶æ
æ·±å¥æµåºåå¸å¼åºç¡æ¶ææ¯ç¬èå½æ¡£èªå·±ï¼å¨å­¦ä¹ ä¸å®è·µè½¯ä»¶åå¸å¼æ¶æè¿ç¨ä¸­çï¼ç¬è®°ä¸ä»£ç çä»åºï¼ä¸»è¦åå«åå¸å¼è®¡ç®ãåå¸å¼ç³»ç»ãæ°æ®å­å¨ãèæåãç½ç»ãæä½ç³»ç»ç­å ä¸ªé¨åãæ¬é¨åè¯¦ç»çåºç¡æ¶æè¯·åèç¬èå¨ 2016: æçææ¯ä½ç³»ç»æå¾ä¸æä¸­çæè¿°ï¼æ¬ä»åºç®ååå«çä¸»è¦åå®¹åä¸ºå¼æºé¡¹ç®ä¸åä¸ªææ¯é¢åçæç« ã

å»ºè®®åå¾ xCompass/alfred-sg äº¤äºå¼å°æ£ç´¢ãæ¥æ¾éè¦çæç« /é¾æ¥/ä¹¦ç±/è¯¾ç¨ï¼æèç´æ¥æµè§æ¬ä»åºçç®å½ä»¥äºè§£æ´å¤åå®¹ã
Nav | å¯¼èª


Linux ç¯


åå¸å¼è®¡ç®ç¯


èæåä¸å®¹å¨è°åº¦ç¯


åå¸å¼å­å¨ç¯


MySQL ç¯


Redis ç¯


Preface | åè¨
çæ


ç¬èæææç« éµå¾ª ç¥è¯å±äº« ç½²å-éåä¸æ§ä½¿ç¨-ç¦æ­¢æ¼ç» 4.0 å½éè®¸å¯åè®®ï¼æ¬¢è¿è½¬è½½ï¼å°éçæãå¦æè§å¾æ¬ç³»åå¯¹ä½ ææå¸®å©ï¼æ¬¢è¿ç»æå®¶å¸ä¸ä¹°ç¹çç²®(æ¯ä»å®æ«ç )~

æ´å¤ç¸å³ä¿¡æ¯è¯·æ¥çå³äºé¡µé¢ã
",411
bounswe/bounswe2019group9,Python,"Who are we ?
We are Group #9 in CMPE 352 course offered in Bogazici University in Spring , 2019. You can visit our  Wiki Page for more details.

Ä°rem UÄuz (Communicator)
Ä°brahim Kaplan
Arda Budak
Burhan AkkuÅ
Egemen GÃ¶l
Emirhan Yasin Ãetin
Gamze GÃ¼lbahar
Halit Ãzsoy
Ahmet Gedemenli
Ali Ramazan Mert

",4
bounswe/bounswe2019group9,Python,"Who are we ?
We are Group #9 in CMPE 352 course offered in Bogazici University in Spring , 2019. You can visit our  Wiki Page for more details.

Ä°rem UÄuz (Communicator)
Ä°brahim Kaplan
Arda Budak
Burhan AkkuÅ
Egemen GÃ¶l
Emirhan Yasin Ãetin
Gamze GÃ¼lbahar
Halit Ãzsoy
Ahmet Gedemenli
Ali Ramazan Mert

",4
cbuijs/shallalist,None,"shallalist
ShallaList unpacked.
http://www.shallalist.de/
",5
mrhso/Cangjie_Note,HTML,"è­¦åï¼å´ç¦æèªå°æ­¤é ç®å§å«è³æçå°å¥èï¼
Cangjie_Note
ç®åå­çè¯´æ
æ­¤åé ¡ç­è¨ææ­ç¤ºåé ¡ä¸çºäººç¥çä¸äºç´°ç¯ï¼åæä¹å±¬æ¼ãåé ¡ Projectãä¸­çå°å±±ä¸è§ã
ä¸»è¦å§å®¹è¬è§£
åé ¡å§ç¢¼ç¸é
è¬è¿°åé ¡å§ç¢¼çè½æåçã
ä¸»è§äººå£«åé ¡æ¢æ¡éï¼ææåé¡åç´è®ï¼
æ¶éèæ¥è©¢åæ²å¥¶å¥¶çä¸ç³»åä¿¡ä»¶ã
éä¸æ¬ç®æ¯è¼ä¸»è§ï¼è«é¸ææ§è§çã
åé ¡è¦åç¸é
è¬è¿°åé ¡çåç¢¼ç­è¦åã
å®æ¹è§£èªª
å®æ¹å°æ¼åé ¡çä¸äºè§£èªªã
å®æ¹è³æ
ç±å®æ¹æä¸­å¾å°çä¸äºè³æã
åé ¡çªå¤
æ°éåé ¡çä¸äºå°ç´°ç¯ã
å¶é¤ãåé ¡ Projectãé ç®

Cangjie3-Plus
Cangjie5
Cangjie_DIY

Binary è³æ
æäºè³æå±¬æ¼ Binaryï¼ä¸ä¾¿æ¼å¨ Git ååº«ç®¡çã
ä½æ¯æåæç¡åå°å¶ææ¬åï¼å æ­¤ä¸è¬æ²æå¿è¦å»ç²åã
åè¡¨

æå³æä»£

ãæå³å§ç¢¼å°ç§è¡¨ãæ­£ææ¬åã
ãäºå­åé ¡å°ç§å§ç¢¼è¡¨ãæ­£ææ¬åã
ãå­ä»£åç¢¼è¦åãå·²ææ¬åã



é ç¨ååº«ç¸½è¡¨

GitHub
GitLab
ç¢¼é²
Bitbucket
Visual Studio Team Services

åæé£æ¥

ãåé ¡ä¹åÂ·é¦¬ä¾è¥¿äºãè«å£
ãå¤©è¼äººé ¡ãè«å£
ãåé ¡è¼¸å¥æ³ãQQ ç¾¤çµ 30476878
ãåé ¡è¼¸å¥æ³ãFreenode IRC é »é #CJDFH
ãåé ¡è¼¸å¥æ³ãTelegram ç¾¤çµ @changjei

é ç®å®æ¹è¨è«ç¾¤çµ

QQ ç¾¤çµ 609486016
Freenode IRC é »é #ezinput
Telegram ç¾¤çµ @ezinput

",2
jihuun/web_crawlers,HTML,"web_crawlers
Variety of scripts for web crawling
",4
lanternpro/intro,None,"intro
",4
lannonbr/vscode-issue-tracker,JavaScript,"VS Code Issue Tracker

The VS Code Issue Tracker is a visualization of the issue count on the Microsoft/vscode repository over time.
The initial inspiration for this was to track the progress of microsoft/vscode#58336.
You can visit the site live here: vscode-issue-tracker.netlify.com
Webstack Description
The basis of the issue tracker is a serverless backend combined with a static frontend.
The backend consists of an AWS Lambda function which sends a query to the Github V4 GraphQL API once an hour to see the current number of issues on the repository. That is stored in a Cloud Firestore database.
Then, I have a scheduled job to pull the last 3 days as well as last month of entries for the recent and monthly graphs. It saves these entries to a local JS file and commits it to the repo once an hour through Git.
Finally, I wrote a simple frontend using C3.js to display the two graphs on a page. This is then committed to GitHub here and deployed to Netlify across their Application Delivery Network.
Future plans include making this more generalized so anyone can spin up a very similar project with ease.
",91
kentcdodds/bookshelf,JavaScript,"Build a ReactJS App - Bookshelf

ð hi there! My name is Kent C. Dodds and this is the
source material for
Build a ReactJS App!




 
Pre-Workshop Instructions/Requirements
In order for us to maximize our efforts during the workshop, please do the
following:

 Setup the project (follow the setup instructions below) (~5 minutes)
 Install and setup Zoom on the computer you will be
using (~5 minutes)
 Watch The Beginner's Guide to React
(available free on Egghead.io), or have the equivalent experience (77
minutes)
 Watch my talk
Why React Hooks
(35 minutes)
 Go through my
Learn React Hooks Workshop, or
have the equivalent basic experience of using hooks. You should be
experienced with useState, useEffect, and useRef.
 Go through my
Advanced React Hooks,
or have the equivalent basic experience of using advanced hooks. You
should be experienced with useContext, useReducer, useMemo, and
useCallback.

The more prepared you are for the workshop, the better it will go for you.
System Requirements

git v2 or greater
NodeJS v8 or greater
yarn v1 or greater (or npm v6 or greater)

All of these must be available in your PATH. To verify things are set up
properly, you can run this:
git --version
node --version
yarn --version # or npm --version
If you have trouble with any of these, learn more about the PATH environment
variable and how to fix it here for windows or
mac/linux.
Setup
You should be able to work through the entire workshop in the browser. This is
actually the recommended approach as it requires absolutely no setup whatsoever.
Go to this codesandbox
and you should be good to go.

If you'd rather be able to work through the workshop on your own computer, then
follow the following instructions.
After you've made sure to have the correct things (and versions) installed, you
should be able to just run a few commands to get set up:
# If you were given instructions for a specific branch to use, then use this command
# git clone --single-branch --branch <branchname> https://github.com/kentcdodds/bookshelf.git

# otherwise, this is fine:
git clone https://github.com/kentcdodds/bookshelf.git

# then do this:
cd bookshelf
npm run setup --silent
This may take a few minutes. It will ask you for your email. This is
optional and just automatically adds your email to the links in the project to
make filling out some forms easier If you get any errors, please read through
them and see if you can find out what the problem is. You may also want to look
at Troubleshooting. If you can't work it out on your own
then please file an issue and provide all the output from the
commands you ran (even if it's a lot).
Running the app
To get the app up and running (and really see if it worked), run:
npm start
This should start up your browser. If you're familiar, this is a standard
react-scripts application.
You can also open
the deployment of the app on Netlify.
Running the tests
npm test
This will start Jest in watch mode. Read the
output and play around with it.
Helpful Emoji ð¨ ð° ð¯ ð¦ ð ð£ ð¨
Each exercise has comments in it to help you get through the exercise. These fun
emoji characters are here to help you.

Kody the Koala Bear ð¨ will tell you when there's something specific you
should do
Marty the Money Bag ð° will give you specific tips (and sometimes code)
along the way
Hannah the Hundred ð¯ will give you extra challenges you can do if you
finish the exercises early.
Olivia the Owl ð¦ will give you useful tidbits/best practice notes and a
link for elaboration and feedback.
Dominic the Document ð will give you links to useful documentation
Berry the Bomb ð£ will be hanging around anywhere you need to blow stuff
up (delete code)
Alfred the Alert ð¨ may occasionally show up in the test failures with
potential explanations for why the tests are failing.

Troubleshooting

""npm run setup"" command not working
Here's what the setup script does. If it fails, try doing each of these things
individually yourself:
# verify your environment will work with the project
node ./scripts/verify

# install dependencies
npm install

# verify the project is ready to run
npm run lint
npm run test:coverage
npm run build

If any of those scripts fail, please try to work out what went wrong by the
error message you get. If you still can't work it out, feel free to open an
issue with all the output from that script. I will try to help if I
can.



  ""Error: ENOSPC: System limit for number of file watchers reached"" when running
  tests

Try increasing your system's file watchers limit:
echo fs.inotify.max_user_watches=524288 | sudo tee -a /etc/sysctl.conf && sudo sysctl -p


Read more about whatâs happening at
https://github.com/guard/listen/wiki/Increasing-the-amount-of-inotify-watchers#the-technical-details


Contributors
Thanks goes to these wonderful people
(emoji key):
Kent C. Doddsð» ð ð â ï¸Vojta Holikð¨ ð»
This project follows the
all-contributors
specification. Contributions of any kind welcome!
License
This material is available for private, non-commercial use under the
GPL version 3. If you
would like to use this material to conduct your own workshop, please contact me
at kent@doddsfamily.us
",16
hafen/htmlwidgetsgallery,CSS,"htmlwidgets gallery
This repository serves the htmwidgets gallery.
Adding a widget
If you are a widget author, you can register your widget by doing the following:

Fork this repository.
Create a png thumbnail of an interesting plot from your widget that will look good on a retina screen at 350x300 pixels and put this file in the images directory of this repository.
Add an entry for your widget in the _config.yml file of this repository with the meta data for your widget (copy another entry and modify).  Please see below for guidance on the meta data.
Push your changes and create a pull request.  To ensure the quality of widgets added to the registry and consistency in how they are displayed, you should expect some amount of discussion during your pull request.

Meta data requirements:

name: the actual name of the R package (required)
thumbnail: location of the thumbnail (required, standard is images/ghuser-ghrepo.png)
url: url to the desired landing page you'd like people to first see for the widget (the widget's home page, a vignette, or as a final resort, if not specified, the widget's github page)
jslibs: a comma separated list of javascript library names that the widget depends on, with markdown links to the home pages of the libraries
ghuser: the github user/org where the github repository for the widget resides (required)
ghrepo: the github repository name where the widget resides (required)
tags: comma separated list (with no spaces) of tags that describe the widget - see other widget's tags for ideas
cran: true if the package is on CRAN, else false
examples: url or list of urls of examples (blog posts, gists, vignettes)
ghauthor: the github handle for the primary author of the widget
short: a short (preferably one sentence) description of the package that will be displayed in limited space under the widget thumbnail in the gallery - ideally should be more than ""An htmlwidget interface to library x"" as that is obvious from jslib, etc. - instead, should describe what you can do with the widget using library x
description: a longer form description

",54
StaceyWhitmore/color-organizer,JavaScript,"Color organizer
To improve my workflow as a UI/UX developer I thought to make this start of a color organizer React app to help me to organize swatches of my favorite colors and color schemes by their hex and rgb values (Similar to what you might see in a stack of Pantone color swatches used by print a maker--only in digital form).
",3
briancrink/dotfiles,HTML,"




Fork
  , review, ð to ~/. 

Setup


Set up a New Machine


Set up Web Workflows


Set up Social Feeds


Migrate Music Collections


Jailbreak Apple Devices


Tools

Autodot
Dotshare.it
Desktoppr
Fileicon
Homebrew Bundle
Homebrew Quicklook
Homebrew Casks
Homebrew Fonts

Guides

Archlinux Wiki: Dotfiles
GitHub's Unofficial Guide to Dotfiles
How To Use and Modify Dotfiles: Corey Schafer
Getting Started with Dries Vints Dotfiles
Dotfiles are Meant to be Forked
Getting Started with Lars Kappert's Dotfiles
Getting Started with Mohammed Ajmal Siddiqui's Dotfiles: Pt. 1
Pt. 2
Hassan Ali's Guide to Managing Dotfiles
Victor Augusteo's Method to Syncing Dotfiles

Reference

Shell Startup Scripts
The Purpose of Bashrc
Bashrc Loading Order

ð¨âð»Communityð©âð»

@ptb's dotfiles
Ben Alman's dotfiles
CÄtÄlin MariÈ dotfiles
Dikiaap's dotfiles
Dries Vints dotfiles:
Brewfile
Gianni Chiappetta's dotfiles
Guillermo Caracuel Ruiz
Jan Moesen's dotfiles
Kevin Suttle's dotfiles
Lars Kappert's dotfiles
Lars Kapperts's awesome dotfiles
Lauri âLriâ Ranta's dotfiles
Mathias Bynens dotfiles
Matijs Brinkhuis's dotfiles
Mohammed Ajmal Siddiqui's dotfiles
Nicolas Gallagher's dotfiles
Tom Ryder's dotfiles

",2
conda-forge/openblas-feedstock,Shell,"About openblas
Home: http://www.openblas.net/
Package license: BSD 3-Clause
Feedstock license: BSD 3-Clause
Summary: An optimized BLAS library based on GotoBLAS2 1.13 BSD version.
Current build status

Travis






Appveyor







Azure








VariantStatus

linux_aarch64_target_platformlinux-aarch64






linux_ppc64le_target_platformlinux-ppc64le






linux_target_platformlinux-64






osx_target_platformosx-64






win_c_compilervs2015target_platformwin-64vc14












Current release info



Name
Downloads
Version
Platforms











Installing openblas
Installing openblas from the conda-forge channel can be achieved by adding conda-forge to your channels with:
conda config --add channels conda-forge

Once the conda-forge channel has been enabled, openblas can be installed with:
conda install openblas

It is possible to list all of the versions of openblas available on your platform with:
conda search openblas --channel conda-forge

About conda-forge

conda-forge is a community-led conda channel of installable packages.
In order to provide high-quality builds, the process has been automated into the
conda-forge GitHub organization. The conda-forge organization contains one repository
for each of the installable packages. Such a repository is known as a feedstock.
A feedstock is made up of a conda recipe (the instructions on what and how to build
the package) and the necessary configurations for automatic building using freely
available continuous integration services. Thanks to the awesome service provided by
CircleCI, AppVeyor
and TravisCI it is possible to build and upload installable
packages to the conda-forge
Anaconda-Cloud channel for Linux, Windows and OSX respectively.
To manage the continuous integration and simplify feedstock maintenance
conda-smithy has been developed.
Using the conda-forge.yml within this repository, it is possible to re-render all of
this feedstock's supporting files (e.g. the CI configuration files) with conda smithy rerender.
For more information please check the conda-forge documentation.
Terminology
feedstock - the conda recipe (raw material), supporting scripts and CI configuration.
conda-smithy - the tool which helps orchestrate the feedstock.
Its primary use is in the construction of the CI .yml files
and simplify the management of many feedstocks.
conda-forge - the place where the feedstock and smithy live and work to
produce the finished article (built conda distributions)
Updating openblas-feedstock
If you would like to improve the openblas recipe or build a new
package version, please fork this repository and submit a PR. Upon submission,
your changes will be run on the appropriate platforms to give the reviewer an
opportunity to confirm that the changes result in a successful build. Once
merged, the recipe will be re-built and uploaded automatically to the
conda-forge channel, whereupon the built conda packages will be available for
everybody to install and use from the conda-forge channel.
Note that all branches in the conda-forge/openblas-feedstock are
immediately built and any created packages are uploaded, so PRs should be based
on branches in forks and branches in the main repository should only be used to
build distinct package versions.
In order to produce a uniquely identifiable distribution:

If the version of a package is not being increased, please add or increase
the build/number.
If the version of a package is being increased, please remember to return
the build/number
back to 0.

Feedstock Maintainers

@gillins
@groutr
@isuruf
@jakirkham
@jschueller

",5
grmat/base16-firefox,HTML,"base16-firefox
base16 themes for Mozilla Firefox. Using WebExtensions Themes.

Example screenshot with Tomorrow Night by chriskempson
Building


Populate working directory with sources.yaml


Use a builder, update colour schemes and add base16-firefox to the templates build


Use a builder to generate the theme files inside the firefox folder, e.g.
pybase16 build -o templates/firefox/ext/



Build the WebExtension, either manually or with web-ext (web-ext build -s ext)


Usage

Load extension temporarily via about:debugging or via about:addons (if signed)
or
Install from AMO
Navigate to about:addons, open the preferences for base16 and select your theme.

Known issues
While the WebExtension stores the theme in its local storage, and it should automatically reload the theme on Firefox restart, it will not be represented in the preferences page. The selector will initially always show the first entry.
",6
rooseveltframework/roosevelt,JavaScript,"Roosevelt MVC web framework
  
Roosevelt is a web application development framework based on Express that aims to be the easiest web framework on the Node.js stack to learn and use.
Some notable features:

Minimal boilerplate to get started. Teddy Rooseveltâthe most badass President of all-timeâcurtailed the abuse of monopolists, so there's no way he would ever put up with all the indecipherable boilerplate common to other web frameworks.
Default directory structure is simple, but easily configured.
Concise default MVC architecture.
Uses Teddy HTML templates by default which are much easier to read and maintain than popular alternatives. Can be configured to use any templating system that supports Express.
LESS and UglifyJS preconfigured out of the box to intelligently minify your external facing CSS and JS files. Other preprocessors are supported via wrapper modules.
Built-in, easy to use interface to browserify bundling for frontend JS modularization using the Node.js module exports and require syntax.
Automatic HTML validation in development mode of your post-server rendered HTML using a local instance of the Nu HTML Checker. 


Note: this is documentation for Roosevelt 0.14.x. If you need API documentation for a previous version of Roosevelt, look here.
Table of contents

Create and run a Roosevelt app

Using the Roosevelt app generator
Create a Roosevelt app manually
Available npm scripts
Available command line arguments
Combining npm scripts and command line arguments
Recognized environment variables


Default directory structure

Default .gitignore


Configure your app with parameters

App behavior parameters
MVC parameters
Statics parameters
Public folder parameters
Events
Event list


Making controller files
Making model files
Making view files
Express variables exposed by Roosevelt
Express middleware and other configurations automatically loaded by Roosevelt
Authoring your own CSS and JS preprocessors
Documentation for previous versions of Roosevelt

Create and run a Roosevelt app
First you will need to install Node.js. Both the current and LTS version of Node.js are supported. It is recommended that you install using a Node.js version manager like nvm rather than the official installer, as a version manager will allow you to switch between multiple versions of Node.js easily.
Some important caveats to note:

nvm is not available on Windows. Windows users should try out nvm-windows or nvs.
It is also recommended that Windows users use a terminal that supports emojis, such as cmder, at least until Microsoft rolls out this planned update to cmd.exe.
Linux/macOS users who install Node.js without a version manager like nvm may need to resolve some commonly encountered permissions headaches associated with npm. As such, use of nvm is strongly recommended.

The Java JDK is also required for development work. The JDK is required for the local HTML validator feature.
Once you have a sane development environment, you can proceed with the standard install procedure below.
Using the Roosevelt app generator
The Roosevelt app generator is a command line script based on Yeoman that can create a sample Roosevelt app for you.
To use it, first globally install Yeoman and the Yeoman-based Roosevelt app generator:
npm i -g yo generator-roosevelt

Create a Roosevelt app using the Roosevelt app generator:
yo roosevelt

Then follow the prompts.
Afterward, cd to your app's directory and install dependencies:
npm i

Run in development mode:
npm run d

Or run in production mode:
npm run p

Create a Roosevelt app manually
It is also possible to create a Roosevelt app without using the app generator. This will result in a more minimalist default configuration (e.g. no CSS or JS preprocessors enabled by default).
To do that:

First create a new folder and cd into it.
Then npm i roosevelt. This will create a node_modules folder with Roosevelt and its bare minimum dependencies.
Create a file named app.js.
Put this code in app.js:
require('roosevelt')({
  'generateFolderStructure': true
}).startServer()

Then node app.js. If the generateFolderStructure param is set to true like the above code example, an entire Roosevelt app with bare minimum viability will be created and the server will be started. See below for more information about parameter configuration.

Available npm scripts
Roosevelt apps created with the app generator come with the following notable npm scripts prepopulated in package.json:


npm run production: Runs the app in production mode.

Default shorthands:

npm run prod
npm run p
npm start


Script is short for: node app.js --production-mode



npm run development: Runs the app in development mode.

Default shorthands:

npm run dev
npm run d


Script is short for: node app.js --development-mode



npm run kill-validator: Finds the HTML validator process and kills it if it is running.

Default shorthand:

npm run kv


Script is short for: node ./node_modules/roosevelt/lib/scripts/killValidator.js



npm run clean: Removes all build artifacts (symlinks and directories) auto-generated by Roosevelt. Will prompt to confirm before deleting any files.

Default shorthand:

npm run c


Script is short for: node ./node_modules/roosevelt/lib/scripts/appCleanup.js



npm run config-audit: Scans current rooseveltConfig and scripts in package.json and warns about any params or npm scripts that don't match the current Roosevelt API:

Default shorthand:

npm run a


Script is short for: node ./node_modules/roosevelt/lib/scripts/configAuditor.js
Note: this will run automatically whenever you run npm i as well.



Available command line arguments

node app.js --production-mode : Runs the app in production mode.

Default shorthands:

--prod
-p




node app.js --development-mode : Runs the app in development mode.

Default shorthands:

--dev
-d




node app.js --cores <m> : Configures how many CPUs your app will run on.

<m> can be either a number representing the desired cores, or you can supply max to use all available CPUs.

Default is 1.


Default shorthand:

-c




node app.js --enable-validator : Forces the HTML validator to be enabled.

Default shorthands:

--html-validator
-h




node app.js --disable-validator : Forces the HTML validator to be disabled.

Default shorthands:

--raw
-r




node app.js --background-validator : Forces the HTML validator to run as a detached background process.

Default shorthand:

-b




node app.js --attach-validator : Forces the HTML validator to run as an attached process.

Default shorthand:

-a




node app.js --enable-validator-autokiller : Forces the HTML validator autokiller to be enabled.

Default shorthands:

--html-validator-autokiller
-k




node app.js --disable-validator-autokiller : Forces the HTML validator autokiller to be disabled.

Default shorthands:

--no-autokiller
-n




node app.js --host-public : Forces Roosevelt to always host the public folder even when alwaysHostPublic is set to false. Useful for testing production mode.

Default shorthands:

--statics
-s





Combining npm scripts and command line arguments
The npm scripts can be combined with the command line flags.
For example, running npm run d -- -r will run your app in development mode and force the HTML validator to be disabled.
Recognized environment variables
The following is a list of environment variables that Roosevelt listens for.

NODE_ENV:

Set to production to force the app into production mode.
Set to development to force the app into development mode.


NODE_PORT: Default HTTP port to run your app on.
HTTP_PORT: Default HTTP port to run your app on. Takes precedence over NODE_PORT.
HTTPS_PORT: Default HTTPS port to run your app on.
ROOSEVELT_VALIDATOR:

Set to detached to force the HTML validator to run as a detached background process.
Set to attached to force the HTML validator to run as an attached process.


ROOSEVELT_AUTOKILLER:

Set to on to spawn a process to kill the HTML validator if it is running in the background and idle for more than a certain amount of time. The timeout can be configured in app behavior params.
Set to offto disable the HTML validator autokiller.



Environment variable precedence:


Environment variables supersede your app's params.


Environment variables can be overridden with command line arguments.


Default directory structure

app.js: Entry point to your application. Feel free to rename this, but make sure to update package.json's reference to it.
mvc: Folder for models, views, and controllers. All configurable via params (see below).

controllers: Folder for controller files.
models: Folder for model files.
views: Folder for view files.


node_modules: A standard folder where all modules your app depends on (such as Roosevelt) are installed to. This folder is created by the npm i command.
package.json: A standard file in Node.js apps for configuring your app.
public: All contents within this folder will be exposed as static files.
statics: Folder for source CSS, image, JS, and other static files. By default some of the contents of this folder are symlinked to from public, which you can configure (see below).

css: Folder for source CSS files.
images: Folder for source image files.
js: Folder for source JS files.


.gitignore: A standard file which contains a list of files and folders to ignore if your project is in a git repo.

Default .gitignore
The default .gitignore file contains many common important things to ignore, however you may need to tweak it to your liking before committing a fresh Roosevelt app to your git repo.
Some notable things ignored by default and why:

public: It's recommended that you don't create files in this folder manually, but instead use the staticsSymlinksToPublic param detailed below to expose folders in your statics directory via auto-generated symlinks.
.build: By default Roosevelt will compile LESS and JS files down to minified versions in statics/.build when the server starts. As such, it's not recommended to place files in the build directory manually.
node_modules: This folder will be auto-generated when you run the npm i step to set up your app. Since some modules you might include later in your app can be platform-specific and are compiled for your OS during the install step, it's generally not recommended to commit the node_modules folder to git.

Configure your app with parameters
Roosevelt is designed to have a minimal amount of boilerplate so you can spend less time focused on configuration and more time writing your app. All parameters are optional. As such, by default, all that's in app.js is this:
require('roosevelt')().startServer();
Roosevelt will determine your app's name by examining ""name"" in package.json. If none is provided, it will use Roosevelt Express instead.
Also, while it is recommended that you pass params to Roosevelt via package.json under ""rooseveltConfig"", you can also pass params programmatically via Roosevelt's constructor like so:
require('roosevelt')({
  paramName: 'paramValue',
  param2:    'value2',
  etc:       'etc'
}).startServer();
This is particularly useful for setting params that can't be defined in package.json such as event handlers (see below).
App behavior parameters


port: The HTTP port your app will run on.

Default: [Number] 43711.



enableCLIFlags: Enables parsing of command line flags.

Default: [Boolean] true.



generateFolderStructure: When enabled Roosevelt will generate user specified directories (e.g. MVC parameters and statics parameters).

Default: [Boolean] true.

Exception to default: When package.json is not present or rooseveltConfig is not present in package.json, this param will be automatically set to false by default. This is a defensive measure to minimize the risk of files and folders being created in scenarios when they are not wanted.


This param is useful in scenarios when you want to create a Roosevelt app entirely from nothing (without using generator-roosevelt). See create a Roosevelt app manually for an example.



appDir: Root directory of your application.

Default: [String] The directory where your project package.json is located.



localhostOnly: Listen only to requests coming from localhost in production mode. This is useful in environments where it is expected that HTTP requests to your app will be proxied through a more traditional web server like Apache or nginx. This setting is ignored in development mode.

Default: [Boolean] true.



logging: Params to pass to roosevelt-logger. See roosevelt-logger params documentation for configuration options.


Default: [Object]
{
  ""methods"": {
    ""http"": true,
    ""info"": true,
    ""warn"": true,
    ""error"": true,
    ""verbose"": false
  }
}


You can also declare a custom log types and classify them as logs, warnings, or errors:


Default logging param with custom log type called debug added to it: [Object]
{
  ""http"": true,
  ""info"": true,
  ""warn"": true,
  ""verbose"": false,
  ""debug"": {
    ""enable"": true,
    ""type"": ""error""
  }
}


enable param: Enables or disables the custom log.

Default: [Boolean] true.



type param: Specifies what kind of log your custom log is:

Allowed values: [String] info, warn, or error.







minify: Enables HTML minification as well as the minification step in supporting CSS and JS compilers.

Default: [Boolean] true.
Note: Automatically disabled during development mode.



htmlValidator: Params to send to html-validator:


enable: [Boolean] Enables or disables the built-in HTML validator.

Note: The validator is only available in development mode.



exceptions: Sending a custom request header can disable the validator on a per request basis. The name of this request header and model value can be customized with this param.


Default: [Object]
""exceptions"": {
  ""requestHeader"": ""Partial"",
  ""modelValue"": ""_disableValidator""
}




port: [Number] Port to spawn the validator process on.


separateProcess: [Object] How to run the validator:

enable: [Boolean] Run the validator as a detached background process.
autoKiller: [Boolean] Spawns a process to kill the validator if it is running in the background and idle for more than a certain amount of time.
autoKillerTimeout: [Number] Time (in milliseconds) that the validator auto-killer process waits before it kills the validator running in the background.



showWarnings: [Boolean] When set to true, shows HTML validation warnings in addition to errors.


Default: [Object]
{
  ""enable"": true,
  ""separateProcess"": {
    ""enable"": true,
    ""autoKiller"": true,
    ""autoKillerTimeout"": 360000
  },
  ""port"": 48888,
  ""exceptions"": {
    ""requestHeader"": ""Partial"",
    ""modelValue"": ""_disableValidator""
  },
  ""showWarnings"": true
}




multipart: Settings to pass along to formidable using formidable's API for multipart form processing. Access files uploaded in your controllers by examining the req.files object. Roosevelt will remove any files uploaded to the uploadDir when the request ends automatically. To keep any, be sure to move them before the request ends. To disable multipart forms entirely, set this param to false.

Default: [Boolean]
{
  ""multiples"": true
}




toobusy: Params to pass to the node-toobusy module.


maxLagPerRequest: [Number] Maximum amount of time (in milliseconds) a given request is allowed to take before being interrupted with a 503 error.


lagCheckInterval: [Number] Interval (in milliseconds) for checking event loop lag in milliseconds.


Default: [Object]
{
  ""maxLagPerRequest"": 70,
  ""lagCheckInterval"": 500,
}




bodyParser: Parameters to supply to body-parser.json.


Default: [Object]
{
  ""urlEncoded"": {
    ""extended"": true
  },
  ""json"": {}
}




checkDependencies: Whether or not to warn if dependencies are out of date.

Default: [Boolean] true.



cores: By default, Roosevelt will run on 1 CPU, but you can change the number of cores that the app will run on with this param.

Default: [Number] 1.
To use all available cores, set this value to max.



shutdownTimeout: Maximum amount of time in milliseconds given to Roosevelt to gracefully shut itself down when sent the kill signal.

Default: [Number] 30000 (30 seconds).



HTTPS parameters

https: [Object] Run a HTTPS server using Roosevelt.

Object members:

enable: Enable a HTTPS server.

Default: [Boolean] false.


force: Disallow unencrypted HTTP and route all traffic through HTTPS.

Default: [Boolean] false.


port: The port your app will run a HTTPS server on.

Default: [Number] 43733.


authInfoPath: [Object] Specify either the paths where the server certificate files can be found or set the appropriate parameters to be a PKCS#12-formatted string or certificate or key strings.

Default: undefined
Object members:

p12: [Object] Parameter used when the server certificate/key is in PKCS#12 format.

Object members:

p12Path:  [String] Either the path to a PKCS#12-formatted file (.p12/.pfx) or a PKCS#12-formatted string or buffer (i.e. the result of fs.readFileSync(/path/to/file/example.p12))

Default: undefined


passphrase: [String] The password used to encrypt the PKCS#12-formatted file or string.

Default: undefined.






authCertAndKey: [Object] Parameter used when the server certificate and key are in separate PEM-encoded files.

Object members:

cert: [String] Either the path to a PEM-encoded certificate file (.crt, .cer, etc.) or a PEM-encoded certificate string.

Default: undefined


key: [String] Either the path to a PEM-encoded key file (.crt, .cer, etc.) or a PEM-encoded key string for the certificate given in cert.

Default: undefined










caCert: [String] Either the path to a PEM-encoded Certificate Authority root certificate or certificate chain or a PEM-encoded Certificate Authority root certificate or certificate chain string. This certificate (chain) will be used to verify client certificates presented to the server. It is only needed if requestCert and rejectUnauthorized are both set to true and the client certificates are not signed by a Certificate Authority in the default publicly trusted list of CAs curated by Mozilla.

Default: undefined.


requestCert: [Boolean] Set whether to request a certificate from the client attempting to connect to the server to verify the client's identity.

Default: undefined.


rejectUnauthorized: [Boolean] Set whether to reject connections from clients that do no present a valid certificate to the server. (Ignored if requestCert is set to false.)

Default:  undefined.


Default: [Object] {}.





MVC parameters


modelsPath: Relative path on filesystem to where your model files are located.

Default: [String] ""mvc/models"".



viewsPath: Relative path on filesystem to where your view files are located.

Default: [String] ""mvc/views"".



viewEngine: What templating engine to use, formatted as ""fileExtension: nodeModule"".


generator-roosevelt default: [String] ""html: teddy"".


Also by default when using the generator, the module teddy is marked as a dependency in package.json.


Bare Roosevelt default (when an app is created without the generator): [String] none. Can also be set to null to use no templating engine.


To use multiple templating systems, supply an array of engines to use in the same string format. Each engine you use must also be marked as a dependency in your app's package.json. Whichever engine you supply first with this parameter will be considered the default.


Example configuration using multiple templating systems: [Object]
{
  ""viewEngine"": [
    ""html: teddy"",
    ""mustache: mustache"",
    ""handlebars: handlebars"",
    ""ejs: ejs""
  ]
}




controllersPath: Relative path on filesystem to where your controller files are located.

Default: [String] ""mvc/controllers"".



errorPages: Relative path on filesystem to where your various error page controller files are located. If you do not supply them, Roosevelt will use its default ones instead:

notFound: Your 404 Not Found error page.

Default: [String] ""404.js"".


internalServerError: Your Internal Server Error error page.

Default: [String] ""5xx.js"".


serviceUnavailable: Your 503 Service Unavailable error page.

Default: [String] ""503.js"".





routers: [Object] List of Express Routers to create for groups of controllers or static files. If none are defined, Roosevelt will default to creating one single global router with the route prefix / that all controllers and all static files will be routed through.

Object members:


controllers: [Array] List of Express Routers which can be used to (among other things) prefix a whole series of controller routes.

prefix: [String] The URL path prefix for the router to use.
files: [Array] List of files or directories in controllersPath that will be mounted to this route.
Default: [Boolean] false.
Note: controllers can also be a [String] that represents a schema file within the controllers directory. That file should define and export the list of Express Routers the same way as you would within the rooseveltConfig.
Example usage:

[{
  ""prefix"": ""/something"",
  ""files"": [""controller.js"", ""directory""]
}]


public: [Array] List of Express Routers which can be used to (among other things) prefix a whole series of static files into a series of public routes.

prefix: [String] The URL path prefix for the public directory to use.
dirs: [Array] List of directories in publicFolder that will be mounted to this route.
Default: [Boolean] false.
Example usage:

[{
  ""prefix"": ""/something"",
  ""dirs"": [""css"", ""images"", ""js""]
}]






Statics parameters


staticsRoot: Relative path on filesystem to where your source static assets are located. By default this folder will not be made public, but is instead meant to store unprocessed or uncompressed source assets that will later be preprocessed and exposed in public.

Default: [String] ""statics"".



htmlMinifier: How you want Roosevelt to minify your HTML:


enable: [Boolean] Enable HTML minification.

Note: Minification is automatically disabled in development mode.



exceptionRoutes: [Array] List of controller routes that will skip minification entirely. Set to false to minify all URLs.


options: [Object] Params to supply to html-minifier's API.


Default: [Object]
{
  ""enable"": true,
  ""exceptionRoutes"": false,
  ""options"": {
    ""removeComments"": true,
    ""collapseWhitespace"": true,
    ""collapseBooleanAttributes"": true,
    ""removeAttributeQuotes"": true,
    ""removeEmptyAttributes"": true
  }
}




css: [Object] How you want Roosevelt to configure your CSS preprocessor:


sourcePath: Subdirectory within staticsRoot where your CSS files are located. By default this folder will not be made public, but is instead meant to store unminified CSS source files which will be minified and written to a build directory when the app is started.


compiler: [Object] Which Roosevelt CSS preprocessor middleware (if any) to use.


nodeModule: [String] Node module name of the Roosevelt CSS preprocessor middleware you wish to use.

Note: Your chosen Roosevelt CSS preprocessor module must also be marked as a dependency in your app's package.json.



params: [Object] Params to send to the Roosevelt CSS preprocessor middleware if it accepts any.


Note: The default preprocessor for a Roosevelt app created with generator-roosevelt is roosevelt-less, which is marked as a dependency in package.json on freshly generated Roosevelt apps. See roosevelt-less usage for details on what params are available.

The Roosevelt team also maintains roosevelt-sass, an alternative to roosevelt-less.



generator-roosevelt default configuration: [Object]
{
  ""nodeModule"": ""roosevelt-less"",
  ""params"": {
    ""cleanCSS"": {
      ""advanced"": true,
      ""aggressiveMerging"": true
    },
    ""sourceMap"": null
  }
}


Bare Roosevelt default (when an app is created without the generator): [String] none. Can also be set to null to use no CSS compiler.




whitelist: Array of CSS files to whitelist for compiling. Leave undefined to compile all files. Supply a : character after each file name to delimit an alternate file path and/or file name for the minified file.

Example array member: [String] less/example.less:.build/css/example.min.css (compiles less/example.less into .build/css/example.min.css).



output: Where to write compiled CSS files to. This folder will be symlinked into public by default.


symlinkToPublic: [Boolean] When enabled Roosevelt will automatically add your CSS directory to the staticsSymlinksToPublic param.

Note: If the compiler is enabled output will be symlinked. If not,  sourcePath will be symlinked.



versionFile: If enabled, Roosevelt will create a CSS file which declares a CSS variable containing your app's version number from package.json. Enable this option by supplying an object with the member variables fileName and varName.


Default: null.


Example usage (with roosevelt-less): [Object]
{
  ""fileName"": ""_version.less"",
  ""varName"": ""appVersion""
}


Assuming the default Roosevelt configuration otherwise, this will result in a file statics/css/_version.less with the following content:
/* do not edit; generated automatically by Roosevelt */ @appVersion: '0.1.0';


Some things to note:

If there is already a file there with that name, this will overwrite it, so be careful!
It's generally a good idea to add this file to .gitignore, since it is a build artifact.





Default: [Object]
{
  ""sourcePath"": ""css"",
  ""compiler"": {
    ""nodeModule"": ""roosevelt-less"",
    ""params"": {
      ""cleanCSS"": {
        ""advanced"": true,
        ""aggressiveMerging"": true
      },
      ""sourceMap"": null
    }
  },
  ""whitelist"": null,
  ""output"": "".build/css"",
  ""symlinkToPublic"": true,
  ""versionFile"": null
}




js: [Object] How you want Roosevelt to configure your JS compiled:


sourcePath: Subdirectory within staticsRoot where your JS files are located. By default this folder will not be made public, but is instead meant to store unminified JS source files which will be minified and written to a build directory when the app is started.


compiler: Which Roosevelt JS minifier middleware (if any) to use.


nodeModule: [String] Node module name of the Roosevelt JS minifier middleware you wish to use.

Note: Your chosen Roosevelt JS minifier module must also be marked as a dependency in your app's package.json.



showWarnings: [Boolean] Set to true to display compiler module warnings.


params: [Object] Params to send to the Roosevelt JS minifier middleware if it accepts any.


Note: The default minifier for a Roosevelt app created with generator-roosevelt is roosevelt-uglify, which is marked as a dependency in package.json on freshly generated Roosevelt apps. See roosevelt-uglify usage for details on what params are available.

The Roosevelt team also maintains roosevelt-closure, an alternative to roosevelt-uglify.



generator-roosevelt default configuration: [Object]
{
  ""nodeModule"": ""roosevelt-uglify"",
  ""showWarnings"": false,
  ""params"": {}
}


Bare Roosevelt default (when an app is created without the generator): [String] none. Can also be set to null to use no JS minifier.




whitelist: Array of JS files to whitelist for minification. Leave undefined to compile all files. Supply a : character after each file name to delimit an alternate file path and/or file name for the minified file.

Default: null (compiles all JS files, if a JS minifier is enabled).
Example array member: [String] library-name/example.js:lib/example.min.js (compiles library-name/example.js into lib/example.min.js).



blacklist: Array of JS files to exempt from minification. These files will be copied as-is to the build folder. Leave undefined to compile all files.

Default: null (compiles all JS files, if a JS minifier is enabled).
Example: [String] example.js.



output: Where to write compiled JS files to. This folder will be symlinked into public by default.

Default: [String] "".build/js"".



symlinkToPublic: [Boolean] When enabled Roosevelt will automatically add your JS directory to the staticsSymlinksToPublic param.

Note: If the compiler is enabled output will be symlinked. If not,  sourcePath will be symlinked.



bundler: Params related to bundling JS with browserify:


Note: Use of browserify in Roosevelt is optional. If no bundles are defined here, the browserify step will be skipped.


bundles: [Array] Declare one or more source JS files in your sourcePath to be browserify bundles via its bundle method.

env: [String] Bundle only in dev or prod mode. Omitting env will result in bundling in both modes.
params: [Object] The browserify params to send to browserify. If it is not set, these default params will be sent: {""paths"": <your jsPath>}.
Examples: [Array] of [Objects]


Browserify bundle example declaring one bundle:
[
  {
    ""outputFile"": ""bundle.js"",
    ""files"": [
      ""landingPage.js"",
      ""main.js"",
      ""etc.js""
    ],
    ""params"": {
      ""someOpt"":
      ""someValue""
    }
  }
]



Browserify bundle example declaring one bundle only used in dev mode:
[
  {
    ""outputFile"": ""bundle.js"",
    ""env"": ""dev"",
    ""files"": [
      ""landingPage.js"",
      ""main.js"",
      ""etc.js""
    ],
    ""params"": {
      ""someOpt"": ""someValue""
    }
  }
]



Browserify bundle example declaring multiple bundles:
[
  {
    ""outputFile"": ""bundle1.js"",
    ""files"": [
      ""landingPage.js"",
      ""main.js"",
      ""etc.js""
    ],
    ""params"": {
      ""someOpt"": ""someValue""
    }
  },
  {
    ""outputFile"": ""bundle2.js"",
    ""files"": [
      ""somethingElse.js"",
      ""anotherThing.js"",
      ""etc.js""
    ]
  },
  etc...
]




Default: [Array] [].



output: Subdirectory within sourcePath where you would like browserify to deposit bundled JS files it produces.

Default: [String] "".bundled"".



expose: Whether or not to copy the output directory to your build directory.

Default: [Boolean] true.





Default: [Object]
{
  ""sourcePath"": ""js"",
  ""compiler"": {
    ""nodeModule"": ""roosevelt-uglify"",
    ""showWarnings"": false,
    ""params"": {}
  },
  ""whitelist"": null,
  ""blacklist"": null,
  ""output"": "".build/js"",
  ""symlinkToPublic"": true,
  ""bundler"": {
    ""bundles"": [],
    ""output"": "".bundled"",
    ""expose"": true
  }
}




cleanTimer: Time in milliseconds to allow before considering files in CSS/JS compile directories stale and recommending running npm run clean.

Default: [Number] 604800000 (1 week)
Useful time conversions to milliseconds to configure this param with:

1 day: 86400000
1 week: 604800000
1 month: 2419200000


Set to 0, null, or anything that isn't a number to disable the check entirely.



Public folder parameters


publicFolder: All files and folders in this directory will be exposed as static files.

Default: [String] ""public"".



favicon: Location of your favicon file.

generator-roosevelt default: [String] ""images/favicon.ico"".
Bare Roosevelt default (when an app is created without the generator): [String] none. Can also be set to null to use no favicon.



staticsSymlinksToPublic: Array of folders from staticsRoot to make symlinks to in your public folder, formatted as either ""linkName: linkTarget"" (whitespace optional) or simply ""linkName"" if the link target has the same name as the desired link name.

Default: [Array] of [Strings]
[
  ""css: .build/css"",
  ""images"",
  ""js: .build/js""
]




versionedPublic: If set to true, Roosevelt will prepend your app's version number from package.json to your public folder. Versioning your public folder is useful for resetting your users' browser cache when you release a new version.

Default: [Boolean] false.



alwaysHostPublic:  By default in production mode Roosevelt will not expose the public folder. It's recommended instead that you host the public folder yourself directly through another web server, such as Apache or nginx. However, if you wish to override this behavior and have Roosevelt host your public folder even in production mode, then set this setting to true.

Default: [Boolean] false.



Events
Roosevelt provides a series of events you can attach code to by passing a function to the desired event as a parameter to Roosevelt's constructor like so:
require('roosevelt')({
  onServerStart: (app) => { /* do something */ }
});
Event list

onServerInit(app): Fired when the server begins starting, prior to any actions taken by Roosevelt.

app: The Express app created by Roosevelt.


onServerStart(app): Fired when the server starts.

app: The Express app created by Roosevelt.


onReqStart(req, res, next): Fired at the beginning of each new request.

req: The request object created by Express.
res: The response object created by Express.
next: Callback to continue with the request. Must be called to continue the request.


onReqBeforeRoute(req, res, next): Fired just before executing the controller.

req: The request object created by Express.
res: The response object created by Express.
next: Callback to continue with the request. Must be called to continue the request.


onReqAfterRoute(req, res): Fired after the request ends.

req: The request object created by Express.
res: The response object created by Express.



Making controller files
Controller files are places to write Express routes. A route is the term Express uses for URL endpoints, such as http://yoursite/blog or http://yoursite/about.
To make a new controller, make a new file in the controllers directory. For example:
module.exports = (router, app) => { // router is an Express router and app is the Express app created by Roosevelt

  // standard Express route
  router.route('/about').get((req, res) => {

    // load a data model
    let model = require('models/dataModel');

    // render a Teddy template and pass it the model
    res.render('about', model);
  });
};
Note: If custom routers are being used, the res.redirect() method will prepend the prefix to redirects that are relative to the hostname. To override this setting pass true as the last argument.
Sometimes it is also useful to separate controller logic from your routing. This can be done by creating a reusable controller module.
An example would be creating a reusable controller for ""404 Not Found"" pages:
// reusable controller ""notFound.js""
module.exports = (app, req, res) => {
  let model = { content: 'Cannot find this page' };
  res.status(404);
  res.render('404', model);
}
Reusable controller modules differ from standard controller modules in that they accept req and res arguments in addition to app. They are meant to be called from within routes rather than define new routes.
This allows them to be called at will in any other controller's route when needed:
// import the ""notFound"" controller logic previously defined
const throw404 = require('controllers/notFound');

module.exports = (router, app) => {
  router.route('/whatever').get((req, res) => {

    // test some logic that could fail
    // thus triggering the need for the 404 controller
    if (something) {

      // logic didn't fail
      // so render the page normally
      let model = require('models/dataModel');
      res.render('whatever', model);
    }
    else {

      // logic failed
      // so throw the 404 by executing your reusable controller
      throw404(app, req, res);
    }
  });
};
Making model files
Since the above example requires a model file named dataModel, you will need to make that too. To do that, place a file named dataModel.js in mvc/models.
Here's a simple example dataModel.js data model:
module.exports = {some: 'data'};
Making view files
Views by default are Teddy templates. See the Teddy documentation for information about how to author Teddy templates.
You can also use different templating engines by tweaking Roosevelt's MVC parameters.
Express variables exposed by Roosevelt
Roosevelt supplies several variables to Express that you may find handy. Access them using app.get('variableName').



Express variable
Description




express
The Express module.


viewEngine e.g. teddy by default
Any view engine(s) you define will be exposed as an Express variable. For instance, the default view engine is teddy. So by default app.get('teddy') will return the teddy module.


formidable
The formidable module. Used for handling multipart forms.


morgan
The morgan module. HTTP request logger middleware.


appName
The name of your app derived from package.json. Uses ""Roosevelt Express"" if no name is supplied.


appVersion
The version number of your app derived from package.json.


appDir
The directory the main module is in.


package
The contents of package.json.


staticsRoot
Full path on the file system to where your app's statics folder is located.


publicFolder
Full path on the file system to where your app's public folder is located.


cssPath
Full path on the file system to where your app's CSS source files are located.


jsPath
Full path on the file system to where your app's JS source files are located.


cssCompiledOutput
Full path on the file system to where your app's minified CSS files are located.


jsCompiledOutput
Full path on the file system to where your app's minified JS files are located.


jsBundledOutput
Full path on the file system to where your app's bundled JS files are located.


modelsPath
Full path on the file system to where your app's models folder is located.


viewsPath
Full path on the file system to where your app's views folder is located.


controllersPath
Full path on the file system to where your app's controllers folder is located.


params
The params you sent to Roosevelt.


flags
Command line flags sent to Roosevelt.


logger
The logging module used for simple parameterized logging.



Additionally the Roosevelt constructor returns the following object:



Roosevelt object members
Description




expressApp
[Object] The Express app created by Roosevelt.


httpServer
[Object] The http server created by Roosevelt. httpServer is also available as a direct child of app, e.g. app.httpServer.


httpsServer
[Object] The https server created by Roosevelt. httpsServer is also available as a direct child of app, e.g. app.httpsServer.


initServer
[Method] Starts the HTML validator, sets up some middleware, runs the CSS and JS preprocessors, and maps routes, but does not start the HTTP server. Call this method manually first instead of startServer if you need to setup the Express app, but still need to do additional setup before the HTTP server is started. This method is automatically called by startServer once per instance if it has not yet already been called.


startServer
[Method] Calls the listen method of http, https, or both (depending on your configuration) to start the web server with Roosevelt's config.


stopServer
[Method] Stops the server and takes an optional argument stopServer('close') which stops the server from accepting new connections before exiting.



Express middleware and other configurations automatically loaded by Roosevelt
In addition to exposing a number of variables to Express and providing the MVC interface outlined above, Roosevelt also:

Includes the compression middleware.
Includes the cookie-parser middleware.
Disables x-powered-by and etag.
Logs HTTP requests to the console using morgan, specifically morgan('combined').
Includes the method-override middleware.

Authoring your own CSS and JS preprocessors
There are two ways to replace Roosevelt's default CSS and JS preprocessors with another one.
The first way is to swap out the default roosevelt-less CSS preprocessor module or roosevelt-uglify JS preprocessor module for something else, e.g. roosevelt-sass, roosevelt-closure, or a custom module that you've created.
You can also define your own preprocessors on the fly at start time in Roosevelt's constructor like so:
let app = require('roosevelt')({
  cssCompiler: app => {
    return {
      versionCode: app => {
        // write code to return the version of your app here
      },
      parse: (app, fileName) => {
        // write code to preprocess CSS here
      }
    }
  },
  jsCompiler: app => {
    return {
      parse: (app, fileName) => {
        // write code to preprocess JS here
      }
    }
  }
})
API:

cssCompiler(app): Custom CSS preprocessor.

versionCode(app): Function to return the version of your app.

app: The Express app created by Roosevelt.


parse(app, fileName): Function to preprocess CSS.

app: The Express app created by Roosevelt.
fileName: Name of file to compile.




jsCompiler(app): Custom JavaScript preprocessor.

parse(app, fileName): Function to preprocess JavaScript.

app: The Express app created by Roosevelt.
fileName: Name of file to compile.





Lastly, in order to activate the custom preprocessor feature, alter package.json to declare the compiler nodeModule to be custom:
""css"": {
  ""compiler"": {
    ""nodeModule"": ""custom"",
  [...]
""js"": {
  ""compiler"": {
    ""nodeModule"": ""custom"",
  [...]
Documentation for previous versions of Roosevelt

0.13.x
0.12.x
0.11.x
0.10.x
0.9.x
0.8.x
0.7.x
0.6.x
Olderâ¦ here be dragons.

",55
SneakyTurt1e/CN_MainlandIP_PAC,JavaScript,"CN MainlandIP PAC
This is the PAC of most IP in mainland China.
Can use in the proxy(WhiteList).
Usage


Use SwitchyOmega as an example


At first create a new profile.




Select PAC profiles and enter a name.



Enter the URL of PAC and update.


How does it work
If any IP in this PAC, your proxy will direct to it.
If not, will able to use your proxy.
",2
Wadauk/scihub_ck,Perl,"scihub_ck
ä¸ä¸ªç®ççSci-hubå¯ç¨ååæ£æ¥å·¥å·ã
Scihub_ck is a tiny tool for checking the working domain of sci-hub. Sci-Hub is a website with over 64.5 million academic papers and articles available for direct download. In 2015 academic publisher Elsevier filed a legal complaint in New York City against Sci-Hub alleging copyright infringement, and the subsequent lawsuit led to a loss of the original sci-hub.org domain. Following the first domain loss, Sci-Hub has cycled through a number of domains, some of which have been blocked in certain countries.
For check the working domains timely, I developed the tiny tool based on Shell and Perl.
Usage
ä½¿ç¨æ¹æ³ï¼
perl scihub_ck list_all
Description
åè¡¨æä»¶åæ¬262ä¸ªåååç¼ä¾æ£æ¥ãè¿è¡äº§ççæä»¶å°ä¿å­å¨webæä»¶å¤¹åãç¨åºè¿è¡å®æåï¼ä¿çå¤§å°ä¸º27kbçæä»¶å³ä¸ºå¯ç¨ååã
The list file contained 262 domains to check. The output file will be generated into the 'web' directory. The files with 27 kb are corresponding to the working domains.
Working domains

Update every minute

Online version is available now: https://wadauk.github.io/scihub_ck/index.html
Versions
v1.0.0
local version
æ¬å°çåå¸
v1.0.1
add online version
å¢å å¨çº¿ç
v1.0.2
add pipeline shell script for local version
å¢å æ¬å°çæµç¨èæ¬
v1.0.3
speed up and shorten the update cycle for online version
æéå¹¶ç¼©ç­å¨çº¿çæ´æ°å¨æ
v1.0.4
move the codes from pi to cloud and speed up
ä»£ç è¿ç§»è³é¿éäºå¹¶æé
v1.0.5
High speed and stable version. New strategy to speed up. Every fast check only need less than 20 seconds!
é«éç¨³å®çæ¬
",72
Mailbrix/lists,None,"lists
IP whitelist & blacklist operated by Mailbrix.mx
Lists are updated hourly and individual records are expired after 1 day of inactivity.
whitelist
The whitelist is intended to be fed to greylisting agents in order to reduce latency,
do not assume the IP addresses in that list to be ""safe"" from spam:
some are safe, others are just less likely.
Applying the whitelist should reduce drastically the greylisting of legitimate hosts,
it is built from three means:

the resolution of SPF records at major mail services providers NOT providing ESP services
lists of legitimate senders gathered from various mailing-lists as well as trusted domains
domain and/or IP reputation

you can't pay your way to the whitelist, be good and you might hit the list naturally
blacklist
The blacklist is intended to be fed to your firewall or MTA in order to IP-block a sender.
The lists are currently generated through various means, it consists mainly of IP addresses that:

do not have rDNS and FCrDNS
hit mailbrix.mx operated spam traps
send Unsolicitated Commercial Email (UCE) to adresses subscribed to specific lists
brute-force addresses
have a very bad domain and/or IP reputation
were reported by a list of trusted sources

you can't pay your way out of the blacklist, be good and you will not enter it
How to use
You can fetch the latest whitelist and blacklist from this repository and feed it directly in your MTA, firewall or antispam solution.
Direct links to latest version:

whitelist
blacklist

",6
openbmc/openbmc,Python,"OpenBMC

The OpenBMC project can be described as a Linux distribution for embedded
devices that have a BMC; typically, but not limited to, things like servers,
top of rack switches or RAID appliances. The OpenBMC stack uses technologies
such as Yocto,
OpenEmbedded,
systemd, and
D-Bus to allow easy
customization for your server platform.
Setting up your OpenBMC project
1) Prerequisite

Ubuntu 14.04

sudo apt-get install -y git build-essential libsdl1.2-dev texinfo gawk chrpath diffstat


Fedora 28

sudo dnf install -y git patch diffstat texinfo chrpath SDL-devel bitbake \
    rpcgen perl-Thread-Queue perl-bignum perl-Crypt-OpenSSL-Bignum
sudo dnf groupinstall ""C Development Tools and Libraries""

2) Download the source
git clone git@github.com:openbmc/openbmc.git
cd openbmc

3) Target your hardware
Any build requires an environment variable known as TEMPLATECONF to be set
to a hardware target.
You can see all of the known targets with
find meta-* -name local.conf.sample. Choose the hardware target and
then move to the next step. Additional examples can be found in the
OpenBMC Cheatsheet



Machine
TEMPLATECONF




Palmetto
meta-ibm/meta-palmetto/conf


Zaius
meta-ingrasys/meta-zaius/conf


Witherspoon
meta-ibm/meta-witherspoon/conf


Romulus
meta-ibm/meta-romulus/conf



As an example target Palmetto
export TEMPLATECONF=meta-ibm/meta-palmetto/conf

4) Build
. openbmc-env
bitbake obmc-phosphor-image

Additional details can be found in the docs
repository.
Build Validation and Testing
Commits submitted by members of the OpenBMC GitHub community are compiled and
tested via our Jenkins server.  Commits are run
through two levels of testing.  At the repository level the makefile make check directive is run.  At the system level, the commit is built into a
firmware image and run with an arm-softmmu QEMU model against a barrage of
CI tests.
Commits submitted by non-members do not automatically proceed through CI
testing. After visual inspection of the commit, a CI run can be manually
performed by the reviewer.
Automated testing against the QEMU model along with supported systems are
performed.  The OpenBMC project uses the
Robot Framework for all automation.  Our
complete test repository can be found
here.
Submitting Patches
Support of additional hardware and software packages is always welcome.
Please follow the contributing guidelines
when making a submission.  It is expected that contributions contain test
cases.
Bug Reporting
Issues are managed on
GitHub.  It is recommended you search through the issues before opening
a new one.
Features of OpenBMC
Feature List

Host management: Power, Cooling, LEDs, Inventory, Events, Watchdog
Full IPMI 2.0 Compliance with DCMI
Code Update Support for multiple BMC/BIOS images
Web-based user interface
REST interfaces
D-Bus based interfaces
SSH based SOL
Remote KVM
Hardware Simulation
Automated Testing

Features In Progress

OpenCompute Redfish Compliance
User management
Virtual media
Verified Boot

Features Requested but need help

OpenBMC performance monitoring

Finding out more
Dive deeper into OpenBMC by opening the
docs repository.
Contact

Mail: openbmc@lists.ozlabs.org https://lists.ozlabs.org/listinfo/openbmc
IRC: #openbmc on freenode.net
Riot: #openbmc:matrix.org

",352
Mailbrix/lists,None,"lists
IP whitelist & blacklist operated by Mailbrix.mx
Lists are updated hourly and individual records are expired after 1 day of inactivity.
whitelist
The whitelist is intended to be fed to greylisting agents in order to reduce latency,
do not assume the IP addresses in that list to be ""safe"" from spam:
some are safe, others are just less likely.
Applying the whitelist should reduce drastically the greylisting of legitimate hosts,
it is built from three means:

the resolution of SPF records at major mail services providers NOT providing ESP services
lists of legitimate senders gathered from various mailing-lists as well as trusted domains
domain and/or IP reputation

you can't pay your way to the whitelist, be good and you might hit the list naturally
blacklist
The blacklist is intended to be fed to your firewall or MTA in order to IP-block a sender.
The lists are currently generated through various means, it consists mainly of IP addresses that:

do not have rDNS and FCrDNS
hit mailbrix.mx operated spam traps
send Unsolicitated Commercial Email (UCE) to adresses subscribed to specific lists
brute-force addresses
have a very bad domain and/or IP reputation
were reported by a list of trusted sources

you can't pay your way out of the blacklist, be good and you will not enter it
How to use
You can fetch the latest whitelist and blacklist from this repository and feed it directly in your MTA, firewall or antispam solution.
Direct links to latest version:

whitelist
blacklist

",6
openbmc/openbmc,Python,"OpenBMC

The OpenBMC project can be described as a Linux distribution for embedded
devices that have a BMC; typically, but not limited to, things like servers,
top of rack switches or RAID appliances. The OpenBMC stack uses technologies
such as Yocto,
OpenEmbedded,
systemd, and
D-Bus to allow easy
customization for your server platform.
Setting up your OpenBMC project
1) Prerequisite

Ubuntu 14.04

sudo apt-get install -y git build-essential libsdl1.2-dev texinfo gawk chrpath diffstat


Fedora 28

sudo dnf install -y git patch diffstat texinfo chrpath SDL-devel bitbake \
    rpcgen perl-Thread-Queue perl-bignum perl-Crypt-OpenSSL-Bignum
sudo dnf groupinstall ""C Development Tools and Libraries""

2) Download the source
git clone git@github.com:openbmc/openbmc.git
cd openbmc

3) Target your hardware
Any build requires an environment variable known as TEMPLATECONF to be set
to a hardware target.
You can see all of the known targets with
find meta-* -name local.conf.sample. Choose the hardware target and
then move to the next step. Additional examples can be found in the
OpenBMC Cheatsheet



Machine
TEMPLATECONF




Palmetto
meta-ibm/meta-palmetto/conf


Zaius
meta-ingrasys/meta-zaius/conf


Witherspoon
meta-ibm/meta-witherspoon/conf


Romulus
meta-ibm/meta-romulus/conf



As an example target Palmetto
export TEMPLATECONF=meta-ibm/meta-palmetto/conf

4) Build
. openbmc-env
bitbake obmc-phosphor-image

Additional details can be found in the docs
repository.
Build Validation and Testing
Commits submitted by members of the OpenBMC GitHub community are compiled and
tested via our Jenkins server.  Commits are run
through two levels of testing.  At the repository level the makefile make check directive is run.  At the system level, the commit is built into a
firmware image and run with an arm-softmmu QEMU model against a barrage of
CI tests.
Commits submitted by non-members do not automatically proceed through CI
testing. After visual inspection of the commit, a CI run can be manually
performed by the reviewer.
Automated testing against the QEMU model along with supported systems are
performed.  The OpenBMC project uses the
Robot Framework for all automation.  Our
complete test repository can be found
here.
Submitting Patches
Support of additional hardware and software packages is always welcome.
Please follow the contributing guidelines
when making a submission.  It is expected that contributions contain test
cases.
Bug Reporting
Issues are managed on
GitHub.  It is recommended you search through the issues before opening
a new one.
Features of OpenBMC
Feature List

Host management: Power, Cooling, LEDs, Inventory, Events, Watchdog
Full IPMI 2.0 Compliance with DCMI
Code Update Support for multiple BMC/BIOS images
Web-based user interface
REST interfaces
D-Bus based interfaces
SSH based SOL
Remote KVM
Hardware Simulation
Automated Testing

Features In Progress

OpenCompute Redfish Compliance
User management
Virtual media
Verified Boot

Features Requested but need help

OpenBMC performance monitoring

Finding out more
Dive deeper into OpenBMC by opening the
docs repository.
Contact

Mail: openbmc@lists.ozlabs.org https://lists.ozlabs.org/listinfo/openbmc
IRC: #openbmc on freenode.net
Riot: #openbmc:matrix.org

",352
bukun/GISLite,Python,"Introduction of GISLite

In English
Static site generator (SSG) for GIS data publishment as light WebGIS application.
Example: http://www.osgeo.cn/gislite/

è¯´æ
åºäºå¼æºGISææ¯å¼åï¼ä½¿ç¨éæç½ç«å½¢å¼å¯¹GISæ°æ®è¿è¡åå¸ã
æ¼ç¤ºç½ç«ï¼ http://www.osgeo.cn/gislite/
åºäº MapServer çæå¡å¨ç«¯GISæ°æ®å¾å±åå¸ç®¡çç³»ç»ã
ç®çæ¯ç¨äºè§£å³åå¸è¾å¤æ°éçå°å¾æ¶çæ°æ®æ´æ°ãæ ·å¼ä¿®æ¹ï¼ä»¥åä¸åæ ·å¼ç»ååºç¨çé®é¢ã
å°½éå®ç°æ°æ®æºå¯ä¸ï¼ä½¿ç¨ XLSX æä»¶å®ä¹æ ·å¼ã
ä¸»è¦å®ç°GISæ°æ®å¾å±çåå¸ï¼ä½ä¹å®ç°äºå¤æºæ°æ®åå¸ä¸ºåä¸ªå°å¾åçï¼ä»¥åå¤ä¸ªå¾å±åå¸ä¸ºå¾å±åç»çåè½ã

åºäºMapServerãMapProxy
ä½¿ç¨å¼æ¾çµå­è¡¨æ ¼æ ¼å¼ XLSX å®ä¹æ ·å¼
å¯ç¨äºå¢éå°çä¿¡æ¯æ°æ®å¿«éåå¸ç®¡ç


ä½¿ç¨ææ¯

MapServer
MapProxy
LeafletJS
Python 3
Jinja2


è¿è¡æ¹å¼
run_gislite.py

æ
python3 run_gislite.py


ç¸å³ç½ç«

http://www.osgeo.cn/pygis/  ãPythonä¸å¼æºGISãï¼ä½¿ç¨ Python è¯»åä¸å¤ç GISæ°æ® çå·¥å·ã
http://www.osgeo.cn/webgis/  æ¶åå° MapServerï¼ MapProxyï¼ Leaflet çå¨çº¿ WebGIS æå­¦ç½ç« ã


è¿è¡ç¯å¢å®è£
å¼åä¸æµè¯è¿è¡äº Debian Stretch / Ubuntu 18.04 ã å¨ç®¡çåæéä¸å®è£è¿è¡ç¯å¢ï¼
apt install -y apache2 php libapache2-mod-fcgid cgi-mapserver mapserver-bin libapache2-mod-php
apt install -y python3-openpyxl python3-mapproxy
apt install -y build-essential  python3-gdal python3-pip
pip3 install mapproxy

å¦å¤ï¼éè¦GISæ°æ®ï¼è·¯å¾ç± cfg.py ä¸­ç ``GIS_BASE``æå®ã
ç¨åºéè¦çèµæºï¼é½å¨ cfg.py ä¸­å®ä¹ã TILE_SVR æ¯ MapProxy æå¡å°åã

MapProxyä½¿ç¨
ä½¿ç¨äº MapProxy çæå°å¾åçãä¸é¢æ¯èæ¬è¿è¡çæ¹å¼ã
é¦åå»ºç«å­é¡¹ç®ï¼
~/.local/bin/mapproxy-util create -t base-config wcs_imgmap

æ
mapproxy-util create -t base-config wcs_imgmap

ç¶åè¿è¡ï¼
~/.local/bin/mapproxy-util serve-develop ./out_mapproxy.yaml -b 0.0.0.0:8011

æ
# mapproxy-util serve-develop ./mapproxy.yaml -b 0.0.0.0:8011

",9
marcelochaves95/MathKit,Swift,"MathKit
MathKit is a Swift library for iOS and macOS that implements common 2D and 3D vector and matrix functions, useful for games or vector-based graphics.
MathKit takes advantage of Swift language features such as function and operator overloading and struct methods to provide a more elegant interface than most C, C++ or Cocoa-based graphics APIs.
MathKit also provides a  handy replacement for the GLKit vector math types and functions, which are not available yet in Swift due to their reliance on union types.
MathKit is a completely standalone library, relying only on the Foundation framework. However, it provides optional compatibility extensions for MapKit, SceneKit and Quartz (CoreGraphics/CoreAnimation) for interoperability with UIKit, AppKit, SpriteKit and SceneKit.
MathKit is designed to be efficient, but has not been heavily optimized yet, and does not yet take advantage of architecture-specific hardware acceleration using the Accelerate framework.
Implementations



 Matrix3x3




 Matrix4x4




 Quaternion




 Scalar




 Vector2




 Vector3




 Vector4




 MapKit




 Quartz




 SceneKit




 Unit Tests



License
MIT license. See the LICENSE file for details.
",2
wikimedia/mediawiki-api-demos,Python,"
MediaWiki API Demos
The MediaWiki Action API is a web service that allows access to some wiki-features like authentication, page operations, and search. It can provide meta information about the wiki and the logged-in user.
This repository contains demo apps and code snippets in Python and Javascript to assist developers for easy use of various modules of the API:

Python
Javascript

Apps

Article ideas generator:
Demo app that suggests articles from various categories that don't yet exist on English Wikipedia. The app uses Parse and Links module.
Nearby places viewer:
Demo of geo search for wiki pages near a location using the Geolocation API and MediaWiki Action API's Geosearch module.
Picture of the day viewer:
Demo app that uses prop=images module to fetch Wikipedia's Picture of the Day (POTD) from a template page and displays it on a webpage. The app also allows users to go backward or forward a date to view other POTD.
User contributions feed:
Demp app that uses list=usercontribs module to fetch the top 50 edits made by a user.
View more demo apps

Installation
$ git clone https://github.com/wikimedia/mediawiki-api-demos.git
$ cd mediawiki-api-demos

For running python code samples: 
$ cd python
$ python3 filename.py 
Note: Install any necessary python modules with pip and enter any credentials 
required in the file to run the sample code

For running javascript code samples:
$ cd javascript
$ node filename.js
Note: Install any necessary node modules with npm and enter any credentials required
in the file to run the sample code

Contributing code samples or demo apps
If you would like to contribute a demo that you have built or a sample code that you have identified as missing for an API module documentation on MediaWiki.org, first create an issue in this repository.
If the repo contributors or maintainers agree that the proposed sample code or demo app would be a useful addition to this repository, go ahead and start working on the issue. Send a pull request when you have your changes ready to be accepted or merged!
Follow the instructions below to create a pull request:
$ git pull origin master
This makes sure that your master branch is up to date

$ git checkout -b BRANCHNAME origin/master
This will create a new branch (BRANCHNAME) from the latest 'master' and check it out for you. 

$ git add filename
$ git commit -m ""your commit message""
Make and commit your changes

$ git pull --rebase origin master
Rebase your changes against master

$ git push origin BRANCHNAME
Push your changes and create a pull request 
Learn more: https://help.github.com/en/articles/creating-a-pull-request

For GET requests modules only, python and javascript sample code can be auto-generated by following the instructions below:
$ cd mediawiki-api-demos
Add module information to `modules.json`
$ python autogenerator.py
Make desired changes to the newly generated file(s)

",50
FrankD412/frankd412.github.io,HTML,"Moon Jekyll Theme 
Sorry guys but there will be no update until I buy a new laptop.
######(If you like this theme or using it, please give a â­ï¸ for motivation.)
Moon is a minimal, one column jekyll theme.
Features

Minimal, you can focus on your content
Responsive
Disqus integration
Syntax highlighting
Optional post image
Social icons
Page for sharing projects
Optional background image
Simple navigation menu
MathJax support

Preview


See a live version of Moon hosted on GitHub.
Getting Started
To learn how to install and use this theme check out the Setup Guide for more information.
",2
parkr/status,JavaScript,"status
This is a repository hosting a status site for my various web properties.
This repository uses sourcegraph/checkup to write to the updates/ directory.
Web
Normal usage of this repository is just visiting https://www.parkermoore.de/status/. It shows a lovely series of graphs for my web properties. It tracks up, down, and degraded states.
Generating
This repo uses Jess Frazelle's Docker image, r.j3ss.co/checkup to run checkup.
It is passed a configuration file like this:
{
  ""storage"": {
    ""provider"": ""github"",
    ""access_token"": ""some_api_access_token_with_repo_scope"",
    ""repository_owner"": ""owner"",
    ""repository_name"": ""repo"",
    ""committer_name"": ""Commiter Name"",
    ""committer_email"": ""you@yours.com"",
    ""branch"": ""gh-pages"",
    ""dir"": ""updates""
  },
  ""checkers"": [
    {
      ""type"": ""http"",
      ""endpoint_name"": ""Example HTTP"",
      ""endpoint_url"": ""http://www.example.com""
    }
  ]
}
Then, I run checkup on a cron. It will automatically write to GitHub.
",4
splewis/csgo-multi-1v1,SourcePawn,"csgo-multi-1v1


Status: Supported.
The multi1v1 plugin sets up any number of players in 1v1-situations on specially made maps and they fight in a ladder-type system each round. The winners move up an arena, and the losers go down an arena. Players choose between specific round types (for example: ""rifle"", ""pistol"", ""awp""), and the plugin automatically spawns and gives players the appropriate weapons each round start.
Also see the AlliedModders thread and the the wiki for more information.
Features

Round types: there are 3 round types: rifle, pistol, and awp
Player selection: players can select to allow pistol and awp rounds or ban them, rifle rounds are always allowed
Player preference: players can also select a preference of round type, if player preferences match they will play that type
Weapon selection: players can select their primary (i.e. their rifle) and their pistol
Armor on pistol rounds: helmets are taken away, and kevlar is also taken away if the player selected an upgraded pistol
ELO ranking system: optionally, player statistics can be stored in a database, see below for details

For plugin developers
Check the multi1v1.inc file to see what natives and forwards are avaliable to tweak the behavior of the plugin in more sophisticated ways.
Extra plugins
Sometimes it's easier to add something in a seperate plugin than add more convars, thus some features may be in support plugins. These are all optional.

multi1v1_flashbangs: if both players in an arena say ""yes"" to getting flashbangs, a flashbang is given to each player
multi1v1_kniferounds: adds unranked knife rounds
multi1v1_online_stats_viewer: adds the !stats and related commands that open up a stats webpage in a MOTD panel

Download
Stable releases are in the GitHub Releases section.
I strongly recommend using the Updater plugin which can automatically update the plugin for bug fixes.
Any changes made through an automatic update will be backwards compatible.
You may also download the latest development build if you wish. If you report any bugs from these, make sure to include the build number (when typing sm plugins list into the server console, the build number will be displayed with the plugin version).
Installation
Requirements
Sourcemod 1.9 or later.
Instructions
Download the archive and extract the files to the game server. From the download, you should have installed the following (to the csgo directory):

addons/sourcemod/plugins/multi1v1.smx
addons/sourcemod/configs/multi1v1_weapons.cfg
addons/sourcemod/translations
cfg/sourcemod/multi1v1

Configuration
The file cfg/sourcemod/multi1v1/multi1v1.cfg will be autogenerated when the plugin is first run and you can tweak it if you wish.
You may also tweak the values in cfg/sourcemod/multi1v1/game_cvars.cfg, which is executed by the plugin each map start.
Here is a brief list of some cvars available. See the auto-generated cfg/sourcemod/multi1v1/multi1v1.cfg file for descriptions.

sm_multi1v1_autoupdate: whether the plugin attempts to use the auto-updater plugin
sm_multi1v1_pistol_behavior: what types of pistols (if any) should be given in non-pistol rounds
sm_multi1v1_roundtime: length of the round
sm_multi1v1_use_database: whether the plugin attempts to store player statistics (e.g. elo ranking) in a MySQL database
sm_multi1v1_verbose_spawns: whether the plugin will dump information on player-spawn clustering on map starts

addons/sourcemod/configs/multi1v1_weapons.cfg contains the list of weapons that are available under the rifle and pistol menus. You are free to add or remove weapons from this as long as they match the correct format. Note that the team part is only for making sure the player gets the correct weapon skin, otherwise it has no effect.
More help on setting up the stats system
There is a wiki page that explains how to setup the stats system with the provided components.
Building
The build process is managed by my smbuilder project. You can still compile multi1v1.sp without it, however.
To compile, you will need:

SMLib (required)

You should make sure you have a relatively recent version of smlib - some changes were made to accommodate sourcemod 1.7 changes.
Maps
I have a workshop collection of maps I know of. The ""am_"" prefix stands for aim_multi, reflecting the fact that the maps are similar to aim_ maps but there are multiple copies of them.
Note: standard maps (de_dust2, etc.) or aim maps (aim_map, etc.) will not work with this plugin. Maps must be custom-made with multiple arenas.
Guidelines for making a multi-1v1 map:

Create 1 arena and test it well, and when are you happy copy it
Create a bunch of arenas, I'd recommend making at least 16
The players shouldn't be able to see each other on spawn
Each group of spawns (e.g. all CT spawns in arena 1) must be within 1600.0 units of each other, this is required to cluster spawns into the arenas and not configurable
Ensure that the arenas are sufficiently far apart so players don't hear shooting in other arenas
If you want to edit your map, it's easiest to delete all but 1 arena and re-copy them. Be warned this can cause issues with the game's lighting and clients may crash the first time they load the new map if they had downloaded the old one previously
You should avoid areas where it's easy for 1 player to hide; ideally they should have to cover multiple angles if they sit in one spot
Here is an example map: am_grass2.vmf
The cvar sm_multi1v1_verbose_spawns can be set to 1 to log information about how the spawns were partitioned into arenas on map changes

Using the statistics database
Note: SQLite is not supported. Only MySQL is.
You should add a database named mult1v1 to your databases.cfg file like so:
""multi1v1""
{
    ""driver""            ""mysql""
    ""host""              ""123.123.123.123""   // localhost works too
    ""database""          ""game_servers_database""
    ""user""              ""mymulti1v1server""
    ""pass""              ""strongpassword""
    ""timeout""           ""10""
    ""port""          ""3306""  // whatever port MySQL is set up on, 3306 is default
}

To create a MySQL user and database on the database server, you can run:
CREATE DATABASE game_servers_database;
CREATE USER 'mymulti1v1server'@'123.123.123.123' IDENTIFIED BY 'strongpassword';
GRANT ALL PRIVILEGES ON game_servers_database.multi1v1_stats TO 'mymulti1v1server'@'123.123.123.123';
FLUSH PRIVILEGES;

Make sure to change the IP, the username, and the password. You should probably change the database as well, especially if you already have one set up you can use.
Schema:
mysql> describe multi1v1_stats;
+--------------+-------------+------+-----+---------+-------+
| Field        | Type        | Null | Key | Default | Extra |
+--------------+-------------+------+-----+---------+-------+
| accountID    | int(11)     | NO   | PRI | 0       |       |
| serverID     | int(11)     | NO   | PRI | 0       |       |
| auth         | varchar(64) | NO   |     |         |       |
| name         | varchar(64) | NO   |     |         |       |
| wins         | int(11)     | NO   |     | 0       |       |
| losses       | int(11)     | NO   |     | 0       |       |
| rating       | float       | NO   |     | 1500    |       |
| lastTime     | int         | NO   |     | 0       |       |
| recentRounds | int         | NO   |     | 0       |       |
+--------------+-------------+------+-----+---------+-------+

Note that the accountID field is what is returned by GetSteamAccountID, which is ""the lower 32 bits of the full 64-bit Steam ID (referred to as community id by some) and is unique per account.""
auth is the steam ID auth string, and the lastTime field is the last time the player connected to the server.
The time comes from GetTime, which returns the ""number of seconds since unix epoch"".
recentRounds is simply incremented each time the player completes a round. This can be used, for example, to check the rounds played on a daily basis and lower ratings if a player didn't play a certain number of rounds.
Clientprefs Usage/Cookies
Player choices (round type preferences, weapon choices) can be saved so they persist across maps for players (via the SourceMod clientprefs API). Installing SQLite should be sufficient for this to work.
If you have a game-hosting specific provider, they may already have SQLite installed
Custom Round Types
There are two ways to add your own round types: through writing another plugin using the forward and natives in multi1v1.inc, and
defining a round type in a config file.
Adding round types via a config file
This is the simpler approach, but you are fairly restricted in the logic you can use. The file to edit is addons/sourcemod/configs/multi1v1_customrounds.cfg.
Here is an example file that adds a scout round and a knife round:
""CustomRoundTypes""
{
    ""scout""
    {
        ""name""      ""Scout""
        ""ranked""        ""1""
        ""ratingFieldName""       ""scoutRating""
        ""optional""      ""1""
        ""enabled""       ""1""
        ""armor""     ""1""
        ""helmet""        ""1""
        ""weapons""
        {
            ""weapon_knife""      """"
            ""weapon_ssg08""      """"
        }
    }
    ""knife""
    {
        ""name""      ""Knife""
        ""ranked""        ""0""
        ""optional""      ""1""
        ""enabled""       ""1""
        ""armor""     ""1""
        ""helmet""        ""1""
        ""weapons""
        {
            ""weapon_knife""      """"
        }
    }
}

Adding round types via another plugin
Using the natives in multi1v1.inc, you can write more complex logic into a round type. To get a simple example, check multi1v1_kniferounds.sp. The key is calling Multi1v1_AddRoundType within the Multi1v1_OnRoundTypesAdded forward.
typedef RoundTypeWeaponHandler = function void (int client);
typedef RoundTypeMenuHandler = function void (int client);

// Registers a new round type by the plugin.
native int Multi1v1_AddRoundType(const char[] displayName,
                                 const char[] internalName,
                                 RoundTypeWeaponHandler weaponsHandler=Multi1v1_NullWeaponHandler,
                                 bool optional=true,
                                 bool ranked=false,
                                 const char[] ratingFieldName="""",
                                 bool enabled=true);
Note that the multi1v1 plugin will

create and update the column for the round-type stats if you set the round type as ranked and give a non-empty string as the ratingFieldName parameter ( note that these columns are only created on database-connections)
create and update the ""allow x rounds"" clientprefs cookie for you (it uses the interalName when naming the cookie)

Contribution and Suggestions
First, check the issue tracker to ask questions or make a suggestion.
If you have a suggestion you can mark it as an enhancement.
Guidelines

Create a fork on github, clone that, then create a branch to work on git checkout -b mybranchname
Follow the code-style already used as much as you can
Submit a pull request when you're happy with the new feature/enhancement/bugfix
Favor readability and correctness over all else
For a moderately advanced feature, it may be simpler to write it as a plugin that uses the multi1v1 natives from multi1v1.inc
Keep it simple, stupid

",157
xndcn/bing-wallpaper-archive,None,"bing-wallpaper-archive
There is a official archive site for bing wallpapers but without videos.
So I have to save them here.
",7
borislav-milkov/CS151-Blackjack,Java,"Blackjack

A WIP Blackjack game following an MVC (Model-View-Controller) design pattern.



Built With

Java
Java Swing
Eclipse

Versioning
Git and GitHub are used for version control.
Authors

Devin Gonzales
Borislav Milkov

",2
lawrencefinn/cloudsidecar,Go,"Cloud Sidecar
Introduction
Cloud Sidecar (CS) is a utility to allow software to be written in a cloud agnostic manner while being able to take advantage
of the features a specific cloud may offer.  It runs next to your existing application and implelments a common API that
is compatible with most cloud SDKs.  Cloud Sidecar allows you to switch providers (or use multiple providers) for common
cloud products like file storage, key vale store, NoSQL database, queues, messaging, etc...
How It Works
Cloud Sidecar exposes an API that is compatible with some AWS APIs.  It is meant to run next to your application as a
sidecar.  It is configuration driven (hot reloads)
and requires very little code change to be used.
Boto3 Python Instructions
Just pass in an endpoint_url when you create a resource or any boto object.  Example:
client = boto3.resource(
    ""dynamodb"",
    region_name=""us-east"",
    aws_access_key_id=""meow"",
    aws_secret_access_key=""cow"",
    endpoint_url='http://localhost:3452',
    use_ssl=False,
)
client = boto3.client(
    ""kinesis"",
    region_name=""us-east"",
    aws_access_key_id=""meow"",
    aws_secret_access_key=""cow"",
    endpoint_url='http://localhost:3451',
    use_ssl=False,
)

This is assuming CS is running on the same host on port 3452 and 3451
Java AWS Instructions
Similar to boto, just set an endpoint when creating your client.  Example:
AmazonS3ClientBuilder.standard()
    .withEndpointConfiguration(new EndpointConfiguration(""http://localhost:3451"", ""bleh""))
    .withPathStyleAccessEnabled(true)
    .build()

This is assuming that CS is running on the same host on port 3451
Pyhon Google Cloud API v2 Not Implemented
You need to extend the Client and change the service address.  Example:
from google.cloud.bigtable_v2.gapic import bigtable_client

class Bleh(bigtable_client.BigtableClient):
  SERVICE_ADDRESS = 'localhost:3453'

bleh = Bleh()

Java Google Cloud API v2 Not Implemented
Set the host of the service via the Java API.  This might vary based on service. Example:
StorageOptions.newBuilder().setHost(""http://localhost:1234"").setProjectId(""boo"").build().getService

InstantiatingGrpcChannelProvider prov = InstantiatingGrpcChannelProvider.newBuilder().setEndpoint(""localhost:1234"").build()
BigtableDataSettings settings = BigtableDataSettings.newBuilder().setTransportChannelProvider(prov).setInstanceName(InstanceName.of(""project"", ""instance"")).build()
BigtableDataClient.create(settings).readRow(""aaa"", ""bbb"")

Installing and compiling
Requires dep
Just run clone and run dep ensure to get dependencies. run go build main.go to compile.
Configure
Take a look at example.yaml
Run
./main example.conf
Plugins
CS lets you add on your own code or third party code.  Plugins do not require recompiling CS, just drop them into a certain path and restart.
Handlers
Handler plugins let you define your own handler code for a config section (port).  It can do whatever you want, raw requests are just passed on.
A handler plugin just needs to expose a Register function with the signature func Register(*mux.Router) awshandler.HandlerInterface.  Your plugin
must be compiled (go build -buildmode=plugin -o your_plugin.so your_plugin_source.go) and placed in plugin/handler.  Set the service_type in the config to the plugin file name without an extension, so your_plugin in this case.
See plugin/handler/example.go
Middleware
Middleware plugins lets you intercept requests before going to a handler.  Great for metrics, logging, adding some crazy logic, etc..
A middleware plugin must expose a Register function with the signature func Register(config *viper.Viper) func(http.Handler) http.Handler).
You need to configure the middleware in the top level middlware section with the type value is the plugin filename without .so.
The plugin file must live in plugin/middlware/.  You can then add add the middleware by adding a middleware section to your config.
See plugin/middleware/example.go
Notes
dep ensure -add gopkg.in/yaml.v2
antlr -Dlanguage=Go -o dynamo_parser Dynamo.g4
",2
skyhigh119/JavQ,Java,"JavQ
Java Library, Simpler your code..

Install
Just import this lib.
Api
I have not made documentation., JavQ will show you on Tester.java
",2
buddystudio/BuddyPP,C,"Buddy++
Buddy++ is an open source Arduino IDE developed based on the Java FX framework. BuddyPP is more beautiful and convenient than the official IDE. We designed many features for zero base developers. We have added a user-friendly interactive programming mechanism in BuddyPP. Developers can generate code in the setting window without the need to keep in mind all sorts of boring keywords, data types, and grammatical structures.

The lastest version: 1.2.1
Buddy++æ¯BuddyStudioåºäºJava FXæ¡æ¶å¼åçå¼æºçArduinoéæå¼åç¯å¢ï¼ä¸Arduinoå®æ¹çIDEç¸æ¯é¤äºçé¢æ´ç¾è§ãæ´ç®çº¦å®ç¨ï¼æä»¬è¿éå¯¹é¶åºç¡å¼åèè®¾è®¡äºåç§ç¹è²åè½ï¼å¶äº¤äºå¼çç¼ç¨æ¹å¼æå¤§å°ä¸ºå¥é¨å¼åèéä½äºé¨æ§ã

ææ°çæ¬ï¼1.2.1
",16
Aeronica/mxTune,Java,"mxTune - a music mod for minecraft forge
This mod adds musical instruments that allow you to play music in MML format. This is a format already used in some popular online games so there are many tunes available or you can create your own. You can play solo or in groups of up to eight players.
Minecraft Forum WIP Post
Development Blog





CurseForge Badges by way2muchnoise
Java Profiler  provided by ej-technologies GmbH
",4
markphelps/flipt,Go,"


A feature flag solution that runs in your existing infrastructure








Documentation
https://flipt.dev/
What is Flipt
Flipt is an open source feature flag application that allows you to run experiments across services in your environment.
This means that you can deploy Flipt within your existing infrastructure and not have to worry about your information being sent to a third party or the latency required to communicate across the internet.
Flipt includes native client SDKs as well as a REST API so you can choose how to best integrate Flipt with your applications.
Flipt Features
Flipt enables you to add feature flag support to your existing applications, with a simple, single UI and API.
This can range from simple on/off feature flags to more advanced use cases where you want to be able to rollout different versions of a feature to percentages of your users.
Flipt features include:

Fast. Written in Go. Optimized for performance
Stand alone, easy to run server with no external dependencies
Ability to create advanced distribution rules to target segments of users
Native GRPC client SDKs to integrate with your applications
Simple REST API
Modern UI and debug console

Why Flipt
Flipt allows you to focus on building your applications without having to worry about implementing your own feature flag solution that works across your infrastructure.
On top of this, Flipt provides a nice, modern UI so that you can always monitor the state of your feature flags and experiments in a single place.
Running Flipt
Flipt is a single, self contained binary that you run on your own servers or cloud infrastructure. There are a multitude of benefits to running Flipt yourself, including:

ð Security - No data leaves your servers and you don't have to open your systems to the outside world to communicate with Flipt. It all runs within your existing infrastructure.
ð Speed - Since Flipt is co-located with your existing services, you do not have to communicate across the internet to another application running on the other side of the world which can add excessive latency and slow down your applications.
â Simplicity - Flipt is a single binary with no external dependencies. This means there is no database server to manage or connect to, no clusters to configure, and data backup is as simple as copying a single file.

Try It
â¯ docker run --rm -p 8080:8080 -p 9000:9000 markphelps/flipt:latest
Flipt UI will now be reachable at http://localhost:8080/.
For more permanent methods of running Flipt, see the Installation section.
Licensing
There are currently two types of licenses in place for Flipt:

Client License
Server License

Client License
All of the code required to generate GRPC clients in other languages as well as the existing GRPC Go client are licensed under the MIT License.
This code exists in the rpc/ directory.
The client code is the code that you would integrate into your applications, which is why a more permissive license is used.
Server License
The server code is licensed under the GPL 3.0 License.
If there are any concerns about the use of this license for the server, please open an issue on GitHub so that we can discuss publicly.
Author

Website: https://markphelps.me
Twitter: @mark_a_phelps
Email: mark.aaron.phelps at gmail.com

Contributing
I would love your help! Before submitting a PR, please read over the Contributing guide.
How To Contribute
No contribution is too small, whether it be bug reports/fixes, feature requests, documentation updates, or anything else that can help drive the project forward.
Here are some good places to start:

Project Kanban Board
Help Wanted Issues
Good First Issue Issues
Documentation Issues

Cheers! ðº
Support Development
Or if you would like to support the continued development of Flipt (and my caffeine addiction), you could always Buy Me A Coffee!

Pro Version
My plan is to soon start working on a Pro Version of Flipt for enterprise. Along with support, some of the planned features include:

User management/permissions
Multiple environments
Audit log
Streaming updates
Metrics
HA support

If you or your organization would like to help beta test a Pro version of Flipt, please get in touch with me:

Twitter: @mark_a_phelps
Email: mark.aaron.phelps at gmail.com

",732
CleverRaven/Cataclysm-DDA,C++,"


Cataclysm: Dark Days Ahead
Cataclysm: Dark Days Ahead is a roguelike set in a post-apocalyptic world. While some have described it as a ""zombie game"", there is far more to Cataclysm than that. Struggle to survive in a harsh, persistent, procedurally generated world. Scavenge the remnants of a dead civilization for food, equipment, or, if you are lucky, a vehicle with a full tank of gas to get you the hell out of Dodge. Fight to defeat or escape from a wide variety of powerful monstrosities, from zombies to giant insects to killer robots and things far stranger and deadlier, and against the others like yourself, who want what you have...
Download
Visit our website for download links to all stable and experimental releases.
The source can either be downloaded as an archive, or you can clone it from our GitHub repository.
Compile
Please read COMPILING.md - it covers general information and more specific recipes for Linux, OS X, Windows and BSD. See doc/COMPILER_SUPPORT.md for details on which compilers we support. And you can always dig for more information in doc/.
We also have the following build guides:

Building on Windows with MSYS2 at COMPILING-MSYS.md
Building on Windows with vcpkg at COMPILING-VS-VCPKG.md
Building with cmake at COMPILING-CMAKE.md  (unofficial guide)

Contribute
Cataclysm:Dark Days Ahead is the result of contributions from over 800 volunteers under the Creative Commons Attribution ShareAlike 3.0 license. The code and content of the game is free to use, modify, and redistribute for any purpose whatsoever. See http://creativecommons.org/licenses/by-sa/3.0/ for details.
Some code distributed with the project is not part of the project and is released under different software licenses, the files covered by different software licenses have their own license notices.

Please see CONTRIBUTING.md for details.
Community
Forums:
https://discourse.cataclysmdda.org
Wiki:
http://cddawiki.chezzo.com/cdda_wiki/index.php
GitHub repo:
https://github.com/CleverRaven/Cataclysm-DDA
IRC:
irc.freenode.net ; #CataclysmDDA
http://webchat.freenode.net/?channels=#CataclysmDDA
Frequently Asked Questions
Is there a tutorial?
Yes, you can find the tutorial in the Special menu at the main menu (be aware that due to many code changes the tutorial may not function). You can also access documentation in-game via the ? key.
How can I change the key bindings?
Press the ? key, followed by the 1 key to see the full list of key commands. Press the + key to add a key binding, select which action with the corresponding letter key a-w, and then the key you wish to assign to that action.
How can I start a new world?
World on the main menu will generate a fresh world for you. Select Create World.
I've found a bug / I would like to make a suggestion. What should I do?
Please submit an issue on our GitHub page. If you're not able to, send an email to kevin.granade@gmail.com.
",2978
csingley/ofxtools,Python,"Open Financial Exchange (OFX) Tools for Python








ofxtools is a Python library for working with Open Financial Exchange (OFX)
data - the standard format for downloading financial information from banks
and stockbrokers.  OFX data is widely provided by financial institutions so
that their customers can import transactions into financial management
software such as Quicken, Microsoft Money, or GnuCash.
If you want to download your transaction data outside of one of these
programs - if you wish to develop a Python application to use this data -
if you need to generate your own OFX-formatted data... ofxtools is for you!

What is it?
ofxtools requests, consumes and
produces both OFXv1 (SGML) and OFXv2 (XML) formats.
It converts serialized markup to/from native Python objects of
the appropriate data type, while preserving structure.
It also handles Quicken's QFX format, although it ignores Intuit's proprietary
extension tags.
In a nutshell, ofxtools makes it simple to get OFX data and extract it,
or export your data in OFX format.
ofxtools takes a comprehensive, standards-based approach to processing OFX.
It targets compliance with the OFX specification, specifically OFX versions
1.6 and 2.03.

ofxtools Coverage of the OFX Specification

Section 7 (financial institution profile)
Section 8 (service activation; account information)
Section 9 (email over OFX)
Section 10 (recurring bank transfers)
Section 11 (banking)
Section 12 (bill pay)
Section 13 (investments)



This should cover the great majority of real-world OFX use cases.  A particular
focus of ofxtools is full support of the OFX investment message set,
which has been somewhat neglected by the Python community.
The major item remaining on the ofxtools ""to do"" list is to implement the
tax schemas.  It's currently a low priority to implement Section 14 (bill pay)
or the extensions contained in OFX versions beyond 2.03, but you're welcome to
contribute code if you need these.
Some care has been taken with the data model to make it easily maintainable
and extensible.  The ofxtools.models subpackage contains simple, direct
translations of the relevant sections of the OFX specification.  Using existing
models as templates, it's quite straightforward to define new models and
cover more of the spec as needed (the odd corner case notwithstanding).
More than 10 years' worth of OFX data from various financial institutions
has been run through the ofxtools parser, with the results checked.  Test
coverage is high.

Where is it?
Full documentation is available at Read the Docs.
For ease of installation, ofxtools is released on PyPI.
Development of ofxtools is centralized at GitHub, where you will find
a bug tracker.

Installation Dependencies
ofxtools requires Python version 3.6+, and depends only on the standard
libary (no external dependencies).
NOTE: As of version 0.6, ofxtools no longer supports Python version 2,
which goes EOL 2020-01-01.
",71
Lombiq/Orchard-Azure-Application-Insights,C#,"Hosting - Azure Application Insights Readme
This Orchard CMS module enables easy integration of Azure Application Insights telemetry into Orchard. Just install the module, configure the instrumentation key from the admin and collected data will start appearing in Application Insights. The module is tenant-aware, so in a multi-tenant setup you can configure different instrumentation keys to collect request tracking and client-side tracking data on different tenants. This is also available on all sites of DotNest, the Orchard CMS as a Service.
Warning: this module is only compatible with the Orchard 1.9+.
Note that the module depends on the Helpful Libraries module so you should have that installed as well.
Hosting - Azure Application Insights is part of the Hosting Suite, which is a complete Orchard DevOps technology suite for building and maintaining scalable Orchard applications.
The module was created by Lombiq, one of the core developers of Orchard itself.
Configuration
You can configure the module, including setting the AI instrumentation key from the admin site, for each tenant. You can also set an application-wide instrumentation key to be used by all tenants (if the module is enabled) in the static configuration (i.e. Web.config, Azure Portal) with the key shown in the Constants class.
To collect detailed dependency data and server resource information you'll need to install the AI Status Monitor (for VMs and local development) or the Application Insights site extension for Azure Web Apps. Be aware that both tools will add DLLs to the app and create an ApplicationInsights.config file, but neither are needed. To fix this remove the config file and re-deploy (or locally: delete Orchard.Web/bin and App_Data/Dependencies and re-build) the app.
Using the AI site extension is currently not supported, the extension needs to be modified.
Extending the module with custom telemetry data
You can send custom events (i.e. totally new events like a user action happening) through a TelemetryClient object (you can see examples for this in the official AI documentation). You can create such an object for the current configuration (i.e. what is also used to send request telemetry) through
ITelemetryClientFactory.CreateTelemetryClientFromCurrentConfiguration().
You can also hook into the default behaviour of the module and e.g. extend what is send during request tracking by implementing the module's event handlers, see the
Events folder/namespace. Particularly you can implement IRequestTrackingEventHandler to add custom data to the request telemetry e.g. by adding custom properties to the Properties dictionary. Furthermore you can implement ITelemetryConfigurationEventHandler to alter the configuration used by any telemetry-sending operation like adding your own ITelemetryInitializers to the TelemetryInitializers collection.
Note on assembly binding errors when using dynamic compilation
Note that when you modify this one or a dependent project in the Orchard solution and then refresh a page without doing a manual rebuild (i.e. letting Orchard's dynamic compilation do the job) you can get the following error:

Could not load file or assembly 'Microsoft.Diagnostics.Tracing.EventSource, Version=1.1.11.0, Culture=neutral, PublicKeyToken=b03f5f7f11d50a3a' or one of its dependencies. The located assembly's manifest definition does not match the assembly reference.

This is because on the fly assembly redirection (see below) doesn't work for some reason in such cases. To solve the issue simply restart the website (from IIS or by restarting IIS Express) after doing a manual build.
Updating AI libraries
When assembly binding redirects are changed make sure to also edit AssemblyRedirectSetupShellEventHandler that mimicks such redirects instead of relying on the Web.config.
Note that since there is a 260 characters limit on paths on Windows, all unused library folders and files should be removed and folders shortened.
After updating you can check for breaking changes between the old and new assembly versions with BitDiffer.
The module's source is available in two public source repositories, automatically mirrored in both directions with Git-hg Mirror:

https://bitbucket.org/Lombiq/hosting-azure-application-insights (Mercurial repository)
https://github.com/Lombiq/Orchard-Azure-Application-Insights (Git repository)

Bug reports, feature requests and comments are warmly welcome, please do so via GitHub.
Feel free to send pull requests too, no matter which source repository you choose for this purpose.
This project is developed by Lombiq Technologies Ltd. Commercial-grade support is available through Lombiq.
",11
ffwff/hana,Rust,"ð¸ hana
hana, a small object oriented programming language.
NOTE: hana's interpreter is under a rewrite in Rust! Please checkout the master branch
Cloning
You'll have to clone it recursively:
git checkout master
git clone --recursive https://github.com/ffwff/hana

Building
(building was tested by using gcc-7 on an x64 with Linux, mileage may vary on other architectures)
You'll need to install libffi and libgc (BoehmGC garbage collector).
For release builds, just do:
make RELEASE=1

It is recommended that you build the interpreter with libreadline and the ENABLE_READLINE flag set for a better REPL.
To bootstrap the init bytecode, compile it using a debug/release build, then remake the interpreter:
make
make build/init.bin
make RELEASE=1 INCLUDE_BYTECODE=1

For debug:
make DEBUG=1

Running
Once built, you can write hana code into a source file, then invoke the interpreter like this:
./main program.hana

Alternatively you could try things out in the REPL:
./main

In the REPL, to type a newline, simply put \ at the end of the line then press enter.
Documentation
see DOCUMENTATION.md
Examples
see DOCUMENTATION.md#Examples for more
Hello World
print(""Hello World\n"")

Variables
name = ""Alice""
age = 20
print(name, "" is "", age, "" years old.\n"")

Fibonacci numbers
// Regular recursive
fib(n) = n <= 1 ? 1 : fib(n-1) + fib(n-2)
print(fib(30), ""\n"")

// Faster recursive (with tail-call optimization!)
fibrec(n, prev, curr) = n <= 0 ? curr : fibrec(n-1, prev+curr, prev)
fib(n) = fibrec(n+1, 1, 0)
print(fib(50), ""\n"")

License
GPLv3 License
",7
projecthorus/horusbinary,C,"Project Horus's Low-Speed Binary Telemetry System
This repository contains documentation and scripts to work with the new horus_demod MFSK/RTTY demodulator, developed by David Rowe. Currently this demodulator provides ~2.5dB better RTTY decode performance than dl-fldigi 3.21.50, and ~0.5dB better performance than fldigi 4.0.1.
It also adds support for a binary-packet 4FSK mode, designed specifically for high-altitude balloon telemetry, and which is intended to supercede RTTY for all Project Horus launches. Preliminary testing shows it has ~6dB improved demodulation performance over RTTY at the same baud rate.
Currently we are developing the modem under Linux & OSX, with the eventual aim to produce a cross-platform GUI. For now, the demodulator is available as a command-line utility, with additional binary packet processing and uploading of data to Habitat performed by the horusbinary.py python script.
These modems have recently been added to the FreeDV GUI, to allow easier usage. Refer to this guide for instructions on using FreeDV to decode Horus Binary telemetry: https://github.com/projecthorus/horusbinary/wiki/FreeDV---HorusBinary-Setup-&-Usage-Instructions
Modes Supported
The horus_demod modem (located within the codec2-dev repo) is in early development, and currently only supports:
MFSK - Horus Binary Packets
Horus Binary packets take the form:
<preamble><unique word><payload>
where
<preamble> = 0x1B1B1B1B
<unique word> = 0x2424

The payload consists of a 22-byte long binary packet, encoded with a Golay (23,12) code, and then interleaved and scrambled, for a total encoded length of 43 bytes. The binary packet format is available here, and the golay-encoding/interleaving/scrambling is performed by horus_l2_encode_packet.
At the start of a packet is a Payload ID (one byte). A lookup table for payload IDs is located here. If you are going to fly your own payload using this mode, you should get a payload ID allocated for your use. This can be done by submitting an issue or a pull request to this repository.
Packets are then transmitted using 4FSK modulation, at 100 baud.
A worked example for generating encoding these packets is available in the RS41HUP repository.
RTTY (UKHAS-Standard Sentences)
UKHAS-standard telemetry sentences, sent via RTTY can be decoded. These take the general form:
$$$$$CALLSIGN,other,fields,here*CRC16\n

Note the use of five (5) '$' symbols at the start of the sentence. This is used as a 'unique word' for packet dection, and must be present. Other quantities of '$'s will not be detected.
Only RTTY telemetry with the following parameters are supported:

Baud Rate: 100
Tone Spacing: 150 to ~1 kHz will work
Encoding: ASCII 7N2 (7-bit ASCII, no parity, 2 stop bits)
CRC: CRC16-CCITT

Hardware Requirements
Both the RTTY and MFSK modes are narrow bandwidth, and can be received using a regular single-sideband (SSB) radio receiver. This could be a 'traditional' receiver (like a Icom IC-7000, Yaesu FT-817 to name but a few), or a software-defined radio receiver. The point is we need to receive the on-air signal (we usually transmit on 70cm) with an Upper-Sideband (USB) demodulator, and then get that audio into your computer.
If you are using a traditional receiver, you'll likely either have some kind of audio interface for it, or will be able to connect an audio cable between it and your computer's sound card. Easy!
With a RTLSDR, you will need to use software like GQRX (Linux/OSX), SDR#, or SDR Console to perform the USB demodulation. You'll then need some kind of loop-back audio interface to present that audio as a virtual sound card. This can be done using:

Linux - via the snd-aloop module. Some information on this is here.
OSX - Using the SoundFlower application.
Windows - Use VBCable

You're also going to need some sort of antenna to receive the signal from the balloon payload, but I figure that's a bit out of scope for this readme!
Software Dependencies
To be able to use the horusbinary.py Python script, you will need a Python interpreter and a few libraries.
Linux / OSX
Under Linux (Ubuntu/Debian) install the required packages using:
$ sudo apt-get install git python-numpy python-pyqtgraph python-crcmod python-requests python-pip sox

Under OSX, Macports or Homebrew should be able to provide the above packages.
If the python-pyqtgraph, python-crcmod and python-requests packages are not available via your package manager, you can try installing them via pip using sudo pip install pyqtgraph crcmod requests.
Windows
Under Windows, the Anaconda Python distribution provides almost everything you need. Download and install the Python 2.7 version of Anaconda. When installing make sure the 'Add Anaconda Python to system PATH' tickbox is checked, else the below commands will not work.
Once Anaconda is installed, grab the rest of the required dependencies by opening an administrator command prompt, and running:
> pip install crcmod python-dateutil

You may wish to set the python interpreter (which should be located at C:\ProgramData\Anaconda2\python.exe) as the default program to open .py files.
Downloading this Repository
You can either clone this repository using git:
$ git clone https://github.com/projecthorus/horusbinary.git

or download a zip file of the repository from here.
Building Horus-Demod
If you wish to use the command-line demodulator (Linux/OSX only) instead of FreeDV, follow these instructions. Otherwise, skip to the next section.
Build Dependencies
We may require a few dependencies to be able to use the new modem. Under Ubuntu/Debian, you can install the required packages using:
$ sudo apt-get install subversion cmake build-essential libfftw3-dev libspeexdsp-dev libsamplerate0-dev libusb-1.0-0-dev

Compiling horus_demod
We need to compile the horus_demod binary (taken from the codec2 repository). This can be accomplished by performing (within this directory):
$ cd src
$ make
$ cp horus_demod ../
$ cd ../

Configuration File
The file user.cfg should be modified to reflect the callsign you wish to use when uploading data to Habitat.
Simply change the following section as appropriate:
[user]
# Your callsign -  used when uploading to the HabHub Tracker.
callsign = YOUR_CALL_HERE

# Your station latitude/longitude, which will show up on tracker.habhub.org.
# These values must be in Decimal Degree format.
# Leave the lat/lon at 0.0 if you do not wish your station plotted on the map.
station_lat = 0.0
station_lon = 0.0
# Radio/Antenna descriptions.
# An optional short decription of your radio/antenna setup.
radio_comment = Your Radio Description Here
antenna_comment = Your Antenna Description Here

Receiving Using FreeDV
NOTE: Horus Binary support in FreeDV is still in development.
Instructions on decoding Horus Binary telemetry using FreeDV are available here: https://github.com/projecthorus/horusbinary/wiki/FreeDV---HorusBinary-Setup-&-Usage-Instructions
Usage - Horus Demod
The horus_demod binary accepts 48khz 16-bit signed-integer samples via stdin, and can decode either RTTY or the MFSK (binary) packets. Successfuly decoded packets are output via stdout, and debug information is provided via stderr.
Suitable audio inputs could be from a sound card input, or from a SDR receiver application such as GQRX.
The horusbinary.py python script will accept decoded packets from horus_demod, and upload them to the HabHub tracker, for display on a map. Uploading to Habitat can be inhibited using the --noupload option. The --stdin option tells horusbinary.py to listen for data via stdin, instead of from UDP packets.
We can string these applications together in the command shell using 'pipes', as follows:
Demodulating from a Sound Card
$ sox -d -r 48k -c 1 -t s16 - | ./horus_demod -m binary - - | python horusbinary.py --stdin

The above command records from the default sound device.
Demodulating using rtl_fm
This assumes you want to use an rtl-sdr dongle on a headless Linux machine.
rtl_fm -M raw -s 48000 -p 0 -f 434410000 | ./horus_demod -q -m binary - - | python horusbinary.py --stdin

Tune 1600 Hz below the expected centre frequency, and make sure that your dongle has a known ppm adjustment.
Demodulating using GQRX
This assumes you have GQRX installed (sudo apt-get install gqrx) and working, have set up a USB demodulator over the signal of interest, and have enabled the UDP output option by clicking the UDP button at the bottom-right of the GQRX window.
$ nc -l -u localhost 7355 | ./horus_demod -m binary - - | python horusbinary.py --stdin

Replace binary in the above command with RTTY to demodulate RTTY telemetry.
On some platforms nc requires the listen port to be specified with the -p argument. In those cases, use:
$ nc -l -u -p 7355 localhost | ./horus_demod -m binary - - | python horusbinary.py --stdin

",2
modin-project/modin,Python,"
Scale your pandas workflows by changing one line of code









To use Modin, replace the pandas import:
# import pandas as pd
import modin.pandas as pd
Installation
Modin can be installed from PyPI:
pip install modin
Full Documentation
Visit the complete documentation on readthedocs: http://modin.readthedocs.io
Scale your pandas workflow by changing a single line of code.
Modin uses Ray to provide an effortless way
to speed up your pandas notebooks, scripts, and libraries. Unlike other distributed
DataFrame libraries, Modin provides seamless integration and compatibility with existing
pandas code. Even using the DataFrame constructor is identical.
import modin.pandas as pd
import numpy as np

frame_data = np.random.randint(0, 100, size=(2**10, 2**8))
df = pd.DataFrame(frame_data)
To use Modin, you do not need to know how many cores your system has and you do not need
to  specify how to distribute the data. In fact, you can continue using your previous
pandas notebooks while experiencing a considerable speedup from Modin, even on a single
machine. Once youâve changed your import statement, youâre ready to use Modin just like
you would pandas.
Faster pandas, even on your laptop

The modin.pandas DataFrame is an extremely light-weight parallel DataFrame. Modin
transparently distributes the data and computation so that all you need to do is
continue using the pandas API as you were before installing Modin. Unlike other parallel
DataFrame systems, Modin is an extremely light-weight, robust DataFrame. Because it is
so light-weight, Modin provides speed-ups of up to 4x on a laptop with 4 physical cores.
In pandas, you are only able to use one core at a time when you are doing computation of
any kind. With Modin, you are able to use all of the CPU cores on your machine. Even in
read_csv, we see large gains by efficiently distributing the work across your entire
machine.
import modin.pandas as pd

df = pd.read_csv(""my_dataset.csv"")
Modin is a DataFrame designed for datasets from 1KB to 1TB+
We have focused heavily on bridging the solutions between DataFrames for small data
(e.g. pandas) and large data. Often data scientists require different tools for doing
the same thing on different sizes of data. The DataFrame solutions that exist for 1KB do
not scale to 1TB+, and the overheads of the solutions for 1TB+ are too costly for
datasets in the 1KB range. With Modin, because of its light-weight, robust, and scalable
nature, you get a fast DataFrame at small and large data. With preliminary cluster
and out of core
support, Modin is a DataFrame library with great single-node performance and high
scalability in a cluster.
modin.pandas is currently under active development. Requests and contributions are welcome!
More information and Getting Involved

Documentation
Ask questions on our mailing list modin-dev@googlegroups.com.
Submit bug reports to our GitHub Issues Page.
Contributions are welcome! Open a pull request.

",2149
magestat/magento2-split-order,PHP,"Split Order for Magento 2
This extension allows your online store to split the order into an order for each item in the cart. With different order IDs, customers can view all the order ids in their Order History and track each item separately. The admin generate separate invoices and shipments for each splitted order. Shipping charges and tax are also split based on items. This extension Magento 2 default offline payment methods: Check / Money Order and Cash on Delivery.
  
1. Installation
Install via composer (recommend)
Run the following command in Magento 2 root folder:
composer require magestat/module-split-order
Using GIT clone
Run the following command in Magento 2 root folder:
git clone git@github.com:magestat/magento2-split-order.git app/code/Magestat/SplitOrder
2. Activation
Run the following command in Magento 2 root folder:
php bin/magento module:enable Magestat_SplitOrder --clear-static-content
php bin/magento setup:upgrade
Clear the caches:
php bin/magento cache:clean
3. Configuration

Go to Stores > Configuration > Magestat > Split Order.
Select Enabled option to enable module.
Change the options selecting the attribute to split the order just like you want.

Contribution
Want to contribute to this extension? The quickest way is to open a pull request on GitHub.
Support
If you encounter any problems or bugs, please open an issue on GitHub.
Need help setting up or want to customize this extension to meet your business needs? Please email willianlkeller@outlook.com and if we like your idea we will add this feature for free or at a discounted rate.
Known issues

Doesn't work with Braintree, Paypal via Braintree, Paypal Express Checkout

Â© Magestat.
",33
BuckeyeSoftware/rex,C++,"Rex engine
Directory layout

src/rx contains engine source files
src/lib contains third party source files
inc/rx contains engine include files
inc/lib contains third party include files

",8
SecOps-Institute/Tor-IP-Addresses,None,"Tor-IP-Addresses
An IP Addresses list of Tor Nodes and Tor Exit Nodes
",4
52ABP/Home,None,"52ABP
æä»¬æ¯ä¸ä¸ªåºäºå¼æºé¡¹ç®å´ç»ä¸­å½ç¹è²ç.NET å¨æ å¼åç¤¾åºï¼ç®åçéå¿æ¯å´ç».Net CoreåAngular ä¸¤ä¸ªçæï¼æ¥æ­å»ºé«å¯ç¨çåºç¨å¼åæ¡æ¶ã
æä»¬æ¨å¨å¼åé«å¯ç¨ãå¤å¤ç¨çæ¡æ¶ãå·¥å·ä»¥åç³»ç»ã
æä»¬å¯¹åå¸å¼æ¶æ/ç³»ç»ï¼å°ç¨åºãå¾®ä¿¡ãAPPé½å¾æå´è¶£ã
æä»¬çç®åæ¯æé ä¸å¥ç¬¦åä¸­å½äººå¼åä¹ æ¯çæ¡æ¶ï¼æ³åå«AI, .NET Core, Linux, Docker, Jenkins, PostgreSql, Entity Framework Core, npm, yarn, vue, angular, redis, rabbitmq, mongodb, jexus, ElasticSearch, nginx, azure, kubernates, service fabric ç­ä¼ä¸çº§å¯è½å°çåºç¨æ¡æ¶çææå¡ã
å³æ³¨æä»¬

å¦ææ¨è§å¾æçæç« è´¨éè¿ä¸éï¼æ¬¢è¿æèµï¼ä¹å¯ä»¥è®¢éæçè§é¢å¦ 
æªå¾å°ææä¸å¾æèªè½¬è½½æ¬æåå®¹,52abp.com ä¿ççæ
äº¤æµ QQ ç¾¤ï¼952387474 ç¹å»é¾æ¥å å¥ QQ ç¾¤ãå¾®è½¯ MVP å¸¦ä½ å­¦ ASP.NETÂ COREã

è§é¢ä¸åº

ãæ¶è´¹ãè¾è®¯è¯¾å :https://ke.qq.com/course/392589?tuin=2522cdf3 

èµèµæ¯æç§çè¯å®




å³æ³¨å¾®ä¿¡å¬ä¼å·ï¼è§è½çç½æ¿æ¥

",50
shen1986/shenBlog,TypeScript,"
å°æ²çä¸ªäººç½ç«
å±ç¤ºèªå·±çä¸ªäººåå®¢ç½ç«
å¥æºåæ¦è¦

ç»åäºé¿æ¶é´çåç«¯å­¦ä¹ ï¼æ³æèªå·±çå­¦ä¹ ææå±ç°åºæ¥ï¼æä»¥æ³åä¸ä¸ªå±ç¤ºèªå·±æ°´å¹³çä¸ªäººåå®¢ç½ç«ã
ä¸å¼å§åªè¦æ±è½æææååºæ¥å°±è¡ï¼åæå¯è½çéç¹å¨ç»é¢çä¸äºæææ¼ç¤ºã
ç½ç«åå®¹ä¸»è¦æ¯åäº«ä¸äºä¸ªäººç»åï¼åææ¯ææ¡ã
é¢æ³çæ¯ååå°åç¦»ãåå°ä¸»è¦æä¾æ¥å£åå¤çæ°æ®ãåç«¯ä¸»è¦æ¯è¡¨ç¤ºã

ç¨å°çææ¯ï¼	//TODO

åç«¯ææ¯ï¼Node.js

æ¨¡æ¿å¼æï¼ art-template
Web å¼åæ¡æ¶ï¼ koa2


åç«¯ææ¯ï¼Vueï¼less, html

åç®¡çå·¥å·: webpack
èè: Ant-Design
å¾æ å­ä½åº: icomoon
å¼æºå·¥å·åï¼bootstrap

åæ¥çæ æ ¼æ¯12ï¼æ¹äºæºä»£ç ææ æ ¼æ¹æ24éæ°ç¼è¯




é¨ç½²ï¼Docker
æ°æ®æä¹åï¼mysql

å®æ½è®¡å

åæè°æ¥ï¼æ ¹æ®githubä¸é¢çç½ç«ï¼åä¸ä¸ªèªå·±çé¡µé¢è®¾è®¡ï¼æå¥½æååå¾
å¶ä½åå°é¡µé¢ååå°éæé¡µé¢
è®¾è®¡è¡¨ç»æã
å¼åé¶æ®µã
è°ä¼é¶æ®µã
åå¸ã
ç»´æ¤ã

å·ä½å®æ½		//TODO

åæè°æ¥

markdownæä»¶çåºæ¬å¸¸ç¨ç¼åè¯­æ³ï¼å¾æå¹¶èï¼ã

MDå­¦ä¹ 


åç§ç½ç«æ¥æ¾ã

åç§ç½ç«1
åç§ç½ç«2
åç§ç½ç«3
fangzh


ååå¾å¶ä½å·¥å·äºè§£ã

Axureå·¥å·ä¸è½½
å¢¨å å®éé¢æå¾å¤é½æ¯ç°æçç»ä»¶ï¼ç´æ¥å¸å±æå¨å°±å¥½äº
ç±äºä¸è¿°çå­¦ä¹ éè¦ä¸äºæ¶é´ï¼åç¦»ä¸»é¢ï¼ææ¶åªç¨ç¨ä¸äºç®åçå·¥å·æ¥å¶ä½èå¾ãä¸è¿å¤æµªè´¹æ¶é´å¨è¿ä¸é¢ãç­ææ¶é´äºåæ¥å­¦ä¹ ã


å¶å®åºç¡è¦ä»¶ï¼æç¡®è¦ååªäºèå´ã

åå°

é¦é¡µï¼logoï¼

è½®æ­å¾ã
ææ°æç« 
æç« åè¡¨


æç« 

æç« åè¡¨


å½æ¡£

å¯æåç±»è¿è¡æ¥è¯¢


ç¹æ»´

å°æ ç­¾é¡µ


æ¢çæ´»

çæ´»ç¹æ»´åäº«




åå°

é¦é¡µ

ç³»ç»ä¿¡æ¯ v1.0


æç« ç®¡ç

æç« åè¡¨
æç« æ·»å ï¼å¯ææ¬ï¼markdownï¼


æ¶èç®¡ç

æ¶èåè¡¨
æ¶èæ·»å 


è¯´è¯´ç®¡ç

è¯´è¯´åè¡¨
è¯´è¯´æ·»å 


ç³»ç»ç®¡ç




åç«¯çæ¨¡æ¿å¼æç¨art-templateï¼å¥é¨é¨æ§è¾ä½ã
ä»£ç é£æ ¼åè§çº¦å¶å®MaintainableJavaScript
åºç¡å·¥ç¨åå»ºã	ï¼é¢è®¡5æåº6æåå¼å§ï¼


å¶ä½åå°é¡µé¢ååå°éæé¡µé¢

ååäºä¸ä¸ªèªæä»ç»çæ¨¡æ¿html,ç¨äºart-templateæ¨¡æ¿å¼æã

resume
åç°ä¸ä¸ªå¨æè¾ççç®åï¼åç§çåäºä¸ï¼ç¨åä¼åæå¬ç¨æ¨¡æ¿å¨æä¸ªäººä»ç»


ååäºä¸ä¸ªæå¡ç«¯æ¸²æï¼æå©äºSEOï¼çä¸ªäººä»ç»,ç¨äºEJSæ¨¡æ¿å¼æã(æ²¡æä½¿ç¨expressï¼æ¯è¾ç®åçå®ç°)

resume-nodejs


é¤äºç¿»é¡µï¼åå°é¡µé¢åºæ¬åå®äºã

åå°åå®¢é¡µé¢TypeScriptç

ç¿»é¡µåå¤å¨åå°é¡µé¢åå¥½ä¹åååï¼ææ°æ®å¥½åç¹ã


Vueåå°åç«¯æ¨¡æ¿é¡µé¢





è¡¥åè¯´æ

æ è®°TODOçå°æ¹ä»¥åä¼æ ¹æ®å®éæåµè¿½å ã
ä¸å¼å§ç¨httpï¼æåè¦æ¹æHttps
å2å¥ç»é¢ï¼çµèåææºåä¸å¥ï¼é¢è®¡ä¸å¹´æ¶é´ãååPCç«¯ï¼ææºç«¯ä½ä¸ºä»¥åè°ä¼åç»´æ¤çåå®¹ã
é¢è®¡è®¿é®éè¾ä½ï¼ä¸ååå¸å¼æ¶æã
èèå°SEO,åå°é¡µé¢ç¨htmlå æ¨¡æ¿å¼æï¼åå°é¡µé¢ç¨VUE
PCç«¯ä¸åæµè§å¨å¼å®¹ãææ°çIEï¼Googleï¼FireFoxåºæ¬è½ä½¿ç¨å°±è¡ã
èèå°å¨æå¤ªé¿ï¼éç¨ææ·å¼åçææ³ï¼ååä¸ä¸ªä¸ªäººä»ç»çç½ç«ä»¥åéæ­¥è¿½å æ°çåå®¹
è¿å¨åç°hexoè¿ä¸ªåå®¢ç®åå·¥å·ï¼ç°é¶æ®µåä½¿ç¨Hexo
https://mlab.com/
ç¨dockerçè¯è¿è½ä½¿ç¨jekyll
.artæä»¶å¦ä½åhtmlçåè²åæç¤º

",3
jgarber623/spaceholder.cc,Ruby,"
A space-themed image placeholder service.





Usage
Jamming on a prototype? Cranking on buildout but you don't have content images from your client yet? Drop the following in your markup and marvel at the wonders of the universe:
<img src=""https://spaceholder.cc/400x300"" alt=""This is an awesome spaceholder!"">
Replace 400x300 with whatever pixel dimensions you like: 200x50, 1200x400, 240x240. You'll be traveling the outer reaches so long as the format is a number, an x (the letter ""x""), and another number. For sanity's sake, both dimensions may be no larger than 5000.
If you'd like a square image, use a single number in the URL:
<img src=""https://spaceholder.cc/400"" alt=""This is an awesome square spaceholder!"">
Improving SpaceHolder
You want to help make SpaceHolder better? Hell yeah! I like your enthusiasm. For more on how you can help, check out CONTRIBUTING.md.
Donations
If diving into Ruby isn't your thing, but you'd still like to support SpaceHolder, consider making a donation! Any amountâlarge or smallâis greatly appreciated. As a token of my gratitude, I'll add your name to the Acknowledgments below.


Acknowledgments
Tip o' the hat to Brad Frost for the inspiration and Alex Rehberg for the name. Many thanks to Ste Grainer for SpaceHolder's logo and visual design.
All those amazing photos are sourced from NASA on The Commons and carry no known copyright restrictions.
SpaceHolder is written and maintained by Jason Garber.
License
SpaceHolder is freely available under the MIT License. Use it, learn from it, fork it, improve it, change it, tailor it to your needs.
",26
jgarber623/spaceholder.cc,Ruby,"
A space-themed image placeholder service.





Usage
Jamming on a prototype? Cranking on buildout but you don't have content images from your client yet? Drop the following in your markup and marvel at the wonders of the universe:
<img src=""https://spaceholder.cc/400x300"" alt=""This is an awesome spaceholder!"">
Replace 400x300 with whatever pixel dimensions you like: 200x50, 1200x400, 240x240. You'll be traveling the outer reaches so long as the format is a number, an x (the letter ""x""), and another number. For sanity's sake, both dimensions may be no larger than 5000.
If you'd like a square image, use a single number in the URL:
<img src=""https://spaceholder.cc/400"" alt=""This is an awesome square spaceholder!"">
Improving SpaceHolder
You want to help make SpaceHolder better? Hell yeah! I like your enthusiasm. For more on how you can help, check out CONTRIBUTING.md.
Donations
If diving into Ruby isn't your thing, but you'd still like to support SpaceHolder, consider making a donation! Any amountâlarge or smallâis greatly appreciated. As a token of my gratitude, I'll add your name to the Acknowledgments below.


Acknowledgments
Tip o' the hat to Brad Frost for the inspiration and Alex Rehberg for the name. Many thanks to Ste Grainer for SpaceHolder's logo and visual design.
All those amazing photos are sourced from NASA on The Commons and carry no known copyright restrictions.
SpaceHolder is written and maintained by Jason Garber.
License
SpaceHolder is freely available under the MIT License. Use it, learn from it, fork it, improve it, change it, tailor it to your needs.
",26
z1lc/core,Java,"core


Description
core is my personal repository. Most of the code is related to providing data for a
quantified self dashboard on Klipfolio. Data is
ETL'd and sent to a
PostgreSQL database hosted on
Google Cloud SQL. Hibernate is used as the ORM and schema
generator. Everything is scheduled with Quartz.
Data Sources

Anki local SQLite database
Goodreads API
Google Sheets API
HERE API
Human API
Kiva API
Last.fm API
LeetCode scraping
LIFX API
RescueTime API
RottenTomatoes scraping
Toodledo API & scraping
WakaTime API
Wikipedia: Wikimedia API, DBpedia scraping,
MediaWiki API

Dependencies

Install the gcloud sdk.

Run gcloud init, enter your credentials into browser.
When prompted, select project z1lc-qs / arctic-rite-143002.


Set the environment variable GOOGLE_APPLICATION_CREDENTIALS to point to z1lc-qs.json. More info
here.
Install Anki, ideally a version â¥2.1.

Log into Anki and sync.
Install the AnkiConnect add-on.


To avoid having passwords and API keys stored alongside code in Git, this project uses a file called
secrets.json which provides secrets to the application at runtime. Ensure you've provided a valid mapping for each
com.robertsanek.util.SecretType within the secrets.json, and that it is located in the root directory. You can find
out where this directory is for your platform by calling
com.robertsanek.util.platform.CrossPlatformUtils::getRootPathIncludingTrailingSlash. You can refer to the
secrets.template.json file for an example of what the real secrets.json should look like.
If you plan on running the ETL command, ensure you've run the ETL_SETUP command once beforehand.

How to run
Pass a command-line argument to select one of the below (documented in Main.java).

ETL will run all ETLs and then run DQ.
DQ will run data quality checks.
HABITICA will generate an html document with a summary of Habitica dailies.
PASSIVE_KIVA will generate an html document with short-duration Kiva loans from
highly-rated field partners.
WIKI will extract basic information about popular Wikipedia articles that refer to people, outputting a csv
file and images to import into Anki.
ETL_SETUP needs to be triggered before ETLs are run.
DAEMON will run some combination of the above commands on a specified schedule. See Main.java for the
exact scheduling.

Example: java -jar target/core-1.0-SNAPSHOT.jar -command etl_setup -type manual
",3
randomwangran/myEmacs,Emacs Lisp,"Motivation
Iâve been using GNU/Emacs for two years, and I am so grateful that I
  met GNU/Emacs. It makes my life interaction with computers in a much
  more simulating way.
The current configuration is just an intermediate state of
  exploration, it is still growing up. As a relatively new user of
  GNU/Emacs, I do not know too much of it, so many times you will see
  the ill-structure and not-good-looking elisp code, but I will try to
  make it simple but not simpler.
In late 2018, I start to learn Emacs as a real-emacser. The definition
  of real-emacser to me, is to use Emacs as much as possible, to
  learn from peopleâs elisp code as much as possible, to write and
  share my elisp to the world as much as possible. I just want continue
  to explore this vast but magic ocean.

âWhat we have once enjoyed deeply we can never lose. All that we
    love deeply becomes a part of us.â

In addition to my âmasterâ, you will find this README file. Basically,
  it is a documentation to this journey. It is a motivation for me and I
  hope it can, perhaps, do the same to you.
Table of Contents

Motivation
Mastering Emacs

if forget kbd?
try undo tree


Branch info
Collected questions

why people use âgit-submoduleâ, whatâs their pros and cons?
when using projectile to index a very large project, it takes forever.
why desktop+ is perfectly working even I am using 26.1?
how to customize the SRC block in LaTex?
how to highlight kbd in org-mode that is shown on GitHub?
what is git-annex
how to launch dired when use projectile?
~C-x C-x~ and ~C-u C-SPE~
tages table looks like a handy tool
why M-a not go back one sentence?
build c++ complier on windows
I want to use emacs as xshell entry point
annoying second cmd emacs launcher
what is ~org-habit.el~
hard time with kbd defination
What is treemacs
Writing commit message how to define a title?
how to constomize the template in magit popup windows?
open file in a general way?
my emacs getting slower
customize capture-mode so that I could add question to here more easily?
how to use git-stash to hand this situation?
how to set indentaion on the code block area?
how to cut a sentence into two but indent properlly?
what is the meaning of sharp in kill-ring?
why dired mode cannot + a folder easily
how to write this diagram in elisp?
how to disable ~/.. command?
for 1st installation on a new computer
magit: after push close the entry panel?
why M-, works in scratch buffer not other?
why Lisp-Interaction mode could automatically find TAGS file
how to use capture to resent file to here?
how to draw ascii art?
how to insert some hyper line within a org-file
what is difference between let and setq?
what is different âpâ and âPâ
how to do copy file multiply times
dired creat a file call PARENT.foam
how to show parent folder name
how to do bracket expansion in dired?
how to set book mark for an org file?
how to do multiply copy to multiply subfolder
how to window explore like copy
org-mode file
how to jump like info links?
dire complicated but might rdc useful question
tty <f1> issue


Side projects

annotate editfns.c source file
read creator of smart-parents
read yinâs blog about lisp
I want to read this blog word-by-word
study centaur emacs
help documentation of spacemacs
read this .emacs


A-ha moment

insert kbd block
basic maneuver
org-mode
ivy
talking with my hero
magit
projectile
searching
jump back and forth
running tty-emacs
info file
dired
major mode
regexp replace
git lfs
macro
Fill Prefix
diredp marks subfolders
calculator
elisp regular expression
message buffer
get cursor position
find something that might exist
kbd for replace-regexp
string-insert-rectangle


appreciating

an emacs-hacker gives me a star!
a second emacs-hacker gives me a star!!
wow a Tinkoff hacker gives me a star!
blue fish
idreamshen



Mastering Emacs
By Mickey Petersen Page 90/281
if forget kbd?
Not a problem, just type C-h.
For example, you know the prefix of some commands, but donât know
  the following stuff. Just type C-h.
C-x 8 C-h
And I finally know how to insert this guy: â
try undo tree
undo-tree
Branch info

âmasterâ is forever?
âlinux-expâ for GNU/Linux: <2019-02-22 Fri> I gave up this
    branch because I found a new better way to manage my
    configuration for emacs
âappreciatingâ for thank you

Collected questions
Those questions will be mared as [TODO] for two months, if it is not
  answer by me, I will post those questions on-line for helping.
It seems that the time is not important. This is not a semester that
  I need to finish it. If the question is not solved. It simply means
  that I am not that interested in that question. If I need to solve
  it, no matter what (unless I am dead), I will figure it out, for
  sure.
why people use âgit-submoduleâ, whatâs their pros and cons?
<2018-12-07 Fri>
https://emacsair.me/2016/05/17/assimilate-emacs-packages-as-git-submodules/
when using projectile to index a very large project, it takes forever.
<2018-12-07 Fri>
Thereâs discussion issue. Some Windows user share their experience,
  but I have no idea with the following concepts:

âalienâ index
ânativeâ index

What are those index methods? How they work? What if I really want
  to use projectile on very large project on Windows?
why desktop+ is perfectly working even I am using 26.1?
<2018-12-07 Fri>

some times buffer fails to load the desired files

how to customize the SRC block in LaTex?
<2018-12-10 Mon>
Insteady of explorting \begin{verbatim} is that possible to
  explort {\tiny \begin{verbatim}?
I need further study following code:
(defun org-export-format-code-default (element info)
  ""Return source code from ELEMENT, formatted in a standard way.

ELEMENT is either a `src-block' or `example-block' element.  INFO
is a plist used as a communication channel.

This function takes care of line numbering and code references
inclusion.  Line numbers, when applicable, appear at the
beginning of the line, separated from the code by two white
spaces.  Code references, on the other hand, appear flushed to
the right, separated by six white spaces from the widest line of
code.""
  ;; Extract code and references.
  (let* ((code-info (org-export-unravel-code element))
         (code (car code-info))
         (code-lines (split-string code ""\n"")))
    (if (null code-lines) """"
      (let* ((refs (and (org-element-property :retain-labels element)
                        (cdr code-info)))
             ;; Handle line numbering.
             (num-start (org-export-get-loc element info))
             (num-fmt
              (and num-start
                   (format ""%%%ds  ""
                           (length (number-to-string
                                    (+ (length code-lines) num-start))))))
             ;; Prepare references display, if required.  Any reference
             ;; should start six columns after the widest line of code,
             ;; wrapped with parenthesis.
             (max-width
              (+ (apply 'max (mapcar 'length code-lines))
                 (if (not num-start) 0 (length (format num-fmt num-start))))))
        (org-export-format-code
         code
         (lambda (loc line-num ref)
           (let ((number-str (and num-fmt (format num-fmt line-num))))
             (concat
              number-str
              loc
              (and ref
                   (concat (make-string (- (+ 6 max-width)
                                           (+ (length loc) (length number-str)))
                                        ?\s)
                           (format ""(%s)"" ref))))))
         num-start refs)))))
how to highlight kbd in org-mode that is shown on GitHub?
<2018-12-13 Thu>
I made several attempts in <2018-12-13 Thu>, but none of them
  successed.
what is git-annex
<2018-12-10 Mon>
  why there is 0/155 user unhappy about it?
an comparison in 2015
how to launch dired when use projectile?
<2018-12-13 Thu>
For example, I have a *.one file find, after C-x p f, is that
  possible to use launch-file instead of directly open it?
C-x C-x and C-u C-SPE
I never use those two commands before, how to properly use them?
C-x C-x: it will mark all the region from the current cursor
  position back to the previous marking point.
But it is hard to use in the real work. previous marking point is
  hard to remember. For example, I do not know where prevous marking
  point is when I am typing this.
In what kind of situation, should I use C-x C-x?
tages table looks like a handy tool
<2018-12-18 Tue>
but! I cannot find it on Windsows machine.
why M-a not go back one sentence?
<2018-12-18 Tue>
I found it goback to the begining of a paragraph not a sentence,
  which is annoying.
build c++ complier on windows
<2018-12-23 Sun>
I found this blog looks great! Have fun if have some time.
https://caiorss.github.io/Emacs-Elisp-Programming/Emacs_On_Windows.html#sec-1-7-1
I want to use emacs as xshell entry point
<2018-12-26 Wed>
ON windows, is that possible?
annoying second cmd emacs launcher
<2018-12-26 Wed>
After I upgrade to 26.1, theseâs always to icon on the bar. I want
  it goback to one.
I end up using ahk to defined WIN+e to launch runemacs.exe
At the same time, I clean everything on the bottom bar, which will
  awlays make emacs window shortcut at the begining, which will help
  me to switch the app.
In addtion, itâs a âminimizationâ. Will see how it works
what is org-habit.el
<2018-12-27 Thu>
I happen to find this file, when I was doing spacemacs project
c:/Program Files
  (x86)/emacs-26.1-x86_64/share/emacs/26.1/lisp/org/org-habit.el
hard time with kbd defination
<2018-12-28 Fri>
I want to use C-x ha to entry the habit stuffâ¦
But it conflict with C-x h (mark-whole-buffer), which is somewhat
  a default and important emacs kbd.
How to deal with this situation?
End up using C-x w: what means what you want to do.
What is treemacs
How it is different from neotree?
Writing commit message how to define a title?
<2018-12-28 Fri>
Just leave a blank line.
how to constomize the template in magit popup windows?
<2018-12-24 Mon>
For example, when I write git commit message, I need something
  like:

reading-books: IPEL :: XXX ::: XXX

I think just add a snippet is okay, but how to achive this?
open file in a general way?
<2018-12-30 Sun>
  I found the qutebrowserâs search command promp very useful.
O KEYWORKS search-text
In my case:
I want to
SOMEKBD KEYWORKS filename
I donât know ivy has this kind of capbility, dired+, or bookmarks?
my emacs getting slower
<2018-12-31 Mon>
If I used desktop+ to load some kits, it becomes slower especially
  when I switch between apps. Not a big issue when I am compleltely
  within the Emacs.
Seems notâ¦ When I save file it takes me ~4 seconds, which makes
  me crazy.
Remark: initilization time for Desktop+ is long, but after that
  everything good. Saving file issue is hardware issue not related to
  emacs.
customize capture-mode so that I could add question to here more easily?
<2018-12-30 Sun>
how to use git-stash to hand this situation?
<2019-01-05 Sat>
For example, I am writing this journey file
\\**** my journey
\\***** intial thoughts

I add some notes there, but have difficult inserting a in-file
  link. I starpage about how to insert â<<>>â, but I found another
  interesting org-mode command: C-c C-o if the marker is in source
  code block.
I found it run the command! It is so cool and the function it use
  is org-babel. I love this command, so I add something docments to
  this point.
However, when I finish the doc, I found it is really hard to
  make two comments obvious! I was editing one file, so all the
  changes will go to one commit.
I know git-stash works for this kind of dirty work, but how?
how to set indentaion on the code block area?
If the code block is automatically indent and it is in a sub-tree
  item. The indentation would be so ugly how to deal with it?
how to cut a sentence into two but indent properlly?
E.g.: this is sis is sifnidfn df.
After some magics:
this is sis i
  s sifnidfn df.
what is the meaning of sharp in kill-ring?
(nth 0 kill-ring)
#(""      I got something like this:"" 0 32 (fontified t font-lock-fontified t))
Whatâs the meaning of â#â?
why dired mode cannot + a folder easily
It will always generate a folder that is autocomplated. It seems
  related to emacs swiper?

~C-M-j~(ivy-immediate-done): Exits with the current input instead of the
    current candidate (like other commands).  This is useful e.g. when
    you call find-file to create a new file, but the desired name
    matches an existing file. In that case, using C-j would select that
    existing file, which isnât what you want - use this command
    instead.

how to write this diagram in elisp?
internal of the kill ring
how to disable ~/.. command?
My patient is gone when waiting Find file: ~/..
But sometimes accident happen.
for 1st installation on a new computer
Thereâs always some issues with magit. It cannot be installed
  automatically. I had to do package-list-packages, which is not
  very handy.
magit: after push close the entry panel?
magit after push close panel, i.e. âqâ
âqâ     (âmagit-mode-bury-bufferâ)
âP pâ     (âmagit-push-current-to-pushremoteâ)

;;;###autoload (autoload 'magit-push-current-to-pushremote ""magit-push"" nil t)
(define-suffix-command magit-push-current-to-pushremote (args &optional set)
""Push the current branch to its push-remote.

When `magit-remote-set-if-missing' is non-nil and
the push-remote is not configured, then read the push-remote from
the user, set it, and then push to it.  With a prefix argument
the push-remote can be changed before pushed to it.""
:if 'magit--pushbranch-suffix-predicate
:description (lambda () (magit--pushbranch-suffix-description t))
(interactive (list (magit-push-arguments)
(magit--transfer-maybe-read-pushremote ""push"")))
(magit--transfer-pushremote set
(lambda (_ branch remote/branch)
(magit-git-push branch remote/branch args))))
Not sure how to change something in above function to run `qâ.
why M-, works in scratch buffer not other?
To solve this issue, I end up study OFâs tags system.
First download `exuberant ctagsâ from
  https://sourceforge.net/projects/ctags/
Then use this script to build tags:
etagsCmd=""/home/superran/bin/bin/etags -e --extra=+fq --file-scope=no --c-kinds=+p -o .tags/etags -L -""

find -H ""/home/superran/opt/OpenFOAM-dev/"" \
  \( -name ""*.[HC]"" -o -name lnInclude -prune -o -name Doxygen -prune \) | \
 $etagsCmd
Finally, use:
`M-.  xref-find-definitions` to do the awsome jump bewteen source
  code.
why Lisp-Interaction mode could automatically find TAGS file
Itâs really a magit to me.
how to use capture to resent file to here?
Idea itself is important.
how to draw ascii art?
 kill-ring                  ---- kill-ring-yank-pointer
|                       |
|                       v
|     --- ---          --- ---      --- ---
 --> |   |   |------> |   |   |--> |   |   |--> nil
      --- ---          --- ---      --- ---
       |                |            |
       |                |            |
       |                |             -->""yet older text""
       |                |
       |                 --> ""a different piece of text""
       |
        --> ""some text""


how to insert some hyper line within a org-file
I found target point could be marked as:
<<target>>
To reference this target, just use square bracket to ref it.
But how to use kbd to do so?
what is difference between let and setq?
what is different âpâ and âPâ
1st understanding
I read this page for understanding what is the difference between
  ~âpâ~ and ~âPâ~.

âpâ tells Emacs to pass the prefix argument (C-u NUMBER C-x
    C-e) to the function
âPâ cannot use a default number. It is codersâ responsibility to
    make sure the input argument passed into the function

2nd study
It seems my 1st understanding is not correct. I wrote this piece:
if I use âPâ
(defun ran-search (STR)
  ""Searching""
  (interactive ""p"")
  (match-beginning STR))
     (ran-search 0)
I got some number
However, if I try to use âPâ:
(defun ran-search (STR)
  ""Searching""
  (interactive ""P"")
  (match-beginning STR))
And I want to pass the prefix argument C-u NUMBER M-x
  ran-search ()to ran-search, it fails.
how to do copy file multiply times
Then name would be like

fileToBeCopy_copy_1
fileToBeCopy_copy_2
fileToBeCopy_copy_3
    â¦

dired creat a file call PARENT.foam
Everytime to creat such a dummy file is painful
	emacs get file parent folder name
    (file-name-d

     (file-name-absolute-p ""rms/foo"")

     (concat () "".foam"")

     emacs get directory name

     (defun test
	  (file-name-nondirectory (directory-file-name (buffer-file-name))))

     (buffer-file-name)

     (defun show-file-name ()
      ""Put the current file name on the clipboard""
      (interactive)
      (let ((filename (if (equal major-mode 'dired-mode)
			   default-directory
			 (buffer-file-name))))
	 (when filename
	   (with-temp-buffer
	     (insert filename)
	     (clipboard-kill-region (point-min) (point-max)))
	   (message filename))))

how to show parent folder name
I try to revise `show-file-nameâ to do this without luck.
May try it latter.
  (defun show-parent-name ()
 ""Put the current file name on the clipboard""
 (interactive)
 (let ((filename (if (equal major-mode 'dired-mode)
                     default-directory
                   (buffer-file-name))))
   (when filename
     (with-temp-buffer
	(insert filename)
	(clipboard-kill-region (search-backward ""/"" (search-backward ""/"")) (search-backward ""/""))
	(message filename))))

how to do bracket expansion in dired?
Iâve attempted to do this without luck. But
  `eshell-brace-expansionâ itself is good. Need to further
  study how dired copy file.
   (defun eshell-brace-expansion (str)
  (let* ((parts (split-string str ""[{}]""))
         (prefix (car parts))
         (body   (nth 1 parts))
         (suffix (nth 2 parts)))
    (mapcar (lambda (x) (concat prefix x suffix))
            (split-string body "",""))))

(dired-do-copy (eshell-brace-expansion ""test-{a,b,c}""))

mkdir ""test-{a,b,c}""(|eshell-brace-expansion)
how to set book mark for an org file?
For example, the doc for c++ journey is so long. Each time I open
  that file, I need some extra time to find where I am.
Is that possible open the org file and then jump into exactly where
  I was?
how to do multiply copy to multiply subfolder
Marked all the files, then call âa functionâ, marked all the
  folders to be copied to. RET. Everythings done.
how to window explore like copy
Mark files then (A Function), every marked files are copied with a
  -prefix in the current directory?
org-mode file
For a long file like this file, is that possible to set an anchor
  point such that I could open it and marker is pointing at the most
  recent place when I open this file?
This my current solution:
I use org-store-link to mark where I am. Then I put this link at
  the beginning section of this file. A little bit easy to jump to
  working place.
how to jump like info links?
I have some links in org files. Sometimes, I want to jump between
  those links. Is that possible to press âTABâ to jump in betweent
  those link. Just like the info file?
Sovled: C-c C-x C-n org-next-link
dire complicated but might rdc useful question
Is that possible to pass all the marked files (abs path?) into
  scratch buffer?
Then, by using macro, it would be much more powerful.
tty <f1> issue
I found when using emacs in tty, <f1> not working when the current
  buffer is in dired mode, but for other mode it still works.
Side projects
annotate editfns.c source file
read instrction
journey
<2019-01-16 Wed>
To view c source code, I download the emacs-26-x86_64-deps.zip.
  But it does not have a src.
study how to annotate
After see the encouragement from the creator, I try to spend
  20 minutes everyday to commit myself to this beautiful project.
(defun elsa-pluralize (word n)
""Return singular or plural of WORD based on N.""
(if (= n 1)
word
(concat word ""s"")))
(elsa-pluralize ""test"" 2)
further study type annotations

The `(elsa-pluralise :: â¦)` inside a comment form provides
    additional information to the Elsa analysis.  Here we say that the
    function following such a comment takes two arguments, string and int,
    and returns a string.

Emm, itâs quite hard to follow this point:
(elsa-pluralize :: String -> Int -> String)
How do we know which one is the input and which is output? For
  example, is that possible this function has one argument, String,
  generating two outputs, Int and String?
questions:

what is test predicates?
what is Cons type?
    
Cons types are specified by prefixing wrapping the `car` and
        `cdr` types with a `Cons` constructor, so `Cons Int Int` is a
        type where the `car` is an int and `cdr` is also an int, for
        example `(1 . 3)`.

I Swiper, (C-s: Cons), this is what I got:
	 ./editfns.c:664:     Consider the case where the point (`.') is between the fields `x' and `y':
	 ./editfns.c:893:	/* Constrain NEW_POS to FIELD_BOUND.  */
    
I donât where I can find it in the C source code within
      editfns.c. Maybe this kinda data is used in other source
      code.


What is meaning of dot in this ()?
(1 . 3)
I found this explaination is great. But when I want to comment,
  I cannot do it due to insufficient reputation.
The list should be started with a single apostrophe, otherwise
  the GNU/Emacs would refuse to recognize the following as a list.
'(a b c d e)                       ; a normal list
'(a . (b . (c . (d . (e . nil))))) ; the same list in primitive form
I donât understand how to create function types?


Function types are created by separating argument types and
      the return type with `->` token.


What does this mean?

Some type constructors have optional arguments, for example
    writing just `Cons` will assume the `car` and `cdr` are of type
    `Mixed`.

Cons are the data type in Elsa?
read this pull request
As suggested by the creator, I start to reading this pull request
  in hoping a btter understanding the data type in Elsaâs world.
After a brief go-though of this page. I still do not have a very
  clear idea of whatâs going on there. For example:
     (defun add-one (x)
	 (declare (elsa (int) int))
	 (1+ x))

     (add-one 4)

     (defun simple-add-one (x)
	 (1+ x))

     (simple-add-one 4)
Why we need to declare?
(declare (elsa (int) int))
I know the purpose of this project is to check the elisp code
  without running it. But, right now, I donât have a clear mind.
So, better to play with Elsa first.
con and cdr
why cdr and car are int?
I check the source code cdr:
	DEFUN (""cdr"", Fcdr, Scdr, 1, 1, 0,
	       doc: /* Return the cdr of LIST.  If arg is nil, return nil.
	Error if arg is not nil and not a cons cell.  See also `cdr-safe'.

	See Info node `(elisp)Cons Cells' for a discussion of related basic
	Lisp concepts such as cdr, car, cons cell and list.  */)
	  (register Lisp_Object list)
	{
	  return CDR (list);
	}
I cannot understand why:

Return the cdr of LIST

will return an interger type of data? Would it imply that it does
  some magic stuff: return CDR (list);. From a newbieâs eye,
  the return value of ~âcdrâ~, will call a function CDR (list),
  which looks like recursive function?
go the minibuf.c
How does he knows there are 22 functions?
install cask
I configure the path for python, emacs, and cask today, but got
  the following error:
	       C:\Users\user\Desktop\New folder>cask init [--dev]
     Traceback (most recent call last):
	 File ""C:\Users\user\test\rep\cask\bin\cask"", line 425, in <module>
	   main()
	 File ""C:\Users\user\test\rep\cask\bin\cask"", line 387, in main
	   if ENVB.get(b'TRAVIS', b'') == b'true':
	 File ""C:\Users\user\AppData\Local\Programs\Python\Python36-32\lib\_collectio
     ns_abc.py"", line 660, in get
	   return self[key]
	 File ""C:\Users\user\AppData\Local\Programs\Python\Python36-32\lib\os.py"", li
     ne 666, in __getitem__
	   value = self._data[self.encodekey(key)]
	 File ""C:\Users\user\AppData\Local\Programs\Python\Python36-32\lib\os.py"", li
     ne 735, in encodekey
	   return encode(key).upper()
	 File ""C:\Users\user\AppData\Local\Programs\Python\Python36-32\lib\os.py"", li
     ne 730, in check_str
	   raise TypeError(""str expected, not %s"" % type(value).__name__)
     TypeError: str expected, not bytes

     C:\Users\user\Desktop\New folder>cask install
     Traceback (most recent call last):
	 File ""C:\Users\user\test\rep\cask\bin\cask"", line 425, in <module>
	   main()
	 File ""C:\Users\user\test\rep\cask\bin\cask"", line 387, in main
	   if ENVB.get(b'TRAVIS', b'') == b'true':
	 File ""C:\Users\user\AppData\Local\Programs\Python\Python36-32\lib\_collectio
     ns_abc.py"", line 660, in get
	   return self[key]
	 File ""C:\Users\user\AppData\Local\Programs\Python\Python36-32\lib\os.py"", li
     ne 666, in __getitem__
	   value = self._data[self.encodekey(key)]
	 File ""C:\Users\user\AppData\Local\Programs\Python\Python36-32\lib\os.py"", li
     ne 735, in encodekey
	   return encode(key).upper()
Need Python 2.6 ? instead of 36?
Interesting, PATH read the path from beginning to the end. Cool.
issue when installing
C:\Users\user\Documents\rep\elsaTest>cask exec elsa elsa.el
cask exec: error: Failed to execute elsa elsa.el: (2, 'No such file or directory
')
Did you run cask install?
preparing to issue installation
I try to run elsa on a windows x64 machine. Not sure it was
  tested yet. If running it on Linux is a must, I would like to
  try. But, in case someone has already play with in Windows. I
  just log something that Iâve encounted.
git clone https://github.com/emacs-elsa/Elsa.git somewhere to your computer.
Iâve download elsa via git clone.
The latest commit: 78273ac.
Add (depends-on âelsaâ) to Cask file of your project
Iâve created a new folder called: elsaTest, which contains two
  files:
   	-rw-rw-rw-  1 user None    643 01-24 21:06 Cask
	-rw-rw-rw-  1 user None   4.9k 01-17 09:53 elsa.el

In the Cask file:
	(source gnu)
	(source melpa)

	(depends-on ""bind-key"")
	(depends-on ""cask"")
	(depends-on ""dash"")
	(depends-on ""drag-stuff"")
	(depends-on ""exec-path-from-shell"")
	(depends-on ""expand-region"")
	(depends-on ""f"")
	(depends-on ""flycheck"")
	(depends-on ""flycheck-cask"")
	(depends-on ""htmlize"")
	(depends-on ""idle-highlight-mode"")
	(depends-on ""magit"")
	(depends-on ""multiple-cursors"")
	(depends-on ""nyan-mode"")
	(depends-on ""pallet"")
	(depends-on ""popwin"")
	(depends-on ""prodigy"")
	(depends-on ""projectile"")
	(depends-on ""s"")
	(depends-on ""smartparens"")
	(depends-on ""smex"")
	(depends-on ""use-package"")
	(depends-on ""web-mode"")
	(depends-on ""yasnippet"")
	(depends-on ""elsa"")
The elsa.el is the exactly same file I clone from:
  https://github.com/emacs-elsa/Elsa.git
Run cask link elsa <path-to-elsa-repo>

open the program: C:\Windows\system32\cmd.exe
go to the path: C:\Windows\user\Documents\rep\Elsa>_
type the command: cask link elsa .

cask exec elsa <file-to-analyse> to analyse the file. Currently only one file at a time can be analysed.

change the path to: C:\Users\user\Documents\rep\elsaTest>
show the content of this directory:
    C:\Users\user\Documents\rep\elsaTest>ls
Cask elsa.el
type the command: C:\Users\user\Documents\rep\elsaTest>cask exec elsa elsa.el

	 cask exec: error: Failed to execute elsa elsa.el: (2, 'No such file or directory
')
         Did you run cask install?


type command: C:\Users\user\Documents\rep\elsaTest>cask
    install

then, a bunch of things shown in the cmd.exe

type command: C:\Users\user\Documents\rep\Elsa>cask link
    elsa .
type command: ~C:\Users\random\Documents\rep\elsaTest>cask exec elsa elsa.el

cask exec: error: Failed to execute elsa elsa.el: (2, âNo such file or directory
  â)
  Did you run cask install?~
to illustrate the installation of cask I did this:
C:\Users\user\Documents\rep\cask>cask version

C:\Users\user\Documents\rep\cask>0.8.4

add an issue
Not sure how to correctly link elsa.
This is what Iâve done:
C:\Users\user\Documents\rep\Elsa>pwd
/c/Users/user/Documents/rep/Elsa

C:\Users\user\Documents\rep\Elsa>cask link elsa elsa.git

C:\Users\user\Documents\rep\Elsa>Cannot create link elsa to non existing path:
c:/Users/user/Documents/rep/Elsa/elsa.git
cask link elsa .git

C:\Users\user\Documents\rep\Elsa>Link source c:/Users/user/Documents/rep/Els
a/.git does not have a Cask or elsa-pkg.el file
cask link elsa Cask

C:\Users\user\Documents\rep\Elsa>Cannot create link elsa to non existing path:
c:/Users/user/Documents/rep/Elsa/Cask

2nd round
I add another test.el file in that testElsa folder, and
  installed elsa via package-install (âmelpaâ). After that, I
  wrote the following code in test.el to test it. Hoping I could
  get the message: âCondition always evaluates to non-nil.â
(defun suspicious-if-else-branch (x)
(if t
""always runs""
""never runs""))
So I try to install flycheck-elsa:
	Status: Incompatible because it depends on uninstallable packages.
	    Archive: melpa
	    Version: 20181029.1421
	     Commit: a48d1b1c28f908dcb0bc3aece38c161059df336d
	    Summary: Flycheck for Elsa.
	   Requires: emacs-25, seq-2.0, cask-0.8.4 (not available)
	   Homepage: https://github.com/emacs-elsa/flycheck-elsa
	   Keywords: convenience 
	Other versions: 20181029.1421 (installed).
Today (<2019-02-02 Sat>) I check it:
	flycheck-elsa is an installed package.

	     Status: Installed in âflycheck-elsa-20181029.1421/â (unsigned). Delete
	    Version: 20181029.1421
	     Commit: a48d1b1c28f908dcb0bc3aece38c161059df336d
	    Summary: Flycheck for Elsa.
	   Requires: emacs-25, seq-2.0, cask-0.8.4
	   Homepage: https://github.com/emacs-elsa/flycheck-elsa
	   Keywords: convenience 
	Other versions: 20181029.1421 (melpa).

	Flycheck integration for Elsa.  See README.md
It is installed. I also install flycheck today.
  Howwever, when I put the marker on the t codition always
  evaluates to non-nil not show up.
It is really hard for me to install it on windows. I try it on
  linux tonight, and I found emake is possible a good choice to
  run elsa.
try on linux
I download cask. Not sure but not sure how to build it
  correctly.  /home/superran/gitHubRep/cask/bin then, type: ./go,
  everything looks great. (I donât know why make not working),
  so I successfully installed cask.
Although I have the following code non-nil:
	(executable-find ""cask"")
The desirable description is not there.
I download cask again from GitHub with zip file, but different
  from another machine, I got this error message:
Cloning into '/home/superran/.cask'...
fatal: unable to find remote helper for 'https'
Cask could not be installed. Try again later, or report an issue at https://github.com/cask/cask/issues

So I go back to old system.
prepare issuefile system
  The desirable description is not there, i.e, when the pointer is
  on t (Detect suspicious branching logic), the prompt should
  remind user the following message:
  
Condition always evaluates to non-nil.
steps to follow

Instead of using git clone, I use package-install:
    
cask:
            cask is a dependency package.

	    Status: Installed in âcask-20181107.942/â (unsigned).
	   Version: 20181107.942
	   Summary: Cask: Project management for Emacs package development
	  Requires: s-1.8.0, dash-2.2.0, f-0.16.0, epl-0.5, shut-up-0.1.0, cl-lib-0.3, package-build-1.2, ansi-0.4.1
    Required by: flycheck-elsa-20181029.1421
	  Homepage: http://github.com/cask/cask
	  Keywords: [speed] [convenience]
    Other versions: 20181107.942 (melpa).
        

elsa:
            elsa is an installed package.

	    Status: Installed in âelsa-20190110.1457/â (unsigned). [Delete]
	   Version: 20190110.1457
	   Summary: Emacs Lisp Static Analyser
	  Requires: trinary-1.0.0, emacs-25.1, f-0, dash-2.14, cl-lib-0.3
    Other versions: 20190110.1457 (melpa).

    [back]
        

flycheck-elsa:
            flycheck-elsa is an installed package.

	    Status: Installed in âflycheck-elsa-20181029.1421/â (unsigned). [Delete]
	   Version: 20181029.1421
	    Commit: a48d1b1c28f908dcb0bc3aece38c161059df336d
	   Summary: Flycheck for Elsa.
	  Requires: emacs-25, seq-2.0, cask-0.8.4
	  Homepage: https://github.com/emacs-elsa/flycheck-elsa
	  Keywords: [convenience] 
    Other versions: 20181029.1421 (melpa).

    Flycheck integration for Elsa.  See README.md

    [back]
        



Add (depends-on âelsaâ) to Cask file of your project
    Please see Cask file descrbed in the next section: test file info

Run cask link elsa <path-to-elsa-repo>
[superran@ip15 pureTest]$ pwd
/home/superran/pureTest
[superran@ip15 pureTest]$ cask link elsa ../gitHubRep/Elsa
[superran@ip15 pureTest]$ cask exec elsa test.el
cask exec: error: Failed to execute elsa test.el: [Errno 2] No such file or directory
Did you run cask install?
[superran@ip15 pureTest]$ ls
Cask  test.el
[superran@ip15 Elsa]$ pwd
/home/superran/gitHubRep/Elsa
[superran@ip15 Elsa]$ ls
bin               elsa.el                    elsa-extension-dash.el   elsa-pkg.el         elsa-state.el          elsa-typed-syntax.el     images
Cask              elsa-english.el            elsa-extension-eieio.el  elsa-reader.el      elsa-typed-builtin.el  elsa-typed-thingatpt.el  LICENSE
dev               elsa-error.el              elsa-extension-elsa.el   elsa-ruleset.el     elsa-typed-cl.el       elsa-type-helpers.el     README.md
elsa-analyser.el  elsa-extension-builtin.el  Elsafile.el              elsa-rules-list.el  elsa-typed-eieio.el    elsa-types.el            tests
elsa-check.el     elsa-extension-cl.el       elsa-font-lock.el        elsa-scope.el       elsa-typed-subr.el     elsa-variable.el
    

test file info
  
test.el
      	    (defun suspicious-if-else-branch ()
	      (if t
		  ""always run""
		""never run""))

	    (executable-find ""cask"")
	    (exec-path)
      

Cask
      	    (source melpa)
	    (source gnu)

	    (package ""elsa"" ""0.1.0"" ""Emacs Lisp Static Analyser"")

	    (files ""*.el"" ""bin/elsa"")

	    (depends-on ""cl-lib"" ""0.3"")
	    (depends-on ""dash"" ""2.14"")
	    (depends-on ""f"" ""0"")
	    (depends-on ""emacs"" ""25.1"")
	    (depends-on ""trinary"" ""1.0.0"")

	    (development
	     (depends-on ""elsa"")
	     (depends-on ""undercover"")
	     (depends-on ""buttercup""))

	    (depends-on ""elsa"")
      

operating system info
      	    LSB Version:	n/a
	    Distributor ID:	CentOS
	    Description:	CentOS Linux release 7.5.1804 (Core) 
	    Release:	7.5.1804
      

emacs version
          GNU Emacs 26.1 (build 1, x86_64-pc-linux-gnu) of 2018-06-29
          

minor modes
          	    Enabled minor modes: Auto-Composition Auto-Compression Auto-Encryption
	    Blink-Cursor Electric-Indent File-Name-Shadow Font-Lock Global-Eldoc
	    Global-Font-Lock Ivy Line-Number Menu-Bar Mouse-Wheel Override-Global
	    Projectile Shell-Dirtrack Tool-Bar Tooltip Transient-Mark
	    Window-Numbering
          




questions
why I cannot open C source code within HELP buffer?
For example:
cdr is a built-in function in âC source codeâ.

(cdr LIST)
Return the cdr of LIST.  If arg is nil, return nil.
    Error if arg is not nil and not a cons cell.  See also âcdr-safeâ.
See Info node â(elisp)Cons Cellsâ for a discussion of related basic
    Lisp concepts such as cdr, car, cons cell and list.

If RET when marker is on C source code, swiper just throw me a
  brunch of meanless completions. But it works for elisp code.
For example, if I put my point under myemacs, then f1 f, I
  will imediately jump into the HELP buffer:
And if I RET at â~/.emacsâ  I will jump into myemacs source code
  at the exactly the position of this function.
read creator of smart-parents
read yinâs blog about lisp
I want to read this blog word-by-word
study centaur emacs
help documentation of spacemacs
https://github.com/syl20bnr/spacemacs/issues/11741
mission
my mission is to summarize the commits on this page into
  CHANGELOG.develop file.
questions
too much deletion?
When I open this commit, I found that the author has deleted
  something in CHANGELOG.org file.
Maybe, this should not to be include to this commit.
Further more, Iâve notice that the author was editing something
  related org-edn. Whatâs that?
what is edn
When I was checking the commit, I found author used org-edn-xx
  what are they?
I found that: edn is a data format, which can be found at this.
what is encoding and utf-8
In reading edn stuff, I found I have no idea whatâs this.
why spacemacs do not use (provide 'xx.el)
<2018-12-28 Fri>
In [[https://github.com/syl20bnr/spacemacs/blob/87a2145b4a77ab836d5ff6cccbf4f3fb17d87186/core/tools/export/_worker.el][_worker.el]], thereâs no (provide â_worker.el), which is not
  the case in most of my packages in my emacs.d files.
Why they donât need to do this?
what is Haskell?
Pure function programming. Sounds cool.
what == in org-mode file
<2018-12-28 Fri>
For example: what's this?
suggestions

In the document, use alphabet order to do the log?

read this .emacs
A-ha moment
insert kbd block
C-c u
basic maneuver

new frame C-x 5 2
delete frame C-x 5 0
mark function C-M h

org-mode
movement
within same level
C-c C-f
C-c C-b
goback to upper level
C-c C-u
links
navigation
C-c C-o (org-open-at-point): jump between markers internally
  C-x & (org-mark-ring-goto): jump back
inserting
creating new headline
same level: put markers on header: C-RET
snippet
<2018-12-16 Sun>
When editing in the org-file,
is that possible let <s TAB expand to elisp code?
Further more, can I add some information on the head so that one
  can expand the source code by the main programming language the
  document is working on.
For example, in this file, one expect it will expand to elisp. In
  some c++ file, it will expand to c++?
what is save-excursion ?
<2018-12-16 Sun>
The author claim that the use of save-excursion is good
  hoursekeeping, but I do not understand.
How to use save-excursion?
C-x n s, you need 100% focus.
Go back:
C-x n w
s for short; and w for wide.
C-x n n, if region being mark, I can focus on the important
  stuff.
C-x n w, again back to normal case
manipulation

C-o (org-open-line): quit handy to edit doc with more space
[not sure how to define kbd for this function]
    (org-store-links): very useful for internal links, but it only
    works for header? After store the links, inserting is pretty
    easy. Nice job, my emacs.

table

C-c SPC handy deletion

(org) Built-in table editor

`C-c SPC     (`org-table-blank-fieldâ)â: delete with much more
    ease

copy column
decent method

mark the column
c-x r r r
c-x r i r

ivy

C-c C-o save search buffer to a new buffer
    I use it to illustrate what Iâve done to the matched string.

talking with my hero
I happen to find this secret someday without checking
  magit manual. After reads your reply, Iâve checked magit manual,
  nothing about it.
I then go to git manual, this page discussed my secret.
They suggest less than 50 character. I did an experment: on this
  commit
It has a maximum number of 69 visable character.
I see you point. The namingspace issue is a big concern if commit
  messages are written in this way.
I do not have too much knowledge on how to organize commit
  message. I see people using CHANGELOG.org stuff to track the
  commit (For example). But they also have have some headaches.
Maybe, just using the namingspace would be an easy way.
I also try to find extend the number 69, for example to 100, to
  make title long for you, but I do not find this info.

Magit 20180620.1224, Git 2.12.2.windows.2, Emacs 26.1, windows-nt

==P.S.
Something unrelated to this comment.
I just want to express my thanks to you Henry Weller. Althought
  Iâve ackknowleged OpenFOAM foundation in thesis. It is quite
  different if I could express my appreciation letting you know.
OpenFOAM not only helps my thesis, it, more importantly, opens a
  door to the vast occean that I never even being to. So many great
  people, so many opensource projects (GNU, emacs, etcâ¦).
After graduation, I still using your source code to do numerical
  analyses and I am enjoying usying your code :). Although I have
  tons of tons things that I do not understand, but I will learn them
  little by little.
Thank you,
magit
movement
alt-p/n: jump between blocks
projectile
movement
-D Opens the root of the project in dired in another frame.
searching
Windows
searching a file with name
M-x everything
  Then give the file name.
searching a string in current folder
grep -s ""delete-and-extract-region"" * .*
searching a string in all subfolder
grep -rl ""clone()"" ./*
jump back and forth
M-. runs the command xref-find-definitions
back:
M-, runs the command xref-pop-marker-stack
running tty-emacs
Using git-bash is good enough, âalt+RETâ gives you a much better
  tty experience even you are in a M$ Windsows machine.
info file
This is a fantastic tool for reading manual.
To use my own dir file: do this within the file ~/.bash_profile
INFOPATH=.:$HOME/gitHubRep/myEmacs/ref/myInfo/:/usr/local/emacs/info
export INFOPATH
To refresh into file just edited, go to one of the node and jump
  back it will then refresh.
where to put manual?
On a windows, I put them in C:/info/ folder.
On linuxs, everything installed already, but I do not have access to change it.
manuipulating

M-n create another windows

refresh a new info file
C-c C-m C-b within a *.info source code.
<2019-02-27 Wed> not sure why C-c c-m is bonded to C-c RET?
âC-c C-m C-bâ âM-x makeinfo-bufferâ should work.
  `C-c RET C-bâ  makeinfo-buffer should also work.
refresh the info buffer: d
Although c-m is stop by RET it still works.
project to write info file with my computer related notes
dired
compress or uncompress
compress:

mark the files
press âcâ
input the name in mini buffer: *.tar.gz

uncompress:

press âZâ
yes

replace a string in file
Once you have a *.py, make it as a TEMP file, where TEMP is the
  key parameters (PATH).
Then copy this file with unique names.
Mark the file.
Press `M-q`, just as you do for replacement in a buffer.
show marked list files
C-M-l
âC-c C-vâ like in Windows

w
+
revise name

major mode
There is only one major mode for a given buffer, you cannot turn
  off a major mode, but you can switch to another.
regexp replace
This will append some texts at the end of each line.
M-x replace-regexp <RET> ^.\{0,72\}$ <RET>
\,(format ""%-72sABC%05d"" \& \#) <RET>
I also found that the mini buffer is so useful. No need to retype
  all those regexp, just ust `M-nâ to do some little adjustment.
git lfs
I want to track those big file in the remote but I donât want them
  locally. This is an experiment I did.
I added this to `.gitconfigâ in $HOME
  [lfs]
	fetchexclude = *

However, I found that it is hard to manually fetch the file I
  want. Sometimes, I need a file that is ignored by this global
  configuration.
As a result, I delete this `.gitconfig`.
macro
f3 f4
  then f4
Fill Prefix
Emacs makes me âwowâ this morning again.
âC-x .â
  Set the fill prefix (âset-fill-prefixâ).
So, I do not need to M-x regâ¦-replace everytime I need to comment
  region in writing Matlab code.
diredp marks subfolders
dired+: diredp-mark-files-regexp-recursive

to mark all subfolder: M-+ % m then type âreg-expâ
    I found a more robust way to do recursive mark:
passing a possitive prefix: C-u 1 M-+ % m

to unmark: `C-u 1 M-+ % m`

Do shell comand recursively:

âM-+ &â

calculator
Super handy!
`C-x * q`
Even the kill ring is shipped.
elisp regular expression
backslash
I was about to ask the following question
(defun reg-test ()
  (re-search-forward ""c[ad]\{1,2\}r""))
;; -> reg-test: Search failed: ""c[ad]{1,2}r""

M-x re-search-forward RET c[ad]\{1,2\}r
;; mark move to end of car

In elisp, you need use double backslash to represent single
  backslash in regular expression.
info:elisp#Regexp Special

Note that â\â also has special meaning in the read syntax of Lisp
    strings (*note String Type::), and must be quoted with â\â.  For
    example, the regular expression that matches the â\â character is
    â\â.  To write a Lisp string that contains the characters â\â,
    Lisp syntax requires you to quote each â\â with another â\â.
    Therefore, the read syntax for a regular expression matching â\â is
    ââ\\ââ.

message buffer
To make all the message in the centered of the buffer, just move
  the cursor at the end of Message buffer.
get cursor position
What if I know this function early?
C-x = : what-cursor-position
find something that might exist
M-x apropos
kbd for replace-regexp
C-M-% runs the command query-replace-regexp
I was about to change this kbd and was thinking which kbd to
  bind. I use M-% a lot, so I guess C-M-% would be a great choice. At
  the time I check this kbd, I find Emacs is inline with me!
Wow.
Donât forget to press â!â after input the content.
string-insert-rectangle
To use this function:

set mark at the upper left corner of the rectangle
move the point to the last raw of the rectangle
input the content of the rectangle

blablabla
  blablabla
  blablabla
  blablabla
  blablabla
  blablabla
  blablabla
  blablabla
blablabla
  blablabla
  blablabla
  blablabla
  blablabla
  blablabla
  blablabla
  blablabla
blablabla
  blablabla
  blablabla
  blablabla
  blablabla
  blablabla
  blablabla
  blablabla
  blablabla
  blablabla
appreciating
an emacs-hacker gives me a star!
I am so excited! Nobody gives me a star on my-emacs utill his
  appreciating. He is the creator of smart-(). Itâs a remarkable day.
a second emacs-hacker gives me a star!!
Wow, he used org-mode to configure stuff, pretty cool. Thank you.
wow a Tinkoff hacker gives me a star!
Oh, man, he is an havily user of (use-package), so cool.
blue fish
He/She is using doom/space, which I cannot read them easily. I
  found the comments in init.el is funny.

(ivy              ; a search engine for love and life
latex ; writing papers in Emacs has never been so fun
perl  ; write code no one else can comprehend
(markdown +pandoc)  ; writing docs for people to ignore

idreamshen
Although s/he does not share a .emacs, I found one of articles in
  his/her blog is very useful:
git clone -b 'v2.0' --single-branch --depth 1
https://github.com/git/git.git
Only clone a branch that you are interested in. I will implyment
  this work flow to my project template.
",5
megabulk/Fix-for-iTunes-file-truncation,None,"Fix-for-iTunes-file-truncation
Fixes the problem described here
with the solution described here
The script loops through all files selected (or in playlist, if nothing's selected), removes them from iTunes, re-adds them, and plays each for 1.5 seconds. Re-adds star rating, play count, last played date
To do

Ask user if they want to do this crazy thing!

",2
hexo-simple-theme/hexo_ejs,JavaScript,"DEMO
",2
shopizer-ecommerce/shopizer-shop-angular,CSS,"Shopizer
Demo : https://shopizer-angular.herokuapp.com/
Development server
Run ng serve for a dev server. Navigate to http://localhost:4200/. The app will automatically reload if you change any of the source files.
",2
CHEF-KOCH/Warez,HTML,"


The biggest Warez list on the entire internet! This list is an overview of Warez related topics, discussions and provides some background information about the scene.
Disclaimer
I or GitHub do not supporting warez - we're also not responsible for external links or their content! If you dislike the information I provide then contact the website owner/webmaster/hoster directly and fill a DMCA request.
Why was the list created?

Research reasons!
Freedom of information!
Most lists you find are outdated, not actively maintained or full of malware links.

Credits
Since this list is huge I can't name each and every single one of you, but here is a short credit list which hopefully covers all of them:

All contributors.
All demoscene people which helped to build the scene.
All developers which build the mentioned programs on this list.
All other people which helped to push this little project forward.
All people which are involved in the piracy & netsec scene or created forums to talk about such topics.

What does not belong on this list?

Illegal programs (cracks, keygens etc.) or direct links to copyright material.
Links to banned websites.
Links to offline websites.
Software which is outdated or not actively maintained, open source software is preferred.
Insecure programs (no audit- or code-review).
Why is program x not listed e.g. K-9 mail, it's FOSS! Not every mention makes sense, especially in a security context.

How can I contribute to this list?

You can submit a pull request - after you read the contributions guidelines.

How to search on this page?

A search function is planned, among other small features.
Since there is (currently) - no filter or search you can navigate trough the page from within your Browser via Ctrl + F or Cmd + F.

Project structure

.github - Documents, Todo etc
Homepage - General Overview (which gets a search/indexer)
Readme.md - This file, provides a smaller overview (includes only website links and no tutorials etc).
Scene Info.md - Beginner Info to get into the scene and warez.
Tools.md - Lists all programs related to warez.
[Extensions & Scripts.md] - Lists Browser Scripts + Extensions which might makes your pirate life a little bit easier.
Tutorials.md - Lists all warez related tools.
Banned.md - Lists all banned groups, programs and topics
Offline.md - Lists all offline or compromised websites.
Trusted.md - Lists trusted groups or people which are known to crack or upload stuff.

Contact


Liability for Contents

MEPs approve sweeping changes to copyright law
The Legalities of Linking
COPYRIGHT LIABILITY FOR LINKING AND EMBEDDING - Klaris Law (.PDF)
EU court says linking to copyrighted material isn't illegal
IP Address is Not Enough to Identify Pirate, US Court of Appeals Rules - (.PDF)
New EU Piracy Watchlist Targets Key Pirate Sites and Cloudflare - (.PDF)
Domain Registrar Can be Held Liable for Pirate Site, Court Rules
Reporting When Pirate Releases Hit The Internet is Apparently Illegal Now
Web Sheriff
List of websites blocked in the United Kingdom

Social Media Alternatives

MeWe - Google+ replacement.
Pleroma - Host your own social media.
Mastodon - Like a decentralized Twitter.
Movim - Movim is a social network, based on XMPP, with Chat and chatrooms, news & communities features.

Penetration Testing Distributions

Android Tamer - OS for Android Security Professionals. Includes all the tools required for Android security testing.
ArchStrike - Arch GNU/Linux repository for security professionals and enthusiasts.
AttifyOS - GNU/Linux distribution focused on tools useful during Internet of Things (IoT) security assessments.
BackBox - Ubuntu-based distribution for penetration tests and security assessments.
BlackArch - Arch GNU/Linux-based distribution for penetration testers and security researchers.
Buscador - GNU/Linux virtual machine that is pre-configured for online investigators.
Kali - GNU/Linux distribution designed for digital forensics and penetration testing.
Network Security Toolkit (NST) - Fedora-based bootable live operating system designed to provide easy access to best-of-breed open source network security applications.
Parrot - Distribution similar to Kali, with multiple architecture.
PentestBox - Opensource pre-configured portable penetration testing environment for Windows OS.
The Pentesters Framework - Distro organized around the Penetration Testing Execution Standard (PTES), providing a curated collection of utilities that eliminates often unused toolchains.

Public Reverse & Cracking Discussion Forums

Cracked.to - Cracked.to is a cracking forum and community.
Cracked A forum for cracking related stuff.
Crackia - Crackia Cracking Forum.Find the latest Cracking info, Premium Account Cracking Forum.
Cracking Forums - GeoIP Ban - Cracking Forum, Cracking Tutorials, Free Premium Accounts.
Cracking Pro  - Cracking Tutorials, Free Premium Accounts, Cracking Configs, Combolists & Proxylists.
CrackingGOD Forum -  Cracking. Hack. Graphics. Webmaster. Marketplace.
Crackmes.cf - (mirror of crackmes.de + reboot)
Forum ExeTools - The original old school forum to share cracking knowledge.
Reverse Club - (needs invite code)
Team-IRA [TIRA] - TIRA Team International Reversers Alliance (needs invite code)
Tuts 4 You - One of the oldest forums to discuss reversing related stuff.

NFO Viewers & KeyGen Music

Defacto2
Evangelion.keygenmusic.org
KeyGen Music
Keygen Music Archive
NFO Force

Anti-DRM Protects, Plugins & Source Code

[C++] Steamless - SteamStub DRM Remover + Homepage
HexRaysPyTools
Microsoft Research Detours Package

VPN Subscription Services (no-logs)

ExpressVPN ExpressVPN - A VPN with 256-bit encryption, over 94 countries, and no logs. Also rated as one of the fastest VPNs out there.
NordVPN - Protect your privacy online and access media content with no regional restrictions, and audit can be found here
Private Internet Access - Popular subscription-based VPN provider with a proven track record for not keeping logs.
ProtonVPN - High-speed Swiss made VPN that safeguards your privacy.

Self-hosted VPNs

n2n - A Peer-to-peer VPN.
OpenVPN - OpenVPN provides flexible VPN solutions to secure your data communications, whether it's for Internet privacy, remote access for employees, securing IoT, or for networking Cloud data centers.
PeerVPN - PeerVPN is a software that builds virtual ethernet networks between multiple computers.
Pritunl - Enterprise Distributed OpenVPN and IPsec Server.
sshuttle - Transparent proxy server that works as a poor man's VPN.
WireGuard VPN - WireGuard is an extremely simple yet fast and modern VPN that utilizes state-of-the-art cryptography. It aims to be faster, simpler, leaner, and more useful than IPSec.

Ad-Blocker

An Overview of Ad Blocking Technology - Basically explains how an Ad Blocker works.
AdGuard - Claims to be the worlds most advance Ad Blocker.
Filterlists - Provides an overview of Ad blocking filters/projects.
uBlock origin - A fast and efficient Ad Blocker.
Nano Defender - Fork of uBlock with sme gimmicks, the defender addon is an anti-adblock defuser for Nano Adblocker and uBlock Origin.
Wikipedia's Website about Ad blocking - Wikipedia's website about ad blockers.

Piracy focused discussion Channels & Blogs

/f/Piracy - Raddle forum for piracy.
/r/privacy - The intersection of technology, privacy, and freedom in a digital world.
Prism Break - Opt-out of global data surveillance programs like PRISM, XKeyscore and Tempora.
TechWorm - Techworm is a Tech, Cyber-security news platform.
TorrentFreak - TorrentFreak is a publication dedicated to bringing the latest news about copyright, privacy, and everything related to filesharing.
/v/piracy - Voat Forum for piracy.

Archives

GOG Dump
Nintendo Games Collection
Microsoft Games Collection

Email Service Providers

Mailbox - Mailbox.org fights for privacy eMails since years and is a big player when it comes to eMail.
Posteo - Email green, secure, simple and ad-free!
ProtonMail - Secure Email Based made in Switzerland.
Tutanota - A secure and open source eMail provider.

Temp eMail Service Providers

10 Minute Mail - Disposable, Private mailboxes.
Cock.li - Yeah, it's mail with cocks.
Disposable - Disposable is arobust disposable email (burner emails) - API designed to help you verify whenever email address is coming from disposable service.
Nada - Fast & free.
Temp Mail - Keep spam out of your mail and stay safe - just use a disposable temporary email address!

eMail self-hosting

docker-mailserver - A fullstack but simple mailserver (smtp, imap, antispam, antivirus, ssl...) using Docker.
FastMail - Email, calendars and contacts done right.
Rainloop - SIMPLE, MODERN & FAST WEB-BASED EMAIL CLIENT.
Roundcube - MIME support, address book, folder manipulation, message searching and spell checking.

DarkNet

DarkNet Stats - Monitors DarkNet Forums & Markets.

Anti-Spammer

Project Honey Pot - Online fraud & abuse tracker.

Audio

Mp3va.com - Free Music (MP3s).
New Album Releases - New Album Releases.

Android

Wikipedia's list of free and open-source applications

APK Forums & Platforms

ACMARKET - Download cracked & modified android apps & games free.
Androeed - (RU) - Russian APK site.
Android Zone - Another place to find premium links for APKs.
APKmb - Download paid Apps & Android Games for free.
APKMirror - Provides legit mirrors with checksums for various apps.
ApkPure - Another free APK mirror site.
Aptoide - Cracked and legit apk's.
BlackMod - Lots of cracked Android games.
iHackedit - Provides Android Apps & Games including Mods.
libre.io - (requires login) - A small forum with some exclusive apps & games.
Mobilism Forum - Large forum of mobile apps and books.
On HAX - APK mirrors for paid and free applications, the website also provides modded APK's.
RevDl - Direct download site for Android apps & games.

Decentralized Networks

Freenet - Freenet is free software which lets you anonymously share files, browse and publish ""freesites"" (web sites accessible only through Freenet) - and chat on forums, without fear of censorship.
I2P - I2P is an anonymous overlay network - a network within a network. It's intended to protect communication from dragnet surveillance and monitoring by third parties such as ISPs.
Loki - Decentralised network that allows users to transact and communicate privately over the internet.
SILO - Offers complete privacy across the network (work in progress project in cooperationship with Loki).
Tor - Tor is free software and an open network that helps you defend against traffic analysis.
Zeronet - Open, free and uncensorable websites, using Bitcoin cryptography and BitTorrent network.

Hardened Operating Systems & Resources

cuckoo - Open source automated malware analysis system.
Overview of Security-focused operating system on Wikipedia
Qubes OS - Qubes OS is a security-oriented operating system.
SIFT - Forensic workstation made by SANS.
Security related Operating Systems @ Rawsec - Complete list of security related operating systems.
Security @ Distrowatch - Website dedicated to talking about, reviewing, and keeping up to date with open source operating systems.
Tails - Tails is a live operating system that you can start on almost any computer from a USB stick or a DVD.

Domain Names

Domainr - Domainr allows you to find domain names and short URLs. Instantly check availability and register for all top-level domains.
Njalla - A privacy-aware domain registration service.
xip.io - Magic domain name that provides wildcard DNS for any IP address.

Countries where downloading copyright content is legal (for personal use only) though publishing it & sharing it - is still illegal

Poland
Spain
Spain
Switzerland

Countries where both downloading & sharing is illegal

Argentina
Bangladesh
Brazil
Canada
Chile
Columbia
Czech Republic
Denmark
Egypt
Greece
India
Iran
Israel
Malaysia
Mexico
Netherlands
Philippines
Romania
Singapore
Slovakia
Slovenia
South Korea
Uruguay

Countries where torrenting is highly illegal

Australia
China
Finland
France
Germany
Itlay
Japan
Korea
Latvia
Portugal
Russia
UAE
UK
US

Countries GeoIP block and/or shutdown the websites

Canada
China
Germany
India
Itlay
Japan
Latvia
Malaysia
Portugal
Russia
Singapore
South Korea
UAE
UK
US

Torrenting

/r/torrents - Questions and discussion about all things torrent-related.
BitTorrent - Wikipedia's article on the BitTorrent file sharing protocol.
Live Tracer - Pre-time tracer for scene releases.
magent2torrent.me - Converts magnet links to torrent files.
peerflix Google Search - Searches Heroku-deployed instances of Peerflix for streaming torrents.
RapidBay - Rapid bay is a self hosted video service/torrent client that makes playing videos from torrents easy.
The Pirate Society - A members-only forum for pirates.
Torrage - Torrage is a free service for caching torrent files online.
Torrents.csv - An open source - collaborative repository of torrents, consisting of a single, searchable torrents.csv.
Torznab - Newznab-like API offering a standardized recent/search API for both TV and movies.
Where are torrents permitted? - A world map (picture) which shows where warez torrenting is allowed.
ZBIGZ - Zbigz is a very good solution if your PC or laptop is locked by your ISP, it allows you to download torrents via Browser.

Trackers

/r/trackers - A subreddit for discussing public & private trackers.
A Simple Guide To A Better Ratio - A good tracker requires you to upload what you download. This guide explains many of the methods involved with keeping on top of this sometimes difficult task.
Bravo List - A public tracker directory.
Tracker Twitters - List Of Private Torrent Trackers & BitTorrent News Accounts To Follow On Twitter.
Trackers List - An updated list of public BitTorrent trackers.

TV-Show Calendar

at.my TV - TV Calendar, TV Episode Guide, TV Show Listings.
DuckieTV - A personalized calendar that tracks the shows you like

Private Trackers

/PTG tracker manifesto - List of private trackers
0QoLttS.jpg - Screenshot of a table from somewhere of private trackers and their sign-up requirements
AlphaRatio - (AR) - A good starter tracker with lots of freeleech content.
AnimeBytes - (AB) - community centralized around Japanese media, including anime, manga, and music.
Audionews - (AN) - Private torrent tracker for music production audio. (DJ apps, audio editor, DAW apps etc) - Open signups on the 1st-2nd every month.
Awesome HD - (AHD) - Awesome-HD is a private tracker for quality enthusiasts.
BakaBT - (BBT) - a torrent tracker which specializes in serving anime fans
BeyondHD - (BHD) - BeyondHD is a ratioless torrent tracker dedicated to HD movies and TV shows in High Definition.
Bibliotik - (BI) - Popular ebooks/audiobooks private tracker
Bitspyder - (BS) - Bitspyder is an educational torrent site devoted to e-Learning content such as e-Books, video courses, and audio books.
Blutopia - (BLU) - Blutopia is a private tracker for HD movies and HD TV shows.
CGPeers - (CGP) - CGPeers is a private torrent tracker for all things computer graphics: tutorials, graphics software, 3D, visual effects, design, and computer-assisted art.
Filelist - (FL) - Large Romanian general tracker with mostly English content. No RAR files allowed. Scene torrents are unrared, and then allowed.
GazelleGames - (GGn) - Currently the largest private tracker for games.
HD-Forever - (HD-F) - HD-Forever is a French private tracker for HD movies.
HD-Space - (HDS) - HD-Space is a private torrent tracker hosting HD movies, TV shows, and music torrents. A good tracker for beginners.
HD4Free - (HD4F) - HD4Free is a general HD tracker with a good range of content.
IPTorrents - (IPT) - Private tracker with movies, books, and more.
JPopsuki - (JPop) - JPopsuki is a torrent tracker focused on Asian music.
MyAnonaMouse - (MAM) - Private E-Learning tracker with about 360 000 torrents including audiobooks, e-learning, musicology, and radio.
MySpleen - (MS) - MySpleen is a private tracker which specialises in comedy, animation, and TV series.
Nostalgic Torrents - (NT) - Private tracker for anime, comics/manga, documentaries, movies, TV - PRE 2013, TV - PRE 2009 With Original Commercials, etc. Also known as The-Archive and HeyNow.
PassThePopcorn - (PTP) - ratio-based torrent tracker for movies (requires login).
PolishSource - (PS) - PolishSource is a big private Polish ratio-less tracker.
PolishTracker - (PT) - PolishTracker is the oldest private Polish tracker.
Private Tracker Flowchart - V4 of the private tracker flowchart. Somewhat out of date.
Private trackers - Guide on how to get into (and survive) - the world of private trackers.
PrivateHD - (PHD) - PrivateHD is a private BitTorrent tracker focused on high definition movies and TV show torrents.
RED Interview Prep - This site was written as a guide for potential users to learn about music formats, transcodes, torrenting, and burning and ripping â everything you need to know in order to pass the RED interview.
Redacted - (CH) - Largest private music tracker at 1.5 million torrents.
SceneTime
TheGeeks - (TGBZ) - Private tracker for e-learning
TorrentLeech - (TL) - Well-known popular private tracker
Tracker Spreadsheet - Comprehensive spreadsheet of private trackers (somewhat out of date).
TVChaos UK - (TVCUK) - Private tracker for British television
UHDBits - (UHD) - UHDBits is a Vietnamese private torrent tracker focused on HD movies and TV shows.
WorldOfP2P - (WOP) - Private tracker for Movies, TV and general P2P stuff.

Semi-Private Trackers

ArenaBG - A Bulgarian tracker with an English translation available.
NoNaMe Club - Russian semi-private tracker and forum.
ruTracker - RuTracker is a huge Russian torrent site with a thriving file-sharing community.
Zamunda.net - A Bulgarian tracker with English and Russian translations available.

Public Trackers

1337x - 1337x is a torrent site that offers verified torrent downloads.
BTDB - Large BitTorrent DHT search engine.
DIGBT - DIGBT is a DHT torrent search engine.
ETTV + EZTV - ETTV is a torrent site specific for movie torrents.
g4u - (Ger) - Movies, TV Shows & Games.
Games4theworld - Torrents and magnet links for games.
GloTorrents - Download Movies, TV, Games and Other Torrents Free.
Goldesel - (Ger) - Games, Movies, Audio & eBooks.
HDSector - Bollywood / Hindi / Hollywood HD Movies.
Idope (Clone) - iDope is a torrent search engine presenting direct magnet links, comments and up to date seeder/leecher statistics.
Isohunt2 - Clone of the original ISOHunt torrent index and repository.
KickAss Torrents - Community-made reincarnation launched in 2016.
LimeTorrents - LimeTorrents has been around for more than half a decade.
MagnetDL - Magnet link only search engine.
metal-tracker.com - Heavy metal music tracker.
Monitor Shodan - Keep track of the devices that you have exposed to the Internet. Setup notifications, launch scans and gain complete visibility into what you have connected.
moviemagnet - Verified torrents for movies.
OTorrents - Yet another public torrent tracker.
Pirateiro - Pirateiro is a torrent index for Brazilian and Portuguese torrents.
RARBG - Public tracker with its own release group, RARBG was founded in 2008 and specializes in high quality video releases.
Remove fake TPB torrents - Script that automatically hides fake torrents on The Pirate Bay based on conditional logic.
Rustorka - (RU) - Software, Games & More.
rutor - Russian public tracker.
Saavn - A search engine designed to find old and new music releases.
Shodan - Shodan is the world's first search engine for Internet-connected devices.
SkyTorrents - Revival of the recently-shut-down, privacy-focused, ad-free torrent indexer.
The Pirate Bay - Well-known torrent site which is somehow still running, blocked in most places. (Be warned: It mines coins in the background!)
The Proxy Bay - Can't access The Pirate Bay? Try one of these proxy sites.
Tor Lock - TorLock is a torrent site that offers verified torrent downloads.
Torlock - Torlock is a torrent index and torrent search that helps to access the latest in TV series and movies.
Torrent9 - French torrent search engine.
TorrentFunk - TorrentFunk is a torrent site providing verified torrents for all kinds of content.
TorrentGalaxy - Public tracker with a clean UI.
TorrentInvites - #1 To Buy, Trade, Sell Or Find Free Tracker Invites!
TorrentKing - Torrentking is a popular movie torrent site.
Torrentz2 - A good replacement of the defunct Torrentz.eu.
trackerslist - An updated list of public BitTorrent trackers.
WebOas - A search engine designed to find warez, music and other stuff in public dirs.
WorldWide Torrents - Another public tracker with a reasonably nice UI.
xbit.pw - A Magnet site search engine.
YggTorrent - French tracker and search engine (have a download/upload ratio limitation).
YTS - Small-size HD movies in a good quality from YIFY.
Zonatorrent - Spanish tracker.
Zooqle - Zooqle is a relatively new torrent index providing a huge database of verified torrents.

Tracker Aggregators

AIO Search - Torrent search engine.
High Resolution Music - FLAC Music collection.
rats-search - P2P Bittorrent search engine.
snowfl - Snowfl is a torrent aggregator which searches various public torrent indexes in real-time.
SolidTorrents - A clean, privacy focused torrent search engine.
Torrents.me - Torrents.me combines popular torrent sites and specialized private trackers in a torrent multi-search.
TParser - Russian torrent sites indexer, good for FLAC music other other stuff.

Tracker Proxies

Cardigann - A proxy server for adding new indexers to Sonarr, SickRage, and other media managers.
CouchPotatoServer - Automatic Movie Downloading via NZBs & Torrents.
Jackett - API Support for your favorite torrent trackers, it translates queries from apps (Sonarr, Radarr, SickRage, CouchPotato, Mylar, DuckieTV, qBittorrent, etc) - into tracker-site-specific http queries, parses the html response, then sends results back to the requesting software.
NewzLeech - Newzleech is a Usenet file search engine.
nzbhydra2 - Primarily a Usenet meta search engine but also supports Torznab.
Radarr - A fork of Sonarr to work with movies Ã  la Couchpotato.
SickRage - Automatic Video Library Manager for TV Shows. It watches for new episodes of your favorite shows, and when they are posted it does its magic.
Sonarr - Smart PVR for newsgroup and Bittorrent users.

Tracker Invites

/r/Invites - Post wanted ads for private tracker invites here.
/r/OpenSignups - Open Signups - When Private Trackers Open Their Doors To The Public.
BTRACS - An automatic information site which periodically checks closed community BitTorrent trackers for being open for signup.
getting_into_private_trackers - Helpful resource from the /r/trackers Wiki.
Open sign-ups thread - /r/trackers thread for posting trackers that are currently open for registration.
Opentrackers.org - Private Torrent Trackers & File Sharing.

rTorrent

flood - A web UI for rTorrent with a Node.js backend and React frontend.
rTorrent ArchWiki Page - Detailed article to answer most common questions about rTorrent.
rTorrent Seedbox Guide - This guide is a single-page, comprehensive guide to take you step-by-step through installation and configuration.
rtorrent-ps - Extended rTorrent distribution with a fully customizable canvas and colors, other feature additions, and complete docs.
rTorrent - rTorrent is a text-based ncurses BitTorrent client written in C++.
rutorrent-themes - A collection of default and new, original themes for ruTorrent.
ruTorrent - Yet another web front-end for rTorrent.

WebTorrent Clients

Instant.io - Streaming file transfer over WebTorrent (torrents on the web).
magnetoo - Fancy new in-browser WebTorrent streaming service.
WebTorrent Desktop - WebTorrent Desktop is for streaming torrents.
Î²Torrent - Fully-featured WebTorrent - browser client written in HTML, JS and CSS

Seedboxes

/r/seedboxes - A place to discuss seedboxes and everything related to them.
2Giga.link - Free file hoster, Torrent caching & Premium link generator.
Bitport.io - Download torrents in the cloud and stream them online.
DediSeedBox - Netherlands located Seeedbox service.
FileStream.me - Free subscription offers 200Mb max file size and 200GB storage total.
Furk.net - Free trial offers 1GB per day or 5GB per week if you can get an invite/voucher or use Facebook.
Put.io automator - A suite of commands for managing torrents, transfers and files on Put.IO.
Seedr - Essentially a seedbox you can paste torrents into which returns a streamable direct link.
Seedbox.io - Provides 99,9% uptime, cheap and claims to have a good support.
SeedSync - SeedSync is a GUI-configurable, LFTP-based file transfer and management program.
Torrent Safe - Free-plan includes 1GB max file size, 2 days file lifetime.
UltraSeedbox - Cheap Seedbox, fast and reliable.
ZXCFiles - A similar service that allows you to paste magnet links or upload torrent files and get a DDL. First 20GB are free.

Seedbox Hosting Providers

/u/Andy10gbit - Reddit user with good deals on servers and seedboxes.
Bytesized Hosting - ""The best Plex server hosting in town"".
Chmuranet - Chmuranet is a small private boutique seedbox provider.
FeralHosting - Shared seedbox hosting provider.
Hetzner - Reliable and affordable server host.
Kimsufi - Affordable dedicated servers.
NZB Monkey - NZB download helper utility.
Online.net - Seedbox-friendly, affordable, dedicated server host.
OVH - Large cloud server provider.
Seedboxes.cc - Reliable and affordable web hosting, with the power of your friendly monsters!
SeedHost - ""Seedhost.eu is the oldest continuously operating seedbox hosting provider on the internet.""
SoYouStart - Another dedicated server host.
UltraSeedbox - ""Plex optimized"" servers to rent.
Whatbox - Whatbox is a BitTorrent CDN.
Xirvik - Preconfigured seedbox servers.

Tracker Frameworks

Gazelle - A web framework geared towards private torrent trackers with a focus on music.
meanTorrent - A BitTorrent Private Tracker CMS with Multilingual, and IRC announce support, CloudFlare support.
NexusPHP - BitTorrent private tracker scripts written in PHP.
OpenTracker - OpenTracker is an open and free BitTorrent tracker project.
Torrent-Tracker-Platforms - A Curated List Of Torrent Tracker Platforms/Codebases Written In Multiple Coding Languages.
UNIT3D - The Nex-Gen Private Torrent Tracker (Aimed For Movie / TV Use).

Usenet Providers

Eweka News - Netherlands-based Usenet provider.
Newsdemon - Cheap and cheerful Usenet provider with frequent discounts.
Newsgroup Ninja - $7.99 per month, SSL encryption, Unmetered usage, Unlimited speeds.
Newsgroup Ninja - Popular Usenet provider with a competitive subscription fee.
Premiumizer - A download management tool for premiumize.me cloud downloads.
Tweaknews - Dutch Usenet provider that offers a Highwinds news feed.
Usenet Crawler - Movies, eBooks, TV Series, Anime & more.
Usenet Providers and Backbones - This is a simple overview of the current companies, backbones, providers and resellers in the Usenet landscape.
Usenet.Farm - Usenet reseller with 1000+ days retention.
UsenetExpress - UsenetExpress is a powerful new tier-1 Usenet provider which offers strong security, a 10GB uplink per server and up to 150 streams for an excellent price.
WorldSrc - Movies, software, apps, games, music, and images available for fast direct download + torrents.
XS News - European Usenet feed.

Usenet Indexing Software

nZEDb-deploy - A collection of scripts to automate and simplify the deployment of a nZEDb Usenet Indexer using the new format of their GitHub repository.
nZEDb - A fork of nnplus(2011) - | NNTP / Usenet / Newsgroup indexer.
newznab-tmux - Laravel based usenet indexer.
newznab - Newznab is a usenet indexing application, that makes building a usenet community easy.

Usenet Paid Indexers

DOGnzb - Invite-only NZB site (although they do have a registration page - at the moment)
DrunkenSlug - Popular NZB indexer with a free tier and decent retention.
NZBCat - NZBCat is an invite-only nZEDb NZB indexer.
NZBFinder - Usenet indexer and newznab API with a clean UI and 8+ year backlog of NZBs.
NZBgeek - Affordable Usenet indexer operating since 2014.
omgwtfnzbs - Invite-only NZB indexer with a funny name.

Usenet Free Indexers

6box - A recently revived free Usenet indexing service with a generous API.
Binsearch - With this site you can search and browse binary Usenet newsgroups.
NZBIndex - The first free Usenet indexer you find in your Google search results.
NZBKing - The service allows you to search and browse binary files that have been posted to Usenet newsgroups.
Usenet Crawler - Usenet indexer with API access for registered users.

Portables & Repacks

FoxxApp PAF Portables - Windows Software repacks and portables.

Custom ""Google"" Search Engines

FileChef - Get direct download links for almost anything!
Jimmyr - Yet abother Music search engine.
lumpySoft.com - A Google index search with predefined tags.
mattpalm.com/search - Get direct download links for almost anything.
Musgle - Musgle in action just type a song title, or the artist name, or both in a search bar and hit 'Enter' - you will be redirected to the Google page with relevant search results. Click on one of those results, and you will have a chance to directly download the song you are searching for - very smooth!
opendirectory-finder - Get direct download links for almost anything.
The Eye CGS Engine - The-Eye - CGS Engine
wtfnzb - Open dir for Software.

FTP Indexers

Davos - Web-based FTP automation for Linux servers.
Mamont's open FTP Index - Browsable directory listing of publicly available FTP-sites.
Napalm FTP Indexer - NAPALM FTP Indexer lets you search and download files located on public FTP servers.
pftp - pftp means Port-File-Transfer-Program not to muddle up with standard FTP which is quite different, it allows you to send and receive directories recursively and move the dirs.

DDL Search Engines and Crawlers

Alluc - Search engine with over 80 million streaming-links from over 700 VOD services, video hosters and file-hosters.
IPLIVE - DDL search engine.
MegaSearch - Search engine for finding content hosted on Mega and other premium hosts like OpenLoad.
OD-Database - Database of searchable open directories curated by The-Eye.eu.
ololo - ololo is a video streaming link search engine.
Orion - Orion is a service that indexes metadata and links from a variety of public websites and networks, including torrent, usenet, and hoster indexes.
VideoSpider - VideoSpider crawls various websites and search engines to find movie and TV episode streaming links.

GoG Repack & Releases + Retro Games

Good-Old-Downloads/gg - A fork of Good Old Downloads' ""GOG Games"" hosted on Tor.
Good-Old-Downloads (GitHub source code) - - Good-Old-Downloads is shooting down, see here - why. There is a full encrypted dump avbl. here, make sure you read the integrated readme file!
Torminatorr.com - Good-Old-Downloads mirror page.

DDL Link Sites

/r/DataHoarder/ - Share download links (similar to /r/opendirectories/).
/f/MEGAlinks - Aims to replace the old /r/megalinks directory.
/r/GDriveLinks - (Multi) - Google Drive Download Links.
/r/ZippyShare - (Multi) - DL links hosted on ZippyShare (blocked in the UK).
0DayDown (CN/EN) MacOS, Music & other links (works with JDownloader).
3dl.tv - (Ger) - Music, Movies, TV Shows, apps & more.
Adit-HD Forum - Forum which provides links to HD rips.
AdiT-HD - Direct movie download database.
AppNee Freeware Group - Massive DDL site, eBooks, Programs, Games, Operating Systems, etc.
Audioz - Provides Audio stuff.
AvaxHome - Another DDL site with eBooks, TV, movies, magazines, software, comics, newspapers, games, graphics, etc.
AVXHome - Best of eBooks, Software, Mag & more.
BetaArchive - Windows ISOs, Windows tools & more.
Board4All - A forum which provides and shares all sorts of stuff.
Boerse.to - (GER) - A german warez forum.
Byte.to - (GER) - Movies (SD/HD/UHD), Docus, WWE & Series.
DDL-Warez - (GER) - German software, movies & tv board.
DDLValley - DDL links for Movies, Games, Tv Shows, Apps, Ebooks and Music.
DeeJayPirate's Pastebin - Pastebin user who uploads premium links for TV shows
DirtyWarez Forum - (EN-US) - Popular warez forum with films, TV shows, ebooks, anime, games, and more.
DL4All - Various Games, Tutorials, TV Shows, Music and mobile stuff.
Dospelis - Spanish DDL indexer.
DownArchive - DDL blog with premium links on a number of hosts. Lots of software
DownloadLY.IR - (IR) - Software download portal.
DownTurk - Software portal.
ExeLab Forums
FilmRls Movies, Series and TV Shows.
filewarez.tv - Invite-only, hosts both Mega and Google Drive links for TV shows
FTP Mirrors - Windows ISO Downloads Mirrors (ftp links not visible in GitHub's Markdown!)
GLOAD.cc - (Ger) - Provides Zippyshare and Openload as download-friendly mirrors.
hdencode - Videos/Movies in HD Quality.
IceFilms.info - Another DDL site with TV and movie links on FileUpload, GoUnlimited, Filecandy, and more.
Intercambios Virtuales - (ES) - Yet another software portal.
KickassWarez - (EN/RU) - Sometimes offline, hosts TV, movies, magazines, software, comics, newspapers, games, graphics, etc.
LavTeam - (RU) - Another russian software portal. Like dust in the desert!
Mawto - (IR) Android apps, Windows Software & Games.
MaxRelease - Games, software, magazines, movies, music & tv shows.
MkvCage -  Big tracker for TV shows & movies.
Movie Glide - Videos/Movies & TV Shows in HD Quality.
MovieFiles - Direct download search engine which generates Google Drive links
Moviesleak - Yet another movie page, the focus is in IMDB annoucements.
Mutaz - Tracks scene software releases.
MyGully - (Ger) - Replacement for the old gulli board.
NaMaMe Club - Provides software for Windows.
NFForce - The old NForce group and it's small website.
NFOHump - Gaming, Apps, Help & more.
NGB.to - (Ger) - Another Gulli/MyGully clone.
Nsane Forum - Public forum for everyone to talk about software & news around the world.
NulledTeam Underground - Software forum.
Onkyo4k - Tracks movies and tv shows.
OSZone - (RU) - Software portal.
PCPortal - (RU) - One of the biggest russian software forums.
PSARips - Popular site for movies and TV shows, includes torrent files
PuZo.org - Direct Download (DDL) Websites for sofwtare.
RADIXX11 - (EN-US) - Software forum.
RapidLinks - (RU) - Software, Movies & more.
RapidMoviez - Direct movie website.
Reduson - (EN/RU) - Another software portal for various type of releases like software, magazines, games and many more.
ReleaseBB - (RU) - Russian Software Portal.
Releaselog - Website for eBooks, Games & more.
RSLinks - Tracks scene software releases and mirrors them.
Rsload - (RU/EN) - A big software portal.
RU-Board - (RU) - Well-known warez board.
RuTracker - (RU) - If you didn't alreay knew RUTracker you never heard of Warez at all.
SceneSource - WordPress powered website dedicated to bringing you the latest info on new scene releases
Serials - Serial keys for software that may or may not work.
SilentGround - (EN)
Snahp Forum - Forum which provides links to HD rips & software (only mega & zippyshare links are allowed).
Soft9 - (RU) - Russian Software Portal.
Soft98.iR - (IR) - All Software Download in Only One Website.
SoftArchive - (RU/EN) - Software portal for various software and scene announcements.
SoftOBase - (RU) - Software forum.
SolidShare - (TR) - Software Portal.
Tekspert - (EN/US) - Software forum.
TheWarezFolder - For All Your Download needs.
TNCTR - (TR) - Turkish Network Community for software, ebooks, apps, portable, AIO & coding.
Twighlight - Warez release blog (sometimes offline!).
TwoDDL - Direct software download links.
UpTown - Software portal.
Vidics - Vidics provides Tv shows and movie releases.
Warez-BB-org - Elite warez forum. ![(invite needed)][inviteneeded]
WarezBB.org - Invite-only elite forum.
Warezforum Asia - PDF's.
Watch Series - WatchSeries provides TV Shows (as the name might already suggests).
watchepisodeseries - Watch Episode Series provides TV Shows releases from the scene.
WatchTVSeries - Watch TV shows online.
Win7DL - Software, Movies, eBooks & more.
ZeroBoard - A board which provides Windows related stuff.

DVB

DVBKing - SkyStar, SoftCam Key ProgDVB Satellite Receiver Dish Network DirecTV HD TV.

Premium Link Generators

File Hosting Wiki - This site aims to provide the most complete lists of premium link generators, torrent downloaders and more, with (possibly) - frequent updates.
Free Premium Leeches - Search up for the website you want to download from and pick from a massive list.
Small File sharing table - Small File sharing table which shows maximum file limit, language etc.
Small cloud storage table - Small cloud storage table which shows maximum file limit, language etc.
OffCloud - A simple, elegant and intuitive SaaS to retrieve any data from the cloud.
Mega-Debrid - 207 Hosters supported.
Premiumize - Combine direct and secure access to premium services.
Premium Link Generator - Over 26 hosts to choose from (needs paid account).
Real-Debrid - Real-Debrid is an unrestricted downloader that allows you to quickly download files hosted on the Internet or instantly stream them into an innovative web player.
Reevown - A free download service with which you can perform premium downloads.
UploadedPremiumLink.xyz - Generate online premium links.

Premium Link Hoster

4shared
DBREE
K!M - Might replaces the original Megaupload (one day).
Mediafire
Mega.nz
NitroFlare
OpenLoad
PutLocker
RapidGator
Sendspace
Uploaded
Zippyshare - - Blocked in the UK, use a proxy or VPN.

Open Directories

""All resources I know related to Open Directories"" - Thorough post from /u/ElectroXexual.
/r/opendirectories - Unprotected directories of pics, vids, music, software and otherwise interesting files.
36 GB of Flash Games - Posted by /u/blue_star_.
FileMasta - Search servers for video, music, books, software, games, subtitles and much more.
httpdirfs - A filesystem which allows you to mount HTTP directory listings.
opendirectories-bot - Bot used on /r/opendirectories for analysing the contents of open directories posted on the subreddit.
Panelshow.club - Directory of panel show TV episodes from /r/panelshow.
The-Eye - The Eye is a non-profit website dedicated towards content archival and long-term preservation.
The Holy Grail of Indexes - Posted by /u/shadow_hunter104.

Anime & Cartoon Streaming (720p+)

480mkv
AnimeKisa - Subs and dubs, no ads, funded by donations, self-hosted.
Animelon - Subs only, multilingual, no ads, funded by donations, only one source, videos hosted by Google, aimed for Japanese learners.
Aniwatcher - Subs and dubs, pop-up ads on video player, downloadable, multiple sources.
AnimeFreak.TV - Subs and sometimes dubs, banner and pre-roll ads, one source.
9Anime - Subs and dubs, many ads, many player alternatives, videos hosted by Google.
Animehd47 - Subs and dubs, banner ads, videos hosted by Google, multiple sources.
Animeboys - (Ger) - Subs and dubs, banner and pop-up ads, multiple sources.
Animefever - Subs only, multilingual, banner ads, self-hosted.
AnimeLand - Dubs only, banner ads, pop-ins, videos hosted by Google (proxy), only 1 source, downloadable.
Anime Rush
Anime Show
Anime Streams - Sub and dub, banner ads.
Anime8
AnimeBam - Subs only, banner ads, only one source.
AnimeDao - No ads, subs only, multiple sources, videos hosted by Google.
Animeflv
AnimeFreak
AnimeHeaven
AnimeHub - Sub and dub, banner ads.
AnimePahe - Subs only, pop-up ads, doesn't show videos with adblocker on, downloadable, only one source.
AnimePie - Subs and dubs, no ads, multiple sources(including from other anime sites).
Animer Reborn
AnimeRush - Subs only, pop-ins, one source.
AnimeSeries
Anime Simple - Subs and dubs, banner ads, multiple sources.
AnimeTV - Subs and dubs, banner ads, many player alternatives.
animeultima - Subs and dubs, banner and pop-up ads, multiple sources.
AnimeVibe - Subs and dubs, no ads, multiple sources, downloadable, funded by donations.
AnimeWorldBD - Banner ads, some videos can only be downloaded, small list.
AnimeXD
Cartoon Crazy
CartoonWire
Chia-Anime
Club Anime
DaiWEEB - Subs only (EN and JP), no ads, only one source, self-hosted, aimed for Japanese learners.
DarkAnime.stream - Subs, no ads, downloadable, some sources.
DubbedAnime - Subs and dubs, banner and pop-up ads, multiple sources.
EyeOnAnime - Subs and dubs, banner ads, uses multiple uploaders/players.
GoGoAnime - Subs and dubs, many ads, many player alternatives.
Hi10Anime
HotAnime - Subs and dubs, lots of banner ads, pop-ins, possibly self-hosted videos, downloadable (via OpenLoad).
Justdubs
Kawaiifu - Videos hosted by Google, only one source, style similar to niconico, missing multiple anime.
KickAssAnime - Subs and dubs, banner ads, some sources.
KimCartoon
Kissanime.ru - or Kissanime.ac (mirror)
KissCartoon
Mangarock
Mejor Torrent - (ES)
MioMio
MoviesEver
NineAnime
OtakuStream - Subs only, banner and pop-up ads, downloadable, multiple sources.
Online WatchCartoon
Otakustream
PutlockerSeries
Randaris Anime - Banner ads, multiple sources, eng & german subs, captcha.
RyuAnime
Serienjunkies - (GER)
SGAnime - Subs only, no ads, few sources.
Supercartoons
Toonova
TVBox
TVRaven
Twist.most
WatchCartoon
WatchCartoonsOnline
WatchAnime - Subs and dubs, banner and pop-up ads, multiple sources.
WatchSeries 2.0
WatchSeries

Specialty Sites

1Liberty - (fr-FR)
6VoierFilms - (fr-FR)
Classic Cinema Online - Classical Films
Classic Movies Channel - Youtube Classic Films
Cliver - Espanol
Club MST3k - Every episode of MST3K
Cuevana2 - Espanol
DaebakDrama - Korean
Danimados - Espanol
DPStream - (fr-FR)
DramaCool - Foreign
Dramago - (fr-FR)
Einthusan - Foreign
EmuleIsland - (fr-FR)
Film1k - - Movies with nudity
Filmz.cc - (fr-FR)
FilmZen - (fr-FR)
FrenchStream - (fr-FR)
K-Streaming - (fr-FR)
KingsofHorror - - Youtube Horror
Layarkaca - Foreign
MutantSorority - - Youtube Horror
Pelisplus - Espanol
Rulu - Youtube Red Series
StreamComplete - (fr-FR)
Time2Watch - (fr-FR)
Top Documentary Films - Documentaries
TromaMovies - Youtube Horror
VFStream - (fr-FR)
Videoneat - Documentaries/Science Movies
WatchAsian
Moviezworldz Hindi movies & TV Shows.
WTvF! - Youtube Grindhouse

Random Streaming Sites

/r/BestOfStreamingVideo
/r/MovieStreamingSites
#1 Movies Website - Watch movies online for free in HD quality without downloading or signing up.
1Movies - Watch Free HD movies online & free download movies at 1movies.pl.
Arabseed - (AR) - Online shopping from a great selection at Digital Music Store.
AZMovies - AZMovies your best source for watching movies online, with High Quality 1080p movies, you can stream anytime.
cine.to -  Sit back and relax while watching the newest Cinema or your favorite Movie for free. Just cine.to & chill.
cinebloom - Action Adventure Animation Biography Comedy Crime Documentary Drama Family Fantasy History Horror Music Musical Mystery Romance Sci-Fi Sport Thriller War Western.
Daxiv Video - Movies & TV shows online or stream right to your smart TV, game console, PC, Mac, mobile, tablet and more. Primarily Chinese content.
DP Stream - (FR) - Films/Series/AnimÃ©s a votre dispositions sur diffÃ©rents herbergeurs. dpstream.net.
eMule Island.ru - (FR/RU) - Site de tÃ©lÃ©chargement gratuit, Telecharger des films complet, series, ebooks, spectacles, documentaires et bien plus, sur uptobox, 1fichier.
Filmstream.online - (FR) - Regarder des films gratuits illimitÃ©s de sur Filmzenstream. Regarder complet des films en streaming hd gratuitement vf sans inscription en franÃ§aise.
FilmXY - Download Free Unlimited Movies Online From Filmxy At Great Quality!! Here You Can Download Movies in Bluray, 1080p, 720p, HD, HDTV, Web-dl, DvD-rip & more
Filmz.cc - (FR) -
Flixanity - Watch movies and TV shows online. Watch from devices like iOS, Android, PC, PS4, Xbox One and more. Registration is 100% free and easy.
FlixGo - Ralph Breaks the Internet. Avengers: Infinity War. Incredibles 2. Ant-Man and the Wasp ... Dawn of Justice. Captain America: Civil War. FlixGo.
FMOVIES - Openload, MyCloud, RapidVideo, Streamango
French Stream - (FR) - Regarder Facilement et Gratuitement Les Meilleurs Films et SÃ©ries en Streaming HD Sans aucune PublicitÃ© GÃªnante ...
HD MOVIES - Watch free movies online in 1080p at HDM.to - Stream & download the latest HD movies online for free without registration.
HDEUROPIX - Free Streaming HD Movies Online with captions. Full Movies Streaming Popular TV Series Watch Free HD topeuropix.net.
HDO - Watch HD Movies Online For Free the latest movies, tv-series without Registration at hdonline.to.
HDOnline - Free Movies Online!
INDOXXI - Movies releases.
KStreaming - (FR) - Film Streaming et SÃ©rie Streaming Gratuit.
libertyVF - (FR) -
LookMovie - Watch Movies and TV Shows for Free in 1080p and 720p. New Movies and Episodes are added every hour.
M4UFree.TV - Free Movies Online. Watch Movies Online Free. Watch all your favorite movies and tv shows online for free on M4ufree .
MegaShare - Watch Full Movies and TV Series Online Free.
MKVHub - MkvHub is the best website to download high-quality 720p, 1080p WEB-DL HDRip BluRay Movies and TV Shows with Single Direct Download Link.
Movie123 - Look no further than Movie123 if you are looking for the best sites to watch free movies online.
Nox - (Ger) - Filme, HD-Filme, 3D-Filme, Serien und Spiele - News. Reporters Without Borders.
onemov - Online Full HD Movie Free.
openloadmovies.net - Reliable movie streaming site which uses OpenLoad.
PelisPedia - (es-do) - Movies & TV Shows.
QQMovies - Stream Movies and TV Shows online in HD quality, 1080p, 4K.
Qwemovies - Watch HD Movies Online For Free and Download the latest movies without Registration at qwemovies.to.
Rainierland - Official home of rainierland - no ads and only good movies.
Sokrostream.vip - (FR) - 2019 Films Â· 2018 Films Â· Action Â· Science-Fiction Â· ComÃ©die Â· Horreur Â· Rapport
Solarmovie - Watch Movies Online and Watch Tv-Series online On Solarmovie without Registration.
Streamcomplete - (FR) - Streaming gratuit des films en VF, Regarder les meilleurs sÃ©lections des films complets en version franÃ§aise a voir online.
StreamCouch - Watch free the newest movie stream indexed as they appear online, in HD high quality.
StreamCR - Watch movies and TV series online for free. Stream episodes of Game of Thrones, Breaking Bad, Stranger Things and more!
TakiART - Watch and download latest Hollywood movies for free.
Time2Watch - (FR) - Films, sÃ©ries et mangas en streaming et tÃ©lÃ©chargement gratuit pour PC, iPhone, iPad et autres Smartphones.
VF-Streaming - (FR) - Voir Les Meilleurs Films, SÃ©ries Et Manga En Streaming HD Gratuit Sans inscription Sur VF Stream Venez dÃ©couvrir les derniers films complet en franÃ§ais.
VodLocker - Official home of vodlocker - no ads and only good movies.
VoirFilms.ws - (FR) -Voir Film Streaming, Streaming Film, telecharger, Films, regarder film streaming, dvdrip, film en streaming, voirfilms, gratuit.
WatchFree - Watch Movies Online Free. Watch your favorite movies and tv-series in hd quality on watchfree.to + putlocker.
WatchFullMovie - Watch 1000 Free full Movies on IMVBox. Free Live TV, Serials and Theatre on IMVBox
xPau.se - Movies, TV Shows & more.
Yes! Movies - Watch movies full HD online free. Watch latests episode series online. Over 9000 free streaming movies, documentaries & TV shows.
XMovies8 - Best site to watch free movies online, just search your favorite movies and Enjoy.
YMovies - Watch Free Full Length yify Movies Online on Yify TV. Torrents, Watch Films online in HD 720p and 1080p quality yts on Yify TV.

Video Game Music (OST)

FFShine Forum - A place for game and video game music.

Sports Streaming

/r/CFBStreams
/r/MLBStreams
/r/mmafights
/r/MMAStreams
/r/motorsportsstreams - Reddit community for motorsports streams.
/r/nbastreams
/r/ncaaBBallStreams
/r/nflstreams
/r/NHLStreams
/r/redsoccer
/r/rugbystreams
/r/WWEstreams
720pStream
Best Sport Streaming - Site that rates sport streaming services.
BossCast.net
cricfree.sx
Cricfree - Offers popular sports streams.
cytu.be/r/heemstream
Drakula Stream
EPCTV
firstrownow.eu
footybite - Soccer streaming site.
Giostreams
Kickboxing - (PO)
LiveTV - Wide variety of sports, results/live scores, video archive and betting.
MamaHD - 24/7 feeds, sports streams offers a clean UI.
myfeed2all.eu
MyP2P
Rojadirect
Send It - Live stream listings for sports, news, gaming, and more.
serbiaplus.club
SportsHD
Stream2Watch
Streamwoop
taima.tv/r/mma
Time4TV
TV Link
VIP Box Sports
VIPBox - (Spanish) - Many sport streams, TV which as a friendly UI.
vipleague.sx
Wiziwig

Media Centre Applications

Emby - A personal media server with apps on just about every device.
Gerbera - UPnP Media Server for 2018 (Based on MediaTomb).
Kodi - An award-winning free and open source home theater/media center software and entertainment hub for digital media.
Myflix - Myflix tries to be a somewhat simple and lightweight ""DIY Netflix"", similar to Plex, streama or Emby, for your DIY NAS, especially aimed at the Raspberry Pi/Odroid/etc ecosystem.
OpenPHT - A community driven fork of Plex Home Theater.
OSMC - OSMC (short for Open Source Media Center) - is a Linux distribution based on Debian that brings Kodi to a variety of devices.
Serviio - Serviio is a free media server. It allows you to stream your media files (music, video or images) - to renderer devices (e.g. a TV set, Blu-ray player, games console or mobile phone) - on your connected home network.
Streama - Self hosted streaming media server.
Stremio - Multi-platform video content aggregator with a comprehensive add-on system for extending functionality
Subsonic - Music and movie streaming server with a client app and web frontend.
Viewscreen - A personal video streaming server.

Stremio Addons

Juan Carlos Torrents - Allows streaming from torrents collected from KAT.cr and others.
Open Directories addon - Finds HTTP streams for movies/shows from open directories.
PirateBay addon - Fetch PirateBay entries on a single episode or series.
Popcorn Time addon - Watch from YTS and EZTV in Stremio
RAR addon - Watch content from RARBG in Stremio.
Zooqle addon - Watch movies and series indexed by Zooqle from RARBG, KAT, YTS, MegaTorrents and other torrent trackers.
/r/plexshares - A nice place to find Plex Media Server shares.
BaconFeet - ""Bringing a difference in streaming to the masses..."".
CDRomance - PSP, PSX, PS2, Gameboy, NDS, SNES, Dreamcast, and Gamecube ROMs and ISOs.
Elysium - Plex media streaming service.
MediaButler - Discord bot for use with PleX and several other apps that work with it.
Mellow - Discord Bot which can communicate with several APIs like Ombi, Sonarr, Radarr and Tautulli which are related to home streaming.
Ombi - Want a Movie or TV Show on Plex or Emby? Use Ombi!
Plex Requests - Simple automated way for users to request new content for Plex
plexrequests-meteor - Meteor version of the original Plex Requests
redump.org - Disc preservation database and internet community dedicated to collecting precise and accurate information about every video game ever released on optical media of any system.
Steamless - Steamless is a DRM remover of the SteamStub variants. The goal of Steamless is to make a single solution for unpacking all Steam DRM packed files. Steamless aims to support as many games as possible.

Plex Logging and Metrics

Plex-Data-Collector-For-InfluxDB - Collects data about your Plex server and sends it to InfluxDB
plexWatch - Notify and Log watched content on a Plex Media Server
Tautulli - Tautulli is a 3rd party application that you can run alongside your Plex Media Server to monitor activity and track various statistics.

Kodi

/r/Addons4Kodi - Discussion and links pertaining to unofficial addons for Kodi Media Center
Elementum - Elementum addon is an addon for Kodi, that manages your virtual library, syncs with your Trakt account.
Exodus Redux - The newest Exodus fork around, paired with LambdaScrapers.
Gaia - Grants the ability to instantly watch high quality files via cached torrents from Real-Debrid or Premiumize.
kodi-headless - A headless install of kodi in a docker container, most useful for a mysql setup of kodi to allow library updates to be sent without the need for a player system to be permanently on.
Official Plex Addon - Official Plex add-on for Kodi.
Placenta - A Fork of Exodus / Covenant with more options and links from Mr Blamo and Muad'Dib.
PlexKodiConnect - Plex integration in Kodi done right.
Plexus - Plexus is used in conjunction with Sparkle to play Ace Stream links.
Sparkle - Kodi addon for finding acestream links.
Tooonmania2 - lets you watch cartoons, dubbed anime and movies (from animetoon) - and subbed anime and movies (from animeplus).
tvtorrentorganizer - Bash 4 Script to Organize TV Show Downloads for Kodi
Ultimate Kodi Guide - ULTIMATE GUIDE TO INSTALL KODI + POPULAR STREAMING ADDONS by /u/giorgiomilan
Yoda - Another solid Exodus/Covenant fork, and this time it's from S-media.

Gaming Infos, Emus & More

/r/CrackWatch - New video game crack releases are posted here.
CreamAPI AutoInstaller - A python script to auto install Cream API for Steam games in order to get all DLCs for free.
Goldberg Steam Emulator - The  project is an attempt to make a generic Steam ddl that lets you play multiplayer games on a LAN without any internet connection.
SmartSteamEmu - A Steam emulator.

Game Repacks

""A simple script for easily downloading emulator.games ROMs"" - Reddit guide and userscript created by /u/estel_smith to allow you to easily download ROMs from Emulator.Games.
BlackBox
Dark Umbra - Forum for sourcing games.
DODI
ElAmigos Games - Premium links to cracked games.
Emulator.Games - Download or play ROMs on your PC, Mobile, Mac, iOS and Android devices.
FitGirl Repacks - Popular DDL and torrent site for game repacks.
Kaoskrew - Repacks from popular repacker SKIDROW, CPY, Razor1911, PLAZA etc.
Kapital Sin -
Nicoblog - Plenty of ISOs, ROMs & repacks.
qoob.name - Repacker site of popular cracker teams like CPY, PLEX etc.
R.G Mechanics - Various repacks.
Revolt Group - Official Revolt website.
Skidrow Repacks - Repacks from popular repacker SKIDROW. Lots of anime stuff too!
Tapochek - Official R.G Mechanics repacks can be found here.
Xatab Repacks - Russian game repacker - primarily torrents.

ROMs

3DSISO - A community based ROM database.
ByAlvRo's Collection - 1Fichier Mirror (132 TB various) via reddit
CoolRom - Your #1 emulation choice.
Darkumbra - Nintendo 3ds CIA files.
Digiex - A forum to share and talk about ROMs, Games & other console games.
Doperoms - A huge collection with over 170,000 ROM files.
Emulanium - Emulators, cheats & roms.
myabandonware - More than 14000 old games to download for free!
No Intro DAT-o-MATIC - List of Xbox, Nintendo etc games.
Old Games Finder - Old Games Finder is an automated old games search engine. (avoid ISO Zone links, as that site is dead).
Rom Links Megathread - 1Fichier, GDrive, Mega - Nintendo, Sony, Microsoft, Romsets, Arcade and other ROm collections.
ROM/ISO sites - Wiki page from gametechwiki.com with more links to ROM and ISO websites.
Romulation.net - Collection of over ~28,000 console game ROMs.
Romsmania - Another great ROMs collection with a decent UI to find stuff quick.
ROMNation - Lots of ROMs.
The Eye ROMs - Open directory of ROMs from The-Eye.
The ROM Depot - Around 3 TB of ROMs (requires a VPN).
Vimm's Lair - Large collection of ROMs.
Ziperto - Nintendo 3ds CIA files, especially for JRPGs.

Good Old Download alternatives

GOD Games - GOD is alive.
GOD Project - Work in Progress Project, aims to reboot the old GOD project.

Console Games (various)

/r/PkgLinks - A place to share working Playstation 4 PKGs.
/r/SwitchNSPs - Nintendo Switch games.
gazellegames - Another xBox 360 collection.
NoPayStation - A Database for PSN Content including Vita, PS3, PSX, and PSP.
PleasureDome Tracker - MAME torrents.
SPEEDLounge - (Ger) - XBox360, XBox, PlayStation and other Games.
Up2date list for Xbox 360 - An up2date list for Xbox 360 games.
xbox360iso - XBox 360 Game collection.

Game Cheats

MPGH - Multiplayer game hacking (makes money via ads).

PC Games

Bzinho Games - Scene releases mirrors.
CompucaliTV - (SP) - Games, Video & more via Mega, OpenLoad, & others).
CS.Rin.RU - NoStream Gaming Servers, Repacks & mods. (Tor Mirror: csrinru3c2ownkep.onion/forum/ + [Userscript] CS.RIN.RU Enhanced) -
DL2-DLFox - FTP Mirror for various Games.
Firestorm - Games & more.
GameBurnWorld - Provides cracks for Games.
GameCopyWorld - Provides cracks for Games.
GamesFull - (SP) - ElAmigos Games and other scene releases. Mega, GDrive, MediaFire.
Games Turret - Proves games via file hosters.
MegaGames - Same like GameCopyWorld, online since 20+ years, old but gold!
OVA Games - Cracks to latest Game Releases from PLAZA, CODEX & Co.
PCMYMJuegos - (SP) - Spanish website for SteamWorkFixs and other stuff. Mega, GDrive, MediaFire.
Skidrow & Reloaded - Fanmade Skidrow & Reloaded mirror website.
SpartaGames - (PT/BR) - Torrent links and direct server mirrors to various scene releases.
Small-Games - (RU) - A russian website which provides their own releases.
Torrents Gamestorrent - PC Game releases from CODEX, SKIDROW, PLAZA & Co.
VseTop - (RU) - Yet another russian website which buy their own games and release it to the mass.
Warmane - Hosts private WoW Servers.

Games Achievements

SSElauncher - SSELauncher Comfy Edition 2018 By LoodBot/Syahmixp (Steam Emulator).
Steam Achievement Manager - A manager for game achievements in Steam.

GameCube Games

Archive.org - Gamecube NTSC-J: Your gonna need an account with archive.org but it should work, speeds are decent.
GDrive

3DS

3DS Decrypter utility - Decrypt 3DS files.
3dscia - Nintendo 3ds CIA files.
GDrive - EN/US based ROMs.
GDrive - All regions collection.
GDrive
MEga.nz - DS Best of Collection
Mega.nz - 3DS Virtual Console
Nintendo 3DSISO - A forum which shares 3DS Roms.
ziperto.com - 3DS CIA collection.

GameBoy Advance

GDrive (mirror) - Password=snahp.it
Mega.nz - Password=snahp.it

Mame Games

PleasureDome - Various Mame games.

Nintendo Switch Games

GDrive (more frequently updated
GDrive
Switch SN Checker

Game Boy

G-Drive - Includes Game Boy ROM's (together with N64 etc) - and BIOS files.

Wii U Games

GDrive - EU only games.
GDrive - Wiiware and VC collection
GDrive - Wii Scrubbed ISOs retail Collection NTSC
GDrive - Mirror from abolve link.

CD Key Sellers

All Key Shop
CDKeyPrices
CDKeys
DLC Compare
G2a
G2Play
GO CD Keys
Ultimatum Game Keys (UGK)

Homebrew and Custom Firmware(s)

/r/3dshacks - Nintendo 3DS hacking and homebrew.
/r/ps3homebrew - News, updates, apps, and answers regarding PS3 homebrew!
/r/ps4homebrew - News, releases, and questions regarding the PS4 jailbreak, homebrew, and mods.
/r/SwitchHacks - Another Nintendo Switch hacking subreddit.
/r/SwitchHaxing - Nintendo Switch hacking & homebrew subreddit.
/r/vitahacks - A place to discuss Vita hacking and homebrew.
/r/WiiHacks - This reddit is for people interested in modifying their Wii.
/r/YuzuPiracy - Links for Yuzu, the open-source Nintendo Switch emulator.
3DS Hacks Guide - A complete guide to 3DS custom firmware, from stock to boot9strap.
The ultimate guide to Nintendo 3DS Piracy - 3DS piracy guide by /u/crazy5.

Anime

/r/animepiracy wiki - Lists for sourcing Anime streaming sites, manga sites, and more.
/r/animepiracy - This sub is about streaming and torrent websites for anime.
/r/sjain_guides - Guides and downloads for CS:GO, Windows 10 gaming optimisations, and more
9Anime Downloader - Download Full Seasons from 9anime.
Alternatives to Kiss websites - /r/KissCartoon wiki page with lots of anime sites.
AniDex - Torrent tracker and indexer, primarily for English fansub groups of anime.
AniLinkz - Large database of streaming anime episodes.
Anime Kaizoku - Up to 1080p DDL links, mostly Google Drive.
Anime Twist - An anime direct streaming site with a decent UI and video player.
anime-sharing - Forum for sharing anime series.
animEncodes - Anime sharing page.
AnimeOut - Over 1000's of Encoded Anime with DDL links.
GoGo Anime - Popular website for watching anime.
Hi10 Anime - High Quality 10-bit Anime Encodes.
HorribleSubs - Download anime via torrent files, magnet links, XDCC, and premium link hosts.
KissAnime - Subs and dubs, many ads, many player alternatives, captcha, anti adblocker, videos hosted by Google & Facebook.
Kissanime - Dubs and up2date animes.
Monimo - Netflix like web app for watching animes.
Nyaa - BitTorrent software for cats (Repo).
NyaaPantsu - Primarily Anime torrents but includes an open directory of DDL links too.
Series9 - Search engine for movies and tv shows (incl. animes).

Cartoons

animetoon - Lots of streaming via premium hosts for cartoons.
KissCartoon - Popular cartoon streaming site.
Toonova - Another site for streaming cartoons.
watchcartoononline.com - Cartoons, dubbed/subbed anime streaming site.
watchcartoononline.io - Large DDL site for cartoons as well as anime and movies.
KimCartoon Large cartoon collection, primarily Openload.
WatchCartoon Outdated site layout, still active, uses Openload.

Album Art

Album Art Downloader - Find and update their album art for their music collection.
newalbum.club - Search and download free music & album arts. No account required!

Music

94hiphop - Download Free Hip Hop Albums!
Beets - The purpose of beets is to get your music collection right once and for all. It catalogs your collection, automatically improving its metadata as it goes using the MusicBrainz database.
CDBao - Chinese invite-only page for music.
LibreSonic - Media streaming software.
MOOVAL - Easily move your playlists, tracks and likes from one streaming service to another.
Madsonic - Madsonic is a web-based media library and media streamer with jukebox functionality.
MusicBrainz - MusicBrainz is an open music encyclopedia that collects music metadata and makes it available to the public.
Redacted - Elite music scene (requires invite).
RuTracker - Ru-Tracker, music info, releases & software.
Slsknet - Soulseek is an ad-free, spyware free, just plain free file sharing network for Windows, Mac and Linux.
airsonic - Airsonic is a free, web-based media streamer, providing ubiquitous access to your music.
streethiphop] - Download free music.

Music Streaming

datmusic - Search engine with a clean UI for streaming music in your browser
GoSong - Streamable MP3s
Hikarinoakariost - Site with Japanese music
mp3.li - Another MP3 streaming site
mp3Clan - Free music streaming
MP3Juices - MP3 search engine tool which uses YouTube
MusicPleer - Another music streaming site with a decent search engine.
Muxiv Music - Stream 45 million songs on all your devices, online or offline. Primarily Chinese content.
SongsPK - Mainly for downloading Bollywood songs. Domain changes frequently.

iOS JailBreak Firmware

IPSW - Provides Jailbreak firmware.

iOS Apps

Cinema Time - Similar like Popcorn Time.
Cotomovies - Streaming Movies and TVShows app.
HDX Online - Another alternative for Cinema Time.
Total files - Basically the IDM under the iOS Download Managern.

iOS Stores

App Valley - Basically the Aptoide under the iOS Stores.
Cydia - Cydia is an alternative to Apple's App Store for ""jailbroken"" devices.

iOS Store Repos

Xarold

iTunes

forked-daapd - Linux/FreeBSD DAAP (iTunes) - and MPD media server with support for AirPlay devices (multiroom), Apple Remote (and compatibles), Chromecast, Spotify and internet radio.
How to Remove DRM From iTunes Movies and TV Shows - HowToGeek article on how to use TunesKit and Requiem
Plus Premieres - Download newest iTunes music in M4A format.
Requiem - Requiem is a program that removes Apple's DRM (called FairPlay) - from songs, videos, and books purchased on iTunes.
TunesKit - iTunes DRM removal tool.

Spotify

BlockTheSpot - Video, Audio & Banner ad-block/skip for Spotify.
Spotify Ad-Free - Modified Client(s), Information, etc.
Spotify Downloader - Download Spotify playlists with albumart and meta-tags.
BlockTheSpot - Video, Audio & Banner ad-block/skip for Spotify.
Spotify Megathread - /r/Piracy Spotify-related discussion and future developments.
Spytify - Records Spotify without ads while it plays and includes media tags to the recorded files.

SoundCloud

scdl - Soundcloud Music Downloader.
scddlr.com - SoundCloud To Mp3 Converter Online.

Software

/r/piracy/wiki/tools - Windows/Office activation tools, and images/installers for Windows, Office, and Adobe
Appked - MacOS application sharing website.
CrackingPatching.com - Cracked software
CracksNow - Cracks for Android, Windows, and macOS applications.
gallery-dl - Command-line program to download image-galleries and -collections from several image hosting sites
Nulled - Nulled is a cracking community where you can find links to cracked software
Team-OS HKRG - Windows software and various activation tools.
Vestathemes - Vestathemes is a website for WordPress - themes and plugins.

Windows

AME - Windows 10 AME aims at delivering a stable, non-intrusive yet fully functional build of Windows 10 to anyone, who requires the Windows operating system natively.
Krakatoa - Office, Windows, KMS and Key checkers.
MDL Forums - Windows topics, hotfixes & self-made tools.
PCBeta - Windows ISOs, hotfixes and discussions.
SamLab - (RU) - Windows Board, ISOs, Hotfixes & more.
Shadow-Trooperz - Provides Windows ISO's and other Windows related software links.
TechBench - Find official Windows isos for Windows 7/8/10.
UUPDump - In-official Windows Hotfix repository + Windows dumps.

Windows Resources (Hotfixes & Patches)

AskWoody - News, tips, advice, support for Windows, Office, PCs & more.
RCC - RCC, check your system's trusted root certificate store.
Simplix Blog - Windows Hotfix repository.
Windows ISO + Hotfix mirrors - AdGuard provides mirrors to hotfixes and Windows ISO's/ESD's.

Windows Activation

PIDChecker - Validate and check Microsoft Product Keys.
KMS Activator - The original repo for KMS related activation & research.

Windows 10 Downloads & Verification

Windows 10 1903 Build 18362.30 Final (May Update '19) - Download + checksum links.
Windows and Office Genuine ISO Verifier - Freeware tool to verify Windows & Office images.
Windows ISO Downloader - Allows an easy and comfortable way to download genuine Windows 7, 8.1 and 10 disk images (ISO) directly from Microsoft's servers (tool contains ads).

eBooks

/r/DHExchange - PDF/eBooks trading.
Apprentice Alf's Blog - Everything you ever wanted to know about DRM and ebooks, but were afraid to ask.
Authorama - This public domain book site has a wide variety of ebooks for free, by Lewis Carroll, Emerson, Kafka, and more.
b-ok - Free ebook library
Baen Free Library - You can download ebooks for HTML, RTF, Microsoft Reader and for Palm, Psion, and Window CE.
Bartleby - While Bartleby charges for some titles, it has a free ebook store here.
bibliomania - You will find over 2,000 classic texts from bibliomania, plus study guides, reference material and more.
BookStack - BookStack is a simple, self-hosted, easy-to-use platform for organising and storing information.
Bookyards - This online ""library to the world"" has over 17,000 ebooks, plus links to other digital libraries.
Boundless - Affordable online textbooks & study materials.
Calibre-Web - Web app for browsing, reading and downloading eBooks stored in a Calibre database
COPS - Calibre OPDS (and HTML) - PHP Server: Web-based light alternative to Calibre content server / Calibre2OPDS to serve ebooks (epub, mobi, pdf, etc.)
Custom Search Engine - A Google custom search engine specifically for ebooks.
DailyLit - Get free downloads sent to your email by RSS feed.
DeDRM_tools A github repository of all the scripts and other tools for removing DRM from ebooks.
DLEBook.me - eBooks, Magazines & software.
ebook Directory - From children's books to IT books to literature to reference, you'll find lots of free titles and book packages here.
ebookee.org - PDF/eBooks trading.
eBookLobby - You'll find lost of self-help, hobby and reference books here, plus children's fiction and more.
eReader.com - eReader.com has many classic lit selections for free.
FicSave - An Open-Source Online Fanfiction Downloader.
Free-eBooks.net - Besides browsing topics such as biography, fan fiction, games, history, or tutorials, you can submit your own ebook, too.
freebookspot.es - Various eBook's.
Get Free Ebooks - This website has free ebooks in categories from writing to environment to fiction to business, plus features and reviews.
Globusz - There are no limits on the number of free books you can download on this online publishing site.
Guide to Copy Kindle Content to PDF using Calibre -
Gutenberg - Project Gutenberg was the first to supply free ebooks, and today they have almost 30,000 free titles in stock.
How can I remove DRM from my ebooks? - DeDRM tools provides a big FAQ and scripts, tools to remove DRM on eBooks.
iBiblio - Find archives, ebooks, tutorials, language books, and more from iBiblio.
LibGen - eBook search. (Mirror) - + (another Mirror)
ManyBooks.net - You can conduct an advanced search, type in a title or author, browse categories or select books by language, from Finnish to Bulgarian to Catalan to Swedish.
Planet PDF - Planet PDF has made available classic titles like Anna Karenina and Frankenstein for free.
Read Print Library - These novels and poems are all free.
Starry.com - These novels and anthologies were last updated in 2006, but you'll still find an interesting selection of online and virtual novels.
TehParadox - eBooks, Apps, Games & more.
The idiot proof guide to downloading ebooks off IRC - Posted by /u/Servaplur
The Online Books Page - You'll be able to access over 35,000 free ebooks from this site, powered by the University of Pennsylvania.
Ubooquity - Ubooquity is a free home server for your comics and ebooks library.

eBook Search Indexer

ABook - One of the oldest book search indexers.
BinSearch - Binary Usenet search engine which can be used for eBooks and other stuff.
EBookEE - Tech, Database, Java and many many other categories.
FreeBookSpot - Similar to eBookEE.
GingaDaddy - A usenet newsgroup for eBooks. (needs login)
Google Search - Preset of indexed websites to search for comics.
oznzb - Yet another search engine.
EBook Bike - Another search indexer which claims to be the ""largest"" on the Internet.
Ebook 3000 - Free ebooks download

Magazines

ebook3000.com - Various magazines.
MagazineLib - Free PDF and interactive e-magazines.
magazinesdownload.org - Magazines hosted on free, fast, file hosting sites.
PDF Giant - Various categories of downloadable PDFs.

Academic Papers & Material

Academic Torrents - A Community-Maintained Distributed Repository for researchers, by researchers. Making 32.66TB of research data available!
BookSC - The world's largest scientific articles store. 50,000,000+ articles for free.
LibGen - search engine for articles and books on various topics, which allows free access to content that is otherwise paywalled or not digitized elsewhere
PDF-Gigant - Lots of different magazines.
Sci-Hub - The first pirate website in the world to provide mass and public access to tens of millions of research papers.

Textbooks

All IT eBooks - A big database of free, direct links for IT and programming ebooks
forcoder - Ebooks & Elearning for Programming
Guide for Finding Textbooks - Extensive tutorial by /u/Amosqu
How to ""rent"" your textbooks for free from Amazon - ""Going to college? Living off top ramen for dinner? Let me show you have to ""rent"" your textbooks for free & for life!""
it-ebooks - Large selection of free and open source IT ebooks
PDF/Ebook trackers for college textbooks - Old-but-still-useful list of ebook/textbook trackers, DDL sites, and IRC communities

Direct Download Streaming

Catchvideo.net - Catchvideo.net is a free online website, which allows you to download a video url from YouTube, Facebook, Dailymotion, Vimeo and more.
HDencode - Download Movies and TV Shows - #1 Source for High Definition Releases.
Movie Files - Download Movies For free.
Movies ""R"" Us - The newest movies in 1080p. Available with DDL through MediaFire and streaming through AnonFile.

Audiobooks

ZLibrary - Part of Z-Library project. The world's largest ebook library.
AAXtoMP3 - Convert Audible's .aax filetype to MP3, FLAC, M4A, or OPUS.
AudioBook Bay - Download unabridged audiobook for free or share your audio books, safe, fast and high quality.
AudioBooks.Cloud - DDL links to a lot of audiobooks.
Booksonic - Booksonic is a server and an app for streaming your audiobooks to any pc or android phone.
The-Eye /public/AudioBooks - Audiobooks hosted by ""The Eye"".
Tokybook - Yet another free audiobook streaming site.
BookFI - The largest ebook library.
Ebooks Shares - A lot of eBooks & audiobooks!
P2PEiite - (HTTP only!) - Yet another oldschool eBook website.

Science Books

BookSC - Part of Z-Library project. The world's largest scientific articles store. 70,000,000+ articles for free.

Comicbooks

getcomics.info - Comics, release info & more.
Comic Extra - General Comic informations.
Gazee! - A WebApp Comic Reader for your favorite digital comics. Reach and read your comic library from any web connected device with a modern web browser.
GetComics - GetComics started as an alternative place to get downloaded comic. files, particularly US based comics published by DC and Marvel.
Readcomicbooksonline - Tends to Error 520 occasionally.
readcomiconline.to - Manga and comics which are been uploaded daily.
ReadComics - Several misc comics published.
WorldWideTorrents - Provides comic releases.

Manga

/r/manga - Everything and anything manga! (manhwa is okay too!)
KissManga - Another manga website.
Madokami 0-E - Download manga titles named 0 to E.
Madokami F-K - Download manga titles named F to K.
Madokami L-Q - Download manga titles named L to Q.
Madokami novels, raws and artbooks - Download novels, manga raws and artbooks.
Madokami R-Z - Download manga titles named R to Z.
MangaDex - MangaDex is an online manga reader that caters to all languages.
MangaZone - A manga reader app.

Documentaries

/r/Documentaries - Popular documentaries subreddit.
DocuWiki-net - DocuWiki.net serves as an index of documentary films on the Edonkey Network.
MVGroup - A forum which shares documentaries via P2P.
whatwhat888 big list of documentary sites (streaming and download) - An old post by /u/whatwhat888 that may still be useful.

Fonts, Icons & Graphics

Get the Font - Searches through GitHub for fonts
GFXDomain - Forum for graphic design resources and software
GFxtra - DDL links for graphics, icons, 3D models, and more
GraphicEx - Stock/vector graphics, PhotoShop/InDesign resources, fonts, and more
How to download paid Fonts for free - Post by /u/Bebhio on how to use clever Google searches to find fonts online
Tomato.to - Supports Shutterstock, Gettyimages, Adobestock, Fotolia, Vectorstock, iStockphoto, PNGTree & PicFair.
Web4Sync - Forum with DDL links catering to web development, graphics design, 3D animation, and photography

P2P-Networks

eDonkey network - A decentralized, mostly server-based, peer-to-peer file sharing network + Server Status
FastTrack - Protocol used by the Kazaa, Grokster, iMesh, and Morpheus file sharing programs
Fildo - Android music streaming app which fetches files from third party MP3 search engines.
Gnutella - P2P network behind the popular LimeWire file sharing app
IPFS - Distributed Web - Peer-to-peer distributed file system that seeks to connect all computing devices with the same system of files
Kad - The Kad network is a peer-to-peer (P2P) - network which implements the Kademlia P2P overlay protocol.
Napster - Peer-to-peer file sharing Internet service that emphasized sharing digital audio files, typically audio songs, encoded in MP3 format.
Peer-to-peer file sharing - Detailed Wikipedia page about file sharing
TiviMate IPTV player - A popular Android app for watching IPTV on Android set-top boxes.
YouTube Vanced - Vanced is a well known modded version of YouTube with many features such as adblocking and background playback and many more.

Ripping, Transcoding, Converting

Automatic Ripping Machine - The A.R.M. (Automatic Ripping Machine) - detects the insertion of an optical disc, identifies the type of media and autonomously performs the appropriate action
DVD Decrypter - The original unofficial DVD Decrypter mirror since June 7th, 2005.
DVDFab - DVD/Blu-ray ripping tool, alternative use AnyDVD HD.
ffmpeg - A complete, cross-platform solution to record, convert and stream audio and video.
Handbrake - HandBrake is a tool for converting video from nearly any format to a selection of modern, widely supported codecs.
MakeMKV - MakeMKV is your one-click solution to convert video that you own into free and patents-unencumbered format that can be played everywhere.
sickbeard_mp4_automator - Automatically convert video files to a standardized mp4 format with proper metadata tagging to create a beautiful and uniform media library
The Encoding Guide - An in-depth guide on video encoding.

Cloud Storage

/r/PlexACD - Discussion about unlimited cloud storage for Plex libraries
Connect Your Plex Server To Your Google Drive - This tutorial will help you connect your Google Drive to your Plex server using Plexdrive.
google-drive-ocamlfuse - FUSE filesystem over Google Drive
plexdrive - Mounts your Google Drive FUSE filesystem (optimized for media playback)
rclone-gdrive - Wiki page on setting up Google Drive with rclone cache and crypt
rclone - Rsync for cloud storage.

File Renaming and Tagging

/r/datacurator - Subreddit for discussion about the curation of digital data. Be it sorting, file formats, file encoding, best practices, discussion of your setup, tips and tricks, asking for help etc.
Beets - Beets is a music library manager.
docker-filebot - A docker container for FileBot
filebot-node - a client-server application that'll allow you to run filebot commands
FileBot - The ultimate tool for organizing and renaming your Movies, TV Shows and Anime as well as fetching subtitles and artwork. It's smart and just works.
iFlicks2 - Useful for adding metadata to movies and TV shows
MediaElch - Media manager for Kodi. Metadata & artwork retrieval, as well as renaming.
MediaInfo - MediaInfo is a convenient unified display of the most relevant technical and tag data for video and audio files.
MediaMonkey - Manage a movie/music library from 100 to 100,000+ audio/video files and playlists
Metatogger - Metatogger is the new generation of tag editor allowing you to rename, tag and easily sort your audio files.
MP3TAG - Mp3tag is a powerful and easy-to-use tool to edit metadata of audio files.
Picard - Picard is an open source cross-platform music tagger written in Python.

Mobile Apps

4PDA.ru - 4PDA is the biggest Russian forum about mobile devices. You can find endless amount of APKs and Mobile software there. For download registration is required, this might help you to solve the captchas.
AiOwares.com - RePacks, mods and other software.
Android Republic - Android Republic is similar to Mobilism, provides mirrors to various apks.
Android Zone - koumkouat website for Android APK's/Games/GPS.
Android-1 - Provides apps & app mods.
AnYme - Unofficial Anime App for MyAnimeList.
AppCake - AppCake is also known as AC Market and provides free apks.
apk4free - Android apk mirrors and patches.
APKDot - APKMirror clone website.
Apkmos - The Best App Store For Download Android Apps, Android Games, Android Themes, Android Wallpapers And Much More For Your Android Smartphone.
Baltagy's Website - Apps, Mods, RePacks and portable releases.
Blokada - Blokada is a compact app that transparently blocks unwanted content like ads, tracking, malware and other annoyances.
Cygery AdSkip for YouTube - Automatically click on the ""Skip ad"" button in the YouTubeâ¢ app when it appears.
FilePursuit Pro - FilePursuit provides a very powerful file indexing and search service allowing you to find a file among millions of files located on web servers.
Haxoff - Haxoff provides cracked games & Android APK's.
HiAppHere
MyJDownloader - enables you to remote control your desktop JDownloader from your pocket while you're on the go.
nzb360 - nzb360 is a full-featured NZB manager that focuses on providing the best experience possible for controlling all of your usenet needs.
Ombi - Companion app for Ombi to request Plex content
Perfect Player - Perfect Player is set-top box style IPTV/Media player for watching videos on TVs, tablets and smartphones.
Platin Mods - As the name says, provides several mods for apks's & games.
ProSmart - ProSmart is a russian site which provides several apks, mods and games.
Release-APK - Balatan's APK page.
Tachiyomi - Tachiyomi is a free and open source manga reader for Android.
Tautulli Remote - Mobile version of Tautilli for monitoring Plex on the go
Trashbox - Trashbox is the russian Mobilism.
YMusic - YouTube Music Player & Downloader

XPosed + Magisk

Magisk - Root & Universal Systemless Interface.
Systemless Xposed For SDK 27 (Android 8.1) - Magisk Xposed version (needs Magsik).
VirtualXposed - Xposed version for non-rooted devices.

Android License Verification Patcher

LuckyPatcher - Patch applications, remove ads and install a modded Google Play Store to bypass Google's license verification.
Jasi Patcher (also known as Uret Patcher) + [ToolKit] - Patching tool for android intended to bypass restrictions in the apps & games, it includes custom patches, support patches, universal patches, offline emulation, spoof, hooks, tools and utilities.

Streaming Apps

99kubo - (Ads) - 99Kubo is a paradise for movie buffs,couch potatoes & social networkers.
AnimÃ©Glare - (Ads) - lets you stream any anime for free.
AnimÃ©Vibe - Watch Anime Online Free HD both Subbed and Dubbed on AnimeVibe without Advertisements!
AOS TV - Watch More than 1000+ Live TV Channels free on your Android Phone from across the world.
ApolloTV - Open-source aggregator for various online video content.
BeeTV - (Ads) - Watch movies & tv shows for free on Android device, Amazon Fire Stick, Fire TV, Nvidia Shield, etc.
CKayTV - (Ads) - Allows you to stream free videos from across the web directly on your Android and Firestick devices.
CinemaHD - (Ads) - FireTV Stick, Nvidia Shield, support Real-Debird, external players, Trakt.tv, series Guide.
Cinema - A lot of Movies & TV/Shows to watch and download.
DreamTV (Terrarium Clone) - (now called Redline) - Needs invite - Download various Movies.
Evolve TV - (Ads) - Watch for free more than 1100+ channels from all over the world, it also works with MXPlayer together.
Exousia - Watch Live Tv & Movies, Sports.
Fildo - Yet another Music streaming app.
Filmix - Watch movies and TV shows using AndroidTV or mobile devices.
KinoTor - (RU) - Provides movies and videos from several russian directories.
Kokotime - Kokotime is an addon-based, simple, free and elegantly designed app that will let you watch all your favorite media content in a unique and elegant user friendly design.
KrakenTV - Watch dozens of different TV channels from the comfort of your Android device.
Live TV - Watch Indian TV Channels live on your mobile free.
Liveflix - The app allows to watch your favorite channels easily, with a very simple UI.
Mega Shows - Watch & Download your favorite movies and TV shows.
Mobdro - Mobdro constantly searches the web for the best free video streams and brings them to your device.
Morph TV (Morpheus Fork)
Newest Movies HD - (en-US) - Watch movies and TV shows using AndroidTV or mobile devices.
Orion TV - (SH) - Allows you to watch live TV channels and recorded selected shows (72h Catch-up TV).
PhoenixTV - Morpheus Fork
RevTV - (es-ES) - Live TV, Movies, TV Shows in Spanish
TVPato2 - (es-ES) - Spanish Live TV App.
TVZion - + Reddit
TeaTV - App for Android, Windows, and macOS for watching 1080p movies and TV shows for free.
TitaniumTV (Terrarium Clone)
UnlockMyTV (Cinema Clone AdFree)
ZippyTv HD - ZippyTv is one of the largest online TV platform with over 500 Live TV Channels.

Big Media Libraries

/r/BestOfStreamingVideo - Reddit, random streaming sites
/r/MovieStreamingSites - Reddit, random streaming sites
123Movies.ooo - Watch & stream full HD movies & TV series online for free.
2TwoMovies - Watch Free Movies Online. TwoMovies is a free online video service that offers large collection of full length movies.
5Movies - Watch FULL HD Quality 1080/720p movies and latest tv series online for free, download the latest movies without registration at all.
8Putlocker - Watch Movies HD Online for Free, you can watch all movies here. All TV Series, Asian Dramas, Anime & Cartoons.
Afdah - Afdah is a web scraper coded to crawl and index online movie sites.
BS.to - (GER) - German Video-on-Demand-Website for TV-Shows, Cartoons & Movies.
CafeHulu - e Best Place To Watch FREE Tv Series And Cartoons.
EZTV (EZTV.AG) - Well known group for movies and series.
filechef - Search Direct Downloads
FreeMoviez - Watch free movies online.
Los-Movies - You can stream High Quality movies and cinema films without any redirection.
M4UFree.TV - Unique design, HD server with backup and additional hosts
Movie4k - Huge Movie/TV Library
Primewire - Free Movies
Putlocker.onl - Watch movies and TV Series for free, watch series full episodes online free with HD quality on Putlocker.
Putlockerfreely - Watch your favorite movies online free on Putlocker. Discover thousands of latest movies online.
Putlockeri - Watch your favorite movies online free on Putlocker.
Putlockertv - Watch movies and TV Series for free, watch series full episodes online free with HD quality on Putlocker.
Sharemovies - Watch Movies in Theatre, Anime & Cartoons and TV Series in HD 1080.
Sockshare - Huge Movie/TV Library
SolarMovieHD - Watch Movies Online and Watch Tv-Series online On Solarmovie without Registration.
Solarmovies - SolarMovie claims to be the biggest Library of free movies and tv shows.
Streaming Multireddit
TORRENTDOWNLOADS - Itâs a no-nonsense index that provides torrents to millions of users each month.
Viooz - (RU) - Discover thousands of movies, watch your favorite movies online for free on VZM, Viooz.

TV & Sports Streaming

123TV
720pstream
All The Best Fights
Arconaitv
Bellator
BilaSport
Couch Tuner
CrickFRee
Daily TV Fix
First Row Sports
Full MMA Videos
LiveTVCafe
M4uFree.tv
MamaHD
MMA Core
MMA Versus
More Live Sports Sites
NewEpisodes
Pluto.tv
ProjectFreeTV
r/MMAFights
Ripple
Send It
SeriesFree
SeriesTop
SportsHD
StreamAll
TVSeries4u
TVZion
uStreamix
VipBox
Watchepisodes4
Watchepisodeseries
WatchKobe

720p Streaming

123GoMovies
123Moviesuk
123NetflixPro
1movies
bmovies + (Mirror) + Mirror)
CafeMovie
ddlhub
FFilms
Fmovies + (Mirror) + (Mirror)
flixtor.to
Flixtor
Full YouTube Movies -
GOMovieshub
HackIMDb
HDeuropix
HDFlix
HDVix
ILoveToWatch
IWannaWatch
Khaanflix
MegaDDL - Various movies via Mega, 1Fitcher, Openload and other file-hoster.
MovieGlide
Movies24
MovieZion
Niter
Oakmovies
Openloadmovies.tv
pahe.in - Streams via Uptostream, Google Drive, Openload or Mega.
ProSpice
Putlockers.fm
Solarmoviefreez
Solarmoviez
Spacemov
StreamDreams
Streamlord
Streamm4u
TimeToWatch
Tubi
TVMovies
ULMovies
VidCloud
WatchFree.ac
Watchfree.at
Watchfree.movie
WatchOnline.al
WatchSeries 2.0
XMovies8
Yes! Movies
YesMovies.fun
ZMovies

1080p Streaming

1Movies
CineBloom
Crackle
crawler
Daxiv
Filmxy
HD Europix + Mirror
HD Multireddit - 1080p Openload, Google Video & Vimeo,..
IceFilms
Kodi - + (Setup guide)
LeonFlix
Megashare9
MovieNight
MovieJagg
MovieStreams
OneMov
OnMovies
QQMovies
RainierLand - Openload, Streamango
SceneSource
Stream Likers
TeaTV
TopEuroPix
UWatchfree
Video2k
Videospider
Vmovee
WatchFullMovie
xPause
Ymovies

Wrestling & MMA

Fight-BB
MMA Releaselog
WWE-TV - (Ger)

Torrent Apps (Android/iOS)

/r/moddedandroidapps - User modified Android App(s).
aTorrent - Another popular torrent client for Android.
BiglyBT - Free, open source torrent client for Android phone, tablet, Chromebook, & Android TV
Flud - Flud is a simple and beautiful BitTorrent client for Android.
LibreTorrent - LibreTorrent is a Free as in Freedom torrent client for Android 4+, based on libtorrent.
Transdrone - Transdrone allows you to manage the torrents you run on your home server or seedbox.
Trireme for Deluge - A Deluge thin client for Android. Written in Flutter.
Vuze - Lightweight & powerful BitTorrent app.

Discord Clients

Ripcord - A closed source no tracking or analytics Discord client (without electron framework part).

Discord Servers

/f/MEGAlinks (Snahp) - Official /f/MEGAlinks Discord server.
/hbg/ Homebrew General A Discord server that shares newer Nintendo Switch Games.
r/PkgLinks - Reddup game sharing Discord Server.
/r/soccerstreams - Official Discord server for the recently-killed /r/soccerstreams subreddit.
9YearOldPirates - Official Discord server for the 9YearOldPirates relaese group.
AnimÃ©Glare - Official AnimÃ©Glare Discord channel.
AnimÃ©Vibe - Official AnimÃ©Vibe Discord channel.
APK'S 2 Day - This is a discord server that acts as a hub for numerous streaming apps.
ApolloTV - The official ApolloTV Discord server.
DoujinStyle - Discord server with Doujin related materials. Things such as Japanese doujin music & games.
DreamTV - A Discord server for the official DreamTV Android app.
legal acquisition club - A piracy server to discuss and share movies, tv and apps.
Morph TV (Morpheus Fork) - Morph TV (Morpheus Fork) official Discord channel.
piratesonline - Official piratesonline.us Discord Server.
PlayStation Homebrew - Home of /r/ps3homebrew and /r/ps4homebrew.
The Eye - Official Discord server for the-eye.eu
The Ratio - A community of seedbox enthusiasts. Buying advice, application setup, and automation help.
WarezNX - Nintendo Switch Warez community server.

IPTV + DVR

/r/IPTV - Subreddit some may find helpful for gauging the current state of IPTV providers.
/r/iptvresellers - Promotions and advertisements from IPTV providers.
/r/IPTVReviews - Reviews of IPTV service providers.
2019 Oscar DVD Screeners - List of DVD screeners for 2019's Oscars.
Academy Awards 2019 Screeners Megathread - Post by /u/idoideas listing all available DVDSCR releases for 2019.
allsprk.tv - Channel-hoppable live streaming site with a chat room.
antennas - HDHomeRun emulator for Plex DVR to connect to Tvheadend.
IPTV Community - Technology and IPTV discussion website, useful for finding an IPTV provider/reseller.
IPTV Providers list - A recently created list of 40+ IPTV providers with notes.
MythTV - Free Open Source software digital video recorder.
STBEmulator - Popular Android app for using IPTV streams with EPG.
telly - IPTV proxy for Plex Live written in Golang.
tvheadend - Tvheadend is a TV streaming server for Linux supporting DVB-S, DVB-S2, DVB-C, DVB-T, ATSC, IPTV,SAT>IP and other formats through the unix pipe as input sources.
UlstreaMix - Live TV streaming site, predominantly sports.
xTeVe - M3U Proxy for Plex DVR.
Xtream Editor - Xtream Editor allow you to create, edit and sort m3u playlists online.

Acestreams

aceproxy - Ace Stream HTTP Proxy. (abandonware)
acestream.org - Ace Stream is a peer-to-peer streaming application that lets you stream live sports and other content
AceStreamSearch - Ace Stream Broadcasts Search
FireDrop - 100GB free cloud storage.
iktason/aceproxy - A docker image to run aceengine + aceproxy, e.g. to watch Torrent-TV.ru.

IRC

autodl-irssi - autodl-irssi is a plugin for irssi that monitors IRC announce channels for torrent trackers and downloads torrent files based on user-defined filters.
XDCC Tutorial - XDCC Downloading For Beginners: Do It Like A Pro!
XDCC - XDCC (Xabi DCC or eXtended DCC) - is a computer file sharing method which uses the Internet Relay Chat (IRC) - network as a host service.
ZNC - An advanced IRC bouncer.

IRC Networks

Beast-XDCC irc://irc.abjects.net/BEAST-XDCC - One more XDCC source.
irc.irchighway.net/ebooks irc://irc.irchighway.net/ebooks - A nice, friendly irc channel for trading ebooks.
irc.undernet.org/bookz irc://irc.undernet.org/bookz - For downloading ebooks (use @search <book name> for a list of available ebooks)
irc://irc.abandoned-irc.net/#ZOMBIE-WAREZ irc://irc.abandoned-irc.net/#ZOMBIE-WAREZ - Zombie Warez channel for various software.
Moviegods irc://irc.abjects.net/MOVIEGODS - XDCC file sharing network, join #mg-chat to continue downloading
The Source irc://irc.scenep2p.net/THE.SOURCE - Another XDCC source
irc.p2p-network.net - P2P file sharing network
Orpheus - Formerly known as Apollo
p2p-network.net channel list - List of all channels on the p2p-network.net IRC network

IRC Search Engines

ixIRC - ixIRC lets you search through 17 IRC networks, 32 channels, and over 189915 user supplied XDCC packs.
SunXDCC - Another XDCC file search engine
xdcc.eu - XDCC search engine indexing packets from a large number of networks
xWeasel - xWeasel is a free stand-alone Download Client based on IRC technology including a multifunctional XDCC Search Engine.

DC++

AirDC++ - Windows GUI and Linux Web DC++ client in active development, with ADC, IPv6 and DHT support.
DC++ - Wikipedia page describing DC++
Direct Connect (protocol) - Wikipedia page describing Direct Connect.
EiskaltDC++ - Windows/Linux/macOS DC++ client, with ADC and DHT support
FlylinkDC++ - Windows DC++ and BitTorrent client in active development, with ADC and DHT support.
Linux DC++ - Easy to configure and use DC++ client
LinuxDC++ - Utilizing the latest DC++ core, LinuxDC++ offers similar functionality to the Windows client like segmented downloading, TTH based file integrity, etc. with a GTK+ user interface.
Tankafett - List of public DC++ hubs, previously known as hublist.org and TheHubList.com.

Full Movies On

/r/1080pMoviesOnline
/r/BestOfStreamingVideo
/r/fullcartoonsonyoutube
/r/FullLengthFilms
/r/FullMovieonViooz
/r/fullmovierequest
/r/FullMoviesDailyMotion
/r/fullmoviesongoogle
/r/fullmoviesonopenload
/r/Fullmoviesonvimeo
/r/fullmoviesonyoutube
/r/fulltvshowsonvimeo
/r/fulltvshowsonyoutube
fullmoviesandtv multireddit - All of the above subreddits as a multireddit

Full TV Shows On

/r/freefolk - Streams for new episodes of Game of Thrones.
/r/ProshotMusicals - Subreddit for all those theatre obsessed people who want proshots instead of bootlegs to be seen.
castnow - Castnow is a command-line utility that can be used to play back media files on your Chromecast device.
How To Get Everything On Netflix - Posted by /u/huldre99.
iNFekt - A text viewer application that has been carefully designed around its main task: viewing and presenting NFO files.
SceneLinkList - SceneLinkList is a project initiated to display and share as many scene and warez links as possible.
TheTrove - The Trove is a non-profit website dedicated to content archival and long-term preservation of RPGs.

Content Discovery

2160p BluRay Remux List - Complete list of all available 2160p remuxes.
Flox - Flox is a self-hosted movie, series and nime watch list.
IMDb - Find movies, TV shows, celebrities, and more.
JustWatch - On JustWatch you are able to find out where to watch your favorite movies & TV series
Letterboxd - Your life in film, the social network for film lovers.
MetaCritic - website that aggregates reviews of media products: music albums, video games, films, TV shows, and formerly, books.
Movieo - Discover, organize and track over 250,000 movies.
nulled.cc - Warez Scripts and a forum for additional piracy related resources.
popular-movies - Tries to create a list of popular movies based on a series of heuristics
SIMKL - Similar like traktv but offers a Chrome app for Netflix.
Squawkr.io - Sends you a notifications when movies are available for download.
Trakt.tv - A platform that does many things, but primarily keeps track of TV shows and movies you watch.
TVmaze - TVmaze is a community of TV lovers and dedicated contributors that discuss and help maintain TV information on the web.
What is my movie? - AI-powered movie search. ""Use your own words, or search with titles, actors, directors, genres etc. We find movies for you to watch.""
WhereYouWatch - Follow upcoming movies and receive email alerts when they are out online as a download or stream â pirated or via retail.

HTCP

Anonmasky - Anonmasky is a beautiful startpage for geeks out there. Clone of weboas.is.
Heimdall - An Application dashboard and launcher
HTPC-Manager - A fully responsive interface to manage all your favorite software on your Htpc.
iDashboard-PHP - HTPC Dashboard to load website services, written in PHP (predecessor to Organizr)
Logarr - ""Logarr"" is a self-hosted, PHP-based, single-page log consolidation tool which formats and displays log files for easy analysis.
Monitorr - Self-hosted PHP-based web front platform that displays the status of any webapp or service in real time.
Muximux - A lightweight way to manage your HTPC
Organizr - HTPC/Homelab Services Organizer - Written in PHP
weboas.is - Another website for pirates.

Proxy Sites to bypass filters to unblock blocked Websites

ByPassed - ByPassed is an all-in-one solution to unblock censored websites including thepiratebay, kickass, eztv, yts, extratorrent & more.
ProxySite.cc + (Mirror) + (for Videos) - Free web proxy site to bypass filters and unblock blocked websites anonymously.
Unblocked - Proxy site for accessing your favourite blocked sites.

Proxies & alternative Protocols/Networks

cjdns - Cjdns (Caleb James DeLisle's Network Suite) is a networking protocol and reference implementation, founded on the ideology that networks should be easy to set up
Freenet - Freenet is free software which lets you anonymously share files, browse and publish ""freesites"" (web sites accessible only through Freenet) and chat on forums, without fear of censorship.
GnUNet - GNUnet is a framework for secure peer-to-peer networking that does not use any centralized or otherwise trusted services
Psiphon - Run your own server, invite your friends, build a community, provide free and unfiltered Internet access to the world.
Scuttlebutt - A decent(ralised) secure gossip platform that aims to harmonize four perspectives of life: Environment reflecting Technology reflecting Community reflecting Society.
Shadowsocks - A secure socks5 proxy, designed to protect your Internet traffic.

Stream Synchronisation

/r/Movie_Club - Where you can get together with strangers and watch a great movie every week!
&chill - Watch videos with other people, it acts like a video streaming service.
ArconaiTV - Another stream sharing platform with a nice UI.
CyTube - Channel-based shared streaming platform for synchronised viewing of YouTube and Google Drive videos
Netflix Party - Netflix Party is a Chrome extension for watching Netflix remotely with other users.
sync - Node.JS Server and JavaScript/HTML Client for synchronizing online media
SyncLounge - Third party tool that allows you to watch Plex in sync with your friends/family, wherever you are.
watch2gether - Enjoy the internet in sync with your friends. Watch videos, listen to music or go shopping on Watch2Gether.

Secure PasteBin alternatives

PrivateBin - A minimalist, open source online pastebin where the server has zero knowledge of pasted data.
ZeroBin + Tor Mirror & source code

DNS based Ad-Blocking

Pi-hole - Pi-Hole is a Linux network-level advertisement and internet tracker blocking application which acts as a DNS sinkhole.

Emby Servers

/r/EmbyShares - This subreddit is dedicated to the sharing of Emby servers.

URL Shortener

Anon.to - URL shortener to de-referer or null-referer your links.

Premium Link Generators

Deepbrid - 1,3 GB of premium links, a ""pro"" version is also avbl. without any download limits.
Free Rapidleech - Daily updated free premium hoster logins. Be Warned: Fake pages are looking similar!

Hardware Security Token

Adding two factor authentication to KeePass & KeePass2Android
Configure YubiKey with Google, LastPass and KeePass
How to use GPG with YubiKey (bonus: WSL)

Reverse Proxies

bitmitigate.com
blazingfast.io
Cloudflare
ddos-guard.net
Geniusguard.com
puroxy.org
x4b.net

Free graphics

PixelPro.io - Provides free (and paid) graphics for streamers.

SMS

Crypton - Secure SMS Cloud service.
SMS Privacy - Send & recieve SMS securely.

Shared Accounts

/f/SharedAcc - Share and use account logins to preserve your online privacy.

Detecting Fake Torrents

Hide Fake Torrent on ThePirateBay - Browser extension to Hide Fake Torrent on The PirateBay.
Solid Torrents - A torrent index search engine, which checks if the torrent has known ""fake"" seeders/leechers based on a predefined database.
The Pirate Bay Tweaks (based on this script) - Userscript to detect fake TPB uploaders/torrents.

YouTube alternatives

DTube - D.Tube aims to become an alternative to YouTube that allows you to watch or upload videos on IPFS and share or comment about it on STEEM.
Minds - Minds is a open source and decentralized platform for Internet freedom.
PeerTube - A decentralized video hosting network, based on free/libre software.

Telegram Piracy Discussion Channels

@bestwarez - Maybe one of the biggest warez telegram channel.
@DeezerMusicBot - Music bot which downloads tracks from Deezer.
@fullalbums - Full Music Albums.
@iMediaShare - Provides links to Movies, TV shows, apps & and more.
@intermedia - Channel for movies.
@itorrentsearchbot - Searchbot which finds torrent and magnet links on 1337x.to by keyword search
@movies_inc - Another Telegram channel for downloading several movies in different quality.
@Moviezworldz - Official Moviezworldz channel.
@MusicHuntersBot - Another music downloader bot for Telegram.
@piracy - A modest group with over 400 pirates.
@piratebazaar - Telegram Channel which provides warez information, lists & more.
@Qualitymovies - Lots of 720p Blu-Ray movie releases.
@RickyChristanto Chan - Movie releases channel provides usually stuff from YTS.
@SMLoadrCommuntiy - Telegram community for SMLoadr.
@UretPatcherByJasi2169 - The official Uret Android patcher group.
@vkmusic_bot - Find and download pretty much any song (uses vkmusic search engine).
@warez - Yet another warez channel on Telegram.

VPS Hosting Providers

24Shells - Get High performance dedicated servers with cheap unmetered bandwidth and managed server hosting options.
2x4.ru - A fast and reliable russian VPS hoster.
AlexHost.md - Yet another russian VPS hoster service.
CyberHour - Rusian based host provider which allows Warez.
Datasource.ch - Swiss made offshore VPS provider.
Hostkey - Dedicated Servers & more.
KnownSRV.com - They use offshore data centers in Romania, Luxembourg and the Netherlands.
NetEngi - Rent professional web hosting of high quality and cheap price with cPanel.
RapidLeechHost.com - RapidLeechHost only allows warez linking on their offshore plans, using servers based in Netherlands.
SporeStack - Truly Hidden Hosting.
Warez Hosting - Private & Anonymous VPS Hosting!
WebCare360 - Powerful Offshore cpanel shared hosting provider.
WRZHost.com - WrzHost specializes in allowing warez, and acts as a safe-haven for people wanting to start warez-related projects with anonymity. They offer shared hosting, Linux VPSâs and dedicated servers.

Homework

Lit Answers - Find homework answers.
Slader - Find textbooks with answers.

Documents Downloaders

DocDownloader.com - Scribd, Issuu, Slideshare & Academia downloader.

Web Page testing

wptagent - Cross-platform WebPageTest agent which supports allmost all current OS.

Alternative Search Engines

DavidWon.com - An alternative search engine for Reddit, Google etc which comes with pre-defined tags to find some things faster.
Mega.nz Search Engine - A search engine for Mega.nz files.
Search Encrypt - The Privacy Based Search Engine.
Startpage.com - The world's most private search engine.
Jive Search - A search engine that doesn't track you.

Online Video Converter/Ripper

MP3Juices.cc - Free MP3 Downloads.
2conv.com - Convert videos from YouTube in 1 click!
Flvto.biz - YouTube Online Converter for Video/Music.
Facebook Down - Facebook Video Downloader.
Online Video Converter - Free online video conversion tool.
Twitter Video Downloader - Twitter Video Downloader.

Subtitles

Addic7ed - Quality Subtitles for TV Shows and movies.
RenameThemSubs - Rename subtitles files according to TV show names found in a directory.
Subscene - Quality Subtitles for Movies.

",140
decred-proposals/mainnet,None,"politeia
Politeia overview
This is the repository for the Decred Politeia service.
Source Code
https://github.com/decred/politeia
Contact
https://decred.org/community
",6
dejavuzhou/md-genie,Go,"Golang Auto Markdown
Chinese Movie Board


movie_2019-05-12.md


movie_2019-05-11.md


movie_2019-05-10.md


movie_2019-05-09.md


movie_2019-05-08.md


movie_2019-05-07.md


movie_2019-05-06.md


movie_2019-05-05.md


movie_2019-05-04.md


movie_2019-05-03.md


movie_2019-05-02.md


movie_2019-05-01.md


movie_2019-04-30.md


movie_2019-04-29.md


movie_2019-04-28.md


movie_2019-04-27.md


movie_2019-04-26.md


movie_2019-04-25.md


movie_2019-04-24.md


movie_2019-04-23.md


movie_2019-04-22.md


movie_2019-04-21.md


movie_2019-04-20.md


movie_2019-04-19.md


movie_2019-04-18.md


movie_2019-04-17.md


movie_2019-04-16.md


movie_2019-04-15.md


movie_2019-04-14.md


movie_2019-04-13.md


movie_2019-04-12.md


movie_2019-04-11.md


movie_2019-04-10.md


movie_2019-04-09.md


movie_2019-04-08.md


movie_2019-04-07.md


movie_2019-04-06.md


movie_2019-04-05.md


movie_2019-04-04.md


movie_2019-04-03.md


movie_2019-04-02.md


movie_2019-04-01.md


movie_2019-03-31.md


movie_2019-03-30.md


movie_2019-03-29.md


movie_2019-03-28.md


movie_2019-03-27.md


movie_2019-03-26.md


movie_2019-03-25.md


movie_2019-03-24.md


movie_2019-03-23.md


movie_2019-03-22.md


movie_2019-03-21.md


movie_2019-03-20.md


movie_2019-03-19.md


movie_2019-03-18.md


movie_2019-03-17.md


movie_2019-03-16.md


movie_2019-03-15.md


movie_2019-03-14.md


movie_2019-03-13.md


movie_2019-03-12.md


movie_2019-03-11.md


movie_2019-03-10.md


movie_2019-03-09.md


movie_2019-03-08.md


movie_2019-03-07.md


movie_2019-03-06.md


movie_2019-03-05.md


movie_2019-03-04.md


movie_2019-03-03.md


movie_2019-03-02.md


movie_2019-03-01.md


movie_2019-02-28.md


movie_2019-02-27.md


movie_2019-02-26.md


movie_2019-02-25.md


movie_2019-02-24.md


movie_2019-02-23.md


movie_2019-02-22.md


movie_2019-02-21.md


movie_2019-02-20.md


movie_2019-02-19.md


movie_2019-02-18.md


movie_2019-02-17.md


movie_2019-02-16.md


movie_2019-02-15.md


movie_2019-02-14.md


movie_2019-02-13.md


movie_2019-02-12.md


movie_2019-02-11.md


movie_2019-02-10.md


movie_2019-02-09.md


movie_2019-02-08.md


movie_2019-02-07.md


movie_2019-02-06.md


movie_2019-02-05.md


movie_2019-02-04.md


movie_2019-02-03.md


movie_2019-02-02.md


movie_2019-02-01.md


movie_2019-01-31.md


movie_2019-01-30.md


movie_2019-01-29.md


movie_2019-01-28.md


movie_2019-01-27.md


movie_2019-01-26.md


movie_2019-01-25.md


movie_2019-01-24.md


movie_2019-01-23.md


movie_2019-01-22.md


movie_2019-01-21.md


movie_2019-01-20.md


movie_2019-01-19.md


movie_2019-01-18.md


movie_2019-01-17.md


movie_2019-01-16.md


movie_2019-01-15.md


movie_2019-01-14.md


movie_2019-01-13.md


movie_2019-01-12.md


movie_2019-01-11.md


movie_2019-01-10.md


movie_2019-01-09.md


movie_2019-01-08.md


movie_2019-01-07.md


movie_2019-01-06.md


movie_2019-01-05.md


movie_2019-01-04.md


movie_2019-01-03.md


movie_2019-01-02.md


movie_2019-01-01.md


movie_2018-12-31.md


movie_2018-12-30.md


movie_2018-12-29.md


movie_2018-12-28.md


movie_2018-12-27.md


movie_2018-12-26.md


movie_2018-12-25.md


movie_2018-12-24.md


movie_2018-12-23.md


movie_2018-12-22.md


movie_2018-12-21.md


movie_2018-12-20.md


movie_2018-12-19.md


movie_2018-12-18.md


movie_2018-12-17.md


movie_2018-12-16.md


movie_2018-12-15.md


movie_2018-12-14.md


movie_2018-12-13.md


movie_2018-12-12.md


movie_2018-12-11.md


movie_2018-12-10.md


movie_2018-12-09.md


movie_2018-12-08.md


movie_2018-12-07.md


movie_2018-12-06.md


movie_2018-12-05.md


movie_2018-12-04.md


movie_2018-12-03.md


movie_2018-12-02.md


movie_2018-12-01.md


movie_2018-11-30.md


movie_2018-11-29.md


movie_2018-11-28.md


movie_2018-11-27.md


movie_2018-11-26.md


movie_2018-11-25.md


movie_2018-11-24.md


movie_2018-11-23.md


movie_2018-11-22.md


movie_2018-11-21.md


movie_2018-11-20.md


movie_2018-11-19.md


movie_2018-11-18.md


movie_2018-11-17.md


movie_2018-11-16.md


movie_2018-11-15.md


movie_2018-11-14.md


movie_2018-11-13.md


movie_2018-11-12.md


movie_2018-11-11.md


movie_2018-11-10.md


movie_2018-11-09.md


movie_2018-11-08.md


movie_2018-11-07.md


movie_2018-11-06.md


movie_2018-11-05.md


movie_2018-11-04.md


movie_2018-11-03.md


movie_2018-11-02.md


movie_2018-11-01.md


movie_2018-10-31.md


movie_2018-10-30.md


movie_2018-10-29.md


movie_2018-10-28.md


movie_2018-10-27.md


movie_2018-10-26.md


movie_2018-10-25.md


movie_2018-10-24.md


movie_2018-10-23.md


movie_2018-10-22.md


movie_2018-10-21.md


movie_2018-10-20.md


movie_2018-10-19.md


movie_2018-10-18.md


movie_2018-10-17.md


movie_2018-10-16.md


movie_2018-10-15.md


movie_2018-10-14.md


movie_2018-10-13.md


movie_2018-10-12.md


movie_2018-10-11.md


movie_2018-10-10.md


movie_2018-10-09.md


movie_2018-10-08.md


movie_2018-10-07.md


movie_2018-10-06.md


movie_2018-10-05.md


movie_2018-10-04.md


movie_2018-10-03.md


movie_2018-10-02.md


movie_2018-10-01.md


movie_2018-09-30.md


movie_2018-09-29.md


movie_2018-09-28.md


movie_2018-09-27.md


movie_2018-09-26.md


movie_2018-09-25.md


movie_2018-09-24.md


movie_2018-09-23.md


movie_2018-09-22.md


movie_2018-09-21.md


movie_2018-09-20.md


movie_2018-09-19.md


movie_2018-09-16.md


movie_2018-09-15.md


movie_2018-09-14.md


movie_2018-09-13.md


movie_2018-09-10.md


movie_2018-09-09.md


movie_2018-09-08.md


movie_2018-09-07.md


movie_2018-09-06.md


movie_2018-09-05.md


movie_2018-09-04.md


movie_2018-09-03.md


movie_2018-09-02.md


movie_2018-09-01.md


movie_2018-08-31.md


movie_2018-08-30.md


movie_2018-08-29.md


movie_2018-08-28.md


movie_2018-08-27.md


movie_2018-08-26.md


movie_2018-08-25.md


movie_2018-08-24.md


movie_2018-08-23.md


movie_2018-08-22.md


movie_2018-08-21.md


movie_2018-08-20.md


movie_2018-08-19.md


movie_2018-08-18.md


movie_2018-08-17.md


movie_2018-08-16.md


movie_2018-08-15.md


movie_2018-08-14.md


movie_2018-08-13.md


movie_2018-08-12.md


movie_2018-08-11.md


movie_2018-08-10.md


movie_2018-08-09.md


movie_2018-08-08.md


movie_2018-08-07.md


movie_2018-08-06.md


movie_2018-08-05.md


movie_2018-08-04.md


movie_2018-08-03.md


movie_2018-08-02.md


movie_2018-08-01.md


movie_2018-07-31.md


movie_2018-07-30.md


movie_2018-07-29.md


movie_2018-07-28.md


movie_2018-07-27.md


movie_2018-07-26.md


movie_2018-07-25.md


movie_2018-07-24.md


movie_2018-07-23.md


movie_2018-07-22.md


movie_2018-07-21.md


movie_2018-07-20.md


movie_2018-07-19.md


Hack News List


hacknews_2019-05-12.md


hacknews_2019-05-11.md


hacknews_2019-05-10.md


hacknews_2019-05-09.md


hacknews_2019-05-08.md


hacknews_2019-05-07.md


hacknews_2019-05-06.md


hacknews_2019-05-05.md


hacknews_2019-05-04.md


hacknews_2019-05-03.md


hacknews_2019-05-02.md


hacknews_2019-05-01.md


hacknews_2019-04-30.md


hacknews_2019-04-29.md


hacknews_2019-04-28.md


hacknews_2019-04-27.md


hacknews_2019-04-26.md


hacknews_2019-04-25.md


hacknews_2019-04-24.md


hacknews_2019-04-23.md


hacknews_2019-04-22.md


hacknews_2019-04-21.md


hacknews_2019-04-20.md


hacknews_2019-04-19.md


hacknews_2019-04-18.md


hacknews_2019-04-17.md


hacknews_2019-04-16.md


hacknews_2019-04-15.md


hacknews_2019-04-14.md


hacknews_2019-04-13.md


hacknews_2019-04-12.md


hacknews_2019-04-11.md


hacknews_2019-04-10.md


hacknews_2019-04-09.md


hacknews_2019-04-08.md


hacknews_2019-04-07.md


hacknews_2019-04-06.md


hacknews_2019-04-05.md


hacknews_2019-04-04.md


hacknews_2019-04-03.md


hacknews_2019-04-02.md


hacknews_2019-04-01.md


hacknews_2019-03-31.md


hacknews_2019-03-30.md


hacknews_2019-03-29.md


hacknews_2019-03-28.md


hacknews_2019-03-27.md


hacknews_2019-03-26.md


hacknews_2019-03-25.md


hacknews_2019-03-24.md


hacknews_2019-03-23.md


hacknews_2019-03-22.md


hacknews_2019-03-21.md


hacknews_2019-03-20.md


hacknews_2019-03-19.md


hacknews_2019-03-18.md


hacknews_2019-03-17.md


hacknews_2019-03-16.md


hacknews_2019-03-15.md


hacknews_2019-03-14.md


hacknews_2019-03-13.md


hacknews_2019-03-12.md


hacknews_2019-03-11.md


hacknews_2019-03-10.md


hacknews_2019-03-09.md


hacknews_2019-03-08.md


hacknews_2019-03-07.md


hacknews_2019-03-06.md


hacknews_2019-03-05.md


hacknews_2019-03-04.md


hacknews_2019-03-03.md


hacknews_2019-03-02.md


hacknews_2019-03-01.md


hacknews_2019-02-28.md


hacknews_2019-02-27.md


hacknews_2019-02-26.md


hacknews_2019-02-25.md


hacknews_2019-02-24.md


hacknews_2019-02-23.md


hacknews_2019-02-22.md


hacknews_2019-02-21.md


hacknews_2019-02-20.md


hacknews_2019-02-19.md


hacknews_2019-02-18.md


hacknews_2019-02-17.md


hacknews_2019-02-16.md


hacknews_2019-02-15.md


hacknews_2019-02-14.md


hacknews_2019-02-13.md


hacknews_2019-02-12.md


hacknews_2019-02-11.md


hacknews_2019-02-10.md


hacknews_2019-02-09.md


hacknews_2019-02-08.md


hacknews_2019-02-07.md


hacknews_2019-02-06.md


hacknews_2019-02-05.md


hacknews_2019-02-04.md


hacknews_2019-02-03.md


hacknews_2019-02-02.md


hacknews_2019-02-01.md


hacknews_2019-01-31.md


hacknews_2019-01-30.md


hacknews_2019-01-29.md


hacknews_2019-01-28.md


hacknews_2019-01-27.md


hacknews_2019-01-26.md


hacknews_2019-01-25.md


hacknews_2019-01-24.md


hacknews_2019-01-23.md


hacknews_2019-01-22.md


hacknews_2019-01-21.md


hacknews_2019-01-20.md


hacknews_2019-01-19.md


hacknews_2019-01-18.md


hacknews_2019-01-17.md


hacknews_2019-01-16.md


hacknews_2019-01-15.md


hacknews_2019-01-14.md


hacknews_2019-01-13.md


hacknews_2019-01-12.md


hacknews_2019-01-11.md


hacknews_2019-01-10.md


hacknews_2019-01-09.md


hacknews_2019-01-08.md


hacknews_2019-01-07.md


hacknews_2019-01-06.md


hacknews_2019-01-05.md


hacknews_2019-01-04.md


hacknews_2019-01-03.md


hacknews_2019-01-02.md


hacknews_2019-01-01.md


hacknews_2018-12-31.md


hacknews_2018-12-30.md


hacknews_2018-12-29.md


hacknews_2018-12-28.md


hacknews_2018-12-27.md


hacknews_2018-12-26.md


hacknews_2018-12-25.md


hacknews_2018-12-24.md


hacknews_2018-12-23.md


hacknews_2018-12-22.md


hacknews_2018-12-21.md


hacknews_2018-12-20.md


hacknews_2018-12-19.md


hacknews_2018-12-18.md


hacknews_2018-12-17.md


hacknews_2018-12-16.md


hacknews_2018-12-15.md


hacknews_2018-12-14.md


hacknews_2018-12-13.md


hacknews_2018-12-12.md


hacknews_2018-12-11.md


hacknews_2018-12-10.md


hacknews_2018-12-09.md


hacknews_2018-12-08.md


hacknews_2018-12-07.md


hacknews_2018-12-06.md


hacknews_2018-12-05.md


hacknews_2018-12-04.md


hacknews_2018-12-03.md


hacknews_2018-12-02.md


hacknews_2018-12-01.md


hacknews_2018-11-30.md


hacknews_2018-11-29.md


hacknews_2018-11-28.md


hacknews_2018-11-27.md


hacknews_2018-11-26.md


hacknews_2018-11-25.md


hacknews_2018-11-24.md


hacknews_2018-11-23.md


hacknews_2018-11-22.md


hacknews_2018-11-21.md


hacknews_2018-11-20.md


hacknews_2018-11-19.md


hacknews_2018-11-18.md


hacknews_2018-11-17.md


hacknews_2018-11-16.md


hacknews_2018-11-15.md


hacknews_2018-11-14.md


hacknews_2018-11-13.md


hacknews_2018-11-12.md


hacknews_2018-11-11.md


hacknews_2018-11-10.md


hacknews_2018-11-09.md


hacknews_2018-11-08.md


hacknews_2018-11-07.md


hacknews_2018-11-06.md


hacknews_2018-11-05.md


hacknews_2018-11-04.md


hacknews_2018-11-03.md


hacknews_2018-11-02.md


hacknews_2018-11-01.md


hacknews_2018-10-31.md


hacknews_2018-10-30.md


hacknews_2018-10-29.md


hacknews_2018-10-28.md


hacknews_2018-10-27.md


hacknews_2018-10-26.md


hacknews_2018-10-25.md


hacknews_2018-10-24.md


hacknews_2018-10-23.md


hacknews_2018-10-22.md


hacknews_2018-10-21.md


hacknews_2018-10-20.md


hacknews_2018-10-19.md


hacknews_2018-10-18.md


hacknews_2018-10-17.md


hacknews_2018-10-16.md


hacknews_2018-10-15.md


hacknews_2018-10-14.md


hacknews_2018-10-13.md


hacknews_2018-10-12.md


hacknews_2018-10-11.md


hacknews_2018-10-10.md


hacknews_2018-10-09.md


hacknews_2018-10-08.md


hacknews_2018-10-07.md


hacknews_2018-10-06.md


hacknews_2018-10-05.md


hacknews_2018-10-04.md


hacknews_2018-10-03.md


hacknews_2018-10-02.md


hacknews_2018-10-01.md


hacknews_2018-09-30.md


hacknews_2018-09-29.md


hacknews_2018-09-28.md


hacknews_2018-09-27.md


hacknews_2018-09-26.md


hacknews_2018-09-25.md


hacknews_2018-09-24.md


hacknews_2018-09-23.md


hacknews_2018-09-22.md


hacknews_2018-09-21.md


hacknews_2018-09-20.md


hacknews_2018-09-19.md


hacknews_2018-09-16.md


hacknews_2018-09-15.md


hacknews_2018-09-14.md


hacknews_2018-09-13.md


hacknews_2018-09-10.md


hacknews_2018-09-09.md


hacknews_2018-09-08.md


hacknews_2018-09-07.md


hacknews_2018-09-06.md


hacknews_2018-09-05.md


hacknews_2018-09-04.md


hacknews_2018-09-03.md


hacknews_2018-09-02.md


hacknews_2018-09-01.md


hacknews_2018-08-31.md


hacknews_2018-08-30.md


hacknews_2018-08-29.md


hacknews_2018-08-28.md


hacknews_2018-08-27.md


hacknews_2018-08-26.md


hacknews_2018-08-25.md


hacknews_2018-08-24.md


hacknews_2018-08-23.md


hacknews_2018-08-22.md


hacknews_2018-08-21.md


hacknews_2018-08-20.md


hacknews_2018-08-19.md


hacknews_2018-08-18.md


hacknews_2018-08-17.md


hacknews_2018-08-16.md


hacknews_2018-08-15.md


hacknews_2018-08-14.md


hacknews_2018-08-13.md


hacknews_2018-08-12.md


hacknews_2018-08-11.md


hacknews_2018-08-10.md


hacknews_2018-08-09.md


hacknews_2018-08-08.md


hacknews_2018-08-07.md


hacknews_2018-08-06.md


hacknews_2018-08-05.md


hacknews_2018-08-04.md


hacknews_2018-08-03.md


hacknews_2018-08-02.md


hacknews_2018-08-01.md


hacknews_2018-07-31.md


hacknews_2018-07-30.md


hacknews_2018-07-29.md


hacknews_2018-07-28.md


hacknews_2018-07-27.md


hacknews_2018-07-26.md


hacknews_2018-07-25.md


hacknews_2018-07-24.md


hacknews_2018-07-23.md


hacknews_2018-07-22.md


hacknews_2018-07-21.md


hacknews_2018-07-20.md


Feature

 Sendimg Logging Message To Dingding Talk
 Golang Redis Package Feature
 Xpath Selector By Golang
 Golang Html/Template
 Golang Executes Git Command

Github Project Created By Eric Zhou

 Golang Base64 Captcha
 Generating Hacknews Maoyan-Movie-Board Markdown Automatically èªå¨çæHacknewsæ°é»
 çæ´»å¤§çç¸-è°¢å°é¡¿-åªåç³å¤´å¸-ç¾åº¦æºè½é³ç®±
 Golang Beegoç½ç« mojotv.cn
 ä½¿ç¨goæ ååº,logä¿¡æ¯å°ééç¾¤
 Forked from fogleman/primitiveå¢å mp4å¯¼åºåè½
 Golang Ginæ¡æ¶RESTful APIsé¡¹ç®
 go+phantomjsç½é¡µå¾çæªåå¾®æå¡
 Python Scrapy+MongoDB+cnbetaç¬è«æ ·æ¿
 Golang Geolocation Ipè½¬æ¢å°çå¸

",2
eagleoflqj/p1a3_script,JavaScript,"p1a3_script
ä¸äº©ä¸åå°çæ²¹ç´èæ¬
å®è£
èªå¨ï¼æ¨èï¼
ç¹å»æ²¹ç´å¾æ ->ç®¡çé¢æ¿ï¼é¡µé¢ä¸­ç¹å»å®ç¨å·¥å·ï¼å¨URLææ¬æ¡è¾å¥æºç å°åï¼ç¹å»å¯¼å¥
æå¨ï¼ä¸æ¨èï¼
ç¹å»æ²¹ç´å¾æ ->æ·»å æ°èæ¬ï¼ç²è´´p1a3_script.jsçæºç ï¼Ctrl+S
æ´æ°
ä¸ºä¿è¯ç¨æ·ä½éªè¯·åæ¶æ´æ°
èªå¨
è¥èªå¨å®è£ï¼åå¯ç¹å»æ²¹ç´å¾æ ->ç¨æ·èæ¬æ£æ¥æ´æ°
æå¨
åæå¨å®è£
åè½
è®ºå
èªå¨ç­¾å°
éè¦ä½ ç»å®å¾®ä¿¡
å®ä½è´´åå½åæ±æ¥è´´
èªå¨æ¥çå­¦æ ¡ãä¸ç»´
éè¦ä½ æè¶³å¤çç§¯å
å½åæ±æ¥ç
èªå¨æå å½åæ±æ¥çè§
éè¦ä½ èªè§éµå®
è®°å½ä¸æ¬¡çå½åæ±æ¥ç­éæ¡ä»¶
éç½®ç­éæ¡ä»¶
Doing
èªå¨ç­é¢
é¢åºç»´æ¤ä¸­ï¼ç®åå±æ29é¢
æåç­é¢æé¢ç®ä¸å¨é¢åºï¼consoleä¼ææç¤º
",8
kabir-shah/conode,HTML,"Conode
Collaborative project-based learning tool for programming.
Authors

Kabir Shah
Oleg Bychenkov
Jared Smith

Contributing

Make a new branch.
$ git checkout -b my-branch


Make changes and commit them.
$ git add .
$ git commit -m ""Commit message""


Push changes to your branch.
$ git push origin my-branch


Create a pull request on GitHub, and select the base branch as master and the compare branch as my-branch.
Wait for your changes to be approved and merged.

",3
tari/warcdedupe,Rust,"warcdedupe: a tool for deduplicating WARC files.
Given an input WARC file, output a copy with duplicate response records
rewritten to be revisit records pointing to the first instance of that response
in the same file.
Future improvements

More speed. Faster decompression (flate2 is faster than libflate for
decompression), parallel reading/parsing with some kind of exotic buffer
(or possibly iobuf).

",3
peachfuzz/spu2you,JavaScript,"Version Control Plan:
Currently we have two branches: dev branch and master branch. Our plan is to create 4 branches off of the dev branch for each team member, to ensure that we can each make commits without disrupting each other's work. Everyone will be working on separate project components so that we don't create rebasing issues. There is a rule in place that won't allow any members make a merge to a branch without another member reviewing the code first. Every member is responsible for fixing any rebasing issues they create. This helps to prevent merge conflicts.
All members are required to use concise but descriptive commit messages. Each message should clearly describe the changes that were made, as fits within the character count.
This project was bootstrapped with Create React App.
Available Scripts
In the project directory, you can run:
npm start
You will need to run
npm install nodemon -g

nodemon will run the node app and when it detects a change in the file, it will restart the server. No more ctrl+c and npm start manually!
npm run build
Builds the app for production to the build folder.
It correctly bundles React in production mode and optimizes the build for the best performance.
The build is minified and the filenames include the hashes.
Your app is ready to be deployed!
See the section about deployment for more information.

services: active-directory
platforms: nodejs
author: brandwe

Securing a web API with Azure AD
This Node.js server will give you a quick and easy way to set up a REST API Service using the OAuth2 protocol. Then this service is integrated with Azure Active Directory for API protection. The sample server included in the download is designed to run on any platform.
This REST API server is built using Restify and MongoDB with the following features:

A node.js server running an REST API interface with JSON using MongoDB as persistent storage
REST APIs leveraging OAuth2 API protection for endpoints using Azure Active Directory

We've released all of the source code for this example in GitHub under an Apache 2.0 license, so feel free to clone (or even better, fork!) and provide feedback on the forums.
Quick Start

[!Note] If you want to run this sample on Azure Government, navigate to the ""Azure Government Deviations"" section at the bottom of this page.

Getting started with the sample is easy. It is configured to run out of the box with minimal setup.
Step 1: Register a Azure AD Tenant
To use this sample you will need a Azure Active Directory Tenant. If you're not sure what a tenant is or how you would get one, read What is an Azure AD tenant? or Sign up for Azure as an organization. These docs should get you started on your way to using Azure AD.
Step 2: Register your Web API with your Azure AD Tenant
After you get your Azure AD tenant, add this sample app to your tenant so you can use it to protect your API endpoints. If you need help with this step, see: Register the REST API Service Azure Active Directory
Step 3: Download node.js for your platform
To successfully use this sample, you need a working installation of Node.js.
Install Node.js from http://nodejs.org.
Step 4: Install MongoDB on to your platform
To successfully use this sample, you must have a working installation of MongoDB. We will use MongoDB to make our REST API persistent across server instances.
Install MongoDB from http://mongodb.org.
NOTE: This walkthrough assumes that you use the default installation and server endpoints for MongoDB, which at the time of this writing is: mongodb://localhost. This should work locally without any configuration changes if you run this sample on the same machine as you've installed and ran mongodb.
Step 5: Download the Sample application and modules
Next, clone the sample repo and install the NPM.
From your shell or command line:

$ git clone https://github.com/Azure-Samples/active-directory-node-webapi.git
$ cd node-server
$ npm install

Step 6: Configure your server using config.js
You will need to update the sample to use your values for the metadata endpoint.
NOTE: If you wish to accept multiple tenants for this app, you'll want to use the common endpoint and you'll need to pass the issuer: and audience: value if you wish to validate that as well.
Step 7: Run the application

$ cd node-server
$ node app.js

Is the server output hard to understand?: We use bunyan for logging in this sample. The console won't make much sense to you unless you also install bunyan and run the server like above but pipe it through the bunyan binary:

$ npm install -g bunyan
$ node app.js | bunyan

You're done!
You will have a server successfully running on http://localhost:3000. Your REST / JSON API Endpoint will be http://localhost:3000/tasks
Azure Active Directory OIDC Web Sample



Library
Docs
Support
Protocol



This sample demonstrates how to set up OpenId Connect authentication in a web application built using Node.js with Express. The sample is designed to run on any platform.
Prerequisites
To run this sample you will need the following:


Install Node.js from http://nodejs.org/


An Azure AD tenant. If you're not sure what a tenant is or how you would get one, read How to get an Azure AD tenant.


Register the sample in your Azure AD tenant


Sign in to the Azure portal.


On the top bar, click on your account, and then on Switch Directory. Once the Directory + subscription pane opens, choose the Active Directory tenant where you wish to register your application.


Click on All services in the left-hand nav, and choose Azure Active Directory.


Click on App registrations and choose New application registration.


Enter a friendly name for the application, for example 'Webapp-Openidconnect' and select 'Web app / API' as the Application Type.


For the sign-on URL, enter the base URL for this sample which is http://localhost:3000/.


Click Create to create the application.


In the succeeding page, Find the Application ID value and record it for later. You'll need it to configure the client ID in the application.


Under Settings, choose Properties and update the App ID URI which is a unique identifier for your app. It is of the format 'https://<your_tenant_name>/<app_name>' replacing <your_tenant_name> with the name of your Azure AD tenant. For example: https://contoso.onmicrosoft.com/Webapp-Openidconnect


Under Settings, click on Reply URLs and set it to http://localhost:3000/auth/openid/return which this sample uses by default.


From the Settings menu, choose Keys and add a new entry in the Password section:

Type a key description (for instance 'app secret'),
Select a key duration of either In 1 year, In 2 years, or Never Expires.
When you save this page, the key value will be displayed. Copy, and save the value in a safe location.
You'll need this key later to configure the client secret in the app. This key value will not be displayed again, nor retrievable by any other means, so record it as soon as it is visible from the Azure portal.



Download the sample application and modules
Next, clone the sample repo and install the NPM modules.
From your shell or command line run:

$ git clone git@github.com:AzureADQuickStarts/WebApp-OpenIDConnect-NodeJS.git

or

$ git clone https://github.com/AzureADQuickStarts/WebApp-OpenIDConnect-NodeJS.git

From the project root directory, run the command:

$ npm install

Configure the application
Provide the parameters in exports.creds in config.js as instructed.

Update <tenant_name> in exports.identityMetadata with the Azure AD tenant name of the format *.onmicrosoft.com.
Update exports.clientID with the Application Id noted from app registration.
Update exports.clientSecret with the Application key noted from app registration.
Update exports.redirectUrl with the Reply URL noted from app registration.

Optional configuration for production apps:


Update exports.destroySessionUrl in config.js, if you want to use a different post_logout_redirect_uri.


Set exports.useMongoDBSessionStore in config.js to true, if you want to use use mongoDB or other compatible session stores.
The default session store in this sample is express-session. Note that the default session store is not suitable for production.


Update exports.databaseUri, if you want to use mongoDB session store and a different database URI.


Update exports.mongoDBSessionMaxAge. Here you can specify how long you want to keep a session in mongoDB. The unit is second(s).


Build and run the application


Start mongoDB service. If you are using mongoDB session store in this app, you have to install mongoDB and start the service first. If you are using the default session store, you can skip this step.


Run the app using the following command from your command line.
$ node app.js



Is the server output hard to understand?: We use bunyan for logging in this sample. The console won't make much sense to you unless you also install bunyan and run the server like above but pipe it through the bunyan binary:
$ npm install -g bunyan

$ node app.js | bunyan

You're done!
You will have a server successfully running on http://localhost:3000.
Community Help and Support
We use Stack Overflow with the community to provide support. We highly recommend you ask your questions on Stack Overflow first and browse existing issues to see if someone has asked your question before. Make sure that your questions or comments are tagged with [azure-active-directory].
If you find a bug or issue with this sample, please raise the issue on GitHub Issues.
For issues with the passport-azure-ad library, please raise the issue on the library GitHub repo.
Contributing
If you'd like to contribute to this sample, please follow the GitHub Fork and Pull request model.
This project has adopted the Microsoft Open Source Code of Conduct. For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments.
Security Library
This library controls how users sign-in and access services. We recommend you always take the latest version of our library in your app when possible.
Security Reporting
If you find a security issue with our libraries or services please report it to secure@microsoft.com with as much detail as possible. Your submission may be eligible for a bounty through the Microsoft Bounty program. Please do not post security issues to GitHub Issues or any other public site. We will contact you shortly upon receiving the information. We encourage you to get notifications of when security incidents occur by visiting this page and subscribing to Security Advisory Alerts.
Acknowledgements
We would like to acknowledge the folks who own/contribute to the following projects for their support of Azure Active Directory and their libraries that were used to build this sample. In places where we forked these libraries to add additional functionality, we ensured that the chain of forking remains intact so you can navigate back to the original package. Working with such great partners in the open source community clearly illustrates what open collaboration can accomplish. Thank you!
About The Code
Copyright (c) Microsoft Corporation. All rights reserved. Licensed under the MIT License (the ""License"");
",4
PureDarwin/PureDarwin,Shell,"PureDarwin 

PureDarwin moved from https://code.google.com/p/puredarwin/
Darwin is the Open Source operating system from Apple that forms the basis for Mac OS X and PureDarwin. PureDarwin is a community project that aims to make Darwin more usable (some people think of it as the informal successor to OpenDarwin).
One current goal of this project is to provide a useful bootable ISO/VM of Darwin 10.x
Come Join our forum over at https:www.pd-devs.org/
See the Wiki for more information.
",739
DerWaldi/ReadMyStuff,Jupyter Notebook,"ReadMyStuff
Install Retinanet
cd main_pipeline
git clone https://github.com/fizyr/keras-retinanet.git
cd keras-retinanet/
pip install .
python setup.py build_ext --inplace

",2
Pokecube-Development/Pokecube-Core,Java,"Pokecube-Core
This is the core section of Pokecube, it contains the main framework needed for the Real-Time battle system and the automatic mob registry
Related/Contained projects
Contains a modifed version of NBTEdit which is currently used for debugging purposes.
Tabula Model loading code is a modified version of the one used for Showcase.
Contains JEP by Nathan Funk and Richard Morris for use with spawn logic, lisence here
",3
gosuri/uiprogress,Go,"uiprogress  
A Go library to render progress bars in terminal applications. It provides a set of flexible features with a customizable API.

Progress bars improve readability for terminal applications with long outputs by providing a concise feedback loop.
Features

Multiple Bars: uiprogress can render multiple progress bars that can be tracked concurrently
Dynamic Addition:  Add additional progress bars any time, even after the progress tracking has started
Prepend and Append Functions: Append or prepend completion percent and time elapsed to the progress bars
Custom Decorator Functions: Add custom functions around the bar along with helper functions

Usage
To start listening for progress bars, call uiprogress.Start() and add a progress bar using uiprogress.AddBar(total int). Update the progress using bar.Incr() or bar.Set(n int). Full source code for the below example is available at example/simple/simple.go
uiprogress.Start()            // start rendering
bar := uiprogress.AddBar(100) // Add a new bar

// optionally, append and prepend completion and elapsed time
bar.AppendCompleted()
bar.PrependElapsed()

for bar.Incr() {
  time.Sleep(time.Millisecond * 20)
}
This will render the below in the terminal

Using Custom Decorators
You can also add a custom decorator function in addition to default bar.AppendCompleted() and bar.PrependElapsed() decorators. The below example tracks the current step for an application deploy progress. Source code for the below example is available at example/full/full.go
var steps = []string{""downloading source"", ""installing deps"", ""compiling"", ""packaging"", ""seeding database"", ""deploying"", ""staring servers""}
bar := uiprogress.AddBar(len(steps))

// prepend the current step to the bar
bar.PrependFunc(func(b *uiprogress.Bar) string {
  return ""app: "" + steps[b.Current()-1]
})

for bar.Incr() {
  time.Sleep(time.Millisecond * 10)
}
Rendering Multiple bars
You can add multiple bars using uiprogress.AddBar(n). The below example demonstrates updating multiple bars concurrently and adding a new bar later in the pipeline. Source for this example is available at example/multi/multi.go
waitTime := time.Millisecond * 100
uiprogress.Start()

// start the progress bars in go routines
var wg sync.WaitGroup

bar1 := uiprogress.AddBar(20).AppendCompleted().PrependElapsed()
wg.Add(1)
go func() {
  defer wg.Done()
  for bar1.Incr() {
    time.Sleep(waitTime)
  }
}()

bar2 := uiprogress.AddBar(40).AppendCompleted().PrependElapsed()
wg.Add(1)
go func() {
  defer wg.Done()
  for bar2.Incr() {
    time.Sleep(waitTime)
  }
}()

time.Sleep(time.Second)
bar3 := uiprogress.AddBar(20).PrependElapsed().AppendCompleted()
wg.Add(1)
go func() {
  defer wg.Done()
  for i := 1; i <= bar3.Total; i++ {
    bar3.Set(i)
    time.Sleep(waitTime)
  }
}()

// wait for all the go routines to finish
wg.Wait()
This will produce

Incr counter
Bar.Incr() is an atomic counter and can be used as a general tracker, making it ideal for tracking progress of work fanned out to a lots of go routines. The source code for the below example is available at example/incr/incr.go
runtime.GOMAXPROCS(runtime.NumCPU()) // use all available cpu cores

// create a new bar and prepend the task progress to the bar and fanout into 1k go routines
count := 1000
bar := uiprogress.AddBar(count).AppendCompleted().PrependElapsed()
bar.PrependFunc(func(b *uiprogress.Bar) string {
  return fmt.Sprintf(""Task (%d/%d)"", b.Current(), count)
})

uiprogress.Start()
var wg sync.WaitGroup

// fanout into go routines
for i := 0; i < count; i++ {
  wg.Add(1)
  go func() {
    defer wg.Done()
    time.Sleep(time.Millisecond * time.Duration(rand.Intn(500)))
    bar.Incr()
  }()
}
time.Sleep(time.Second) // wait for a second for all the go routines to finish
wg.Wait()
uiprogress.Stop()
Installation
$ go get -v github.com/gosuri/uiprogress
Todos

 Resize bars and decorators by auto detecting window's dimensions
 Handle more progress bars than vertical screen allows

License
uiprogress is released under the MIT License. See LICENSE.
",1261
JiejayLan/CSC322_group_project,JavaScript,"Report and Documents
visit our Wiki Page

Getting started
I. clone repo
II. setup local and remote branch
III. using npm or yarn to install all dependencies on your machine
IV. setup .env.development and .env.test by heading to console of firebase

create .env.development and .env.test at root of project folder
open console of firebase
click Mini-eByMazon and click </>
setup key-value pair inside .env.development in following format

    FIREBASE_API=values copy from firebase without double quotes
    FIREBASE_AUTH_DOMAIN=values copy from firebase without double quotes
    FIREBASE_DATABASE_URL=values copy from firebase without double quotes
    FIREBASE_PROJECT_ID=values copy from firebase without double quotes
    FIREBASE_STORAGE_BUCKET=values copy from firebase without double quotes
    FIREBASE_MESSAGING_SENDER_ID=values copy from firebase without double quotes


click Mini-eByMazon Test and click </>
setup key-value pair inside .env.test in the same format in step 4 with values for Mini-eByMazon Test


Suggested Tools
React Developer Tools and Redux DevTools installed for Google Chrome

How to login
For login page, you dont't need to enter any username or password, because I set up a corrrect default username(""jay"") and password(""123"") in login-page react state.

Suggestion for development

""npm run deve"" for development //still can't set up the reload package to reload the page automatically
put component and pages into different folders
don't connet to firebase from client side.You should add a route controller on the server folder. You can take a look at how I write the login page

",4
ad-fidelitas/ctf-admin-website,Vue,"ctf-admin-website
Project setup
npm install

Compiles and hot-reloads for development
npm run serve

Compiles and minifies for production
npm run build

Run your tests
npm run test

Lints and fixes files
npm run lint

Customize configuration
See Configuration Reference.
",2
Tobybsmith/falppy_bird,Processing,"falppy_bird
",2
Pttn/rieMiner,Assembly,"rieMiner 0.9
rieMiner is a Riecoin miner supporting both solo and pooled mining. It was originally adapted and refactored from gatra's cpuminer-rminerd (https://github.com/gatra/cpuminer-rminerd) and dave-andersen's fastrie (https://github.com/dave-andersen/fastrie), though there is no remaining code from rminerd anymore.
Solo mining is done using the GetBlockTemplate protocol, while pooled mining is via the Stratum protocol. A benchmark mode is also proposed to compare more easily the performance between different computers.
Direct links to the latest official Windows x64 and Win32 standalone executables. Binaries built on Debian 9 with almost complete static linking also available (these should run on fresh Debian and Ubuntu installations): Deb64 and Deb32. Also note that 32 bits builds are much slower.
This README serves as manual for rieMiner, and you can also find a PDF version (without build instructions). I hope that this program will be useful for you!
The Riecoin community thanks you for your participation, you will be a contributor to the robustness of the Riecoin network. Happy mining!

I provide a Profitability Calculator here.
Minimum requirements
Only x64 systems with SSE are supported.

Windows 7 or later, or recent enough Linux;
x64 CPU with SSE instruction set;
1 GiB of RAM (the prime table limit must be manually set at a lower value in the options).

Recommended:

Windows 10 or Debian 9;
Intel Core i7 6700 or better, or AMD Ryzen R5 1600 or better;
8 GiB of RAM.

Compile this program
In Debian/Ubuntu x64
You can compile this C++ program with g++, as, m4 and make, install them if needed. Then, get if needed the following dependencies:

Jansson
cURL
libSSL
GMP

On a recent enough Debian or Ubuntu, you can easily install these by doing as root:
apt install g++ make m4 git libjansson-dev libcurl4-openssl-dev libssl-dev libgmp-dev
Then, just download the source files, go/cd to the directory, and do a simple make:
git clone https://github.com/Pttn/rieMiner.git
cd rieMiner
make
For other Linux, executing equivalent commands (using pacman instead of apt,...) should work.
If you get a warning after the compilation that there may be a conflict between libcrypto.so files, install libssl1.0-dev instead of libssl-dev.
In Windows x64
You can compile rieMiner in Windows, and here is one way to do this. First, install MSYS2 (follow the instructions on the website), then enter in the MSYS MinGW-w64 console, and install the tools and dependencies:
pacman -S make git
pacman -S mingw64/mingw-w64-x86_64-gcc
pacman -S mingw64/mingw-w64-x86_64-curl
Note that you must install the mingw64/mingw-w64-x86_64-... packages and not just gcc or curl.
Clone rieMiner with git like for Linux, go to its directory with cd, and compile with make.
Static building
The produced executable will only run in the MSYS console, or if all the needed DLLs are next to the executable. To obtain a standalone executable, you need to link statically the dependencies. Unfortunately, libcurl will give you a hard time, and you need to compile it yourself.
First, download the latest official libcurl code on their website, under ""Source Archives"", and decompress the folder somewhere (for example, next to the rieMiner's one).
In the MSYS MinGW-w64 console, cd to the libcurl directory. We will now configure it to not build unused features, then compile it:
./configure --disable-dict --disable-file --disable-ftp --disable-gopher --disable-imap --disable-ldap --disable-ldaps --disable-pop3 --disable-rtsp --disable-smtp --disable-telnet --disable-tftp --without-ssl --without-libssh2 --without-zlib --without-brotli --without-libidn2  --without-ldap  --without-ldaps --without-rtsp --without-psl --without-librtmp --without-libpsl --without-nghttp2 --disable-shared --disable-libcurl-option
make
Once done:

Create ""incs"" and ""libs"" folders in the rieMiner directory;
In the downloaded libcurl directory, go to the include directory and copy the ""curl"" folder to the ""incs"" folder;
Do the same with the file ""libcurl.a"" from the libs/.lib folder to the rieMiner's ""libs"" folder.

Now, you should be able to compile rieMiner with make static and produce a standalone executable.
Run and configure this program
You can finally run the newly created rieMiner executable using
./rieMiner
If no ""rieMiner.conf"" next to the executable was found, you will be assisted to configure rieMiner. Answer to its questions to start mining. If there is a ""rieMiner.conf"" file next to the executable with incorrect information that was read, you can delete this to get the assistant.
Alternatively, you can create or edit this ""rieMiner.conf"" file next to the executable yourself, in order to provide options to the miner. The rieMiner.conf syntax is very simple: each option is given by a line such
Option type = Option value

It is case sensitive, but spaces and invalid lines are ignored. A line starting with ""#"" will also be ignored. Do not put ; at the end or use other delimiters than = for each line, and do not confuse rieMiner.conf with riecoin.conf! If an option is missing, the default value(s) will be used. If there are duplicate lines, the last one will be used. Here is a sample configuration file for solo mining, with comments explaining the main available options.
# Mining mode: Solo for solo mining via GetBlockTemplate, Pool for pooled mining using Stratum, Benchmark for testing. Default: Benchmark
Mode = Solo

# IP and port of the Riecoin wallet/server or pool. Default: 127.0.0.1 (your computer), port 28332 (default port for Riecoin-Qt)
Host = 127.0.0.1
Port = 28332

# Username and password used to connect to the server (same as rpcuser and rpcpassword in riecoin.conf for solo mining).
# If using Stratum, the username includes the worker name (username.worker). Default: empty values
Username = user
Password = /70P$â¬CRâ¬7/

# Custom payout address for solo mining (GetBlockTemplate only). Default: this donation address
PayoutAddress = RPttnMeDWkzjqqVp62SdG2ExtCor9w54EB

# Number of threads used for mining. Default: 8
Threads = 8

# The prime table used for mining will contain primes up to the given number.
# Use a bigger limit if you have 16 GiB of available RAM or more, as this will reduce the ratio between the n-tuple and (n + 1)-tuple counts (but also the 1-tuple find rate).
# Reduce if you have less than 8 GiB of RAM (or if you want to reduce memory usage).
# It can go up to 2^64 - 1, but setting this at more than 2^33 will usually be too much and decrease performance. Default: 2^31
PrimeTableLimit = 2147483648

# Refresh rate of the stats in seconds. 0 to disable them and only notify when a long enough tuple or share is found, or when the network finds a block. Default: 30
RefreshInterval = 60

# For solo mining, submit not only blocks (6-tuples) but also k-tuples of at least the given length.
# Additionally, the base prime of such tuple will be shown in the Benchmark Mode. Default: 6
TupleLengthMin = 4

# For solo mining, add consensus rules in the GetBlockTemplate RPC call, each separated by a comma.
# Useful for softforks, for example, to mine SegWit transactions, you would need the following line. Default: no rule
# Rules = segwit

# Other options
# BenchmarkDifficulty = 1600
# BenchmarkTimeLimit = 0
# Benchmark2tupleCountLimit = 100000
# SieveBits = 25
# SieveWorkers = 0
# ConstellationType = 0, 4, 2, 4, 2, 4
# PrimorialNumber = 40
# PrimorialOffsets = 4209995887, 4209999247, 4210002607, 4210005967, 7452755407, 7452758767, 7452762127, 7452765487, 8145217177, 8145220537, 8145223897, 8145227257
# Debug = 0

It is also possible to use custom configuration file paths, examples:
./rieMiner config/example.txt
./rieMiner ""config 2.conf""
./rieMiner /home/user/rieMiner/rieMiner.conf
Benchmark Mode options

BenchmarkDifficulty : sets the testing difficulty (must be from 265 to 32767). Default: 1600;
BenchmarkTimeLimit : sets the testing duration in s. 0 for no time limit. Default: 0;
Benchmark2tupleCountLimit : stops testing after finding this number of 2-tuples. 0 for no limit. Default: 50000.

Advanced/Tweaking/Dev options
They can be useful to get better performance depending on your computer.

SieveBits : size of the segment sieve is 2^SieveBits bits, e.g. 25 means the segment sieve size is 4 MiB. Choose this so that SieveWorkers*SieveBits fits in your L3 cache. Default: 25;
SieveWorkers : the number of threads to use for sieving. Increasing it may solve some CPU underuse problems, but will use more memory. 0 for choosing automatically based on number of Threads and PrimeTableLimit. Default: 0.

These ones should never be modified outside developing purposes and research for now.

ConstellationType : set your Constellation Type, i. e. the primes tuple offsets, each separated by a comma. Default: 0, 4, 2, 4, 2, 4 (values for Riecoin mining);
PrimorialNumber : Primorial Number for the Wheel Factorization. Default: 40;
PrimorialOffsets : list of Offsets from the Primorial for the first number in the prime tuple. Same syntax as ConsType. Default: carefully chosen offsets;
Debug : activate Debug Mode: rieMiner will print a lot of debug messages. Set to 1 to enable, 0 to disable. Other values may introduce some more specific debug messages. Default : 0.

Some possible constellations types (format: (type) -> offsets to put for ConstellationType ; 3 first constellations (n + 0) which can be used for PrimorialOffsets, though some might not work)

5-tuples

(0, 2, 6,  8, 12) -> 0, 2, 4, 2, 4 ; 5, 11, 101,...
(0, 4, 6, 10, 12) -> 0, 4, 2, 4, 2 ; 7, 97, 1867,...


6-tuples

(0, 4, 6, 10, 12, 16) -> 0, 4, 2, 4, 2, 4 (Riecoin) ; 7, 97, 16057,...


7-tuples

(0, 2, 6,  8, 12, 18, 20) -> 0, 2, 4, 2, 4, 6, 2 ; 11, 165701, 1068701,...
(0, 2, 8, 12, 14, 18, 20) -> 0, 2, 6, 4, 2, 4, 2 ; 5639, 88799, 284729,...


8-tuples

(0, 2, 6,  8, 12, 18, 20, 26) -> 0, 2, 4, 2, 4, 6, 2, 6 ; 11, 15760091, 25658441,...
(0, 2, 6, 12, 14, 20, 24, 26) -> 0, 2, 4, 6, 2, 6, 4, 2 ; 17, 1277, 113147,...
(0, 6, 8, 14, 18, 20, 24, 26) -> 0, 6, 2, 6, 4, 2, 4, 2 ; 88793, 284723, 855713,...



Also see the constellationsGen tool in my rieTools repository (https://github.com/Pttn/rieTools).
Memory problems
If you have memory errors (Unable to allocate... or Bad Allocs), try to lower the PrimeTableLimit value in the configuration file.
Statistics
rieMiner will regularly print some stats, and the frequency of this can be changed with the RefreshInterval parameter as said earlier.
For solo mining, rieMiner will regularly show the primes per second speed, and the 1 to 2-tuples/s ratio. From this, it will also estimate the average time to find a block (note that all the ratios are the same, and the estimation should be fairly precise). Of course, even if the average time to find a block is for example 2 days, you could find a block in the next hour as you could find nothing during a week. The number of 2 to 6-tuples found since the start of the mining is also shown.
For pooled mining, the shares per minute metric and the numbers of valid and total shares are shown instead. As it is hard to get a correct earnings estimation from k-shares, no other metric is shown. The Benchmark Mode (or solo mining) can be used to get better figures for comparisons.
rieMiner will also notify if it found a k-tuple (k >= Tuples option value) in solo mining or a share in pooled mining, and if the network found a new block. If it finds a block or a share, it will tell if the submission was accepted (solo mining only) or not. For solo mining, if the block was accepted, the reward will be generated for the address specified in the options. You can then spend it after 100 confirmations. Note that orphaned blocks will be shown as accepted.
Solo mining specific information
Note that other ways for solo mining (protocol proxies,...) were never tested with rieMiner. It was written specifically for the official wallet and the existing Riecoin pools.
Configure the Riecoin wallet for solo mining
We assume that Riecoin Core is already working and synced. To solo mine with it, you have to configure it.

Find the riecoin.conf configuration file. It should be located in /home/username/.riecoin or equivalent in Windows;
Do not confuse this file with the rieMiner.conf!
An example of riecoin.conf content suitable for mining is

rpcuser=(username)
rpcpassword=(password)
rpcport=28332
port=28333
rpcallowip=127.0.0.1
server=1
daemon=1

If you feel the need, you can add more nodes manually with connect=(nodeip), (nodeip) after connect being a node's IP. You can find a list of the nodes connected the last 24 h here: https://chainz.cryptoid.info/ric/#!network.
If you wish to mine from another computer, add another rpcallowip=ip.of.the.computer, or else the connection will be refused. Choose a username and a password and replace (username) and (password).
Work control
You might have to wait some consequent time before finding a block. What if something is actually wrong and then the time the miner finally found a block, the submission fails?
First, if for some reason rieMiner disconnects from the wallet (you killed it or its computer crashed), it will detect that it has not received the mining data and then just stop mining: so if it is currently mining, everything should be fine.
If you are worried about the fact that the block will be incorrectly submitted, here comes the TupleLengthMin option. Indeed, you can send invalid blocks to the wallet (after all, it is yours), and check if the wallet actually received them and if these submissions are properly processed. When such invalid block is submitted, you can check the debug.log file in the same location as riecoin.conf, and then, you should see something like
ERROR: CheckProofOfWork() : n+10 not prime

Remember that the miner searches numbers n such that n, n + 2, n + 6, n + 10, n + 12 and n + 16 are prime, so if you set the TupleLengthMin option to for example 3, rieMiner will submit a n such that n, n + 2 and n + 6 are prime, but not necessarily the other numbers, so you can conclude that the wallet successfully decoded the submission here, and that everything works fine. If you see nothing or another error message, then something is wrong (possible example would be an unstable overclock)...
Also watch regularly if the wallet is correctly syncing, especially if the message Blockheight = ... did not appear since a very long time (except if the network is mining the superblock). In Riecoin-Qt, this can be done by hovering the check at the lower right corner, and comparing the number with the latest block found in a Riecoin explorer. If something is wrong, try to change the nodes in riecoin.conf or check your connection.
Pooled mining specific information
Existing pools:

XPoolX

Host = mining.xpoolx.com
Port = 5000
Owner: xpoolx - info@xpoolx.com
They also support Solo mining via Stratum with a 5% fee


uBlock.it

Host = mine.ublock.it or mine.blockocean.com
Port = 5000
Owner: ziiip - netops.ublock.it@gmail.com



The miner will disconnect if it did not receive anything during 3 minutes (time out).
Benchmarking
rieMiner provides a way to test the performance of a computer, and compare with others. This feature can also be used to appreciate the improvements when trying to improve the miner algorithm. When sharing benchmark results, you must always communicate the difficulty, the prime table limit (PTL), the test duration, the CPU model, the memory speeds (frequency and CL), the miner version, and the OS. Also, do not forget to precise if you changed other options, like the SieveWorkers or Bits.
To compare two different platforms or settings, you must absolutely test with the same difficulty, during enough time. The proposed parameters, conditions and interpretations for serious benchmarking are:

Standard Benchmark

Difficulty of 1600;
PTL of 2^31 = 2147483648;
No time limit;
Stop after finding 50000 2-tuples or more;
The computer must not do anything else during testing;
The system must not swap. Else, the result would not make much sense. Ensure that you have enough memory when benchmarking.



The test will be fairly long, but similar to the real mining conditions. Once the benchmark finished itself (not by the user), it will print something like:
100000 2-tuples found, test finished. rieMiner 0.9, difficulty 1600, PTL 2147483648
BENCHMARK RESULTS: 233.354130 primes/s with ratio 28.955020 -> 0.990626 block(s)/day

Generally speaking, the block(s)/day metric is the one that should be shared or used to compare performance, though it is always good to also take in consideration the other ones. Moreover, for a given difficulty and PTL, the ratio should be the same, and the more precise primes/day metric can be used instead for comparisons.
The precision will be about 2 significant digits for the block(s)/day. To get 3 solid digits, about 1 million of 2-tuples would need to be found, which would be way too long to be practical for the Standard Benchmark.
A run with valid parameters for the Standard Benchmark will additionally print the message
VALID parameters for Standard Benchmark

Which should appear if you want to share your results.
You could stop before 50000 2-tuples, for example at 10000, if you just want a rough estimation of the performance. However, even after this long, the values are often still very imprecise, and can lead to confusion, like a slightly slower computer getting better results. This remark is critical for people wanting to optimize the miner.
A few results
Done with rieMiner 0.9, 100000 2-tuples except otherwise said. Unit: primes/s

AMD Ryzen R7 2700X @4 GHz, DDR4 3200 CL14, Debian 9: 235.856209
AMD Ryzen R7 2700X @4 GHz, DDR4 2400 CL15, Debian 9: 233.354130
AMD Ryzen R7 2700X @3 GHz, DDR4 2400 CL15, Debian 9: 177.234506
Intel Core i7 6700K @3 GHz, DDR4 2400 CL15, Debian 9: 89.288621
Intel Core 2 Quad Q9650 @3 GHz, DDR3 1067 CL6, Debian 9: 40.673097
Intel Pentium D 925 @3 GHz, DDR3 1000 CL6, Debian 9: 7.466797 (10000 2-tuples)

As said, we should use the primes/s metric for fixed difficulty and PTL. The ratio for the Standard Benchmark is about 28.9.
For a given architecture, the performance is basically proportional to the number of cores and frequency. However, we notice that much better RAM doesn't really matter.
Miscellaneous
Unless the weather is very cold, I do not recommend to overclock a CPU for mining, unless you can do that without increasing noticeably the power consumption. My 2700X computer would draw much, much more power at 4 GHz/1.2875 V instead of 3.7 GHz/1.08125 V, which is certainly absurd for a mere 8% increase. To get maximum efficiency, you might want to find the frequency with the best performance/power consumption ratio (which could also be obtained by underclocking the processor).
If you can, try to undervolt the CPU to reduce power consumption, heat and noise.
Developers and license

Pttn, author and maintainer, contact: dev at Pttn dot me

Parts coming from other projects and libraries are subject to their respective licenses. Else, this work is released under the MIT license. See the LICENSE or top of source files for details.
Notable contributors

Michael Bell: assembly optimizations, improvements of work management between threads, and some more.

Versioning
The version naming scheme is 0.9, 0.99, 0.999 and so on for major versions, analogous to 1.0, 2.0, 3.0,.... The first non 9 decimal digit is minor, etc. For example, the version 0.9925a can be thought as 2.2.5a. A perfect bug-free software will be version 1. No precise criteria have been decided about incrementing major or minor versions for now.
Contributing
Feel free to do a pull request or open an issue, and I will review it. I am open for adding new features, but I also wish to keep this project minimalist. Any useful contribution will be welcomed.
By contributing to rieMiner, you accept to place your code in the MIT license.
Donations welcome:

Bitcoin: 1PttnMeD9X6imTsRojmhHa1rjudW8Bjok5
Riecoin: RPttnMeDWkzjqqVp62SdG2ExtCor9w54EB
Gapcoin: GgCyVr6y6beBbTofmTLJHvGc1NCWynQyvw
Ethereum: 0x32de6b854b6a05448b4f25d4496990bece8a2862

Quick contributor's checklist

Your code must compile and work on recent Debian based distributions, and Windows using MSYS;
If modifying the miner, you must ensure that your changes do not cause any performance loss. You have to do proper and long enough before/after benchmarks;
rieMiner must work for any realistic setting, at least try these in the Benchmark Mode (and do some actual mining):

Difficulty 304, PTL 2^20 (Testnet mining conditions);
Difficulty 800, PTL 2^27;
Difficulty 1600, PTL 2^31 (Standard Benchmark, similar to real mining conditions);
Difficulty 3200, PTL 2^31 or more (we will eventually reach such Difficulties someday...).


Ensure that your changes did not break anything, even if it compiles. Examples (if applicable):

There should never be random (or not) segmentation faults or any other bug, try to do actual mining with Gdb, debugging symbols and Debug Mode enabled during hours or even days to catch possible bugs;
Ensure that valid work is produced (pools and Riecoin-Qt must not reject submissions);
Mining must stop completely while disconnected and restart properly when connection is established again.


Follow the style of the rest of the code (curly braces position, camelCase variable names, tabs and not spaces, spaces around + and - but not around * and /,...).

Resources

rieMiner thread on Riecoin-Community.com forum
My personal website about Riecoin
Get the Riecoin wallet
Fast prime cluster search - or building a fast Riecoin miner (part 1), nice article by dave-andersen explaining how Riecoin works and how to build an efficient miner and the algorithms. Unfortunately, he never published part 2...
Riecoin FAQ and technical aspects
Bitcoin Wiki - Getblocktemplate
BIP141 (Segwit)
Bitcoin Wiki - Stratum

",2
vinta/awesome-python,Python,"Awesome Python 
A curated list of awesome Python frameworks, libraries, software and resources.
Inspired by awesome-php.

Awesome Python

Admin Panels
Algorithms and Design Patterns
Audio
Authentication
Build Tools
Built-in Classes Enhancement
Caching
ChatOps Tools
CMS
Code Analysis
Command-line Tools
Compatibility
Computer Vision
Concurrency and Parallelism
Configuration
Cryptography
Data Analysis
Data Validation
Data Visualization
Database Drivers
Database
Date and Time
Debugging Tools
Deep Learning
DevOps Tools
Distributed Computing
Distribution
Documentation
Downloader
E-commerce
Editor Plugins and IDEs
Email
Environment Management
Files
Foreign Function Interface
Forms
Functional Programming
Game Development
Geolocation
GUI
Hardware
HTML Manipulation
HTTP
Image Processing
Implementations
Interactive Interpreter
Internationalization
Job Scheduler
Logging
Machine Learning
Miscellaneous
Natural Language Processing
Network Virtualization
Networking
News Feed
ORM
Package Management
Package Repositories
Permissions
Processes
Queue
Recommender Systems
RESTful API
Robotics
RPC Servers
Science
Search
Serialization
Serverless Frameworks
Specific Formats Processing
Static Site Generator
Tagging
Template Engine
Testing
Text Processing
Third-party APIs
URL Manipulation
Video
Web Asset Management
Web Content Extracting
Web Crawling & Web Scraping
Web Frameworks
WebSocket
WSGI Servers


Services

Code Quality
Continuous Integration


Resources

Podcasts
Twitter
Websites
Weekly


Other Awesome Lists
Contributing


Admin Panels
Libraries for administrative interfaces.

ajenti - The admin panel your servers deserve.
django-grappelli - A jazzy skin for the Django Admin-Interface.
django-suit - Alternative Django Admin-Interface (free only for Non-commercial use).
django-xadmin - Drop-in replacement of Django admin comes with lots of goodies.
flask-admin - Simple and extensible administrative interface framework for Flask.
flower - Real-time monitor and web admin for Celery.
wooey - A Django app which creates automatic web UIs for Python scripts.

Algorithms and Design Patterns
Python implementation of algorithms and design patterns.

algorithms - Minimal examples of data structures and algorithms in Python.
PyPattyrn - A simple yet effective library for implementing common design patterns.
python-patterns - A collection of design patterns in Python.
sortedcontainers - Fast, pure-Python implementation of SortedList, SortedDict, and SortedSet types.

Audio
Libraries for manipulating audio and its metadata.

Audio

audioread - Cross-library (GStreamer + Core Audio + MAD + FFmpeg) audio decoding.
dejavu - Audio fingerprinting and recognition.
mingus - An advanced music theory and notation package with MIDI file and playback support.
pyAudioAnalysis - Python Audio Analysis Library: Feature Extraction, Classification, Segmentation and Applications
pydub - Manipulate audio with a simple and easy high level interface.
TimeSide - Open web audio processing framework.


Metadata

beets - A music library manager and MusicBrainz tagger.
eyeD3 - A tool for working with audio files, specifically MP3 files containing ID3 metadata.
mutagen - A Python module to handle audio metadata.
tinytag - A library for reading music meta data of MP3, OGG, FLAC and Wave files.



Authentication
Libraries for implementing authentications schemes.

OAuth

authlib - JavaScript Object Signing and Encryption draft implementation.
django-allauth - Authentication app for Django that ""just works.""
django-oauth-toolkit - OAuth 2 goodies for Django.
oauthlib - A generic and thorough implementation of the OAuth request-signing logic.
python-oauth2 - A fully tested, abstract interface to creating OAuth clients and servers.
python-social-auth - An easy-to-setup social authentication mechanism.


JWT

pyjwt - JSON Web Token implementation in Python.
python-jose - A JOSE implementation in Python.
python-jwt - A module for generating and verifying JSON Web Tokens.



Build Tools
Compile software from source code.

BitBake - A make-like build tool for embedded Linux.
buildout - A build system for creating, assembling and deploying applications from multiple parts.
PlatformIO - A console tool to build code with different development platforms.
pybuilder - A continuous build tool written in pure Python.
SCons - A software construction tool.

Built-in Classes Enhancement
Libraries for enhancing Python built-in classes.

dataclasses - (Python standard library) Data classes.
attrs - Replacement for __init__, __eq__, __repr__, etc. boilerplate in class definitions.
bidict - Efficient, Pythonic bidirectional map data structures and related functionality..
Box - Python dictionaries with advanced dot notation access.
DottedDict - A library that provides a method of accessing lists and dicts with a dotted path notation.

CMS
Content Management Systems.

wagtail - A Django content management system.
django-cms - An Open source enterprise CMS based on the Django.
feincms - One of the most advanced Content Management Systems built on Django.
Kotti - A high-level, Pythonic web application framework built on Pyramid.
mezzanine - A powerful, consistent, and flexible content management platform.
plone - A CMS built on top of the open source application server Zope.
quokka - Flexible, extensible, small CMS powered by Flask and MongoDB.

Caching
Libraries for caching data.

beaker - A WSGI middleware for sessions and caching.
django-cache-machine - Automatic caching and invalidation for Django models.
django-cacheops - A slick ORM cache with automatic granular event-driven invalidation.
dogpile.cache - dogpile.cache is next generation replacement for Beaker made by same authors.
HermesCache - Python caching library with tag-based invalidation and dogpile effect prevention.
pylibmc - A Python wrapper around the libmemcached interface.
python-diskcache - SQLite and file backed cache backend with faster lookups than memcached and redis.

ChatOps Tools
Libraries for chatbot development.

errbot - The easiest and most popular chatbot to implement ChatOps.

Code Analysis
Tools of static analysis, linters and code quality checkers. See: awesome-static-analysis.

Code Analysis

coala - Language independent and easily extendable code analysis application.
code2flow - Turn your Python and JavaScript code into DOT flowcharts.
prospector - A tool to analyse Python code.
pycallgraph - A library that visualises the flow (call graph) of your Python application.


Code Linters

flake8 - A wrapper around pycodestyle, pyflakes and McCabe.
pylint - A fully customizable source code analyzer.
pylama - A code audit tool for Python and JavaScript.
Code Formatters
black - The uncompromising Python code formatter.
yapf - Yet another Python code formatter from Google.


Static Type Checkers

mypy - Check variable types during compile time.
pyre-check - Performant type checking.


Static Type Annotations Generators

MonkeyType - A system for Python that generates static type annotations by collecting runtime types



Command-line Tools
Libraries for building command-line application.

Command-line Application Development

cement - CLI Application Framework for Python.
click - A package for creating beautiful command line interfaces in a composable way.
cliff - A framework for creating command-line programs with multi-level commands.
clint - Python Command-line Application Tools.
docopt - Pythonic command line arguments parser.
python-fire - A library for creating command line interfaces from absolutely any Python object.
python-prompt-toolkit - A library for building powerful interactive command lines.


Terminal Rendering

asciimatics - A package to create full-screen text UIs (from interactive forms to ASCII animations).
bashplotlib - Making basic plots in the terminal.
colorama - Cross-platform colored terminal text.


Productivity Tools

cookiecutter - A command-line utility that creates projects from cookiecutters (project templates).
doitlive - A tool for live presentations in the terminal.
howdoi - Instant coding answers via the command line.
PathPicker - Select files out of bash output.
percol - Adds flavor of interactive selection to the traditional pipe concept on UNIX.
thefuck - Correcting your previous console command.
tmuxp - A tmux session manager.
try - A dead simple CLI to try out python packages - it's never been easier.


CLI Enhancements

httpie - A command line HTTP client, a user-friendly cURL replacement.
kube-shell - An integrated shell for working with the Kubernetes CLI.
mycli - A Terminal Client for MySQL with AutoCompletion and Syntax Highlighting.
pgcli - Postgres CLI with autocompletion and syntax highlighting.
saws - A Supercharged aws-cli.



Compatibility
Libraries for migrating from Python 2 to 3.

python-future - The missing compatibility layer between Python 2 and Python 3.
python-modernize - Modernizes Python code for eventual Python 3 migration.
six - Python 2 and 3 compatibility utilities.

Computer Vision
Libraries for computer vision.

OpenCV - Open Source Computer Vision Library.
pytesseract - Another wrapper for Google Tesseract OCR.
SimpleCV - An open source framework for building computer vision applications.

Concurrency and Parallelism
Libraries for concurrent and parallel execution. See awesome-asyncio.

concurrent.futures - (Python standard library) A high-level interface for asynchronously executing callables.
multiprocessing - (Python standard library) Process-based parallelism.
eventlet - Asynchronous framework with WSGI support.
gevent - A coroutine-based Python networking library that uses greenlet.
uvloop - Ultra fast implementation of asyncio event loop on top of libuv.
scoop - Scalable Concurrent Operations in Python.

Configuration
Libraries for storing and parsing configuration options.

configobj - INI file parser with validation.
configparser - (Python standard library) INI file parser.
profig - Config from multiple formats with value conversion.
python-decouple - Strict separation of settings from code.

Cryptography

cryptography - A package designed to expose cryptographic primitives and recipes to Python developers.
paramiko - A Python (2.6+, 3.3+) implementation of the SSHv2 protocol, providing both client and server functionality.
passlib - Secure password storage/hashing library, very high level.
pynacl - Python binding to the Networking and Cryptography (NaCl) library.

Data Analysis
Libraries for data analyzing.

Blaze - NumPy and Pandas interface to Big Data.
Open Mining - Business Intelligence (BI) in Pandas interface.
Orange - Data mining, data visualization, analysis and machine learning through visual programming or scripts.
Pandas - A library providing high-performance, easy-to-use data structures and data analysis tools.
Optimus - Cleansing, pre-processing, feature engineering, exploratory data analysis and easy Machine Learning with a PySpark backend.

Data Validation
Libraries for validating data. Used for forms in many cases.

Cerberus - A lightweight and extensible data validation library.
colander - Validating and deserializing data obtained via XML, JSON, an HTML form post.
Dash - Built on top of Flask, React and Plotly aimed at analytical web applications.

awesome-dash


jsonschema - An implementation of JSON Schema for Python.
schema - A library for validating Python data structures.
Schematics - Data Structure Validation.
valideer - Lightweight extensible data validation and adaptation library.
voluptuous - A Python data validation library.

Data Visualization
Libraries for visualizing data. See: awesome-javascript.

Altair - Declarative statistical visualization library for Python.
Bokeh - Interactive Web Plotting for Python.
bqplot - Interactive Plotting Library for the Jupyter Notebook
ggplot - Same API as ggplot2 for R.
Matplotlib - A Python 2D plotting library.
Pygal - A Python SVG Charts Creator.
PyGraphviz - Python interface to Graphviz.
PyQtGraph - Interactive and realtime 2D/3D/Image plotting and science/engineering widgets.
Seaborn - Statistical data visualization using Matplotlib.
VisPy - High-performance scientific visualization based on OpenGL.

Database
Databases implemented in Python.

pickleDB - A simple and lightweight key-value store for Python.
tinydb - A tiny, document-oriented database.
ZODB - A native object database for Python. A key-value and object graph database.

Database Drivers
Libraries for connecting and operating databases.

MySQL - awesome-mysql

mysqlclient - MySQL connector with Python 3 support (mysql-python fork).
PyMySQL - A pure Python MySQL driver compatible to mysql-python.


PostgreSQL - awesome-postgres

psycopg2 - The most popular PostgreSQL adapter for Python.
queries - A wrapper of the psycopg2 library for interacting with PostgreSQL.


Other Relational Databases

pymssql - A simple database interface to Microsoft SQL Server.


NoSQL Databases

cassandra-driver - The Python Driver for Apache Cassandra.
happybase - A developer-friendly library for Apache HBase.
kafka-python - The Python client for Apache Kafka.
py2neo - Python wrapper client for Neo4j's restful interface.
pymongo - The official Python client for MongoDB.
redis-py - The Python client for Redis.


Asynchronous Clients

motor - The async Python driver for MongoDB.
Telephus - Twisted based client for Cassandra.
txpostgres - Twisted based asynchronous driver for PostgreSQL.
txRedis - Twisted based client for Redis.



Date and Time
Libraries for working with dates and times.

Chronyk - A Python 3 library for parsing human-written times and dates.
dateutil - Extensions to the standard Python datetime module.
delorean - A library for clearing up the inconvenient truths that arise dealing with datetimes.
moment - A Python library for dealing with dates/times. Inspired by Moment.js.
Pendulum - Python datetimes made easy.
PyTime - A easy-use Python module which aims to operate date/time/datetime by string.
pytz - World timezone definitions, modern and historical. Brings the tz database into Python.
when.py - Providing user-friendly functions to help perform common date and time actions.
maya - Datetimes for Humans, Maya is mostly built around the headaches and use-cases around parsing datetime data from websites.

Debugging Tools
Libraries for debugging code.

pdb-like Debugger

ipdb - IPython-enabled pdb.
pdb++ - Another drop-in replacement for pdb.
pudb - A full-screen, console-based Python debugger.
wdb - An improbable web debugger through WebSockets.


Tracing

lptrace - strace for Python programs.
manhole - Debug service that will accept unix domain socket connections and present the stacktraces for all threads and an interactive prompt.
pyringe - Debugger capable of attaching to and injecting code into Python processes.
python-hunter - A flexible code tracing toolkit.


Profiler

line_profiler - Line-by-line profiling.
memory_profiler - Monitor Memory usage of Python code.
profiling - An interactive Python profiler.
py-spy - A sampling profiler for Python programs. Written in Rust.
pyflame - A ptracing profiler For Python.
vprof - Visual Python profiler.


Others

icecream - Inspect variables, expressions, and program execution with a single, simple function call.
django-debug-toolbar - Display various debug information for Django.
django-devserver - A drop-in replacement for Django's runserver.
flask-debugtoolbar - A port of the django-debug-toolbar to flask.
pyelftools - Parsing and analyzing ELF files and DWARF debugging information.



Deep Learning
Frameworks for Neural Networks and Deep Learning. See: awesome-deep-learning.

caffe - A fast open framework for deep learning..
keras - A high-level neural networks library and capable of running on top of either TensorFlow or Theano.
mxnet - A deep learning framework designed for both efficiency and flexibility.
pytorch - Tensors and Dynamic neural networks in Python with strong GPU acceleration.
SerpentAI - Game agent framework. Use any video game as a deep learning sandbox.
tensorflow - The most popular Deep Learning framework created by Google.
Theano - A library for fast numerical computation.

DevOps Tools
Software and libraries for DevOps.

ansible - A radically simple IT automation platform.
cloudinit - A multi-distribution package that handles early initialization of a cloud instance.
cuisine - Chef-like functionality for Fabric.
docker-compose - Fast, isolated development environments using Docker.
fabric - A simple, Pythonic tool for remote execution and deployment.
fabtools - Tools for writing awesome Fabric files.
honcho - A Python clone of Foreman, for managing Procfile-based applications.
OpenStack - Open source software for building private and public clouds.
pexpect - Controlling interactive programs in a pseudo-terminal like GNU expect.
psutil - A cross-platform process and system utilities module.
saltstack - Infrastructure automation and management system.
supervisor - Supervisor process control system for UNIX.

Distributed Computing
Frameworks and libraries for Distributed Computing.

Batch Processing

PySpark - Apache Spark Python API.
dask - A flexible parallel computing library for analytic computing.
luigi - A module that helps you build complex pipelines of batch jobs.
mrjob - Run MapReduce jobs on Hadoop or Amazon Web Services.
Ray - A system for parallel and distributed Python that unifies the machine learning ecosystem.


Stream Processing

faust - A stream processing library, porting the ideas from Kafka Streams to Python.
streamparse - Run Python code against real-time streams of data via Apache Storm.



Distribution
Libraries to create packaged executables for release distribution.

dh-virtualenv - Build and distribute a virtualenv as a Debian package.
Nuitka - Compile scripts, modules, packages to an executable or extension module.
py2app - Freezes Python scripts (Mac OS X).
py2exe - Freezes Python scripts (Windows).
PyInstaller - Converts Python programs into stand-alone executables (cross-platform).
pynsist - A tool to build Windows installers, installers bundle Python itself.

Documentation
Libraries for generating project documentation.

sphinx - Python Documentation generator.

awesome-sphinxdoc


pdoc - Epydoc replacement to auto generate API documentation for Python libraries.
pycco - The literate-programming-style documentation generator.

Downloader
Libraries for downloading.

s3cmd - A command line tool for managing Amazon S3 and CloudFront.
s4cmd - Super S3 command line tool, good for higher performance.
you-get - A YouTube/Youku/Niconico video downloader written in Python 3.
youtube-dl - A small command-line program to download videos from YouTube.

E-commerce
Frameworks and libraries for e-commerce and payments.

alipay - Unofficial Alipay API for Python.
Cartridge - A shopping cart app built using the Mezzanine.
django-oscar - An open-source e-commerce framework for Django.
django-shop - A Django based shop system.
merchant - A Django app to accept payments from various payment processors.
money - Money class with optional CLDR-backed locale-aware formatting and an extensible currency exchange solution.
python-currencies - Display money format and its filthy currencies.
forex-python - Foreign exchange rates, Bitcoin price index and currency conversion.
saleor - An e-commerce storefront for Django.
shoop - An open source E-Commerce platform based on Django.

Editor Plugins and IDEs

Emacs

elpy - Emacs Python Development Environment.


Sublime Text

anaconda - Anaconda turns your Sublime Text 3 in a full featured Python development IDE.
SublimeJEDI - A Sublime Text plugin to the awesome auto-complete library Jedi.


Vim

jedi-vim - Vim bindings for the Jedi auto-completion library for Python.
python-mode - An all in one plugin for turning Vim into a Python IDE.
YouCompleteMe - Includes Jedi-based completion engine for Python.


Visual Studio

PTVS - Python Tools for Visual Studio.


Visual Studio Code

Python - An extension with rich support for the Python language, with features including linting, IntelliSense, formatting, refactoring, debugging, unit tests, and jupyter support.


IDE

PyCharm - Commercial Python IDE by JetBrains. Has free community edition available.
spyder - Open Source Python IDE.



Email
Libraries for sending and parsing email.

envelopes - Mailing for human beings.
flanker - A email address and Mime parsing library.
imbox - Python IMAP for Humans.
inbox.py - Python SMTP Server for Humans.
lamson - Pythonic SMTP Application Server.
Marrow Mailer - High-performance extensible mail delivery framework.
modoboa - A mail hosting and management platform including a modern and simplified Web UI.
Nylas Sync Engine - Providing a RESTful API on top of a powerful email sync platform.
yagmail - Yet another Gmail/SMTP client.

Environment Management
Libraries for Python version and environment management.

pipenv - Sacred Marriage of Pipfile, Pip, & Virtualenv.
poetry - Python dependency management and packaging made easy.
pyenv - Simple Python version management.
venv - (Python standard library in Python 3.3+) Creating lightweight virtual environments.
virtualenv - A tool to create isolated Python environments.

Files
Libraries for file manipulation and MIME type detection.

mimetypes - (Python standard library) Map filenames to MIME types.
path.py - A module wrapper for os.path.
pathlib - (Python standard library) An cross-platform, object-oriented path library.
PyFilesystem2 - Python's filesystem abstraction layer.
python-magic - A Python interface to the libmagic file type identification library.
Unipath - An object-oriented approach to file/directory operations.
watchdog - API and shell utilities to monitor file system events.

Foreign Function Interface
Libraries for providing foreign function interface.

cffi - Foreign Function Interface for Python calling C code.
ctypes - (Python standard library) Foreign Function Interface for Python calling C code.
PyCUDA - A Python wrapper for Nvidia's CUDA API.
SWIG - Simplified Wrapper and Interface Generator.

Forms
Libraries for working with forms.

Deform - Python HTML form generation library influenced by the formish form generation library.
django-bootstrap3 - Bootstrap 3 integration with Django.
django-bootstrap4 - Bootstrap 4 integration with Django.
django-crispy-forms - A Django app which lets you create beautiful forms in a very elegant and DRY way.
django-remote-forms - A platform independent Django form serializer.
WTForms - A flexible forms validation and rendering library.

Functional Programming
Functional Programming with Python.

Coconut - Coconut is a variant of Python built for simple, elegant, Pythonic functional programming.
CyToolz - Cython implementation of Toolz: High performance functional utilities.
fn.py - Functional programming in Python: implementation of missing features to enjoy FP.
funcy - A fancy and practical functional tools.
Toolz - A collection of functional utilities for iterators, functions, and dictionaries.

GUI
Libraries for working with graphical user interface applications.

curses - Built-in wrapper for ncurses used to create terminal GUI applications.
Eel - Little library for making simple Electron-like offline HTML/JS GUI apps, with full access to Python capabilities and libraries.
enaml - Creating beautiful user-interfaces with Declaratic Syntax like QML.
Flexx - Flexx is a pure Python toolkit for creating GUI's, that uses web technology for its rendering.
Gooey - Turn command line programs into a full GUI application with one line.
kivy - A library for creating NUI applications, running on Windows, Linux, Mac OS X, Android and iOS.
pyglet - A cross-platform windowing and multimedia library for Python.
PyGObject - Python Bindings for GLib/GObject/GIO/GTK+ (GTK+3).
PyQt - Python bindings for the Qt cross-platform application and UI framework, with support for both Qt v4 and Qt v5 frameworks.
PySide - Python bindings for the Qt cross-platform application and UI framework, supporting the Qt v4 framework.
PySimpleGUI - Wrapper for tkinter, Qt, WxPython and Remi that creates a unified, easy to understand & more Python-like interface for beginner and intermediate level custom GUIs.
pywebview - A lightweight cross-platform native wrapper around a webview component that allows to display HTML content in its own native dedicated window.
Tkinter - Tkinter is Python's de-facto standard GUI package.
Toga - A Python native, OS native GUI toolkit.
urwid - A library for creating terminal GUI applications with strong support for widgets, events, rich colors, etc.
wxPython - A blending of the wxWidgets C++ class library with the Python.

Game Development
Awesome game development libraries.

Cocos2d - cocos2d is a framework for building 2D games, demos, and other graphical/interactive applications. It is based on pyglet.
Harfang3D - Python framework for 3D, VR and game development. Manage and display complex 3D scenes, with physics, video, sound and music, access VR devices. All written in C++.
Panda3D - 3D game engine developed by Disney and maintained by Carnegie Mellon's Entertainment Technology Center. Written in C++, completely wrapped in Python.
Pygame - Pygame is a set of Python modules designed for writing games.
PyOgre - Python bindings for the Ogre 3D render engine, can be used for games, simulations, anything 3D.
PyOpenGL - Python ctypes bindings for OpenGL and it's related APIs.
PySDL2 - A ctypes based wrapper for the SDL2 library.
RenPy - A Visual Novel engine.

Geolocation
Libraries for geocoding addresses and working with latitudes and longitudes.

django-countries - A Django app that provides country choices for use with forms, flag icons static files, and a country field for models.
GeoDjango - A world-class geographic web framework.
GeoIP - Python API for MaxMind GeoIP Legacy Database.
geojson - Python bindings and utilities for GeoJSON.
geopy - Python Geocoding Toolbox.
pygeoip - Pure Python GeoIP API.

HTML Manipulation
Libraries for working with HTML and XML.

BeautifulSoup - Providing Pythonic idioms for iterating, searching, and modifying HTML or XML.
bleach - A whitelist-based HTML sanitization and text linkification library.
cssutils - A CSS library for Python.
html5lib - A standards-compliant library for parsing and serializing HTML documents and fragments.
lxml - A very fast, easy-to-use and versatile library for handling HTML and XML.
MarkupSafe - Implements a XML/HTML/XHTML Markup safe string for Python.
pyquery - A jQuery-like library for parsing HTML.
untangle - Converts XML documents to Python objects for easy access.
WeasyPrint - A visual rendering engine for HTML and CSS that can export to PDF.
xmldataset - Simple XML Parsing.
xmltodict - Working with XML feel like you are working with JSON.

HTTP
Libraries for working with HTTP.

grequests - requests + gevent for asynchronous HTTP requests.
httplib2 - Comprehensive HTTP client library.
requests - HTTP Requests for Humansâ¢.
treq - Python requests like API built on top of Twisted's HTTP client.
urllib3 - A HTTP library with thread-safe connection pooling, file post support, sanity friendly.

Hardware
Libraries for programming with hardware.

ino - Command line toolkit for working with Arduino.
keyboard - Hook and simulate global keyboard events on Windows and Linux.
mouse - Hook and simulate global mouse events on Windows and Linux.
Pingo - Pingo provides a uniform API to program devices like the Raspberry Pi, pcDuino, Intel Galileo, etc.
PyUserInput - A module for cross-platform control of the mouse and keyboard.
scapy - A brilliant packet manipulation library.
wifi - A Python library and command line tool for working with WiFi on Linux.

Image Processing
Libraries for manipulating images.

hmap - Image histogram remapping.
imgSeek - A project for searching a collection of images using visual similarity.
nude.py - Nudity detection.
pagan - Retro identicon (Avatar) generation based on input string and hash.
pillow - Pillow is the friendly PIL fork.
pyBarcode - Create barcodes in Python without needing PIL.
pygram - Instagram-like image filters.
python-qrcode - A pure Python QR Code generator.
Quads - Computer art based on quadtrees.
scikit-image - A Python library for (scientific) image processing.
thumbor - A smart imaging service. It enables on-demand crop, re-sizing and flipping of images.
wand - Python bindings for MagickWand, C API for ImageMagick.

Implementations
Implementations of Python.

CLPython - Implementation of the Python programming language written in Common Lisp.
CPython - Default, most widely used implementation of the Python programming language written in C.
Cython - Optimizing Static Compiler for Python. Uses type mixins to compile Python into C or C++ modules resulting in large performance gains
Grumpy - More compiler than interpreter as more powerful CPython2.7 replacement (alpha).
IronPython - Implementation of the Python programming language written in C# targeting the .NET Framework and Mono.
Jython - Implementation of Python programming language written in Java for the Java virtual machine (JVM).
MicroPython - MicroPython - a lean and efficient Python programming language implementation for microcontrollers and constrained systems
Numba - Python JIT compiler to LLVM aimed at scientific Python.
PeachPy - x86-64 assembler embedded in Python. Can be used as inline assembler for Python or as a stand-alone assembler for Windows, Linux, OS X, Native Client and Go.
Pyjion - A JIT for Python based upon CoreCLR.
PyPy - Implementation of the Python programming language written in RPython and translated into C. PyPy focuses on speed, efficiency and compatibility with the original CPython interpreter. The interpreter uses black magic to make Python very fast without having to add in additional type information.
PySec - Hardened version of python that makes it easier for security professionals and developers to write applications more resilient to attacks and manipulations.
Pyston - A Python implementation built using LLVM and modern JIT techniques with the goal of achieving good performance.
Stackless Python - An enhanced version of the Python programming language which allows programmers to reap the benefits of thread-based programming without the performance and complexity problems associated with conventional threads.

Interactive Interpreter
Interactive Python interpreters (REPL).

bpython - A fancy interface to the Python interpreter.
Jupyter Notebook (IPython) - A rich toolkit to help you make the most out of using Python interactively.

awesome-jupyter


ptpython - Advanced Python REPL built on top of the python-prompt-toolkit.

Internationalization
Libraries for working with i18n.

Babel - An internationalization library for Python.
PyICU - A wrapper of International Components for Unicode C++ library (ICU).

Job Scheduler
Libraries for scheduling jobs.

APScheduler - A light but powerful in-process task scheduler that lets you schedule functions.
django-schedule - A calendaring app for Django.
doit - A task runner and build tool.
gunnery - Multipurpose task execution tool for distributed systems with web-based interface.
Joblib - A set of tools to provide lightweight pipelining in Python.
Plan - Writing crontab file in Python like a charm.
schedule - Python job scheduling for humans.
Spiff - A powerful workflow engine implemented in pure Python.
TaskFlow - A Python library that helps to make task execution easy, consistent and reliable.
Airflow - Airflow is a platform to programmatically author, schedule and monitor workflows.

Logging
Libraries for generating and working with logs.

Eliot - Logging for complex & distributed systems.
logbook - Logging replacement for Python.
logging - (Python standard library) Logging facility for Python.
raven - Python client for Sentry, a log/error tracking, crash reporting and aggregation platform for web applications.

Machine Learning
Libraries for Machine Learning. See: awesome-machine-learning.

H2O - Open Source Fast Scalable Machine Learning Platform.
Metrics - Machine learning evaluation metrics.
NuPIC - Numenta Platform for Intelligent Computing.
scikit-learn - The most popular Python library for Machine Learning.
Spark ML - Apache Spark's scalable Machine Learning library.
vowpal_porpoise - A lightweight Python wrapper for Vowpal Wabbit.
xgboost - A scalable, portable, and distributed gradient boosting library.

Microsoft Windows
Python programming on Microsoft Windows.

Python(x,y) - Scientific-applications-oriented Python Distribution based on Qt and Spyder.
pythonlibs - Unofficial Windows binaries for Python extension packages.
PythonNet - Python Integration with the .NET Common Language Runtime (CLR).
PyWin32 - Python Extensions for Windows.
WinPython - Portable development environment for Windows 7/8.

Miscellaneous
Useful libraries or tools that don't fit in the categories above.

blinker - A fast Python in-process signal/event dispatching system.
boltons - A set of pure-Python utilities.
itsdangerous - Various helpers to pass trusted data to untrusted environments.
pluginbase - A simple but flexible plugin system for Python.
tryton - A general purpose business framework.

Natural Language Processing
Libraries for working with human languages.

General

gensim - Topic Modelling for Humans.
langid.py - Stand-alone language identification system.
nltk - A leading platform for building Python programs to work with human language data.
pattern - A web mining module for the Python.
polyglot - Natural language pipeline supporting hundreds of languages.
pytext - A natural language modeling framework based on PyTorch.
PyTorch-NLP - A toolkit enabling rapid deep learning NLP prototyping for research.
spacy - A library for industrial-strength natural language processing in Python and Cython.
stanfordnlp - The Stanford NLP Group's official Python library, supporting 50+ languages.


Chinese

jieba - The most popular Chinese text segmentation library.
pkuseg-python - A toolkit for Chinese word segmentation in various domains.
snownlp - A library for processing Chinese text.
funNLP - A collection of tools and datasets for Chinese NLP.



Network Virtualization
Tools and libraries for Virtual Networking and SDN (Software Defined Networking).

mininet - A popular network emulator and API written in Python.
pox - A Python-based SDN control applications, such as OpenFlow SDN controllers.

Networking
Libraries for networking programming.

asyncio - (Python standard library) Asynchronous I/O, event loop, coroutines and tasks.

awesome-asyncio


pulsar - Event-driven concurrent framework for Python.
pyzmq - A Python wrapper for the ZeroMQ message library.
Twisted - An event-driven networking engine.
napalm - Cross-vendor API to manipulate network devices.

News Feed
Libraries for building user's activities.

django-activity-stream - Generating generic activity streams from the actions on your site.
Stream Framework - Building newsfeed and notification systems using Cassandra and Redis.

ORM
Libraries that implement Object-Relational Mapping or data mapping techniques.

Relational Databases

Django Models - A part of Django.
SQLAlchemy - The Python SQL Toolkit and Object Relational Mapper.

awesome-sqlalchemy


dataset - Store Python dicts in a database - works with SQLite, MySQL, and PostgreSQL.
orator -  The Orator ORM provides a simple yet beautiful ActiveRecord implementation.
peewee - A small, expressive ORM.
pony - ORM that provides a generator-oriented interface to SQL.
pydal - A pure Python Database Abstraction Layer.


NoSQL Databases

hot-redis - Rich Python data types for Redis.
mongoengine - A Python Object-Document-Mapper for working with MongoDB.
PynamoDB - A Pythonic interface for Amazon DynamoDB.
redisco - A Python Library for Simple Models and Containers Persisted in Redis.



Package Management
Libraries for package and dependency management.

pip - The Python package and dependency manager.

PyPI
pip-tools - A set of tools to keep your pinned Python dependencies fresh.


conda - Cross-platform, Python-agnostic binary package manager.

Package Repositories
Local PyPI repository server and proxies.

warehouse - Next generation Python Package Repository (PyPI).
bandersnatch - PyPI mirroring tool provided by Python Packaging Authority (PyPA).
devpi - PyPI server and packaging/testing/release tool.
localshop - Local PyPI server (custom packages and auto-mirroring of pypi).

Permissions
Libraries that allow or deny users access to data or functionality.

django-guardian - Implementation of per object permissions for Django 1.2+
django-rules - A tiny but powerful app providing object-level permissions to Django, without requiring a database.

Processes
Libraries for starting and communicating with OS processes.

delegator.py - Subprocesses for Humansâ¢ 2.0.
sarge - Yet another wrapper for subprocess.
sh - A full-fledged subprocess replacement for Python.

Queue
Libraries for working with event and task queues.

celery - An asynchronous task queue/job queue based on distributed message passing.
huey - Little multi-threaded task queue.
mrq - Mr. Queue - A distributed worker task queue in Python using Redis & gevent.
rq - Simple job queues for Python.

Recommender Systems
Libraries for building recommender systems.

annoy - Approximate Nearest Neighbors in C++/Python optimized for memory usage.
fastFM - A library for Factorization Machines.
implicit - A fast Python implementation of collaborative filtering for implicit datasets.
libffm - A library for Field-aware Factorization Machine (FFM).
lightfm - A Python implementation of a number of popular recommendation algorithms.
spotlight - Deep recommender models using PyTorch.
Surprise - A scikit for building and analyzing recommender systems.
tensorrec - A Recommendation Engine Framework in TensorFlow.

RESTful API
Libraries for developing RESTful APIs.

Django

django-rest-framework - A powerful and flexible toolkit to build web APIs.
django-tastypie - Creating delicious APIs for Django apps.


Flask

eve - REST API framework powered by Flask, MongoDB and good intentions.
flask-api-utils - Taking care of API representation and authentication for Flask.
flask-api - Browsable Web APIs for Flask.
flask-restful - Quickly building REST APIs for Flask.
flask-restless - Generating RESTful APIs for database models defined with SQLAlchemy.


Pyramid

cornice - A RESTful framework for Pyramid.


Framework agnostic

apistar - A smart Web API framework, designed for Python 3.
falcon - A high-performance framework for building cloud APIs and web app backends.
hug - A Python3 framework for cleanly exposing APIs over HTTP and the Command Line with automatic documentation and validation.
restless - Framework agnostic REST framework based on lessons learned from Tastypie.
ripozo - Quickly creating REST/HATEOAS/Hypermedia APIs.
sandman - Automated REST APIs for existing database-driven systems.



Robotics
Libraries for robotics.

PythonRobotics - This is a compilation of various robotics algorithms with visualizations.
rospy - This is a library for ROS (Robot Operating System).

RPC Servers
RPC-compatible servers.

SimpleJSONRPCServer - This library is an implementation of the JSON-RPC specification.
SimpleXMLRPCServer - (Python standard library) Simple XML-RPC server implementation, single-threaded.
zeroRPC - zerorpc is a flexible RPC implementation based on ZeroMQ and MessagePack.

Science
Libraries for scientific computing.

astropy - A community Python library for Astronomy.
bcbio-nextgen - Providing best-practice pipelines for fully automated high throughput sequencing analysis.
bccb - Collection of useful code related to biological analysis.
Biopython - Biopython is a set of freely available tools for biological computation.
cclib - A library for parsing and interpreting the results of computational chemistry packages.
Colour - A colour science package implementing a comprehensive number of colour theory transformations and algorithms.
NetworkX - A high-productivity software for complex networks.
NIPY - A collection of neuroimaging toolkits.
NumPy - A fundamental package for scientific computing with Python.
Open Babel - A chemical toolbox designed to speak the many languages of chemical data.
ObsPy - A Python toolbox for seismology.
PyDy - Short for Python Dynamics, used to assist with workflow in the modeling of dynamic motion.
PyMC - Markov Chain Monte Carlo sampling toolkit.
QuTiP - Quantum Toolbox in Python.
RDKit - Cheminformatics and Machine Learning Software.
SciPy - A Python-based ecosystem of open-source software for mathematics, science, and engineering.
statsmodels - Statistical modeling and econometrics in Python.
SymPy - A Python library for symbolic mathematics.
Zipline - A Pythonic algorithmic trading library.
SimPy -  A process-based discrete-event simulation framework.

Search
Libraries and software for indexing and performing search queries on data.

elasticsearch-py - The official low-level Python client for Elasticsearch.
elasticsearch-dsl-py - The official high-level Python client for Elasticsearch.
django-haystack - Modular search for Django.
pysolr - A lightweight Python wrapper for Apache Solr.
whoosh - A fast, pure Python search engine library.

Serialization
Libraries for serializing complex data types

marshmallow - A lightweight library for converting complex objects to and from simple Python datatypes.
pysimdjson - A Python bindings for simdjson.
python-rapidjson - A Python wrapper around RapidJSON.

Serverless Frameworks
Frameworks for developing serverless Python code.

python-lambda - A toolkit for developing and deploying Python code in AWS Lambda.
Zappa - A tool for deploying WSGI applications on AWS Lambda and API Gateway.

Specific Formats Processing
Libraries for parsing and manipulating specific text formats.

General

tablib - A module for Tabular Datasets in XLS, CSV, JSON, YAML.


Office

openpyxl - A library for reading and writing Excel 2010 xlsx/xlsm/xltx/xltm files.
pyexcel - Providing one API for reading, manipulating and writing csv, ods, xls, xlsx and xlsm files.
python-docx - Reads, queries and modifies Microsoft Word 2007/2008 docx files.
python-pptx - Python library for creating and updating PowerPoint (.pptx) files.
unoconv - Convert between any document format supported by LibreOffice/OpenOffice.
XlsxWriter - A Python module for creating Excel .xlsx files.
xlwings - A BSD-licensed library that makes it easy to call Python from Excel and vice versa.
xlwt / xlrd - Writing and reading data and formatting information from Excel files.


PDF

PDFMiner - A tool for extracting information from PDF documents.
PyPDF2 - A library capable of splitting, merging and transforming PDF pages.
ReportLab - Allowing Rapid creation of rich PDF documents.


Markdown

Mistune - Fastest and full featured pure Python parsers of Markdown.
Python-Markdown - A Python implementation of John Gruberâs Markdown.


YAML

PyYAML - YAML implementations for Python.


CSV

csvkit - Utilities for converting to and working with CSV.


Archive

unp - A command line tool that can unpack archives easily.



Static Site Generator
Static site generator is a software that takes some text + templates as input and produces HTML files on the output.

mkdocs - Markdown friendly documentation generator.
pelican - Static site generator that supports Markdown and reST syntax.
lektor - An easy to use static CMS and blog engine.
nikola - A static website and blog generator.

Tagging
Libraries for tagging items.

django-taggit - Simple tagging for Django.

Template Engine
Libraries and tools for templating and lexing.

Jinja2 - A modern and designer friendly templating language.
Genshi - Python templating toolkit for generation of web-aware output.
Mako - Hyperfast and lightweight templating for the Python platform.

Testing
Libraries for testing codebases and generating test data.

Testing Frameworks

pytest - A mature full-featured Python testing tool.
hypothesis - Hypothesis is an advanced Quickcheck style property based testing library.
nose2 - The successor to nose, based on `unittest2.
Robot Framework - A generic test automation framework.
unittest - (Python standard library) Unit testing framework.


Test Runners

green - A clean, colorful test runner.
mamba - The definitive testing tool for Python. Born under the banner of BDD.
tox - Auto builds and tests distributions in multiple Python versions


GUI / Web Testing

locust - Scalable user load testing tool written in Python.
PyAutoGUI - PyAutoGUI is a cross-platform GUI automation Python module for human beings.
Selenium - Python bindings for Selenium WebDriver.
sixpack - A language-agnostic A/B Testing framework.
splinter - Open source tool for testing web applications.


Mock

doublex - Powerful test doubles framework for Python.
freezegun - Travel through time by mocking the datetime module.
httmock - A mocking library for requests for Python 2.6+ and 3.2+.
httpretty - HTTP request mock tool for Python.
mock - (Python standard library) A mocking and patching library.
Mocket - Socket Mock Framework plus HTTP[S]/asyncio/gevent mocking library with recording/replaying capability.
responses - A utility library for mocking out the requests Python library.
VCR.py - Record and replay HTTP interactions on your tests.


Object Factories

factory_boy - A test fixtures replacement for Python.
mixer - Another fixtures replacement. Supported Django, Flask, SQLAlchemy, Peewee and etc.
model_mommy - Creating random fixtures for testing in Django.


Code Coverage

coverage - Code coverage measurement.


Fake Data

mimesis - is a Python library that help you generate fake data.
fake2db - Fake database generator.
faker - A Python package that generates fake data.
radar - Generate random datetime / time.


Error Handler

FuckIt.py - FuckIt.py uses state-of-the-art technology to make sure your Python code runs whether it has any right to or not.



Text Processing
Libraries for parsing and manipulating plain texts.

General

chardet - Python 2/3 compatible character encoding detector.
difflib - (Python standard library) Helpers for computing deltas.
ftfy - Makes Unicode text less broken and more consistent automagically.
fuzzywuzzy - Fuzzy String Matching.
Levenshtein - Fast computation of Levenshtein distance and string similarity.
pangu.py - Paranoid text spacing.
pyfiglet - An implementation of figlet written in Python.
pypinyin - Convert Chinese hanzi (æ¼¢å­) to pinyin (æ¼é³).
textdistance - Compute distance between sequences. 30+ algorithms, pure python implementation, common interface, optional external libs usage.
unidecode - ASCII transliterations of Unicode text.


Slugify

awesome-slugify - A Python slugify library that can preserve unicode.
python-slugify - A Python slugify library that translates unicode to ASCII.
unicode-slugify - A slugifier that generates unicode slugs with Django as a dependency.


Unique identifiers

hashids - Implementation of hashids in Python.
shortuuid - A generator library for concise, unambiguous and URL-safe UUIDs.


Parser

ply - Implementation of lex and yacc parsing tools for Python.
pygments - A generic syntax highlighter.
pyparsing - A general purpose framework for generating parsers.
python-nameparser - Parsing human names into their individual components.
python-phonenumbers - Parsing, formatting, storing and validating international phone numbers.
python-user-agents - Browser user agent parser.
sqlparse - A non-validating SQL parser.



Third-party APIs
Libraries for accessing third party services APIs. See: List of Python API Wrappers and Libraries.

apache-libcloud - One Python library for all clouds.
boto3 - Python interface to Amazon Web Services.
django-wordpress - WordPress models and views for Django.
facebook-sdk - Facebook Platform Python SDK.
google-api-python-client - Google APIs Client Library for Python.
gspread - Google Spreadsheets Python API.
twython - A Python wrapper for the Twitter API.

URL Manipulation
Libraries for parsing URLs.

furl - A small Python library that makes parsing and manipulating URLs easy.
purl - A simple, immutable URL class with a clean API for interrogation and manipulation.
pyshorteners - A pure Python URL shortening lib.
webargs - A friendly library for parsing HTTP request arguments, with built-in support for popular web frameworks, including Flask, Django, Bottle, Tornado, and Pyramid.

Video
Libraries for manipulating video and GIFs.

moviepy - A module for script-based movie editing with many formats, including animated GIFs.
scikit-video - Video processing routines for SciPy.

WSGI Servers
WSGI-compatible web servers.

bjoern - Asynchronous, very fast and written in C.
gunicorn - Pre-forked, partly written in C.
uWSGI - A project aims at developing a full stack for building hosting services, written in C.
waitress - Multi-threaded, powers Pyramid.
werkzeug - A WSGI utility library for Python that powers Flask and can easily be embedded into your own projects.

Web Asset Management
Tools for managing, compressing and minifying website assets.

django-compressor - Compresses linked and inline JavaScript or CSS into a single cached file.
django-pipeline - An asset packaging library for Django.
django-storages - A collection of custom storage back ends for Django.
fanstatic - Packages, optimizes, and serves static file dependencies as Python packages.
fileconveyor - A daemon to detect and sync files to CDNs, S3 and FTP.
flask-assets - Helps you integrate webassets into your Flask app.
webassets - Bundles, optimizes, and manages unique cache-busting URLs for static resources.

Web Content Extracting
Libraries for extracting web contents.

html2text - Convert HTML to Markdown-formatted text.
lassie - Web Content Retrieval for Humans.
micawber - A small library for extracting rich content from URLs.
newspaper - News extraction, article extraction and content curation in Python.
python-readability - Fast Python port of arc90's readability tool.
requests-html - Pythonic HTML Parsing for Humans.
sumy - A module for automatic summarization of text documents and HTML pages.
textract - Extract text from any document, Word, PowerPoint, PDFs, etc.
toapi - Every web site provides APIs.

Web Crawling & Web Scraping
Libraries to automate data extraction from websites.

cola - A distributed crawling framework.
feedparser - Universal feed parser.
grab - Site scraping framework.
MechanicalSoup - A Python library for automating interaction with websites.
portia - Visual scraping for Scrapy.
pyspider - A powerful spider system.
robobrowser - A simple, Pythonic library for browsing the web without a standalone web browser.
scrapy - A fast high-level screen scraping and web crawling framework.

Web Frameworks
Full stack web frameworks.

Django - The most popular web framework in Python.

awesome-django


Flask - A microframework for Python.

awesome-flask


Pyramid - A small, fast, down-to-earth, open source Python web framework.

awesome-pyramid


Sanic - Web server that's written to go fast.
Vibora - Fast, efficient and asynchronous Web framework inspired by Flask.
Tornado - A Web framework and asynchronous networking library.

WebSocket
Libraries for working with WebSocket.

autobahn-python - WebSocket & WAMP for Python on Twisted and asyncio.
crossbar - Open-source Unified Application Router (Websocket & WAMP for Python on Autobahn).
django-channels - Developer-friendly asynchrony for Django.
django-socketio - WebSockets for Django.
WebSocket-for-Python - WebSocket client and server library for Python 2 and 3 as well as PyPy.

Services
Online tools and APIs to simplify development.
Continuous Integration
See: awesome-CIandCD.

CircleCI - A CI service that can run very fast parallel testing. (GitHub only)
Travis CI - A popular CI service for your open source and private projects. (GitHub only)
Vexor CI - A continuous integration tool for private apps with pay-per-minute billing model.
Wercker - A Docker-based platform for building and deploying applications and microservices.

Code Quality

Codacy - Automated Code Review to ship better code, faster.
Codecov - Code coverage dashboard.
CodeFactor - Automated Code Review for Git.
Landscape - Hosted continuous Python code metrics.

Resources
Where to discover new Python libraries.
Podcasts

From Python Import Podcast
Podcast.init
Python Bytes
Python Testing
Radio Free Python
Talk Python To Me

Twitter

@codetengu
@getpy
@importpython
@planetpython
@pycoders
@pypi
@pythontrending
@PythonWeekly
@TalkPython
@realpython

Websites

/r/CoolGithubProjects
/r/Python
Awesome Python @LibHunt
Django Packages
Full Stack Python
PyPI Ranking
Python 3 Wall of Superpowers
Python Hackers
Python ZEEF
Python å¼åç¤¾åº
Real Python
Trending Python repositories on GitHub today

Weekly

CodeTengu Weekly ç¢¼å¤©çé±å
Import Python Newsletter
Pycoder's Weekly
Python Weekly
Python Tricks

Contributing
Your contributions are always welcome! Please take a look at the contribution guidelines first.
I will keep some pull requests open if I'm not sure whether those libraries are awesome, you could vote for them by adding ð to them. Pull requests will be merged when their votes reach 20.

If you have any question about this opinionated list, do not hesitate to contact me @vinta on Twitter or open an issue on GitHub.
",67185
X-CASH-official/XCASH_proof_of_stake_consensus_node,C,"X-CASH Proof of stake - consensus node
More details will be released on the consensus node soon!
Installation
This program will only run on a Linux/Unix OS at this time. We recommend installing this on a Ubuntu VPS/Server (16.04 or 18.04) for the best compatibility.
You will also need to run an X-CASH Daemon and X-CASH RPC wallet on the server. You can either download the latest X-CASH release or build from source
Compiling X-CASH Proof of stake - consensus node from source
Dependencies
The following table summarizes the tools and libraries required to build.



Dependencies
Min. version
Ubuntu package




GCC
4.7.3
build-essential


CMake
3.0.0
cmake


pkg-config
any
pkg-config


OpenSSL
any
libssl-dev


Git
any
git


MongoDB
4.0.3
install from binaries


MongoDB C Driver (includes BSON libary)
1.13.1
build from source



Installing MongoDB from binaries
Visit https://www.mongodb.com/download-center/community
Then choose your OS, and make sure the version is the current version and the package is server. Then click on All version binaries. Now find the current version to download. You do not want the debug symbols or the rc version, just the regular current version.
Once you have downloaded the file move the file to a location where you want to keep the binaries, then run this set of commands
tar -xf mongodb-linux-x86_64-*.tgz && rm mongodb-linux-x86_64-*.tgz && sudo mkdir -p /data/db && sudo chmod 770 /data/db && sudo chown $USER /data/db
Building the MongoDB C driver from source
Visit the offical websites installation instructions at http://mongoc.org/libmongoc/current/installing.html
You will need to follow the instructions for Building from a release tarball or Building from git since you need the header files, not just the library files.
After you have built the MongoDB C driver from source, you will need to run
sudo ldconfig
Adding MongoDB to your PATH
You will probably want to add MongoDB to your path so you can run MonogDB by typing mongod at any terminal.
To add MongoDB to your PATH (replace ""MongoDB_folder"" with the location of the bin folder in the folder you installed MongoDB in
echo -e '\nexport PATH=MongoDB_folder:$PATH' >> ~/.profile && source ~/.profile
Cloning the repository
$ git clone https://github.com/X-CASH-official/XCASH_proof_of_stake_consensus_node.git
Build instructions
X-CASH Proof of stake - consensus node uses a Make file.
After cloning the repository, navigate to the folder
cd XCASH_proof_of_stake_consensus_node
Then use the make file to build the binary file
make clean ; make
Running MongoDB
To run MongoDB you will need to navigate to the folder you downloaded the binaries to, and in the bin folder run mongod by running
./mongod
If you have already added MongoDB to your path, you can just type in any terminal
mongod
Setting up the xcashd and xcash-wallet-RPC
First you will need to run xcashd in the background. Navigate to the folder that contains the xcash binaries, then run
./xcashd
Next you need to run a xcash-wallet-rpc. Depending on if this is the consensus node or the consensus backup node, you will need to the run the wallet that contains the public address in the Proof of stake for the CONSENSUS_NODE_PUBLIC_ADDRESS or CONSENSUS_BACKUP_NODE_PUBLIC_ADDRESS
To run the rpc wallet you can run
./xcash-wallet-rpc --wallet-file NAME_OF_WALLET_FILE --password WALLET_FILE_PASSWORD --rpc-bind-port 18285 --confirm-external-bind --daemon-port 18281 --disable-rpc-login --trusted-daemon
Just replace NAME_OF_WALLET_FILE with the name of your wallet file and WALLET_FILE_PASSWORD with the password of that wallet file. Make sure to use port 18285 as this is the port that is used in the program.
We suggest you use the screen command to run the program in the background, this way you can still maintenance the server. To do this run
screen -dmS Daemon ./xcashd
You can also run the RPC wallet this way as well
screen -dmS RPC-Wallet ./xcash-wallet-rpc --wallet-file NAME_OF_WALLET_FILE --password WALLET_FILE_PASSWORD --rpc-bind-port 18285 --confirm-external-bind --daemon-port 18281 --disable-rpc-login --trusted-daemon
To bring the screen from the bacground process to the active process run
screen -x NAME_OF_BACKGROUNDS_SCREEN
Where NAME_OF_BACKGROUNDS_SCREEN would be Daemon or RPC-Wallet in the above examples.
To exit a screen if it is the active process, you can press Control + C. To exit a screen that is a background process you can run
screen -XS NAME_OF_BACKGROUNDS_SCREEN quit
Running X-CASH Proof of stake - consensus node test
It is recomeneded to run the X-CASH Proof of stake test before you run the main program. The test will ensure that your system is compatbile, and that you have setup your system correctly.
To run the X-CASH Proof of stake test, Navigate to the folder that contains the binary, then run
./xcash_proof_of_stake_consensus_node --test
The test will return the number of passed and failed test on the bottom of the console. The failed test need to be 0 before you run the node. If the output is not showing 0 for failed test, then you need to scroll through the testing output and find what test failed (It will be red instead of green). If this is a system compatibility test, then you will need to fix the system. If this is a core test that has failed, then you need to possibly rebuild, or contact us with your OS version, and we can look into it.
Running X-CASH Proof of stake - consensus node
Then you will need to run the xcash_proof_of_stake_consensus_node. Navigate to the folder that contains the binary, then run
./xcash_proof_of_stake_consensus_node
We suggest you use the screen command to run the program in the background, this way you can still maintenance the server. To do this run
screen -dmS xcash_proof_of_stake_consensus_node ./xcash_proof_of_stake_consensus_node
To bring the screen from the bacground process to the active process run
screen -x NAME_OF_BACKGROUNDS_SCREEN
Where NAME_OF_BACKGROUNDS_SCREEN would be xcash_proof_of_stake_consensus_node in the above example.
To exit a screen if it is the active process, you can press Control + C. To exit a screen that is a background process you can run
screen -XS NAME_OF_BACKGROUNDS_SCREEN quit
",2
AngelKitty/review_the_national_post-graduate_entrance_examination,C++,"å¤ä¹ èç çé£äºäºå¿ï½ï½
è¿éæå°è®°å½æèç çå¨è¿ç¨ï¼åæ¬çè¿çä¹¦ï¼åè¿çç¬è®°ï¼è¯»è¿çæå¿ï¼æ¨èççªå§ï¼çµå½±ï¼ä»¥åæå¨çæ´»ä¸­ä¸äºé¶ç¢çè®°å½åæèã
ä¹è®¸è¿ä¸åå¯¹ä½ ä»¬å¯è½ä¸æ æ¯å¤ï¼ä½å¯¹æèè¨ï¼è¿å°ä¼æ¯äººçä¸­æå®è´µçä¸æ®µåå¿ï¼æå¸æä»¥è¿ç§æ¹å¼è®°å½ä¸æ¥ï¼æä»¥å¨ Github ä¸å¼äºæ­¤é¡¹ç®ã
ç½ä¸å¾å¤upä¸»é½åæ¬¢éè¿ææ vlog è¿ç§å½¢å¼æ¥è®°å½èªå·±çæ¥å¸¸ï¼æå°±çªåå¥æ³ï¼è½ä¸è½å¨è¿ä¸ªè¯åºç¡ä¸ç¨å¾®ä¿®æ¹ä¸ä¸ãäºæ¯æå°±æ³å°äºä¸ä¸ªéå¸¸ nice çè¯ï¼èªå·±åä¸ä¸ªåå« plog (Page weblogï¼plogä¼¼ä¹æä»£çææå¾å¤ï¼ä½æ¯å¤§å¤é½æ¯åæ¥å¿ç³»ç»æå³å§ï¼æä»¥æè¿ä¸ªç¿»è¯åºè¯¥ä¸ç®å¾åé¨å§23333)
å½ç¶ä¹æ¬¢è¿ä½ ä»¬å å¥å°æä»¬çå¤ä¹ éä¼ä¸­ï¼æå¥½çççµå½±ãçªå§æ¨èæèä¸äºæææçä¹¦ç±ï¼è¯· fork æ¬é¡¹ç®å°æ¨çä»åºåï¼åè¿è¡ pull requestã
æ¬é¡¹ç®åä¸ºå¦ä¸ä¸ä¸ªé¨åï¼

books_and_notesï¼å­æ¾çæå¤ä¹ æ¶åçè¿çä¹¦ä»¥åç¬è®°
examï¼ä¸äºæå¤ä¹ çæ¶ååè¿çä¸äºé¢ç®
plogï¼è®°å½çææ¯å¨çä¸äºæ¥å¸¸ã

å¦ä½è·åæ­¤é¡¹ç®ï¼
æ¬é¡¹ç®å¯ä»¥ç´æ¥éè¿ä»¥ä¸æ¹å¼è·åï¼
# clone
git clone git@github.com:AngelKitty/review_the_national_post-graduate_entrance_examination.git

çæå£°æ

æ¬ä½åéç¨ç¥è¯å±äº«ç½²å-éåä¸æ§ä½¿ç¨-ç¸åæ¹å¼å±äº« 4.0 å½éè®¸å¯åè®®è¿è¡è®¸å¯ã
The Star And Thank Author License
",25
owlboy/greatpug-public,None,"
The Great Pug
A Bar in the Metaverse (VRChat)
thegreatpug.com
This Repository
This repository is the public sister repository to the private repository for The Great Pug.
Bug Reports and Feature Requests
Feel free to use the issues feature of this repository to report bugs or make feature requests relating to The Great Pug.
Support On-going Development
You can support on-going maintenance, events, and expansion to The Great Pug by joining my Patreon.
You can also donate crypto currency at the following addresses:

Etherium (ETH): 0xa2e7aBB300728afc7564874B12975D2f311687a6
Bitcoin (BTC): 16tWrVpZWJcw64aE5su8bRQJgyAVhBeNZQ
Litecoin (LTC): MCjYc1wm2r1f8uM5FPTyqZbKxnxwvNf7UQ

 
Change Log
5/11/19 (65mb)

Reduced draw called depending on your POV
Simplified some colliders
Rebaked lighting
Rebaked Occlusion
Fixed UV unwraps on some models
Adjusted some audio clip sizes

5/10/19 (71mb)

Reduced Draw Calls by a few depending on your POV
Updated calendar (10 days late!)
Rebaked lighting
Reduced material count by a few
Fixed a few incorrect materials
Safety and Security fixes

5/02/19 (69.82mb)

Removed 33.78mb from the build(!!!) (Huge thanks to TCL!)
Fixed an incorrect texture on the light over the notice board #18 (Thanks @HugoZink!)
Disabled the live audio player temporarily

04/27/19 (103.6 mb)

Fixed inconsistent and broken Pickup Respawners
Fixed the Pillows in The Roost
Fixed UV1 on meshes above main bar

04/24/19 (103.6 mb)

Possibly removed extranious refrences to unused objects
Adjusted texture sizes
Adjusted texture filtering to be trilinear on almost all textures
Removed extrainous material slots on some meshes
Removed extrainous some extrainous geometry
Rebaked Occlusion
Power Water and Kirito are back from holiday
(Also did lots of Quest work)

04/10/19 (104.98 mb)

Reduced overdraw on walls in main bar
Reduced overdraw on winndows in main bar
Updated the calendar (10 days late!)
Removed a few extranious materials

03/27/19 (106.89 mb)

Fixed the milky water (Thanks Meme_man!)
Fixed the Desaturated White Russian (Thanks Meme_man!)
Added photos from Saint Patrick's at The Pug 2019
Fixed texture on the lamp in The Roost

03/21/19 (106.78 mb)

Updated lamp and fixture emissive maps
Rebaked lighting
Rebaked Occlusion
Added bells to each floor

03/19/19 (106.52 mb)

Adjusted lighting down a bit in the main bar
Tweaked The Bucket
Adjusted PPV transition falloff for the kitchen coolers
Adjusted compression on some textures
Fixed the high gloss on the banners

03/18/19 (106.26 mb)

Took down the decorations
Updated lighting in many areas
Improved lightmap UVs on booth backs
Improved overdraw in the bathrooms

03/16/19 (108.52 mb) (444)

Saint Patrick's at The Pug 2019!
Thanks to Polopo for the help getting the Leprachaun avatar optimized!
Thanks to Zarniwoop and ShutUpSargent for suggesting hidden Leprecauns!

03/05/19 (105.32 mb)

Fixed the seat toggle for the chairs near the corner booth on the first floor (Thanks Zarniwoop!)
Turned off dithering in the material shaders. Dithering is still applied by the Post Processing Stack (Thanks Poplopo, HugoZink!)
Fixed an incompatibility between the liquid shader and an upcoming patch (Thanks TCL!)
Fixed the fireplace chimney being visible through the window in The Roost
Fixed the visible floating square in the sky
Fixed a gap behind the fireplace
Updated Calendar (5 days late!)
Put up Saint Patrickâs Day promotional decorations

02/21/19 (106.01 mb)

Fixed stage mic not respawning
Fixed misaligned collider near the lamp in The Roost
Rebaked lighting in the main hallway
Updated Patron flyers

02/15/19 (105.61 mb)

Stoves are ready for Udon ð
Updated Patron flyers

01/31/19 (104.5 mb)

Fixed the Night View bar lock
Updated Lightmaps on various objects in The Roost
Updated wood grain on various objects in The Roost
Fixed Z-Fighting on the table behind the couch in The Roost
Fixed Z-Fighting on Night View bar
Fixed low resolution texture on the sword in The Roost
Updated Light Probes in the main bar to be more consistent
Updated calendar (one day early!)
SDK Bump: VRCSDK-2018.12.19.17.03_Public

01/16/19 (103mb)

Rebaked Lighting
Updated Patron flyers
Updated Specular proxy objects

01/03/19 (103mb)

Adjustments to the live audio setup
Adjustments to textures and meshes to reduces the download size a bit
Fixes to reflection probes (Thanks Zarniwoop!)
Fixed house music

01/02/19 (107mb)

Took down holiday decorations
Adjusted bloom a bit
Fixed texture on the solo stool in The Roost
Adjusted collision on the stage edge

12/31/18 (113mb)

New Years decorations and Music

(Thanks CubedParadox for lending me your Record Player!)
(Radio Soulwax - Under the Covers)


Clamped bloom more aggressively
Drywall is now uniformly scaled and oriented
Updated the calendar
Misc fixes

12/28/18 (107mb)

Fixed the missing colliders in the women's bathroom (Thanks @SplitScream#8411!)
Removed the invisible collider in the first-floor hallway (Thanks @Sheppard#1998!)
Fixed missing collider along the doorway to the back stairs (Thanks @Sheppard#1998!)
Implemented a new ""lightmap method"" on some objects. Notably the bar in Night View.
Fixed hole in the ceiling near the kitchen door
Fixed floating baseboard in the back staircase
Improved lightmaps on various objects
Added a new lamp!
Padded the seat backs on the chairs in Night View (The Roost will follow later)
Rounded the Globes on the tables in Night View
Brightened up Night View a bit
Repainted the ceiling in Night View
Updated stools in the main bar so they can hold pickups
Misc fixes
Switched to Post Processing Stack v2

Flashing light from broken geometry should no longer happen
Bloom is clamped to prevent malicious emission values
Testing Post Processing Volumes with the kitchen coolers
Testing auto-exposure



12/24/18 (106mb)

Finished the refactor on the corner booth and near by booths
Fixed wood grain on the trim of the lower landing of the stairs to Night View
Added wood trim along the red wall on the first run of stairs to Night View
Added baseboard to wall near the main bar mirror
Added tiles to the walls that were missing them in the bathrooms
Improved light maps on many meshes
Cleaned up the geometry of some meshes

12/23/18 (108mb)

The Yule Goat has risen! ð
Fixed the floor from the hallway sticking into the womens bathroom

12/20/18 (105mb)

Refactored parts of the booths around the corner booth on the first floor to fix lightmapping and lower draw calls
Lowered the intensity of the specular light proxy objects (Thanks Korro Bravin!)
Adjusted the live stream audio sources
Fixed hazy materials on some objects

12/19/18 (105mb)

Tweaked reflection probles
Tweaked specular on many objects
Improved normals on beer taps
Improved normals on trash taps
Improved fake mirrors in light of the new specular profile
Improved light mapping on various small objects
Reduced download size a bit

12/18/18 (109mb)

Added a few more holiday decorations
Added a new sculpture to The Roost (Thanks Poplopo!)
Fixed dark table tops
Fixed lightmapping throughout The Pug
Improved specular response throughout The Pug. - Still needs tweaking (Thanks SeraRealm!)

12/12/18 (93mb)

Rebaked lightmap - fixed many issues/errors from the 5.6-2017.4 upgrade
Restored holiday banners

12/11/18 (91mb)

Fixed regressions (Reapplied the last update)
Updated patron flyers
Added a few holiday decorations to Night View and The Roost
Added new textures for the red phone
SDK Bump: 2018.12.04.10.25
Engine Bump: 2017.4.15f1

12/07/18 (92mb) - Final FIVE SIX update

Updated the Calendar (7 days late!)
Updated Patron flyers
Fixed the floor in Night View (Thanks laugexd!) [ Issue #10 ]
Started decorating for the holidays
Rebaked Occlusion

11/15/18

Unity 2017 shenanigans.

11/09/18 (96mb)

Adjusted a broken trigger in the Mr. Whiskers Puzzle to hopefully fix it (Thanks Naelstof)
Tweaked live stream playback component
Added a toggle to disable interaction with seats in The Roost
Adjusted some seats in The Roost so they are a bit easier to interact with for desktop users
Fixed missing seats on side couch in The Roost
Updated various materials
Rebaked Occlusion

11/08/18 (97mb)

Added a toggle to disable interaction with seats in the main bar - it is in the back room
Fixed ObjectRespawners on some more objects, including the Pillows in The Roost - Caused by this bug: http://bit.ly/vrc-teleportTo-hierarchy
Fixed missing Corner Booth seat stations
Fixed offset seat stations on stools near the bar mirror (Thanks Zarniwoop!)
Updated some parts of the Mr. Whiskers puzzle to use Custom Triggers
Shined up the booth table legs
Reduced drawcalls by 1 or 2

11/06/18 (98mb)

Fixed ObjectRespawners - Caused by this bug: http://bit.ly/vrc-teleportTo-hierarchy
Fixed Mr. Whiskers Puzzle - Caused by this bug: http://bit.ly/vrc-teleportTo-hierarchy
Fixed unsightly seams on the new booth models
Fixed a missing booth barrier in the Bar mirror (thanks Sheppard#1998!)
Fixed some lightmap issues on the Night View Bar (more need fixing)
Fixed some lightmap issues with the stools on the first floor
Fixed light leaks near the ceiling on the stairs to The Roost
Fixed light leak from the back staircase into the back hallway
Fixed tall baseboard along the tall windows in Night View - you can't walk on it anymore.
Fixed the taps, they were still hooked up to the Halloween kegs
Fixed disappearing White Russian liquid
Improved framing on Halloween 2018 Photo
Removed a draw call or two in Night View
Updated drink menu models
Updated textures the on the ceiling vents
Updated Patron flyers
Rebaked Occlusion
SDK Bump: 2018.11.05.17.42

11/02/18 (102mb)

Reduced a couple more draw calls throughout the map
Rebuilt the meshes for the booths near the mirror on the first floor
Updated all of the drywall materials
Improved colliders near corner stool on the first floor
Improved colliders along the base of the tall windows in Night View
Improved lightmap on the stairs to The Roost (Dark upper border should be gone)
Fixed missing light near the back exit
Added a group photo from Halloween at The Pug 2018 to the wall on the stairs
Readded tags: bar, stage, hangout, social, classic

11/01/18 - 2 (97mb)

Reduced draw calls on various objects around the main bar a bit.
Updated fishbowl water - hopefully fixing the flickering.
Rebaked occlusion
Removed a few stray Halloween remnants
Added tags: bar, stage, hangout, social, classic
SDK Bump: 2018.10.31.10.45

11/01/18 (96mb)

Removed Halloween Decor
Updated calendar
Updated patron flyers
Trigger adjustments to the Mr. Whiskers puzzle

10/27/18 (102mb)

ð Halloween at The Pug 2018

10/17/18 (90mb)

Adjusted liquid shaders some more
Fixed the missing colors from the red/blue/green pints (Thanks Hystericmikey!)
Removed additional superflus objects and materials

10/16/18 (90mb)

Reduced draw calls by 0-4 in main bar area and stage area
Fixed sorting issues with liquid and glass (Hopefully)
Fixed the shifted fireplace light
Removed some un-needed disabled objects

10/15/18 (90mb)

Updated Patron flyers
Updated liquid shader
Updated the glass material on the clocks

10/10/18 (91mb)

Adjusted the liquid shader (hopefully the weird refraction rendering is gone)
Removed a draw call on the rose in The Roost
Fixed a seat on the fireplace couch in The Roost that had a very long interaction distance (Thanks Pan Diman!)
Fixed the oversized interaction boxes on the fireplace couch in The Roost
Adjusted the glass on the mirrors
Removed a draw call on the clocks

10/09/18 (90mb)

Fixed the performance issue with the new glass shader (Thanks CubedParadox!)
Added table tents

10/08/18

New glass shader (Thanks CubedParadox!)
Banners for the Halloween Party are up

10/03/18 (350) (89mb)

Updated the SDK - VRCSDK-2018.10.02.10.29_Public
Updated the Calendar (3 days late)
Fixed some occlusion errors
Patron poster updates

09/20/18 (88mb)

Fixed a Patron poster
Fixed eject buttons in the bar (Thanks Meme Man!)
Fixed a phone receiver that was made of cloth
Fixed some reflection probe placements
Rebaked lighting

09/19/18 (88mb)

Adjusted some light probe placements
Updated/fixed respawn timers on a few objects
Updated Patron posters
Deleted some extranious objects that I found hiding in nooks and crannies

09/18/18 (87mb)

Cleaned the darkness off the Orchid on the welcome desk
Worked around a bug with onTimer triggers (hopefully)
Fixed weird geometry on the main staircase
Improved wood grain direction on the main staircase
Improved lightmap on walls on the main staircase
Improved wood grain direction on the sleeping platform in The Roost
Rounded up the plates
Patched some holes in The Roost ceiling (again)
Solidified the top of the stools in Night View (Thanks Poplopo!)
Removed a weird onInteract trigger near the entrance (Thanks Meme Man!)
Removed some errant animations on the Yellow Spotlight on the Stage
Updated Patron posters
Minor fixes

09/13/18 (86mb)

Updated patron posters
Added steamer pans
Minor fixes

09/9/18 (86mb)

Fixed weirdly shiny materials on main staircase and stage
Fixed leaky faucets in the men's bathroom
Fixed the issue with the sinks being missing in the bathroom mirrors
Added a lot more brushed steel in the kitchen

09/7/18 (85mb)

Loaded up a new Calendar (7 days late)
Sanded down the bathroom sinks to round them out, then re-polished them
Fixed the issue with the Whiskey being a vampire (Thanks Exiled!)
Fixed the issue with teleporting booth seats (Thanks Jordo!) [ Issue #8 ]
Fixed the issue with the missing wall collider near the bar mirror (Thanks Misaki and others!)
Updated TheArchitects poster - He does more than homeworlds now!

08/31/18 (89mb)

Added a new bottle label for Presence
Updates to stage controls for performers
Tweaked the tap triggers to be less square
Rebaked occlusion to fix up the stage
Tweaked toilet sounds so they should be audible again

08/30/18 (89mb)

Moved stage speakers off the stage and added monitors fulfilling Issue #3
Fixed the missing animation on the toilet water
Updated toilet and tap timers to (hopefully) work around a current bug with timers
Reduced range of toilet flush sound (hopefully)
Updated models and materials on stage equipment to reduce the draw calls a bit
Updated the live performer controls
Updated the meshes/materials on ceiling lights in Night View to reduce the draw calls a bit

08/29/18 (89mb)

Peformed some plumbing; The toilets may or may not ""work"" now
Hooked up the beer taps in the Night View bar
Added timers to the beer taps so they turn off after being left on - they were wasting so much beer!
Took down the open sign for Night View (it's always open these days!)
Adjusted the basement door so it is more logical when open, and when being handled
Adjusted lights near the main staircase and first-floor hallway entrance
Fixed the issue causing a teleport if you walked under the back stairs on the first floor (Thanks Exiled!)
Fixed texture tiling on toilets
Fixed more descended canister lights
Adjusted draw calls a tiny bit in the main bar area
Adjusted they way some sound effects play
Restored the MIP Maps on the posters

This exists now: The Great Pug - Steam Group
08/28/18 (91mb)

Made refinements to the Night View shelving meshes
Made refinements to the lightmap on the Night View bar
Made the main staircase a bit brighter at the first-floor landing (Thanks Exiled!)
Fixed the light canisters that were descending on the main staircase (Thanks Garret!)
Updated the Security Colliders; they should be a little more forgiving now (Thanks Korro!)

08/24/18 (91mb)

Fixed the flickering doors in the buffet in The Roost
Updated the textures on the clock and banners
Tweaked some baked lights
Made some minor draw call optimizations
Other minor tweaks

08/23/18 (91mb)

Removed some legacy VRC Chair scripts I found hiding around the map
Minor tweaks

08/22/18 (91mb)

That missing door frame returned home and apologized. It just needed some time away from all the people.
Re-jiggered texture compression on some things
Re-jiggered audio compression on some things
Made adjustments to the lighting
Further adjusted the Post Processing stack
A very Rigid Body was found in The Roost and removed.

08/21/18 (100mb)

Bloomified the fire in The Roost for a more cozy glow
Added a new menu model â more to come down the road here
Material adjustments
More draw call optimizations in the main bar area; 5-10 draw calls depending on the direction you are looking
Patched up the hole in the ceiling near the kitchen door

08/20/18 (97mb)

Fixed Basement occlusion issues
Fixed collider sticking into the main bar from the basement
More draw call optimizations in the main bar area; 1-12 draw calls depending on the direction you are looking
Adjusted the post-processing stack
Minor collider adjustments
The Devil Bucket should be easier to pick up now

08/18/18 (99mb)

Refactored the basement meshes

08/17/18 (99mb)

Fixed collider above the table behind the couch in The Roost
The VRCHAT ARCHIVES advert has gotten a bit dirty in the past year and a half. (Thanks Zarniwoop!)
Material updates
More materials are now using the Dithering Shader

08/16/18 (100mb)

Fixes/Adjustments for the live show audio
Adjustments to shadow casters in The Roost and on the stage
At least 1 draw call removed.

08/12/18

Fixed the missing/shifted colliders on the upstairs bar
Fixed the missing colliders on the downstairs bar cooler
Adjusted the Dithering Shader a bit

08/11/18

Updated the Dithering Shader to v.1.calm.0.0.pseudology.1534016371.7
Many wood materials updated
Bloom is back to its previous level
Light Probes should no longer bleed out of the cooler into the back stairway as easily
Fixed weird light fixture placements throughout the first floor
LOD adjustments for various signs
Fire extinguishers should no longer be inside the wall
Bar Two has slightly better UV unwrapping now
Reflection Probes adjusted down
Removed 3 draw calls from the bar cooler.

08/08/18

THE BELL WORKS AGAIN!
Fixed issues with the beta Dithering Shader by Xiexe (Thanks TCL!)
Fixed the weird sheen on the First Dollar plaque (Thanks Exiled!)
Shaved 1-2 draw calls off of a couple items
Fixed the weird ceilings in The Roost staircase
Fixed light baking issues in a few places
Fixed the ghost chairs by the Corner Booth on the first floor
Fixed the floor material in the bathrooms
Removed references to non-existent chair placement scripts by CubedParadox (Thanks Cubed!)

08/07/18

Calendar Update (7 days late)
Many shaders changed to a beta version of a Dithering Shader by Xiexe (Thanks Xiexe!)
Shaved 1-2 draw calls off stage props

07/27/18

Additions to the live streaming audio support
Minor fixes

07/19/18

SDK Bump - 2018.06.21.13.02
Added experimental live streaming audio support
Made some Minor LOD tweaks

07/03/18 (314)

LOD Tweaks
Reflection Probe fixes
Metalic tables fixed

07/02/18 (312)

Collider blocking stairs fixed

06/29/18 (311)

Bell should be fixed
Lightmap fixes
Gap below short wall at the top of the roost stairs fixed
New Brushed Metal material
Minor optimizations
LOD setup on many items, we will see how that goes.
Collision changes
Reflection probe adjustments

06/29/18 (310) (110mb)

Implemented minor draw call optimizations
Updated lightmaps on back hallway, no more light leaks near the exit sign
Greatly reduced lightmap artifacts on main stairs leading to Night View
Overall lightmap filesize dropped

06/28/18 (308) (116mb)

Implemented additional minor draw call optimizations
Updated the wine bottle labels
Reflection probe resolution changes to reduce download size

06/22/18 (307) (122mb)

Texture resolution increases
Texture compresion changes
Reduced overall download size by 6mb

06/08/18 (306)

Made draw call optimizations
Added missing baseboards in Night View
Reflection Probe Adjustments
Stools have shadows again!
Boxes under the Night View bar are now walkthrough (thanks Meme Man)

06/07/18 (305)

Updated the appearance of the lampshades
Made some minor draw call optimizations
Modified lightmap settings

06/05/18 (303)

Made some minor draw call optimizations
Updated some meshes to have better geometry and normals

06/04/18 (302)

Made some minor draw call optimizations
Fixed a missing collider near the bar mirror

06/03/18 (300)

Made a few draw calls optimizations
Changed the near clipping plane distance on the reference camera (the far clip was not changed)
Rebaked occlusion
Updated the meshes for the sink, Roost shelves, stair railings, booth base/backing, and other minor meshes
Made minor Trigger broadcast type adjustments
Re-painted the wall near the main bar
Added a new Patron flyer

Quick Fix (301)

Fixed some mis-aligned colliders that were out of place.

06/01/18 (298)

Made some draw call optimizations!
Made changes to the Object Respawing behavior to attempt to address lag when a new user joins the world.
Mixed Lights now are forced off when you are not in view of them. This is being done as a precaution because Occlusion Culling may not have been doing the job in all cases.
Rebuilt the shelves under the bar
Updated the Calendar
Tweaked the lighting
Changed the material on the dynamic towel
Fixed a gap in the ceiling in The Roost
Tweaks to various trigger broadcast types
Made some chair upgrades

05/24/18

House Music placement/falloff changes
Stage Lighting Updates
New Stage Lighting Control Board
Addition of Dynamic Event Posters for Spork of Love
Minor Updates to the Event Posters for MckMuze
Bulletin Board Updates

05/10/18

Administration controls added to lock and unlock the stage in a basic manner. (Issue #2 - MckMuze)

More work still needs to be done to fully satisfy the bounty to my satisfaction.


Stage lighting has been improved
Dynamic lights in Night View have been improved
Mesh updates for the stage - Rounder!
Material updates to the sage, Night View Floor, and Bars
This change log had dome embarrassing typoss

05/07/18

Reflection Probe Updates
SDK Bump - 2018.05.01.20.38
Flyers Added

04/24/18

New Bulletin boards

04/19/18

Bathrooms should be back to normal

04/14/18

You should no longer stick to the walls when using the main stairway or the stairs in The Roost
Mckmuze setlist lighting has been fixed
Missing lightmap on painting has been found and reapplied
New decorations in Night View and The Roost
New furniture in The Roost
Hopefully fixed some lag issues related to triggers

04/11/18

Weird, the basement door kept staying opened. - Fixed

04/08/18

Coasters added around The Pug to keep the finish on the wood nice
Eggs removed

03/30/18

Cleaned up straggling Saint Patrick's Day decorations
Improved Resolution on wireframe posters
Possible fix for the flickering hub portal
Eggs.

03/19/18

Removed Saint Patrick's Day decorations

03/17/18

Saint Patrick's at The Pug - 2018
UV fixes for the shelves in the wall behind the main bar
New wall art
Fixes to the glass roof in The Roost
Duplicated mesh fixes
Security Improvements

03/13/18

Calendar Update
Moon Fix

02/24/18

St. Patrickâs Day 2018 - Promotional Table Tents
Enhanced appearance of Night View stage spotlights and floor lights
Multiple spawns
Minor draw call optimizations
Lightmap fixes
Rose added in The Roost - Thanks Poplopo!
New shelves in Night View
Improved the readability of the bulletin board flyers
Fixed typo on bulletin board
Humoungously improved the wall near the back storage room
Security Improvements
SDK Bump

Thanks for the help testing Zarniwoop, Poplopo, and Zircronswift!
02/06/18

Removed birthday decorations
Removed portal to the prototype

02/02/18

Birthday decorations
Temporary portal to the prototype

02/01/18

Added a delightful painting above the fireplace. It was painted by Dicidius. Thanks, Dicidius!
A matching sword is on display
New shelf along the back wall in The Roost
Telephone ring volume lowered a bit
Calendar updated
Moon and city lights properly restored for real this time
Bulletin board updated

01/05/18 (268)

Added security colliders to prevent trolling from outside the map.
SDK Bump

01/02/18

New Years Decorations Removed
Moon and city lights restored
Phone Ring distance adjusted - hopefully, the beds are usable now

12/31/17

Far Back Staircase/Fire Escape
Most objects should Respawn when left lying on the floor, in weird places or outside of the map.
Exterior Meshes
Woodgrain direction fixes
Mesh improvements on the bar
Ambient Lighting Tweaks
Bathroom Stalls now have handles and latches
Skybox uses fewer draw calls
Hole in Phone base fixed
Material(s) consolidated on the phone base
General draw call optimizations
Lighting tweaks
Christmas Decor Removed
Calendar Updated
Disc for 2018 added
Champagne for New Years
Decorations for New Years

12/22/17

Seat Fixes

12/14/17

SDK Bump - VRCSDK-2017.12.12.13.36_Public
Martini added (941101501153505281)
Occlusion Settings Reverted
Lightmap tweaks
Material fixes

12/12/17

Downstairs beer taps should work correctly now
Christmas Decoration Updates
Draw Call Optimizations
Light Probe Improvements
Mesh Updates on the Night View bar
Material Tweaks
Toilet seat fixes
Dining chairs should be easier for desktop users to use
Occlusion changes

12/01/17

Calendar Updated
Lightmap Tweaks
Christmas Decorations
Material Optimizations
Thanksgiving meal put in storage

11/22/17

The Roost is Open
Added Thanksgiving Food
Improved Night View Hall sign (Thanks Poplopo)
Adjusted audio volume falloff on sink taps
Updated Meshes in The Roost
Added fireplace in The Roost
Added seating area in front of the fireplace in The Roost
Added table and chairs in The Roost
Fixed Grain Direction on various objects
Updated Proximity Dance Club Portal

11/16/17 (200)

Lighting Tweaks
UV Fixes on the 2nd Floor floor
Mesh Updates on Booth's backs
UV Fixes on Booth bases
Increased Red Phone ring frequency

11/15/17

Adjustments to the way pickups reset, hopefully fixing them
Patched over Z-Fighting at the top of the stairs
""Un-Fixed"" the Devil Bucket
The Red Phone should now randomly ring
Audio played from the phones should be easier to hear now

11/14/17

First attempt at making pickups reset when idle in undesirable locations.

11/09/17

Calendar Added
Red Phone Added
Various Materials Improved
Lighting Tweaks
Lightmap Resolution Changes
Minor Fixes
VRCSDK Updated to 2017.10.26.17.36

11/07/17

Material Updates
Material Fixes
Minor Fixes

11/06/17

Material Updates
Bar Mesh Updates
More Face Weighted Normals
Minor Fixes

11/04/17

Small Ceiling Vents Added
Face Weighted Normals on various objects
Faucets in the bathrooms now work
Toilets have been scrubbed
Minor Fixes

10/30/17

Post Halloween Party restore

10/24/17

Reflectiopn probe fixes
Halloween prep

10/13/17

VRCSDK Update to 2017.10.04.13.58

10/12/17

Halloween Promotional signs put up
WebPanel disabled
Minor Fixes

09/22/17

Lighting Tweaks
Material Updates (Albedo Checks)
Minor Fixes

09/19/17

Lighting Updates
Minor Fixes

09/12/17

Lighting Updates
Birthday Cake Optimizations
Minor Fixes

09/11/17

Bathroom Collider Fixes
Martial Swaps
Major Light Probe Overhaul
Minor Fixes

09/09/17

Bathroom ceiling now reflects in the bathroom mirrors

09/05/17

Minor Fixes

09/01/17

Bottle Liquid Fixes
Bathroom Walls Fixed

08/31/17

Updated Materials
Optimization for Bathroom Mirrors
Minor Fixes

08/30/17

Five Six

08/17/17

Karaoke added for Karaoke night

08/10/17

Karaoke functionality testing

07/12/17

SnailLock testing

06/30/17

Fireworks added
Minor fixes

06/22/17

Lighting updates
Trigger updates

06/21/17

Minor changes

06/20/17

Dance lights / floor lights added to Night View
Stage lights updates
Overall nightview light added

06/19/17

Sleeping roost updates
Minor fixes

06/14/17

Rounded edges on the lower bar
Added door latches

06/13/17

Refinements to the stairs
Fixes to the Night View floor

06/10/17

Basement optimizations
Sleeping Roost started

06/01/17

Additions for Contact
56 - Stage Lights
Reload button added for the YouTube panel

05/23/17

Texture size optimizations
Floor UV fixes
Adjusted seats for desktop users
Light probes reduced in overall count

05/19/17

Event board typo fixed

05/18/17

Collider fixes
Combined various meshes

05/17/17

Optimized SmÃ¶rgÃ¥stÃ¥rta
Added SmÃ¶rgÃ¥stÃ¥rta under glass to the back room
Texture fixes
Mesh fixes

05/16/17

Occlusion fixes
Baseboards added in various places
Coffee added
A large number of mesh colliders have been replaced with box colliders

05/15/17

Doorbell updates
Occlusion changes
Backroom additions
Security camera added and removed

05/12/17

Doorbell added
Cans of fish added
Lighting updates
SmÃ¶rgÃ¥stÃ¥rta.

04/21/17

White Russians
Light probe fixes
Booth fixes
Lighting changes
Tapster locks added
Switched to using Euan's video player

04/19/17

Eggs removed
Sink handles added
Event board updates

04/15/17

Minor fixes

04/14/17

Event board added
Easter eggs added for easter
Lighting changes
Wine bottles added
Wine glasses added

04/13/17

YouTube panels trigger fix
Stage Prop updates
Trigger updates
MckMuze setlist added
Stage updates
Occlusion fixes in the basement

04/12/17

Lightmap resolution adjustments

04/10/17

Corner booth fixes
Booth seat fixes
Upstairs gate fixes
Lighting fixes
Basement Door added
Basement wall issues fixed
Texture storage size optimizations

04/07/17

Basement
New chairs
YouTube panel fixes
Minor fixes

04/06/17

Mckmuze decor updates
Bar Two - Tigger and button fixes

04/05/17

Bar Two - Improvements
Trigger updates (groan)
Podium added to Night View

04/04/17

Mirror fixes
Metal material updates
Bar top fixes

04/03/17

Bar Two - shelves added
Lighting and light probe changes
Upstairs security changes

04/02/17

Video screen fixes
Brighter lighting

03/31/17

Second bar added in Night View
Stage lights added
New back panel controls

03/30/17

Foot pedals and amp added to the stage

03/29/17

YouTube panels added to the stage
Minor fixes

03/24/17

Corner booth implemented (it's too small!)
PhysSound added
Music fixed

03/23/17

Materials updated
LOD enabled on booth backs

03/22/17

Minor fixes

03/21/17

Decorations taken down
Minor mesh updates
Taps now dispense normal beer

03/17/17

St Patrick's Day Decorations
Taps are now interactable
Speakers
Party Music Player - Thanks Cubedparadox for the youtube playlist sync!

03/13/17

Trigger fixes (grumble)

03/12/17

bathroom Updates
Material atlasing
Security updates

03/10/17

Optimized Meshes
Added St Patrick's Day table tents
Minor Fixes

03/09/17

Added lights to the St Patrick's Day posters
Updated Materials

03/08/17

St Patrick's Day Posters added
Bar height adjusted
Measuring sticks added

03/07/17

Added a Clock
Updated those fancy liquid shaders
Minor fixes

03/06/17

Added fancy liquid shaders
Minor fixes

03/03/17

Added Your Favorite Beer Neon Sign
Updated Materials
Added lights above the bar top
Minor fixes

02/27/17

Implemented Security for the Bar
Added Your Favorite Beer
Optimized Meshes
Optimized Objects
Minor Fixes

02/24/17

Added the back room and it's keypad
Minor fixes

02/23/17

Added MckMuze signs
Minor fixes

02/21/17

Fixed the bar mirror
Optimized Geometry
Optimized Materials
Optimized Occlusion
Minor fixes

02/20/17

Smaller Light Maps
Lighting Changes
Added Gates to the bar
Added Staff Only Sign
Added more canister lights in the Ceiling
Added photo of Q sleeping

02/19/17

Fish Bowl Added
Light bake fixes

02/17/17

Posted my Liquor License
Mesh optimizations

02/01/17

Initial Release
VRCSDK version 2016.12.01.18.02

",12
jimboy3100/jimboy3100.github.io,JavaScript,"Legend Mod
Mod for Agar.io multiplayer action browser game.

Author: jimboy3100@hotmail.com
Website: www.legendmod.ml
<iframe width=""800"" height=""452"" src=""https://www.youtube.com/embed/CnIfNSpCf70?rel=0"" frameborder=""0"" allow=""autoplay; encrypted-media"" allowfullscreen></iframe>
Legend mod GitHub Library
Feature Highlights

10% extra zoom-out (see enemies from further)
Fast feed shortcut (hit viruses and feed team mates faster)
Double split shortcut
Triple split shortcut (for tricksplits)
Minimap (find your team mates, avoid getting cornered etc)
15 configurable shortcut keys to send messages to your team quickly

Other Features

Updates automatically
Unlimited FPS unlocked (quicker than Vanilla)
Old Skins
Animated Skins
UserScripts Manager (URL or pasted)
Language Packs
Direct PARTY / FFA / EXP / TEAM server by using tokens/sips or connector
Search engine for player name / clan / tag / leaderboard / ip / token
Integrated Chat, minimap and teamboard. Chat rooms per server/per team password(or public)
New Template / skins / animations / zoom / respawn / helpers / hud controls and many extras
Themes for quite all textures and map (Basic / Menu / Hud / chat / minimap / graphics and cursor)
Banners for many clans (Email me your symbol and weblink for updates)
60++ Macros / Events / Hotkeys (Script does many calculations)
Tools for quests / youtubers / timers / coin auto digger/youtube video player
Send message pictures, videos and also various message commands directly to teammate's script
Change various textures, add photos on huds and clan's pictures and url links
Dying Light Expansion
Discord webhook handler's for sending IP, and many more...

Legend Mod libraries
Github,
Greasyfiork,
Agarioscripts Chrome Extension
Installation

Install Tampermonkey browser extension on Chrome , Opera
Install Legend Express script here Â 

Screenshots
Welcome Screen - Copy Token, Leaderboard, IP

Searching

Youtube

Features

Big Names (visible to legend/ogario users only)

Banners and website anchors for many clans

Old Skins

Legend mod is based on many scripts (ogario, kitty, turtle clan scripts and others that can be found on greasyfork website).
",5
unknown321/mgsv_nuke_watcher,HTML,"https://unknown321.github.io/mgsv_nuke_watcher
A sample app using mgsv-emulator (https://github.com/unknown321/mgsv_emulator ).
",2
99designs/gqlgen,Go,"gqlgen  
What is gqlgen?
gqlgen is a Go library for building GraphQL servers without any fuss. gqlgen is:

Schema first â Define your API using the GraphQL Schema Definition Language.
Type safe â You should never see map[string]interface{} here.
Codegen â Let us generate the boring bits, so you can build your app quickly.

Feature Comparison
Getting Started
First work your way through the Getting Started tutorial.
If you can't find what your looking for, look at our examples for example usage of gqlgen.
Reporting Issues
If you think you've found a bug, or something isn't behaving the way you think it should, please raise an issue on GitHub.
Contributing
Read our Contribution Guidelines for information on how you can help out gqlgen.
Other Resources

Christopher Biscardi @ Gophercon UK 2018
Introducing gqlgen: a GraphQL Server Generator for Go
GraphQL workshop for Golang developers by IvÃ¡n Corrales Solera

",2753
evsinev/grpc-java-long-polling,Java,"gRPC long polling implementation






Many web servers (ex. nginx), load balancers do not yet support HTTP/2 upstream.
This project implemented both gRPC server and client with long polling via HTTP/1.1
Client example
ManagedChannel channel = LongPollingChannelBuilder.forTarget(""http://localhost:9096/test"").build();
GreeterGrpc.GreeterBlockingStub service = GreeterGrpc
        .newBlockingStub(channel)
        .withDeadlineAfter(5, TimeUnit.SECONDS);

HelloRequest request = HelloRequest.newBuilder().setName(""hello"").build();
HelloReply reply = service.sayHello(request);
Server example
LongPollingServer pollingServer = new LongPollingServer();

Server grpcServer = LongPollingServerBuilder.forPort(-1)
        .longPollingServer(pollingServer)
        .addService(new GreeterImpl())
        .build();
grpcServer.start();

ServerListener serverListener = pollingServer.waitForServerListener();

HelloWorldServer server = new HelloWorldServer(9096, new LongPollingDispatcherServlet(serverListener));
server.start();
",3
fbieberly/orbcomm_decoder,Python,"orbcomm_decoder
A software receiver for ORBCOMM satellite transmissions.
Description
This is a software receiver for decoding packets from ORBCOMM satellites. I don't know what all of the various packets are for, but for the ones I do, I attempt to decode the packet data.
I am writing this decoder as an instructional personal project. Hopefully it
can be used by others to learn about designing satellite communication
receivers.
If you want a more full-featured ORBCOMM receiver please check out:
https://www.coaa.co.uk/orbcommplotter.htm
http://f6cte.free.fr/index_anglais.htm
Dependencies
Should work with either Python 2.X or 3.X
I use pyrtlsdr to record the RF signal with an RTLSDR receiver.
NumPy and SciPy are used for signal processing.
PyEphem is used to calculate Az/El and doppler shift of the satellites.
pip install pyrtlsdr, numpy, scipy, pyephem
Getting started
Offline recording and decoding

First run the update_orbcomm_tle.py script to get the latest two-line elements for the orbcomm satellites.
Update latitude and longitude of your receiver in record_orbcomm.py
Record IQ data by running record_orbcomm.py
Run file_decoder.py to decode a single recording file (defaults to the first file in the /data folder)

EXAMPLE OUTPUT  
Filename: ./data/1552071892p6.mat
Timestamp: 1552071892.6
Data collected on: 2019-03-08 19:04:52.600117
Satellites in recording: orbcomm fm114
SDR Sample rate: 1228800.0 Hz
SDR Center frequency: 137500000.0 Hz
Satellite frequencies: 137287500.0, 137737500.0
Remaining frequency offset after doppler compensation: -141.0 Hz
Number of possible packets: 100

List of packets: (### indicates checksum failed)
### Unrecognized packet: AF0C3958A56A1A7A9BE0ED2B
Fill: Data: 19F1D8528E1EF9701DED 
Fill: Data: 5A8C1A5E354CE775C6A3 
Message: Total length: 2 Part: 0 Data: 001F05CE01C0721828 
Message: Total length: 2 Part: 1 Data: 507102000000000032 
Message: Total length: 3 Part: 0 Data: A241000129687B035E 
Message: Total length: 3 Part: 1 Data: 921E026637E0228277 
Message: Total length: 3 Part: 2 Data: A236830000000000F7 
Unrecognized packet: 0B01FD24CCCCCC204501CF3A
Sync: Code: 65A8F9 Sat ID: 2C 
Downlink_info: Total length: 3 Part: 0 Data: 27310750A005640094 
Downlink_info: Total length: 3 Part: 1 Data: 7D000BB89010130195 
Downlink_info: Total length: 3 Part: 2 Data: 1D011400000000003F 
Network: Total length: 1 Part: 0 Data: 7800010000000000E2 
Ephemeris: Sat ID: 2C Data: 98E3D5043B9BC34CDDF04C3CE66F98D5A307FB07E1D8 
	Current satellite time: 2019-03-08 19:04:53 Z
	Lat/Lon:  36.9359, -119.0865, Altitude: 1041.4 km
Unrecognized packet: 0B011C2AEDEEEE409B02A761
Unrecognized packet: 0B01641D76989944450169D9

Real-time recording and decoding
Not implemented yet.
DSP Training
In the dsp_training folder are a number of scripts that I used to help me understand the DSP that I needed to decode the ORBCOMM signals. The scripts are simulation only and help understand phase recovery, timing recovery, creating symbols from bits, mixing, filtering, etc.
Scripts
Scripts include:

sat_db.py: just a dictionary of orbcomm satellites I know are active
helpers.py: a file with useful helper functions
mat_file_explorer.py: a script that shows what is in a .mat file
plot_recording_waterfall.py: plots a waterfall of recordings
update_orbcomm_tle.py: downloads the latest orbcomm tles from celestrack.com
record_orbcomm.py: records orbcomm satellites when they are overhead with an RTLSDR
file_decoder.py: If you have .mat files in the data folder, this script will attempt to decode one

References
I used these two resources as my primary references.
http://mdkenny.customer.netspace.net.au/Orbcomm.pdf
http://www.decodesystems.com/orbcomm.html
Data format
In the data folder is a couple files of samples that I have recorded.
The files are .mat files. They can be opened with MATLAB or Python (using SciPy's loadmat function).
The files include metadata:

fc: center frequency
fs: sample rate
sats: a list of the names of the satellites overhead
tles: a list of lists of the tle lines for each satellite (in the order of the sats list)
timestamp: unix time of the start of the recording
samples: a numpy complex64 array of the samples
lat: the latitude of the receiver when the samples were recorded
lon: the longitude of the receiver when the samples were recorded
alt: the elevation of the receiver when the samples were recorded

Look at the mat_file_explorer.py script to see an example of how to access the metadata.
",2
GoogleChromeLabs/confluence,JavaScript,"Web API Confluence Dashboard 
A web service and UI for describing API confluence metrics. These metrics are
intended to capture the how browser vendors
are
stretching the elastic band of
the web platform.
Stretching is good: Browsers should be implementing new APIs to add value to
the platform.
Breaking is bad: Implementing too many new APIs before other browsers
catch up, or failing to remove APIs other browsers don't intend to ship causes
fragmentation.
The purpose of API Confluence Metrics is to capture the ways in which
different browsers risk breaking the elastic band.

Data for this project is collected using BrowserStack.
Table of Contents generated with DocToc

The Catalog

Querying the catalog

Examples




The Metrics

API Count

Definition
Rationale


Lone Omission

Definition
Rationale


Lone Removal

Definition
Rationale


Browser-Specific

Definition
Rationale




Contributing

Filing issues and contributing code
Running locally
Collecting data



The Catalog
The dashboard contains an API catalog that lists attributes/properties and
operations/methods exposed on constructor functions and their prototypes. The
catalog constitutes the raw data from which aggregate API confluence metrics
are computed. See CatalogDataCollection.md for
details on how the catalog is created.
Querying the catalog
The catalog supports structured queries. Some query atoms apply to all
cataloged browser releases, while others apply to the releases currently
in view (i.e., the releases currently shown as columns in the table of APIs).
Query atoms may be joined by whitespace, conjunction (and or &), or
disjunction (or or |), with parentheses to disambiguate as needed. Atoms are
one of the following:

(Not-)in-releases clause: A phrase of the form in:release or
notin:release where release is identified by case-insensitive
[release-name-prefix][release-version-prefix][os-name-prefix][os-version-prefix].
Any of these, except [release-name-prefix] may be empty. For example,
in:fir59 describes APIs shipped in all releases of Firefox 59 (that are
included in the catalog). These atoms apply to all releases.
Count-of-releases clause: A phrase of the form count:n where n is a
non-negative integer describes APIs that are shipped in exactly n releases
currently in view.
Keyword: An atom matching the regular expression [a-zA-Z0-9_#-]+
describes APIs that contain the atom by case-insensitive substring match.

Examples
window# count:1: APIs on intefaces with the case-insensitive window suffix
that are shipped in exactly one of the releases in view.
count:1 or count:2 or count:3 or count:4: On a view with showing four or fewer
releases, APIs that are shipped by at least one release in view.
in:chrome65 and notin:chrome66: APIs removed in Chrome 66.
The Metrics
API confluence metrics are a count of âAPIsâ that meet specific criteria with
respect to browser releases that include these âAPIsâ.
Definition: API: For the purposes of these metrics, an âAPIâ is an
interface name + attribute or operation pair.
Definition: The Browser: Each API Confluence Metric is computed with
respect to some particular browser; this is whatâs meant by The Browser. E.g.,
the âLone Removal metric for Safari on 2016-09-01â describes APIs that
Safari once provided (but no longer does) that where the latest release of all
other browsers a year later contains the APIs; in this case Safari is The
Browser.
Definition: Grace Period: Most metrics are deliberately calculated with
respect to releases of browsers other than The Browser sometime in the
past. This avoids penalizing The Browser for making a change (i.e., shipping
or removing an API) when other browsers respond in kind. Currently, the Grace
Period used for all metrics that have one is one year. The ""a year later"" in
the above example refers to the Lone Removal Grace Period.
API Confluence metrics are API counts assessed for a particular browser at a
particular point in time. Most metrics are computed on every date that any
browser has a major release. Some metrics are only computed on dates when The
Browser has a major release.
API Count
Definition
The API Count metric contains three values; the total number of APIs provided
as of the latest browser release, the number of APIs removed (since the previous
release) and the number of APIs added (since the previous release). This metric
is computed on dates when The Browser has a major release.
Rationale
When browsers move too slowly, it holds back the platform. When browsers move
too quickly, they risk âleaving other browsers behindâ. Steady growth is good;
wild variation is bad.
Lone Omission
Definition
The Lone Omission metric indicates the number of APIs that The Browser does
not provide provide for the duration of the Grace Period, but all other
browsers do provide throughout the Grace Period.
Rationale
Failing to ship an API that other major vendors provide requires web
developers to use special code paths to remain interoperable. Smaller values
are good; larger values are bad.
Lone Removal
Definition
The Lone Removal metric indicates the number of APIs removed from a The
Browser prior to the Grace Period, that have not been added back in the
latest relase following the Grace Period, and that are provided in all other
browsers in the latest relase following the Grace Period.
Rationale
Removing an API from only one browser risks breaking existing sites that
(reasonably) assume that all browsers support the API. Smaller values are
good; larger values are bad.
Browser-Specific
Definition
The Browser-Specific metric indicates the number of APIs that The Browser
provides for the duration of the Grace Period, but all other browsers do not
provide throughout the Grace Period.
Rationale
Adding APIs that are provided by only one browser makes that browser more and
more like its own platform (rather than an implementation of a common web
platform). Smaller values are good; larger values are bad.
Contributing
Want to contribute to Web API Confluence? Great!
Filing issues and contributing code
Please use GitHubâs issue tracker and pull request features.
Running locally


Clone this repository.


Install: npm install


Launch the local server:


mkdir -p data/json
Then, either:

Copy the latest data:

cd data/json
curl https://storage.googleapis.com/web-api-confluence-data-cache/latest/json/org.chromium.apis.web.ApiCountData.json > org.chromium.apis.web.ApiCountData.json
curl https://storage.googleapis.com/web-api-confluence-data-cache/latest/json/org.chromium.apis.web.ReleaseWebInterfaceJunction.json > org.chromium.apis.web.ReleaseWebInterfaceJunction.json
curl https://storage.googleapis.com/web-api-confluence-data-cache/latest/json/org.chromium.apis.web.BrowserMetricData.json > org.chromium.apis.web.BrowserMetricData.json
curl https://storage.googleapis.com/web-api-confluence-data-cache/latest/json/org.chromium.apis.web.WebInterface.json > org.chromium.apis.web.WebInterface.json
curl https://storage.googleapis.com/web-api-confluence-data-cache/latest/json/org.chromium.apis.web.Release.json > org.chromium.apis.web.Release.json
cd ../..
or

Collect the data yourself.

Finally, use npm run serve to launch a local instance of the service. This
will load local data, which can take up to a minute to be ready to serve.

Hack away! npm run serve uses webpack --watch to observe local
changes. Making changes to server code will require a service restart, but
client-side changes will be reflected soon after they are saved.

Collecting data
NOTE: The current data collection process requires a
BrowserStack account, two separate git clones, and a whole lot of RAM. We hope to streamline and simplify this process
soon. If you have all the prerequisites, read onâ¦


Clone mdittmer/web-apis and follow
the
data collection instructions for
historical data collection using BrowserStack.


Create /path/to/confluence/data/object-graph and copy
/path/to/web-apis/data/og/*.json into it.


Create /path/to/confluence/data/json and run
./scripts/og_to_confluence.sh to derive confluence data from the object
graphs.


To run the service locally based on your generated data invoke node main/serve.js ""LOCAL"" ""DEV"". If you want live reloading of client code,
change the parameters passed to main/serve.js in scripts/serve.sh and
start webpack alongside the service with `npm run serve.


Caveat: In order to serve the data you collect, you must ensure that a { <browser name}: { <browser version prefix>: <release date> } } for every
version you have imported appears in data/version_history.json.
",63
edufonseca/icassp19,Python,"Learning Sound Event Classifiers from Web Audio with Noisy Labels
This repository contains the code corresponding to the following ICASSP 2019 paper. If you use this code or part of it, please cite:

Eduardo Fonseca, Manoj Plakal, Daniel P. W. Ellis, Frederic Font, Xavier Favory, Xavier Serra, ""Learning Sound Event Classifiers from Web Audio with Noisy Labels"", In proceedings of ICASSP 2019, Brighton, UK

The framework comprises all the basic stages: feature extraction, training, inference and evaluation. After loading the FSDnoisy18k dataset, log-mel energies are computed and a CNN baseline is trained and evaluated. The code also allows to test four noise-robust loss functions. Please check our paper for more details. The system is implemented in Keras and TensorFlow.
The FSDnoisy18k dataset described in our ICASSP 2019 paper is available through Zenodo from its companion site: http://www.eduardofonseca.net/FSDnoisy18k/.
Dependencies
This framework is tested on Ubuntu 17.10 using a conda environment. To duplicate the conda environment:
conda create --name <envname> --file requirements.txt
Directories and files
config/ includes a *.yaml file with the parameters for the experiment
logs/ folder where to include output files per experiment
main.py is the main script
data.py contains the data generators
feat_extract.py contains feature extraction code
architectures.py contains the architecture for the baseline system
utils.py some basic utilities
eval.py evaluation code
losses.py definition of several loss functions
Usage
(0) Download the dataset:
Download FSDnoisy18k from Zenodo through the dataset companion site, unzip it and locate it in a given directory.
(1) Edit config/*.yaml file:
The goal is to define the parameters of the experiment. The file is structured with self-descriptive sections. The most important parameters are:
ctrl.dataset_path: path where the dataset is located, eg, /data/FSDnoisy18k/.
ctrl.train_data: define the subset of training data to consider in the experiment. To be decided among: ['all', 'noisy', 'noisy_small', 'clean'] (see paper)
loss.q_loss: this is an example of a hyper-parameter of a loss function, according to the paper. For example, q_loss corresponds to q in equation (3) of the paper and reed_beta corresponds to beta in equation (2).
loss.type: defines the loss function. To be decided among:

CCE: categorical_crossentropy aka cross entropy loss
lq_loss: L_q loss
CCE_max: CCE loss & discard loss values using maximum-based threshold
CCE_outlier: CCE loss & discard loss values using outlier-based threshold
bootstrapping: L_soft loss
lq_loss_origin: L_q loss applied selectively based on data origin*
CCE_max_origin: CCE_max applied selectively based on data origin*
CCE_outlier_origin: CCE_outlier applied selectively based on data origin*
bootstrapping_origin: L_soft loss applied selectively based on data origin*

*The selective application of the loss functions makes sense when training with the entire train set (that is, considering clean and noisy data), ie ctrl.train_data: all  (see paper).
The rest of the parameters should be rather intuitive.
(2) Execute the code by:

activating the conda env
run, for instance: CUDA_VISIBLE_DEVICES=0 KERAS_BACKEND=tensorflow python main.py -p config/params.yaml &> logs/output_file.out

In the first run, log-mel features are extracted and saved. In the following times, the code detects that there is a feature folder. It only checks the folder; not the content. If some feature extraction parameters are changed, the program wonât know it.
(3) See results:
You can check the logs/*.out. Results are shown in a table (you can search for the string ACCURACY - MICRO and it will take you to them).
Reproducing the baseline
(1) Edit config/*.yaml file

ctrl.train_data: all # (or any other train subset)
loss.type: CCE # this is standard cross entropy loss

(2) Execute the code.
Baseline system details
Incoming audio is transformed to 96-band, log-mel spectrogram as input representation.
To deal with the variable-length clips, we use time-frequency patches of 2s (which is equivalent to 100 frames of 40ms with 50% overlap). Shorter clips are replicated while longer clips are trimmed in several patches inheriting the clip-level label (this is the meaning of the parameter ctrl.load_mode = varup in the config/*.yaml file).
The model used is a CNN (3 conv layers + 1 dense layer) following that of this paper, with two main changes. First, we include Batch Normalization (BN) between each convolutional layer and ReLU non-linearity. Second, we use pre-activation, a technique initially devised in deep residual networks which essentially consists of applying BN and ReLU as pre-activation before each convolutional layer.
It was proved beneficial for acoustic scene classification in this paper, where it showed convenient generalization properties. Likewise, in preliminary experiments with FSDnoisy18k it was shown to slightly improve the classification accuracy. The baseline system has 531,624 weights and its architecture is summarized in the next figure.



As for the learning strategy, the default loss function is categorical cross-entropy (CCE), the batch size is 64, and we use Adam optimizer with initial learning rate of 0.001, which is halved whenever the validation accuracy plateaus for 5 epochs. The training samples are shuffled between epochs. Earlystopping is adopted with a patience of 15 epochs on the validation accuracy. To this end, a 15% validation set is split randomly from the training data of every class. This validation split is the random 15% of every class, considering both clean and noisy subsets together. Preliminary experiments revealed that this provides slightly better results if compared to using only the clean subset for validation (which amounts to roughly 10% of the training set, but it is highly imbalanced class-wise, from 6.1% to 22.4%).
On inference, the prediction for every clip is obtained by computing predictions at the patch level, and aggregating them with geometric mean to produce a clip-level prediction.
The goal of the baseline is to give a sense of the classification accuracy that a well-known architecture can attain and not to maximize the performance.
Extensive hyper-parameter tuning or additional model exploration was not conducted.
Contact
You are welcome to contact me privately should you have any question/suggestion or if you have any problems running the code at eduardo.fonseca@upf.edu. You can also create an issue.
",31
daizutabi/pheasant,HTML,"Pheasant






Description
Pheasant is a Markdown converter which is designed to be used as a plugin for static site generators, especially MkDocs. The one of the main features of Pheasant is auto Markdown generation of outputs after execution of any Python or other language codes written in a fenced code block of Markdown source. This process is executed by the Jupyter client functionality. In addition to the code execution, Pheasant can automatically number headers, figures, tables, etcs.
Document
See Pheasant document.
",2
zhkl0228/emulator,Java,"emulator
Allows you to emulate an Android ARM32 and/or ARM64 native library.
This is an educational project to learn more about the ELF file format and ARM assembly.
Usage
VM options: -Djava.library.path=prebuilt/os -Djna.library.path=prebuilt/os
Where os may: linux64, win32, win64, osx64
Simple tests under src/test directory

src/test/java/com/bytedance/frameworks/core/encrypt/TTEncrypt.java




src/test/java/com/sun/jna/JniDispatch32.java




src/test/java/com/sun/jna/JniDispatch64.java




src/test/java/org/telegram/messenger/Utilities32.java




src/test/java/org/telegram/messenger/Utilities64.java


Features

Emulation of the JNI Invocation API so JNI_OnLoad can be called.
Support JavaVM, JNIEnv.
Emulation of syscalls instruction.
Support ARM32 and ARM64 bit ELF.
Inline hook, thanks to HookZz.
Import hook, thanks to xHook.
Support simple debugger, instruction trace, memory read/write trace.

TODO

Working iOS emulation.
Support iOS objc.

Thanks

unicorn
HookZz
xHook
AndroidNativeEmu
usercorn
keystone
capstone
idaemu
jelf
whale
kaitai_struct

",159
MetacoSA/NBitcoin,C#,"NBitcoin



 
NBitcoin is the most complete Bitcoin library for the .NET platform. It implements all most relevant Bitcoin Improvement Proposals (BIPs). It also provides low level access to Bitcoin primitives so you can easily build your application on top of it. Join us in our gitter chat room.
It works on Windows, Mac and Linux with Xamarin, Unity, .NET Core or CLR. (Porting to Unity should not be that hard if you need it)
The best documentation available is our eBook, and the excellent unit tests. There are also some more resources below.
You can also browse the API easily through the API reference.
How to use ?
With NuGet :

Install-Package NBitcoin

Go on the NuGet website for more information.
The packages support:

With full features: Windows Desktop applications, Mono Desktop applications and platforms supported by .NET Standard 1.3 (.NET Core, Xamarin IOS, Xamarin Android, UWP and more).
With limited features: platforms supported by .NET Standard 1.1 (Windows Phone, Windows 8.0 apps).

To compile it by yourself, you can git clone, open the project and hit the compile button in Visual Studio.
How to get started ? Check out this article on CodeProject for some basic Bitcoin operations, or this Introduction to NBitcoin video.
How to use with Altcoins ?

Install-Package NBitcoin.Altcoins

Find more information here.
How to debug in NBitcoin source code?
When a new version of NBitcoin, NBitcoin.Altcoins or NBitcoin.TestFramework is released on Nuget, we also upload a separate symbol package (snupkg) with SourceLink enabled. This is enabled from version 4.1.1.73.
This means that it is possible to debug into NBitcoin code, and the source will be fetched transparently from github.
This works on both Visual Studio Code and Visual Studio for Windows.
Debug inside source with Visual Studio
You need to run at least Visual Studio 15.9.
Then, you need to:

Go in Tools / Options / Debugging / General and turn off Enable Just My Code.
Go in Tools / Options / Debugging / Symbols and add https://symbols.nuget.org/download/symbols to the Symbol file (.pdb) locations, make sure it is checked.

You should also check Microsoft Symbol Server or your debugging experience in visual studio will be slowed down.
Now you can Debug your project and step inside any call to NBitcoin.
Debug inside source with Visual Studio Code
Inside your launch.json, add the following to .NET Core Launch (console) configuration:
""justMyCode"": false,
""symbolOptions"": {
    ""searchPaths"": [ ""https://symbols.nuget.org/download/symbols"" ],
    ""searchMicrosoftSymbolServer"": true
},
Now you can Debug your project and step inside any call to NBitcoin.
How to use with my own blockchain?
Find more information here.
How to use in Unity?
You should use at least Unity 2018.2 using Script Runtime Version .NET 4.x Equivalent and Api Compatibility Level .NET Standard 2.0.
You can see more on this post.
Then you need to compile NBitcoin:
git clone https://github.com/MetacoSA/NBitcoin/
cd NBitcoin/NBitcoin
dotnet publish -c Release -f netstandard2.0
Remove-Item -Force -Recurse .\bin\Release\netstandard2.0\publish\runtimes\
Then put the libraries of .\bin\Release\netstandard2.0 into your asset folder.
If you need altcoins support, use the same step but with cd NBitcoin/NBitcoin.Altcoins instead.
How to use in .NET Core
If you want to use .NET Core, first install .NET Core as documented here.
Then:
mkdir MyProject
cd MyProject
dotnet new console
dotnet add package NBitcoin
dotnet restore

Then edit your Program.cs:
using System;
using NBitcoin;

namespace _125350929
{
    class Program
    {
        static void Main(string[] args)
        {
            Console.WriteLine(""Hello World! "" + new Key().GetWif(Network.Main));
        }
    }
}

You can then run with
dotnet run

We advise you to use Visual Studio Code as the editor for your project.
Description
NBitcoin notably includes:

A TransactionBuilder supporting Stealth, Open Asset, and all standard transactions
Full script evaluation and parsing
A RPC Client
A Rest Client
The parsing of standard scripts and creation of custom ones
The serialization of blocks, transactions and scripts
The signing and verification with private keys (with support for compact signatures) for proving ownership
Bloom filters and partial merkle trees
Segregated Witness (BIP 141, BIP 143, BIP 144)
Bech32 segwit address implementation with error detection BIP 173
Mnemonic code for generating deterministic keys (BIP 39), credits to Thasshiznets
Hierarchical Deterministic Wallets (BIP 32)
Payment URLs (BIP 21)
Full Bitcoin P2P implementation with SOCKS5 support for connecting through Tor

Please read our ebook to understand the capabilities.
NBitcoin is inspired by Bitcoin Core code but provides a simpler object oriented API (e.g., new Key().PubKey.Address.ToString() to generate a key and get the associated address). It relies on the BouncyCastle cryptography library instead of OpenSSL, yet replicates OpenSSL bugs to guarantee compatibility. NBitcoin also ports the integrality of Bitcoin Core unit tests with their original data in order to validate the compatibility of the two implementations.
NBitcoin is licensed under the MIT License and we encourage you to use it to explore, learn, debug, play, share and create software for Bitcoin and with other Metaco services.
How to connect use a SOCKS5 proxy to connect to a Bitcoin node?
Here an example which assume you run Tor with SOCKS5 proxy on port 9050.
var connectionParameters = new NodeConnectionParameters();
connectionParameters.TemplateBehaviors.Add(new SocksSettingsBehavior(Utils.ParseEndpoint(""localhost"", 9050)));
Node node = await Node.ConnectAsync(Network.Main, ""7xnmrhmkvptbcvpl.onion:8333"", connectionParameters);
node.VersionHandshake();
Some OSS projects using NBitcoin


Wasabi: Privacy focused, ZeroLink compliant Bitcoin wallet.


StratisBitcoinFullNode: Bitcoin full node in C# https://stratisplatform.com


Breeze: Breeze Wallet, the first full-block SPV bitcoin wallet


BlockExplorer: A set of projects that can index and query stratis blockchains on the fullnode.


BTCPay Server: A cross platform, self-hosted server compatible with Bitpay API


NTumbleBit: TumbleBit Implementation in .NET Core


BitPoker: Decentralised peer to peer poker, using bitcoin http://www.bitpoker.io


Zen-Wallet: Node and GUI for the Zen Protocol. https://www.zenprotocol.com


Metaco-Trader: Bitcoin Wallet for advanced user based on a NBitcoin.Server


Swarmops: Admin backend for any bitcoin-native or swarm organization http://sandbox.swarmops.com/


Nako: A Bitcoin and Altcoin server api that indexes blockchain transactions and addresses


NBXplorer: A minimalist UTXO tracker for HD Wallets with bitcoin based altcoin support


UnitCurrency: UnitCoin - a hybrid scrypt PoW + PoS based cryptocurrency.


Openchain: Openchain node reference implementation. https://www.openchain.org/


BreezeProject: Breeze Masternode and Wallet with Breeze Privacy Protocol


Geewallet: a minimalistic and pragmatist lightweight wallet for people that want to hold the most important cryptocurrencies in the same application without hassle


Useful doc :


Ebook Programming The Blockchain in C#


NBitcoin Github : https://github.com/NicolasDorier/NBitcoin


NBitcoin Nuget : https://www.nuget.org/packages/NBitcoin/


Intro: http://www.codeproject.com/Articles/768412/NBitcoin-The-most-complete-Bitcoin-port-Part-Crypt


Stealth Payment, and BIP38 : http://www.codeproject.com/Articles/775226/NBitcoin-Cryptography-Part


How to build transaction : http://www.codeproject.com/Articles/835098/NBitcoin-Build-Them-All


Using the NBitcoin Indexer : http://www.codeproject.com/Articles/819567/NBitcoin-Indexer-A-scalable-and-fault-tolerant-blo


How to Scan the blockchain : http://www.codeproject.com/Articles/784519/NBitcoin-How-to-scan-the-Blockchain (You can dismiss the ScanState for that, now I concentrate on the indexer)


Please, use github issues for questions or feedback. For confidential requests or specific demands, contact us on Metaco support.
Useful link for a free IDE :
Visual Studio Community Edition : https://www.visualstudio.com/products/visual-studio-community-vs
",1313
voteflux/flux-website-v2,HTML,"Instructions
Dependencies
Docker
If you have docker installed just run ./dev-docker.sh - that should get you developing straight away (well, minus the minutes required to build and install deps)
Manually
We presume your environment is OSX.

Install node, npm, ruby, yarn first
macOS: brew install ruby node npm yarn
ubuntu: sudo apt install ruby nodejs (aside: does this include npm?)
Ubuntu: Note: you'll need to install yarn yourself
Fedora: redhat-rpm-config
Install dependencies: ./dev-install-deps.sh or if that doesn't work: gem install bundle then bundle install then yarn install

Note: Node v11 doesn't seem to work building for some deps
Development

To run a development copy for everything run ./dev-watch-all.sh or yarn flux
To simulate a build run yarn build

Deployment

Deployments automatically happen via the master branch.
All merges require a PR.

Hints and Tips
brew install ruby for ruby
gem install bundle for bundle
bundle install to install dependencies
bundle exec jekyll serve --watch to run a dev server for just jekyll stuff.
React is used for the signup form but not for anything else.
Kip's notes on contributing
MK note: if you need to use sudo to run ./dev-docker.sh you should add yourself to the docker group (or google what to do for your OS); typically you shouldn't need sudo for docker, or at least it's good not to run it like that on your dev machine.

Install git
Install Docker
Get an IDE (I use Atom)
fork the flux-website
https://github.com/voteflux/flux-website-v2 - use the fork button
clone your copy onto your machine. For me in a terminal it's:
git clone https://github.com/KipCrossing/flux-website-v2
Read the Readme and run: sudo ./dev-docker.sh
Once the flie has run it will tell you the server address. for me it was: http://0.0.0.0:9000/
Paste that into your web browser
Open the flux-website repo as a project in your IDE
Make changes
in terminal:
git add .
git commit -m ""Write a commit message""
git push
Go to your repo on GitHub and make a pull request
This will help with the Pull Request https://github.com/voteflux/flux-docs/blob/master/docs/contributing/index.rst

",8
voteflux/flux-website-v2,HTML,"Instructions
Dependencies
Docker
If you have docker installed just run ./dev-docker.sh - that should get you developing straight away (well, minus the minutes required to build and install deps)
Manually
We presume your environment is OSX.

Install node, npm, ruby, yarn first
macOS: brew install ruby node npm yarn
ubuntu: sudo apt install ruby nodejs (aside: does this include npm?)
Ubuntu: Note: you'll need to install yarn yourself
Fedora: redhat-rpm-config
Install dependencies: ./dev-install-deps.sh or if that doesn't work: gem install bundle then bundle install then yarn install

Note: Node v11 doesn't seem to work building for some deps
Development

To run a development copy for everything run ./dev-watch-all.sh or yarn flux
To simulate a build run yarn build

Deployment

Deployments automatically happen via the master branch.
All merges require a PR.

Hints and Tips
brew install ruby for ruby
gem install bundle for bundle
bundle install to install dependencies
bundle exec jekyll serve --watch to run a dev server for just jekyll stuff.
React is used for the signup form but not for anything else.
Kip's notes on contributing
MK note: if you need to use sudo to run ./dev-docker.sh you should add yourself to the docker group (or google what to do for your OS); typically you shouldn't need sudo for docker, or at least it's good not to run it like that on your dev machine.

Install git
Install Docker
Get an IDE (I use Atom)
fork the flux-website
https://github.com/voteflux/flux-website-v2 - use the fork button
clone your copy onto your machine. For me in a terminal it's:
git clone https://github.com/KipCrossing/flux-website-v2
Read the Readme and run: sudo ./dev-docker.sh
Once the flie has run it will tell you the server address. for me it was: http://0.0.0.0:9000/
Paste that into your web browser
Open the flux-website repo as a project in your IDE
Make changes
in terminal:
git add .
git commit -m ""Write a commit message""
git push
Go to your repo on GitHub and make a pull request
This will help with the Pull Request https://github.com/voteflux/flux-docs/blob/master/docs/contributing/index.rst

",8
evanrelf/sort-imports,Haskell,"sort-imports
Sort Haskell import statements
Install
git clone https://github.com/evanrelf/sort-imports.git
cd sort-imports
stack install
Usage
Takes input on stdin or with --file 'path/to/file.hs', and outputs to stdout. For example:
sort-imports < input.hs > output.hs
input.hs:
module Main where

import qualified ModuleC as C
import ModuleD ((>>=), function, Type(..))
import ModuleA
import ModuleB hiding (aaa, ccc, bbb)

import AnotherModuleB
import AnotherModuleC
import AnotherModuleA

main :: IO ()
main = putStrLn ""Hello world""
output.hs:
module Main where

import ModuleA
import ModuleB hiding (aaa, bbb, ccc)
import qualified ModuleC as C
import ModuleD (Type(..), function, (>>=))

import AnotherModuleA
import AnotherModuleB
import AnotherModuleC

main :: IO ()
main = putStrLn ""Hello world""
Type sort-imports --help for more information.
Editor integration
Vim/Neovim

sbdchd/neoformat

",2
qword-os/qword,C,"qword - A KISS Unix-like operating system, written in C and Assembly for x86_64.


Talk to us!
We have a Discord server with all the developers for any question, support, contribution, or just chat!
Features

SMP (multicore) scheduler supporting thread scheduling.
Program loading with minimal userspace.
Fully functional VFS with support for several filesystems.
Support for AHCI/SATA.
ATA disk support.

Build requirements
In order to build qword, make sure to have the following installed:
wget, git, bash, make (gmake on *BSD), meson, ninja, gcc/g++ (8 or higher), nasm, xz, autoconf, and QEMU (to test it).
Building
# Clone repo wherever you like
git clone https://github.com/qword-os/qword.git
cd qword/host
# Let's first build and install the echfs-utils
git clone https://github.com/qword-os/echfs.git
cd echfs
make
# This will install echfs-utils in /usr/local
sudo make install
# Else specify a PREFIX variable if you want to install it elsewhere
#make PREFIX=<myprefix> install
# Now build the toolchain (this step will take a while)
cd ../toolchain
# You can replace the 4 in -j4 with your number of cores + 1
./make_toolchain.sh -j4
# Go back to the root of the tree
cd ../..
# Build the ports distribution
cd root/src
MAKEFLAGS=-j4 ./makeworld.sh
# Now to build qword itself
cd ../..
# You might need to use gmake instead of make here on FreeBSD
make clean && make img               # For a standard release build
make clean && make DBGOUT=qemu img   # For QEMU console debug output
make clean && make DBGOUT=tty img    # For kernel tty debug output
make clean && make DBGOUT=both img   # For both of the above
make clean && make DBGSYM=yes img    # For compilation with debug symbols and other debug facilities (can be used in combination with the other options)
You've now built qword, a flat qword.img disk image has been generated.
To run the OS in QEMU, use make run-img.
To run it with KVM enabled, use make run-img-kvm.
",115
godka/kurento-rtmp,JavaScript,"kurento-rtmp
Here is a simple demo which can provide a pipeline from kurento-webrtc to rtmp server (eg., srs, nginx-rtmp-module, etc.).
You can browse https://1029.mythkast.net to test this demo.

The pipeline of the work is described as follows:
[Browser] -> WebrtcEndpoint -> [Kurento] -> RtpEndpoint -> 
[FFmpeg] -> RTMP -> [Node_Media_Server(srs)] -> RTMP -> [Browser]

Build
1.install node && npm
2.git clone https://github.com/godka/kurento-rtmp
3.cd kurento-rtmp
4.npm install
5.node server.js
6.Open https://yourhost on Chrome or Firefox
7.Click Start button and have fun!

Notation
Before running this demo,you must have build FFmpeg and Kurento Media Server on your server.
Licensing and distribution
Licensed under the Apache License, Version 2.0 (the ""License"");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an ""AS IS"" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
",75
andrewrothstein/ansible-vault,None,"andrewrothstein.vault

Install's Hashicorp's Vault
Requirements
See meta/main.yml
Role Variables
See defaults/main.yml
Dependencies
See meta/main.yml
Example Playbook
- hosts: servers
  roles:
    - andrewrothstein.vault

License
MIT
Author Information
Andrew Rothstein andrew.rothstein@gmail.com
",2
deepgrace/giant,C++,"


Algorithms and Data Structures in Modern C++
Overview
permutation
#include <vector>
#include <algorithm>
using namespace std;

template <typename T>
bool next_permutation(vector<T>& A)
{
    int k = A.size() - 1;
    while (k > 0 && A[k-1] >= A[k])
           --k;
    if (k == 0)
        return false;

    swap(*find_if(A.rbegin(), A.rend(), [&](auto t){ return t > A[k-1]; }), A[k-1]);
    reverse(A.begin() + k, A.end());

    return true;
}

template <typename T>
bool prev_permutation(vector<T>& A)
{
    int k = A.size() - 1;
    while (k > 0 && A[k-1] <= A[k])
           --k;
    if (k == 0)
        return false;

    swap(*find_if(A.rbegin(), A.rend(), [&](auto t){ return t < A[k-1]; }), A[k-1]);
    reverse(A.begin() + k, A.end());

    return true;
}

template <typename T>
bool next_partial_permutation(vector<T>& A, int k)
{
   reverse(A.begin() + k, A.end());
   return next_permutation(A);
} 

template <typename T>
bool prev_partial_permutation(vector<T>& A, int k)
{
   bool result = prev_permutation(A);
   reverse(A.begin() + k, A.end());
   return result;
} 
combination
#include <algorithm>

template <typename Iterator>
bool combination(Iterator first1, Iterator last1, Iterator first2, Iterator last2, bool ASC)
{
    if (first1 == last1 || first2 == last2)
          return false;

    Iterator m1 = last1;
    Iterator m2 = last2;
    --m2;

    auto comp = [ASC](const auto& x, const auto& y){ return ASC ? x < y : x > y; };

    while (--m1 != first1 && !comp(*m1, *m2));

    bool result = m1 == first1 && !comp(*first1, *m2);
    if (! result)
    {
        while (first2 != m2 && !comp(*m1, *first2))
               ++first2;

        first1 = m1;
        std::iter_swap(first1, first2);
        ++first1;
        ++first2;
    }

    if (first1 != last1 && first2 != last2)
    {
        m1 = last1; 
        m2 = first2;

        while (m1 != first1 && m2 != last2)
        {
               std::iter_swap(--m1 , m2);
               ++m2;
        }

       std::reverse(first1, m1);
       std::reverse(first1, last1);
       std::reverse(m2, last2);
       std::reverse(first2, last2);
    }
    return !result;
}

template <typename Iterator>
bool next_combination(Iterator first, Iterator middle, Iterator last)
{
    return combination(first, middle, middle, last, true);
}

template <typename Iterator>
bool prev_combination(Iterator first, Iterator middle, Iterator last)
{
    return combination(first, middle, middle, last, false);
}
",3
arhat-dev/aranya,Go,"aranya é¿å°è¥
   
A Kubernetes operator for edge devices
(This project also includes arhat's source, which is the agent for edge device to communicate with aranya)
Purpose

Deploy and manage edge devices with ease.
Remove the boundry between Edge and Cloud.
Integrate every device with container runtime into your Kubernetes cluster.
Help everyone to share Kubernetes masters to others. (see docs/Multi-tenancy.md)

Non-Purpose
Simplify Kubernetes
State
EXPERIMENTAL, USE AT YOUR OWN RISK
Features

Pod modeled container management in edge device

Support Pod creation with Env, Volume

Sources: plain text, Secret, ConfigMap




Remote device management with kubectl (both container and host)

cp
log
exec
attach
port-forward


Built-in Prometheus node-exporter to collect and upload metrics efficiently

NOTE: For details of the host management, please refer to Maintenance #Host Management
Restrictions

Kubernetes cluster network not working for edge devices, see Roadmap #Networking

Build
see docs/Build.md
Deployment Prerequisites

Kubernetes cluster with RBAC enabled

Minimum cluster requirements: 1 master (must have) with 1 node (to deploy aranya)



Deployment Workflow


Deploy aranya to your Kubernetes cluster for evaluation with following commands (see docs/Maintenance.md for more deployment tips)
# set the namespace for edge devices, aranya will be deployed to this namespace
$ export NS=edge

# create the namespace
$ kubectl create namespace ${NS}

# create custom resource definitions (CRDs) used by aranya
$ kubectl apply -f https://raw.githubusercontent.com/arhat-dev/aranya/master/cicd/k8s/crds/aranya_v1alpha1_edgedevice_crd.yaml

# create service account for aranya (we will bind both cluster role and namespace role to it)
$ kubectl -n ${NS} create serviceaccount aranya

# create cluster role and namespace role for aranya
$ kubectl -n ${NS} apply -f https://raw.githubusercontent.com/arhat-dev/aranya/master/cicd/k8s/aranya-roles.yaml

# create role bindings for aranya
$ kubectl -n ${NS} create rolebinding aranya --role=aranya --serviceaccount=${NS}:aranya
$ kubectl create clusterrolebinding aranya --clusterrole=aranya --serviceaccount=${NS}:aranya

# deploy aranya to your cluster
$ kubectl -n ${NS} apply -f https://raw.githubusercontent.com/arhat-dev/aranya/master/cicd/k8s/aranya-deploy.yaml


Create EdgeDevice resource objects for each one of your edge devices (see sample-edge-devices.yaml for example)

aranya will create a node object with the same name for every EdgeDevice in your cluster
Configure the connectivity between aranya and your edge devices, depending on the connectivity method set in the spec (spec.connectivity.method):

grpc

A gRPC server will be created and served by aranya according to the spec.connectivity.grpcConfig, aranya also maintains an according service object for that server.
If you want to access the newly created gRPC service for your edge device outside the cluster, you need to setup Kubernetes Ingress using applications like ingress-nginx, traefik etc. at first. Then you need to create an Ingress object (see sample-ingress-traefik.yaml for example) for the gRPC service.
Configure your edge device's arhat to connect the gRPC server accoding to your Ingress's host


mqtt (WIP, see Roadmap #Connectivity)

aranya will try to talk to your mqtt broker accoding to the spec.connectivity.mqttConfig.
You need to configure your edge device's arhat to talk to the same mqtt broker or one broker in the same mqtt broker cluster depending on your own usecase, the config option messageNamespace must match to get arhat able to communicate with aranya.




Deploy arhat with configuration to your edge devices, start and wait to get connected to aranya

You can get araht by downloading from latest releases or build you own easily (see docs/Build.md).
For configuration references, please refer to config/arhat for configuration samples.
Run /path/to/arhat -c /path/to/arhat-config.yaml





aranya will create a virtualpod with the name of the EdgeDevice in the same namespace, kuebctl log/exec/attach/port-froward to the virtualpod will work in edge device host if allowed. (see design reasons at Maintenance #Host Management)


Create workloads with tolerations (taints for edge devices) and use label selectors or node affinity to assign to specific edge devices (see sample-workload.yaml for example)


Common Node Taints



Taint Key
Value




arhat.dev/namespace
Name of the namespace the edge device deployed to





Common Node Labels



Label Name
Value




arhat.dev/role
EdgeDevice


arhat.dev/name
The edge device name







Performance
Every EdgeDevice object needs to setup a kubelet server to serve kubectl commands which could execute into certain pods, thus we need to provision node certifications for each one of EdgeDevices' virtual node in cluster, which would take a lot of time for lage scale deployment. The performance test was taken on my own Kubernetes cluster described in my homelab after all the required node certifications has been provisioned.


Test Workload

1000 EdgeDevice using gRPC (generated with ./scripts/gen-deploy-script.sh 1000)

each requires a gRPC and kubelet server
each requires a Node and Service object





Resuts
---
Deployment Speed:   ~ 5 devices/s
Memory Usage:       ~ 280 MB
CPU Usage:          ~ 3 GHz

---
Delete Speed:       ~ 6 devices/s



However, after 1000 devices and node objects deployed and serving, my cluster shuts me out due to the kube-apiserver unable to handle more requests, but it's farely good result for my 4 core virtual machine serving both etcd and kube-apiserver.
Roadmap
see ROADMAP.md
Q&A

Why not k3s?

k3s is really awesome for some kind of edge devices, but still requires lots of work to be done to serve all kinds of edge devices right. One of the most significant problems is the splited networks with NAT or Firewall (such as homelab), and we don't think problems like that should be resolved in k3s project which would totally change the way k3s works.


Why not using virtual-kubelet?

virtual-kubelet is designed for cloud providers such as Azure, GCP, AWS to run containers at network edge. However, most edge device users aren't able to or don't want to setup such kind of network infrastructure.
A virtual-kubelet is deployed as a pod on behalf of a contaienr runtime, if this model is applied for edge devices, then large scale edge device cluster would claim a lot of pod resource, which requires a lot of node to serve, it's inefficient.


Why arhat and aranya (why not kubelet)?

kubelet is heavily dependent on http, maybe it's not a good idea for edge devices with poor network to communicate with each other via http.
aranya is the watcher part in kubelet, lots of kubelet's work such as cluster resource fetch and update is done by aranya, aranya resolves everything in cluster for arhat before any command was delivered to arhat.
arhat is the worker part in kubelet, it's an event driven agent and only tend to command execution.
Due to the design decisions above, we only need to transfer necessary messages between aranya and arhat such as pod creation command, container status update, node status update etc. Keeping the edge device's data usage for management as low as possible.



Thanks to

Kubernetes

Really eased my life with my homelab.


virtual-kubelet

This project was inspired by its idea, which introduced an cloud agent to run containers in network edge.


Buddhism

Which is the origin of the name aranya and arhat.



Authors

Jeffrey Stoke

I'm seeking for career opportunities (associate to junior level) in Deutschland



License

Copyright 2019 The arhat.dev Authors.

Licensed under the Apache License, Version 2.0 (the ""License"");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an ""AS IS"" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.

",31
abelykh0/stm32f407-z80emu,C,"stm32f407-z80emu
Spectrum ZX 48K emulator (using STM32F407 microcontroller)

What it can do

Emulate Spectrum ZX 48K
Load snapshot in .Z80 format from SD card
Save snapshot in .Z80 format to SD card


Video
Installation
If you want to try my project, this is the only part that you need.



Hardware
Qty




Black F407VET6 board
1


VGA connector
1


PS/2 Keyboard
1


Power supply 5V DC for keyboard
1


Resistors 470 Ohm
3


Resistors 680 Ohm
3


Resistors 2.2 KOhm
2


Resistors 3.3 KOhm
2


Breadboard
1


Jumper wires
18


ST-Link v2 or clone
1



Software: Install free IDE System Workbench for STM32. I am using Windows 10, however STMicroelectronics claims that it also supports Linux and Mac.
How to connect wires:



PIN
Description
Connect To
Output




PE8
Red 1
Resistor 470 Ohm
VGA red (1)


PE9
Red 2
Resistor 680 Ohm
VGA red (1)


PE10
Green 1
Resistor 470 Ohm
VGA green (2)


PE11
Green 2
Resistor 680 Ohm
VGA green (2)


PE12
Blue 1
Resistor 470 Ohm
VGA blue (3)


PE13
Blue 2
Resistor 680 Ohm
VGA blue (3)


PD15
HSync

VGA HSync (13)


PD14
VSync

VGA VSync (14)


PB14
CLK
Resistor 2K2 to keyboard CLK and resistor 3K3 to GND



PB13
DATA
Resistor 2K2 to keyboard DATA and resistor 3K3 to GND



G
Ground

VGA Ground (5,6,7,8,10), '-' of passive speaker



Third party software
This project uses several libraries (in addition to HAL drivers from STMicroelectronics):

To display video using VGA: https://github.com/cbiffle/m4vgalib (which requires https://github.com/cbiffle/etl)
Z80 emulator: https://github.com/anotherlin/z80emu
FATFS for SD card: http://elm-chan.org/fsw/ff/00index_e.html

Plans for the future / issues

Flickering in some games
The speed is 12% faster than it is supposed to be
Sound

",10
ParaffinIoT/brokero,JavaScript,"brokero
Installer shell script for open source Paraffin microservice IoT platform. See Paraffin Platform
About
Paraffin is IoT platform based on node.js and mongodb with MQTT, HTTP and CoAP bridge.
Paraffin will enable you to put your IoT API services on your own server simply and painless in one command. It supports the popular MQTT and CoAP protocols in sync with HTTP. It is in javascript and by Parse Server api server will be able to authorize your device list so broker perform authentication by your entry data in MongoDB by api server.
Features

Simple and Scalable.
HTTP, MQTT and CoAP connections together as a bridge.
MQTT 3.1 and 3.1.1 compliant.
Sercured with authentication and JWT.

Install
Run the following command in your terminal to install the latest official Paraffin IoT Platform release.
sudo curl -o- https://raw.githubusercontent.com/ParaffinIoT/brokero/master/install.sh | bash
",2
bharti27/BestForMe,JavaScript,"BestForMe
BestForME is a Cross Domain Media Recommendation system. BFM recommend media based on users interest not just in one domain but in multiple domains like, movies, books, podcasts, video games
Available Scripts
In the project directory, you can run:
npm start
Runs the app in the development mode.
Open http://localhost:3000 to view it in the browser.
The page will reload if you make edits.
You will also see any lint errors in the console.
npm test
Launches the test runner in the interactive watch mode.
npm run build
Builds the app for production to the build folder.
It correctly bundles React in production mode and optimizes the build for the best performance.
The build is minified and the filenames include the hashes.
Your app is ready to be deployed!
Demo Link on S3
This is a demo link: http://bharti.project.s3-website-us-east-1.amazonaws.com/
Credentials
username: dexter27
password: password
username: Josephine88
password: password
or you can create a new user by clicking on registration.
",2
Lombiq/Pretty-Good-Bootstrap-Base-Theme,HTML,"Pretty Good Bootstrap Base Theme Orchard Theme Readme
Project Description
An Orchard base theme building on Twitter's Bootstrap framework.
We've also created a complete sample theme demonstrating what you can do with PGBBT.
PGBBT is the base for the themes of all Lombiq websites, including Lombiq.com, Orchard Dojo and DotNest.com.
The theme is also available for DotNest sites.
Documentation

What's the Great Purpose?
Structure
How to...
Updating Bootstrap

PGBBT currently includes the Bootstrap 3.3.4.
The module's source is available in two public source repositories, automatically mirrored in both directions with Git-hg Mirror:

https://bitbucket.org/Lombiq/pretty-good-bootstrap-base-theme (Mercurial repository)
https://github.com/Lombiq/Pretty-Good-Bootstrap-Base-Theme (Git repository)

Bug reports, feature requests and comments are warmly welcome, please do so via GitHub.
Feel free to send pull requests too, no matter which source repository you choose for this purpose.
This project is developed by Lombiq Technologies Ltd. Commercial-grade support is available through Lombiq.
",6
DVE2000/Dogbone,Python,"Dogbone addin for fusion 360
Version: 2.0


Windows users:

You can download a self extracting file here



Mac users:


If you installed F360 directly from AD - download self extracting file here


If you installed F360 from Apple App Store - download self extracting file here


If you're having problems due to Apple Security, instead of clicking in the Downloads Dock icon Folder or Stack, click ""Open in Finder"" and then right-click the package and select ""Open"". You'll be able to install it then.


zip and tar files available (for both Mac and Windows) here

Description



Face selected and top face dogbones











Minimal dogbone
Long side mortise dogbone
Short side mortise dogbone










This addin includes 3 dogbone styles (normal, minimal and mortise) and allows dogbones to be cut from either the topface or selected face.  Both static and parametric options are available - however due to a number of bugs in F360, parametric will fail on mirrored components and some component copies.  These bugs have been reported (see here), but as of writing AD has not addressed them.
The interface has been improved, and specifically allows any face orientation to be chosen on any component.  The addin is based on the f360 primitive hole feature, and is as efficient as f360 single threaded engine allows.  In Static mode it will create 70 dogbones in about 7 seconds.  Parametric mode takes a little longer to calculate initially, but recalculation is very fast if you change your model parameters.  Of course, speed also depends on the processing power of your computer.

Notes:
This version should work with all static dogbones. Parameterized dogbones mostly work, but there are definite issues with the Fusion360 API that may cause problems when trying to create dogbones. If that happens, you can create a logfile and post it here to let us know. If it turns out that it is a Fusion360 bug, please report it to Autodesk.

Dogbones has been completed revamped. Some of the original utilities have remained, as well as some original mathematical formulaes, but mostly everything else has changed.
The original add-in was based on creating sketches and extruding - Peter found using this approach to be very heavy on processing resources, so this version has been designed to create dogbones directly by using a hole tool.

This version should work with all static dogbones. Parameterized dogbones mostly work, but there are definite issues with the Fusion360 API that may cause problems when trying to create dogbones. If that happens, you can create a logfile and post it here to let us know. If it turns out that it is a Fusion360 bug, please report it to Autodesk.

WARNING: use at your own risk.
The code provided is provided ""as is"" and with all faults. We specifically disclaim any implied warranty of merchantability or fitness for a particular use. The operation of the code provided is not warranted to be uninterrupted or error free.

Installation
See How to install sample Add-Ins and Scripts
Instructions
Note that you can hover your cursor over any Dogbone dialog item and you will get an explanatory popup in Fusion360.

Select the face(s) you want the dogbones to drop from. The add-in will only allow you to select appropriate and/or parallel faces for the body, once a primary face has been selected. The orientation of the primary face for unique components or bodies may be in any direction.

All edges associated with the selected face will be automatically selected. You can select the ""Dogbone Edges"" selector in the Dogbone popup, and that will allow you to deselect or reselect only internal edges. Note that only internal edges belonging to a selected face can be selected or deselected.

Specify a tool diameter and a radial offset.
Select the Mode - Static Dogbones or Parameterized Dogbones. Parameters are created for the second mode - dogbones will move with edge changes, and you can change diameter or offset from the normal ""Change Parameters"" dialog.
Choose the type of dogbone - Normal, Minimal or Mortise. See http://fablab.ruc.dk/more-elegant-cnc-dogbones/ for a description of minimal dogbones. Mortise dogbones place the dogbones along the sides, so that they can be hidden by a connecting piece with a cut tenon. Minimal and Mortise dogbones have their own option lines become visible when selected.  Note: In the minimal dogbone dialog, you can make the Percentage Reduction negative (eg -20), to inset the dogbone into the workpiece.
Decide if you'd like dogbones to be cut to the top. (Useful if you have steps, but can't do two sided machining.)
 
You can expand Settings and specify if you'd like to see benchmark time or do any logging.
Click ok.

The add-in will then create the specified dogbones. If you choose parameterized, the critical dimensions are maintained in the parameters - so you can change the dimensions as and when needed.

If you need dogbones in different orientations for the same body, you'll have to run the addin once for each direction.
The direction for egdes for a body is locked onve any face is selected. De-select all faces if you want to change edge selection direction.
Edges are selected down from a face. Generally, selecting a bottom face will not add any edges, but de-selecting one may remove some edges.

To do:

Handle acute angles (<90 degrees) by generating a slot.
Handle obtuse angles (>90 degrees)
... who knows

License
Samples are licensed under the terms of the MIT License. Please see the LICENSE file for full details.
Authors
Peter Ludikar (pludikar), Gary Singer (DVE2000), Casey Rogers (casycrogers)

Original version by Casey Rogers: https://github.com/caseycrogers/Dogbone/tree/cbe8f2c95317ae7eded43fee384171a492c6900e
Original version Modified by Patrick Rainsberry (Autodesk Fusion 360 Business Development)
Original version Modified by David Liu (http://github.com/iceboundflame/)

",72
zhuyizhuo/notes,JavaScript,"ç®å½

notes [folder]

convention [folder]

çæ¬å·å½åè§è


database [folder]

mongodb
mysql
oracle sql
oracle åç½®å½æ°
oracle


java [folder]

annotations
cron
dubbo
freemarker
java åºç¡
java è°ä¼
java-design-patterns
jsp
jstl
jvm
mybatis
questions [folder]

questions


spring
validation
é¡¹ç®ç®¡ç [folder]

maven plugin
maven




javascript [folder]

javascript
js [folder]


linux [folder]

linux-grep
linux-top
linux


pics [folder]
README
software-install [folder]

java ç¯å¢åééç½®
mysql å®è£
pics [folder]


tools-and-settings [folder]

eclipse ä¸­çéæåè½
eclipse è®¾ç½®åå¿«æ·é®
git
idea å¿«æ·é®
idea-settings
power-designer
sublime
svn version
tools
typora å¿«æ·é®


website [folder]

reference-materials
website


windows [folder]

windows-question





TIPS
1. ç¬è®°å±ä¸ªäººå¹³æ¶ç§¯ç´¯è®°å½,å¦æè§å¾æç¨,æ¬¢è¿åä½Pull requests.
2. æ¬¢è¿ææ­£ç¬è®°ä¸­çéè¯¯.
3. æ¬¢è¿issueçè¨äº¤æµ.

èç³»æ¹å¼
æ·»å è¯·æ³¨æ:æ¥èªgitHub

QQ: 2361883887
ä¸ªäººå¾®ä¿¡:

",5
guanguans/favorite-link,Python,"favorite link
æ¶éåæ¬¢çç½å
License
GNU General Public License v3.0
May 12, 2019

æ¾ç¤ºåæ§å¶æ¨çAndroidè®¾å¤
Tpay_Svræ¯å¾®ä¿¡åæ¯ä»å®çä¸ªäººåç­¾ 24å°æ¶å¨èªå¨åè°æ¯ä»ç³»ç»çphpæå¡ç«¯ç¨åº 
å¾®ä¿¡/æ¯ä»å®äºç»´ç æ¯ä»çå¬å¨ - åç­¾æ¥å£ ææ¯ä»/ééæ¯ä»/ä¸ªäººäºç»´ç æ¶æ¬¾ç³»ç»/å¾®ä¿¡æ¯ä»æ¯ä»å®æ¯ä»äºç»´ç çå¬èªå¨åè´§/ä¸ªäººåç­¾ç³»ç»/ä¸ªäººåç­¾æ¯ä» å¾®ä¿¡.æ¯ä»å® ä¸ªäººæ¯ä»çæ§ 
æ¬¢è¿ä½¿ç¨ composer åç­¾çº¦æ¯ä»å®ä¸å¾®ä¿¡ å¸¦çå¬
æç½å¯¼èª

May 11, 2019

BeEFæ¯The Browser Exploitation Frameworkçç¼©åãå®æ¯ä¸ç§ä¸æ³¨äºWebæµè§å¨çæ¸éæµè¯å·¥å·ã
Content Security Policy å¥é¨æç¨
è¯¦ç»ä»ç»å¦ä½ä½¿ç¨ CSP é²æ­¢ XSS æ»å»ã
éå¸¸ç®åçç¹å»å¤å¶CSSææ
è±ç¹å°å¬å¸
ä¸ä¸ä»£å¯¹è±¡å³ç³»æ°æ®åºãä¸ä¸ª@MagicStacké¡¹ç®ã
PowerToysæ¯ä¸ç»ç¨äºé«çº§ç¨æ·è°æ´åç®åå¶Windowsä½éªä»¥æé«å·¥ä½æççå®ç¨ç¨åºã
Overlordæ¯åå©åå©åºäºGoè¯­è¨ç¼åçmemcacheåredis&clusterçä»£çåéç¾¤ç®¡çåè½ï¼è´åäºæä¾èªå¨åé«å¯ç¨çç¼å­æå¡è§£å³æ¹æ¡ã bilibili.com
Thruwayæ¯ç¨äºPHPçWAMPï¼Webåºç¨ç¨åºæ¶æ¯ä¼ éåè®®ï¼çå¼æºå®¢æ·ç«¯åè·¯ç±å¨å®ç°ãThruwayä½¿ç¨äºä»¶é©±å¨çéé»å¡I / Oæ¨¡åï¼reactphpï¼ï¼éå¸¸éåç°ä»£å®æ¶åºç¨ã
éç¨äºç§»å¨è¾è®¯åæHTML5çPHP SDK
Symfonyç¼ç æ åçå¼åå­å¨åº
ä½¿ç¨phpå¼åå®ç°webdavåè®®çé¡¹ç®
ð PHPççä»£ç æ´æ´ä¹é ä¸­æç¿»è¯
çç ´å­å¸
TensorFlowçRustè¯­è¨ç»å®
Yii2 Auditè®°å½å¹¶æ¾ç¤ºweb / cliè¯·æ±ï¼æ°æ®åºæ´æ¹ï¼php / jséè¯¯åç¸å³æ°æ®ã
åºäºDockerå¿«éæ­å»ºGitlabä¸Gitlab CI/CDæå¡
Laravel Envoyæä¾äºä¸ç§ç®æ´çè¯­æ³ï¼ç¨äºå®ä¹æ¨å¨è¿ç¨æå¡å¨ä¸è¿è¡çå¸¸è§ä»»å¡ãä½¿ç¨Bladeæ ·å¼è¯­æ³ï¼æ¨å¯ä»¥è½»æ¾è®¾ç½®é¨ç½²ä»»å¡ï¼Artisanå½ä»¤ç­ã
V8 JavaScriptå¼æçPHPæ©å±
RESTful API è®¾è®¡åèæç®åè¡¨ï¼å¯å¸®å©ä½ æ´å å½»åºçäºè§£RESTé£æ ¼çæ¥å£è®¾è®¡ã
JWT Framework
å¸¦æè§£æå¨çHTML5è§é¢æ­æ¾å¨ï¼å¯ä»¥èçæµé
å­èè·³å¨
Chromeè¿è¡æ¶æ§è½ç¶é¢åæ
Vue.jsåªè´´æ¿åºï¼æ ä¾èµå³ç³»ï¼å°äº2kbï¼
å¨æµè§å¨ä¸­ä½¿ç¨åç±»æä½³çç¼è§£ç å¨ç¼©å°å¾åã
K8sæ¬æºç®¡éèµæºã
goç¨åºç­ç¼è¯å·¥å·ï¼æåå¼åæç
ç¨ReactãReduxãImmutableåä¿ç½æ¯æ¹å
ç¨VueãVuex åä¿ç½æ¯æ¹å
PhpStorm Plugins-æåº use ååç§°
ä½¿ç¨Dockerådocker-composeè¿è¡Symfonyåºç¨ç¨åº

May 10, 2019

OpenMVç¸æºæ¨¡å
å¨æ¬ç¬è®°æ¬ä¸­ï¼æå°åå»ºä¸ä¸ªé¢æµè¡ç¥¨ä»·æ ¼åå¨çå®æ´æµç¨ã è·çæä»¬ï¼æä»¬å°åå¾ä¸äºéå¸¸å¥½çç»æã
HQå¼æ¾æ°æ®éçä»¥ä¸»é¢ä¸ºä¸­å¿çåè¡¨ã
âï¸Fusumaè½»æ¾å¶ä½å¸¦æMarkdownçå¹»ç¯çã
æç¬æ¥-æ¤æ¤é½ä¼æç - åç»å¥³ççæ§é«æ½®æå
ä¸ä¸ªç®åï¼è½»éçº§çJavaScript APIï¼ç¨äºå¤çæµè§å¨cookie
å°æ¨çasciiå¾è¡¨æ¶é¸¦è½¬æ¢ä¸ºå¿«ä¹çå°SVG
è¿ç¨ç®¡çå·¥å·
æ¬æåæç±ç¥åHacker Eric S. Raymond ææ°åï¼æä½ å¦ä½æä¸ºä¸åé»å®¢ã
ðç»ç«¯å­ç¬¦ä¸²æ ·å¼æ­£ç¡®å®æ
ä½¿ç¨ç²æ°´å°ä¿æ¤åä½èçç¥è¯äº§æ
Golangçæ¯ç¨HTTPä¸­é´ä»¶
ç¤¾åºBashæ¡æ¶ã
ç¨äºæ ¼å¼ååæä½æ°å­çJavaScriptåºã
è¿æ¯å¨Node.jsä¸­æå»ºCLIçæ¡æ¶ã æ­¤æ¡æ¶æ¯ä½¿ç¨Heroku CLIæå»ºçï¼ä½éç¨äºæå»ºä»»ä½èªå®ä¹CLIã
cvpr2019 papersï¼æå¸å¢éæ´ç 
ä½¿ç¨GitHubåSlackéæå°æ¨çä»£ç å¸¦å°æ¨å³å¿çå¯¹è¯ä¸­
Vim ä»å¥é¨å°ç²¾é
IPFSçæ¡é¢å®¢æ·ç«¯ã
PHPä¸­IPFS APIçå®¢æ·ç«¯åº
Generatedataæ¯ä¸ä¸ªåè´¹ãå¼æ¾æºç çèæ¬ï¼ä¸»è¦ç±javascript ï¼ PHPåMySQLææï¼å®å¯ä»¥è®©æ¨å¯ä»¥è¿éçæå¤§éåç§æ ¼å¼çå®¢æ·æ°æ®ï¼ç¨äºæµè¯è½¯ä»¶ï¼ææ°æ®è¾å¥æ°æ®åºç­ã
åå»ºä½¿ç¨èåæ°æ®å¡«åçèªå®ä¹æµè¯æ°æ®åº
8ä¸ªä¸éçéæºçææ°æ®åºæµè¯æ°æ®çå©å¨ - æå°±æ¯snailå¦ - OSCHINA
ä¸ä¸ªå¼æºå·¥å·ï¼ç¨äºä»MySqlæ°æ®åºçæå®æ´çåç«¯ã
Dockeræåçæ¬çbenkeen / generatedataé¡¹ç®
ðWebåç«¯å©æ--FeHelper

May 9, 2019

Cloud-Adminæ¯å½åé¦ä¸ªåºäºSpring Cloudå¾®æå¡åå¼åå¹³å°ï¼å·æç»ä¸ææãè®¤è¯åå°ç®¡çç³»ç»ï¼å¶ä¸­åå«å·å¤ç¨æ·ç®¡çãèµæºæéç®¡çãç½å³APIç®¡çç­å¤ä¸ªæ¨¡åï¼æ¯æå¤ä¸å¡ç³»ç»å¹¶è¡å¼åï¼å¯ä»¥ä½ä¸ºåç«¯æå¡çå¼åèææ¶ã
ä½¿ç¨Headless Chromeå°javascriptåç°çé¡µé¢åç°ä¸ºHTMLçèç¹æå¡å¨ãä¸prerenderä¸­é´ä»¶ä¸èµ·ä½¿ç¨ã
ä¸ä»½ç½ç»å®å¨å¥é¨çèµæã
ARP+DNSæ¬ºéªå·¥å·ï¼ç½ç»å®å¨ç¬¬ä¸æ¬¡å®éªï¼è¯¾å æ¼ç¤ºç¨ï¼ä¸¥ç¦éæ³ç¨éãARPSpoofï¼wifi hijackï¼dns spoof
Kubernetesä¸­ææå/äºåçåºç¨æ¶æå®è·µæå 
Vuidoæ¯ä¸ä¸ªåºäºVue.jsåå»ºæ¬æºæ¡é¢åºç¨ç¨åºçæ¡æ¶ãä½¿ç¨Vuidoçåºç¨ç¨åºå¯ä»¥å¨Windowsï¼OS XåLinuxä¸è¿è¡ï¼ä½¿ç¨æ¬æºGUIç»ä»¶ï¼ä¸éè¦Electronã
React in patterns ä¸­æç 
ð è®©æå¸®ä½ ç¾åº¦ä¸ä¸ï¼
ãMastering GOãä¸­æè¯æ¬ï¼ææ¶å½åä¸ºãç©è½¬ GOãã
Docker MachineçVMWare Workstationé©±å¨ç¨åº
åè½é½å¨çBitTorrentå®¢æ·ç«¯è½¯ä»¶ååå®ç¨ç¨åº
GitLab APIå®¢æ·ç«¯ï¼ä½¿Goç¨åºè½å¤ä»¥ç®åç»ä¸çæ¹å¼ä¸GitLabäº¤äº
GolangçHTTPæ¨¡æ
ãGOä¸å®¶ç¼ç¨ã
å°æ¨çFlutterä»£ç å¸¦å°Webæµè§å¨
ä¸ä¸ªçæ­£å¯æçå¼æ­¥ç½ç»èå¤©ï¼å¨åç«¯æ²¡æä½¿ç¨ä»»ä½JS
ä½¿ç¨Reactæå»ºæ¬æºWindowsåºç¨ç¨åºçæ¡æ¶ã
æ¡é¢èªå¨åæ¡æ¶
m4b-toolæ¯ä¸ä¸ªå½ä»¤è¡å®ç¨ç¨åºï¼ç¨äºåå¹¶ï¼æåååç« æå£°è¯»ç©æä»¶ï¼å¦mp3ï¼oggï¼flacï¼m4aæm4b
Laravelé¡¹ç®çèªå¨ä»£ç æ ¼å¼
10 åéææ¡ MySQL çç´¢å¼æ¥è¯¢ä¼åæå·§
æä»¬åå¸äºä¸ä¸ªæ°çé¡¹ç®âCrypkoãå¨Crypkoä¸­ï¼ä½ å¯ä»¥ä»ä»¥å¤ªååºåé¾ä¸è·åå¹¶äº¤æAIçæçäºæ¬¡åè§è²ã
ä½¿ç¨MakeGirlsMoeåå»ºå¨ç»è§è²
MyFlashæ¯ç±ç¾å¢ç¹è¯å¬å¸ææ¯å·¥ç¨é¨å¼åç»´æ¤çä¸ä¸ªåæ»DMLæä½çå·¥å·ãè¯¥å·¥å·éè¿è§£æv4çæ¬çbinlogï¼å®æåæ»æä½ãç¸å¯¹å·²æçåæ»å·¥å·ï¼å¶å¢å äºæ´å¤çè¿æ»¤éé¡¹ï¼è®©åæ»æ´å å®¹æã è¯¥å·¥å·å·²ç»å¨ç¾å¢ç¹è¯åé¨ä½¿ç¨
Laravel best practices
ç¨äºå­¦ä¹ ç®æ³å¹¶å¨ä»»ä½ç¼ç¨è¯­è¨ä¸­å®ç°å®ä»¬

May 8, 2019

Githubç¨æ·æå
CockroachDB  - å¼æºçäºåçSQLæ°æ®åºã
go.riceæ¯ä¸ä¸ªGoåï¼å®å¯ä»¥å¾å®¹æå°å¤çhtmlï¼jsï¼cssï¼å¾åï¼æ¨¡æ¿ç­èµæºã
å°æ¬å°æå¡å¨å¬å¼ç»å¤é¨ç½ç»
Laravelçµå­åå¡å¥é¤ï¼éç¨äºä¸ä¸ï¼è¶å¿«çå¨çº¿ååºï¼å¤æçB2Båºç¨ç¨åºå#gigacommerce
Rustééçå¤è¿ç¨ç´æ¥æ¿æ¢
ç¨äºä»Google Analyticsæ£ç´¢ç»¼åæµè§éåå¶ä»æ°æ®çLaravelç¨åºå
å¾®ä¿¡å®æ¹ js-sdk CommonJS çæ¬
åä¸½çåºç¨ç¨åºï¼çº æ­£æ¨ä»¥åçæ§å¶å°å½ä»¤ã
åè´¹è´­ç©è½¦ç³»ç»ãOpenCartæ¯ä¸ä¸ªåºäºPHPçå¼æºå¨çº¿çµå­åå¡è§£å³æ¹æ¡ã
å²ä¸æå¨çPyTorchå­¦ä¹ èµæºæ±æ»
åå¸å¼æå¡æ¡æ¶Zookeeper -- ç®¡çåå¸å¼ç¯å¢ä¸­çæ°æ® 
ð å³å» â¿ SDK 
ä¼åå³å»ç½é¡µçä½éªç Chrome æä»¶ 
ç®åçéè¯¯å¤çåè¯­
ä¸ºæ¹ä¾¿WAFå¥åºçé¡¹ç® | åäº«PHPåæå¤§é©¬ | èæ¯åç½ª | å¤å§¿å¿(åçå°±ä¸ä¸ª)
å¹²å°æ¯ä¸ä¸ªèªå¨åæä»¶å¼ç½ç»æ¼æ´æ£æµç³»ç»
ThinkCMFçµåçï¼åºäºThinkCMF5.1å¼å
Honukaiä¸»é¢åé¢è²å¦æçZSHåiTerm
cos-php-sdk-v5
åæäº SDK for PHPer

May 7, 2019

åå¸å¼ç¥è¯å¾å­å¨
phpEnvä¸æ¬¾ä¼éå¼ºå¤§çphpéæç¯å¢
Symfonyä¸Swooleéæä»¥å éæ¨çåºç¨ç¨åºã
Php-webdriveråºæ¯Selenium WebDriverçPHPè¯­è¨ç»å®ï¼å®åè®¸æ¨ä»PHPæ§å¶Webæµè§å¨ã
Golangä¼éçå®æ¿åæåå¨æ¡æ¶
å­è±ªåçé¶åºç¡æ èæ´¾æç¨ï¼ä»£ç å­æ¾å°åæ´æ°åè¯¯
vue.js(elementæ¡æ¶)+golang(beegoæ¡æ¶)å¼åçè¿ç»´åå¸ç³»ç»,æ¯ægit,jenkinsçæ¬åå¸,go ssh,BTä¸¤ç§æä»¶ä¼ è¾æ¹å¼éæ©,æ¯æé¨ç½²ååå¤ä»»å¡åé¨ç½²åä»»å¡é©å­å½æ°
Wizardæ¯åºäºLaravelå¼åæ¡æ¶å¼åçä¸æ¬¾å¼æºé¡¹ç®ï¼APIï¼ææ¡£ç®¡çå·¥å·ã
æä¾å¨Linuxä¸è¿è¡ææ°çè¾è®¯QQä¸TIMçè§£å³æ¹æ¡
è¯¥å­å¨åºåå«æçO'Reillyä¹¦ç±Flask Web Developmentç¬¬äºççæºä»£ç ç¤ºä¾ã
AnyBaræ¯æ¨çèåæ çä¸ä¸ªå°æç¤ºå¨ï¼å¯ä»¥åä¸ä»¶ç®åçäºæï¼å®æ¾ç¤ºä¸ä¸ªå½©è²åç¹ãç¹çå«ä¹ä»¥åä½æ¶æ´æ¹å®åå³äºæ¨ã
ç¼ååä¼åGoä»£ç 
SQLFlowæ¯è¿æ¥SQLå¼æçæ¡¥æ¢ï¼ä¾å¦MySQLï¼Hiveï¼SparkSQLæSQL Serverï¼å¸¦æTensorFlowåå¶ä»æºå¨å­¦ä¹ å·¥å·åãSQLFlowæ©å±äºSQLè¯­è¨ï¼ä»¥æ¯ææ¨¡åè®­ç»ï¼é¢æµåæ¨çã
å·¥å èå - éè¿ä¼éçæ§å¶å°GUIä½¿ç¨Artisan
ShopXOååç³»ç»ãå½åé¢åä¼ä¸çº§B2Cåè´¹å¼æºçµåç³»ç»ï¼åå«PC/wap/å°ç¨åº
ä¸­å½é¦ä¸ªå¼æºå­¦æ ¡æå¡ç®¡çç³»ç»ãç½ç«å¸å±èªå¨åãå­¦ç/æç»©/æå¸ãæç»©æ¥è¯¢ 
ä»ä¾åºåç®å½ä¸­å é¤æµè¯åææ¡£å¹¶ç¼©å°ææphpæä»¶
BladeOneæ¯åçæ¨¡æ¿å¼æçç¬ç«çæ¬ï¼å®ä½¿ç¨åä¸ªPHPæä»¶ï¼å¯ä»¥ç§»æ¤å¹¶å¨ä¸åçé¡¹ç®ä¸­ä½¿ç¨ãå®åè®¸æ¨å¨Laravelå¤é¨ä½¿ç¨åçæ¨¡æ¿ã
docker-slimï¼èªå¨ç¼©å docker éåçä½ç§¯çå·¥å·ãå¤§å¹åº¦ç¼©å docker éåçä½ç§¯ï¼æ¹ä¾¿ååï¼ä½¿ç¨å½ä»¤ docker-slim build --http-probe your-name/your-appãæ¯å¦ Node.js éåç¼©ååçå¯¹æ¯ï¼ from ubuntu:14.04 - 432MB => 14MB (ç¼©åäº 30.85 å)
å°é¸çï¼å¶ä¹æ ç©· ãçº¢ç½æºï¼FCå¨çº¿æ¸¸æ
ç®æ¦ ( SimpRead ) - è®©ä½ ç¬é´è¿å¥æ²æµ¸å¼éè¯»çæ©å±
gh-ostæ¯MySQLçæ è§¦åå¨çº¿æ¨¡å¼è¿ç§»è§£å³æ¹æ¡ã
å©ç¨HTTPåè®® è¿ç¨å è§£å¯æ°æ®åï¼å®ç°Burpä¸æ¡é¾æå¡ã
api-standards
APIè®¾è®¡æå
Standard Readme
ä¸­åäººæ°å±åå½å¯ç è¡ä¸æ å(GM/T)ææ¬
æ¯æå½å¯SM2/SM3/SM4/SM9/ZUC/SSLçOpenSSLåæ¯
pt-query-digest
READMEæä»¶è¯­æ³è§£è¯»ï¼å³Github Flavored Markdownè¯­æ³ä»ç»

May 6, 2019

ntpåæ¯åºäºRFC5905çSimple NTPï¼SNTPï¼å®¢æ·ç«¯çå®ç°ãå®åè®¸æ¨è¿æ¥å°è¿ç¨NTPæå¡å¨å¹¶è¯·æ±æå³å½åæ¶é´çä¿¡æ¯ã
å°Wordææ¡£ï¼.docxæä»¶ï¼è½¬æ¢ä¸ºHTML
kunpengæ¯ä¸ä¸ªGolangç¼åçå¼æºPOCæ¡æ¶/åºï¼ä»¥å¨æé¾æ¥åºçå½¢å¼æä¾åç§è¯­è¨è°ç¨ï¼éè¿æ­¤é¡¹ç®å¯å¿«éå¼åæ¼æ´æ£æµç±»çç³»ç»ã
vfsStreamæ¯èææä»¶ç³»ç»çæµåè£å¨ï¼å¯è½æå©äºååæµè¯æ¨¡æçå®æä»¶ç³»ç»ãå®å¯ä»¥ä¸ä»»ä½ååæµè¯æ¡æ¶ä¸èµ·ä½¿ç¨ï¼å¦PHPUnitæSimpleTestã
ä¸ä¸ªPHPå¿«éCGIå®¢æ·ç«¯ï¼ç¨äºåæ­¥åPHP-FPMåéè¯·æ±ï¼aï¼
ä¸åè¡ä¸çåºç¨æºå¨å­¦ä¹ åæ°æ®ç§å­¦ç¬è®°æ¬åå¾ä¹¦é¦çç²¾éåè¡¨ã
å³å»é»åmacOS Saver
ç¦å©ç´éè½¦
éåå¤å®¶ API çæ°ä¸ä»£å¾åº 
UrlHumæ¯ä¸ä¸ªä½¿ç¨PHPåLaravel Frameworkæå»ºçç°ä»£ï¼éç§åå¿«éURL Shortener
laravel telescope æ¯Laravelæ¡æ¶çä¼éè°è¯å©æãTelescopeå¯æ·±å¥äºè§£è¿å¥åºç¨ç¨åºçè¯·æ±ï¼å¼å¸¸ï¼æ¥å¿æ¡ç®ï¼æ°æ®åºæ¥è¯¢ï¼æéä½ä¸ï¼é®ä»¶ï¼éç¥ï¼ç¼å­æä½ï¼è®¡åä»»å¡ï¼åéè½¬å¨ç­ãæè¿éæ¯æ¨å½å°Laravelå¼åç¯å¢çç»ä½³ä¼´ä¾£ã
commit æäº¤æå

May 5, 2019

åç§xlsxçåæå¨åç¼åå¨ã
ä½¿ç¨WordpressåWooCommerceæå»ºé«åº¦å¯å®å¶ççµå­åå¡ç½ç«ï¼éå®shadowsocksæå¡
FydeOS - é¢åæªæ¥çäºé©±å¨æä½ç³»ç» | ä¸ºä¸­å½ç¨æ·æé ç Chrome OS
Quicker-windowèªå¨åè½¯ä»¶
Quicker IOS å®¢æ·ç«¯
CCå©æ - è¶è¶åªè´´æ¿

May 4, 2019

GraphQL å¼ååå
éè¿æç»´å¯¼å¾æ´çredisçéè¦ç¥è¯ç¹
ç¨äºä»Google Analyticsæ£ç´¢ç»¼åæµè§éåå¶ä»æ°æ®çLaravelç¨åºå
slimdumpæ¯ä¸ä¸ªå°å·¥å·ï¼å¯ä»¥å¸®å©æ¨åå»ºå¤§åMySQLæ°æ®åºçå¯éç½®è½¬å¨
é¦æ¬¾å¾®ä¿¡ macOS å®¢æ·ç«¯æ¤åæ¦æªä¸å¤å¼ 
ä¸ææ£çå¼æº Win10 æ°å­æå©ï¼æ°å­è®¸å¯è¯ï¼æ¿æ´»å·¥å·ï¼ 

May 3, 2019

æäºä¸æçæ ·ååèå¾®æå¡ååºäºå®¹å¨çåºç¨ã LinuxåWindows Dockerå®¹å¨ä¸çè·¨å¹³å°ï¼ç±.NET Core 2.2ï¼Dockerå¼æä»¥åAzureï¼KubernetesæService Fabricæä¾æ¯æã
Surface Pro 6 é»è¹æå¨çé¦å
ä¸ä¸ªéæç½ç«çæå¨ï¼ç¨äºä½¿ç¨Vue.jsæå»ºè¶å¿«éçç½ç«
ä¾ Dash ä½¿ç¨çä¸­æææ¡£
Dashä¸­æææ¡£
go è¯­è¨æ¡æ¶ gin çä¸­æææ¡£
å¿«éå¼åmacOS PHPå¼åç¯å¢
å¿«éï¼è¯è®ºï¼èç¹çæç®ä¸»ä¹Webæ¡æ¶ã
æ·±å¥çè§£Node.jsï¼æ ¸å¿ææ³ä¸æºç åæ
Vue.docset dash ææ¡£ Vue ç¦»çº¿ææ¡£ä¸­æç
leetcodeé¢è§£ï¼è®°å½èªå·±çleetcodeè§£é¢ä¹è·¯ã
ä¸ä¸ªåºæ¬çæ¸¸ææ¨¡æå¨ï¼æ¯æç»ç«¯âäºæ¸¸æâ

May 2, 2019

LeanCloud åå¸ç Git Commit æ¥å¿é£æ ¼æåã
å¨æ¼«åºæ¯æå¾æç´¢
ç±»ä¼¼unixçéåå·¥ç¨æ¡æ¶åå½ä»¤è¡å·¥å·
æµè¯å¯è½æ¯æç´¯ã AVAå¯ä»¥å¸®å©æ¨å®æä»»å¡ã AVAæ¯Node.jsçæµè¯è¿è¡å¨ï¼å·æç®æ´çAPIï¼è¯¦ç»çéè¯¯è¾åºï¼æ°è¯­è¨åè½çæ¥æ±åè¿ç¨éç¦»ï¼å¯è®©æ¨æ´ææå°ç¼åæµè¯ã
FreeRDPæ¯ä¸ä¸ªåè´¹çè¿ç¨æ¡é¢åè®®åºåå®¢æ·ç«¯
ç®¡çhostsçæ´å¥½æ¹æ³ã
mysqlæ³¨å¥,bypassçä¸äºå¿å¾

May 1, 2019

ç²¾éä»¥å¤ªå ï¼ä¸­æçï¼
Cloud-Native APIç½å³
ä»VS Codeè°è¯å¨Google Chromeä¸­è¿è¡çJavaScriptä»£ç ã
whenå½æé®å¥kubectl runæ¶ä¼åçä»ä¹ï¼
ç¨äºæ¶éåæ¥åææ çæä»¶é©±å¨çæå¡å¨ä»£çã
ä¸ä¸ªç»å¸çXSSæ¸éç®¡çå¹³å°
Macçå¾®ä¿¡çåè½æå±
å¦ä½ç¨GitHub Actionsç¼è¯Golangé¡¹ç®

April 30, 2019

å¤å¿å
200+ Macèåæ åºç¨ç¨åº
ä¸ä¸ªç®åçmacOSåºç¨ç¨åºï¼ç¨äºçæ§äºæå¡çç¶æ
Pythonä¸­çç®ååºåé¾
Sortableæ¯ä¸ä¸ªç¨äºå¯éæ°æåºçææ¾åè¡¨çJavaScriptåºã
ð¬ä½¿ç¨Google Translateï¼Bing Translatorï¼Yandex.Translateç­çå½ä»¤è¡ç¿»è¯å¨
å¼å¯¼æ¨çç¨æ·æµè§æ¨çåºç¨
Traefikæ¯ä¸ä¸ªç°ä»£HTTPååä»£çåè´è½½åè¡¡å¨ï¼å¯ä»¥è½»æ¾é¨ç½²å¾®æå¡ãTraefikä¸æ¨ç°æçåºç¡æ¶æç»ä»¶ï¼Dockerï¼Swarmæ¨¡å¼ï¼Kubernetesï¼Marathonï¼Consulï¼Etcdï¼Rancherï¼Amazon ECS ......ï¼éæï¼å¹¶èªå¨å¨æéç½®ãå¨æ¨çåè°å¨ä¸æåTraefikåºè¯¥æ¯æ¨éè¦çå¯ä¸éç½®æ­¥éª¤ã
SeaweedFSæ¯ä¸ä¸ªç®åä¸é«åº¦å¯æ©å±çåå¸å¼æä»¶ç³»ç»ãæä¸¤ä¸ªç®æ ï¼å­å¨æ°åäº¿ä¸ªæä»¶ï¼å¿«éæä¾æä»¶ï¼SeaweedFSå®ç°äºä¸ä¸ªå¸¦æOï¼1ï¼ç£çæç´¢çå¯¹è±¡å­å¨åä¸ä¸ªå¸¦æPOSIXæ¥å£çå¯éFilerï¼æ¯æS3 APIï¼FUSEæè½½ï¼å¼å®¹Hadoopã
Uber Technologieså¬å¼åå¸çåå¸å¼è·è¸ªç³»ç»ã å®å¯ç¨äºçè§åºäºå¾®æå¡çåå¸å¼ç³»ç»
ðå¨é¢çPHPå®¢æ·ç«¯è½¯ä»¶åï¼ç¨äºä½¿ç¨Hubtel Payment API
ç°ä»£HTTPåºåæµè¯å·¥å·
Javaèµæºå¤§å¨ä¸­æçï¼åæ¬å¼ååºãå¼åå·¥å·ãç½ç«ãåå®¢ãå¾®ä¿¡ãå¾®åç­ï¼ç±ä¼¯ä¹å¨çº¿æç»­æ´æ°ã
ææç®æ³é½å¨Pythonä¸­å®ç°
Cyberââneticallyå¢å¼ºçç½ç»åºç¨ç¨åº
ä¸ä¸ªé«çº§webç®å½æ«æå·¥å·ï¼åè½å°ä¼å¼ºäºDirBusterãDirsearchãcansinaãå¾¡åã
ä¸ä¸ªå¤è§æ¼äº®ä¸æäºä½¿ç¨çç§çç®¡çç³»ç»ï¼æ¨å¯ä»¥å¨æå¡å¨ä¸è¿è¡ï¼ç®¡çåå±äº«ç§çã
url2pdfåºäºä¸­ææ¯æwkhtmltopdfçdockeréåã
æ­¤ç¨åºååè®¸æ¨ç®¡çæ°æ®åºä¸­çç¨æ·æéåç»ã
âï¸LskyProï¼æ¨å¨äºç«¯çç¸åã
â¨å¦ä¸ä¸ªOneDriveç®å½ç´¢å¼
Scoop bucket ç¨äºå¼æº/åè´¹è½¯ä»¶æ¸¸æåæ¸¸æç¸å³å·¥å·
scoop-extras

April 29, 2019

PHP MySQLç±»çåè£å¨ï¼å®ä½¿ç¨MySQLiåé¢å¤çè¯­å¥ã
æ¶é&æ¨èä¼ç§ç Apps/ç¡¬ä»¶/æå·§/å¨è¾¹ç­

April 28, 2019

ä¸ç§æ¥çåå¯¼èªç®å½æ çæ°æ¹æ³
åºäºworkermançåå¸å¼å®æ¶æ¶æ¯ä¼ éæ¡æ¶ã
Webå®å¨å­¦ä¹ ç¬è®°

April 27, 2019

å¾®ä¿¡æ¯ä»å®ä¸ªäººåç­¾æ¶æ¬¾Apiç³»ç»ï¼æäºå®å¯¹æ¥åä¹ä¸ç¨æå¿æçä¸å¡ä¸è½æ¯ä»äºã
åºäºswoft-cloudçå¾®æå¡æ¶æï¼æå°åæåç²åº¦ï¼PHP7ãå¤è¿ç¨ãåç¨ãå¼æ­¥ä»»å¡ãmysqlè¿æ¥æ± ãrediè¿æ¥æ± ãrpcè¿æ¥æ± ãæå¡æ²»çãæå¡æ³¨åä¸åç°ãAopåé¢ãå¨æ³¨è§£
yqæ¯ä¸ä¸ªä¾¿æºå¼å½ä»¤è¡YAMLå¤çå¨
ãæ·±å¥è§£æGoã
è¿æ¬ä¹¦æ¯æ¥èªwaluçphpbookåçº§ç
éç¨äºmacOSçæ´å¥½çCmd-Tabï¼OSXï¼
éç¨äºæ¨å¯ç±ç½ç«çCSSå¯ä¸å·¥å·æç¤ºåºã
å¨éLaravelåºç¨ç¨åºä¸­ä½¿ç¨æ¯ä¸ªIlluminateç»ä»¶çç¤ºä¾
ðChrome/ Firefox Extensionå¯ä»¥ä»WebSiteä¸­æç´¢RSSæºURLï¼æ¯æRSSHub

April 26, 2019

ææ¡£åæºä»£ç PopClipæ©å±ã
ç¨Cç¼åçéç¨æ°æ®ç»æåç®æ³åºã
ç¼è¯å¨å·¥å·åãå¯¹äºPHPï¼æ¯çï¼æå¨å½åäºç©ä¸å¾æåæï¼......
å¦ä½æç´¢åéè¯»ä¸ç¯è®ºæ 
qqç¾¤åsoyunç¤¾å·¥åºçæ¥è¯¢sqlåç´¢å¼å­å¨è¿ç¨
ä¸ä¸ªå°åçè¾ä¸ºç®éçç¤¾å·¥åºæ¥è¯¢ç³»ç»,ä½¿ç¨Vue.js+Flask+MongoDB.å¯ç¨52g, æ¬äººä¸æä¾ä»»ä½ç¤¾å·¥åºèµæº. 
æå¼ç¤¾å·¥åº
ç¤¾å·¥åºæ¥è¯¢ç³»ç»
PHPçç°ä»£ä»»å¡è¿è¡å¨
å¨ 2019 æä¸ºä¸å Go å¼åèçè·¯çº¿å¾ãä¸ºå­¦ä¹  Go çäººèåå¤ã
ðå¨chromeæ©å±ä¸­ååå®¢å¹¶æ¨éå°github pages

April 25, 2019

ç¨äºä¸ªäººç¨éçé¨ç½²æºå¨äººã
ãKoa2è¿é¶å­¦ä¹ ç¬è®°ãå·²å®ç»ððð
å°ç½å¥é¨å­¦ä¹ vueåvueå®ä¾ï¼vueæ»ç»
HTTPè´è½½çæå¨ï¼ApacheBenchï¼abï¼æ¿æ¢ï¼ä»¥åç§°ä¸ºrakyll / boom
åºäºGolangè§£å³çé¿è¿æ¥å¹¶åæå¡å¨æ¡æ¶
Goä¸­å¿«éï¼ç»æåï¼æ°´å¹³çæ¥å¿è®°å½ã
electron builder 
åå¿åæ¬¡ä½¿ç¨æå°è¿è¡è°è¯
ç¨äºè¾å©å®å¨å·¥ç¨å¸æ¼æ´ææãæµè¯ãå¤ç°ï¼éåäºmockãhttplogãdns toolsãxssï¼å¯ç¨äºæµè¯åç±»æ åæ¾ãæ æ³ç´è§å¤æ­æç¹å®åºæ¯ä¸çæ¼æ´ã
ä»çäº§ä¸­ä¸éè¦çæä»¶ä¸­æ¸é¤PHP Composerä¾åºåæä»¶å¤¹
tj/node-prune: Remove unnecessary files from node_modules (.md, .ts, ...)ä»node_modulesï¼.mdï¼.tsï¼...ï¼ä¸­å é¤ä¸å¿è¦çæä»¶
Github é¡¹ç®æ´»è·åº¦åæå·¥å·
lanproxyæ¯ä¸ä¸ªå°å±åç½ä¸ªäººçµèãæå¡å¨ä»£çå°å¬ç½çåç½ç©¿éå·¥å·ï¼ç®åä»æ¯ætcpæµéè½¬åï¼å¯æ¯æä»»ä½tcpä¸å±åè®®ï¼è®¿é®åç½ç½ç«ãæ¬å°æ¯ä»æ¥å£è°è¯ãsshè®¿é®ãè¿ç¨æ¡é¢...ï¼ã
Windows 10çmacOS Mojave Dynamic Desktopåè½ç«¯å£

April 24, 2019

æå°çMarkdownç¼è¾å¨æ¡é¢åºç¨ç¨åº
tsharkçç»ç«¯UIï¼çµææ¥èªWireshark
åºäºGitHubé®é¢çè¯è®ºç³»ç»ã
åäº«ä¸äºé»è¹æcloveréç½®æä»¶
é»å®¢ç¥å¨ï¼è°ç¨è°ç¥éï¼
âåºåé¾åºç¨æ¡æ¶â¨
Vue.jsé©±å¨çç°ä»£ç½ç«çæå¨
åä»£ç æ¶ï¼æç»­æèè¿æ®µä»£ç è½ä¸è½å¾å®¹æçååºååæµè¯ï¼è½å¤å¤§å¹åº¦æé«æç»äº§åºçä»£ç è´¨é(å³ä½¿å®éä¸æ²¡åååæµè¯...)
ç¨JavaScriptç¼åçHTML to Markdownè½¬æ¢å¨
HackMD
Githubå³éMarkdownç¼è¾å¨ã
åå»ºåºäºComposerçPhar of PHPåºç¨ç¨åº
binä¾èµé¡¹æ²¡æå²çª
Brookæ¯ä¸ä¸ªè·¨å¹³å°ï¼Linux / MacOS / Windows / Android / iOSï¼ä»£ç/ VPNè½¯ä»¶

April 23, 2019

phpå¯¼åºå¯¼å¥excel
A LotServer KeyGen
Bluecherryçæ§ç³»ç»ï¼æå¡å¨åºç¨ï¼
Kratosæ¯bilibiliå¼æºçä¸å¥Goå¾®æå¡æ¡æ¶ï¼åå«å¤§éå¾®æå¡ç¸å³æ¡æ¶åå·¥å·ã
swoole source reading æºç åæ

April 22, 2019

wtfpythonçä¸­æç¿»è¯/æ½å·¥ç»æ/ è½åæéï¼æ¬¢è¿å¸®ææ¹è¿ç¿»è¯
ðdocsify cliå·¥å· - ä¸ä¸ªç¥å¥çææ¡£çæå¨ã
ä½¿ç¨node.jsçOAuth2.0çä¸ä¸ªéå¸¸ç®åçæ¼ç¤º
FastAPIæ¡æ¶ï¼é«æ§è½ï¼æå­¦ï¼å¿«éç¼ç ï¼éæ¶å¯ç¨äºå¶ä½
åºäºçº¯PHPå®ç°çDHåºï¼ç¨äºæå¡å¨ç«¯
dogeTV for macOS
Commit messages guide
ä¸ä¸ªä¸æ³¨äºéç§ï¼å¯æ©å±åç¾ä¸½çWebæµè§å¨
2019å¹´æä¸ºGoå¼åèçè·¯çº¿å¾
ä¸ä¸ªå¸¦æè°è¯å·¥å·çpython vmæ³¨å¥å¨ï¼åºäºgdbã
mathdroid (Odi)
å°æ¨çPythonåJavascriptä»£ç è½¬æ¢ä¸ºDOTæµç¨å¾
è½»æ¾å°å°å¾åç»åå¨ä¸èµ·ï¼èä¸ä¼å¼ä¹±ç»å¸

April 21, 2019

nicedoc.ioæ¯ä¸ä¸ªè¡¨ç¤ºå±ï¼ç¨äºç¾ågithub.comä¸æç®¡çä»»ä½docæä»¶ã
å©ç¨æç»´å¯¼å¾æ´ççdockerç¥è¯ç¹
å¼åæçæåï¼Macçäº§åå·¥å·é¾æ¨è
ä¸­å½5çº§è¡æ¿åºåmysqlåº
msgpack.org [PHP]
Ãbersicht
ä¸ä¸ªæ¼äº®çç»ç«¯ä»¿çå¨ï¼æ¨¡ä»¿æ§çé´ææ¾ç¤ºå¨......
Goè®¾è®¡æ¨¡å¼çç²¾éåè¡¨
 Full-featured code intelligence and smart autocomplete for Sublime Text
å¯¹è±¡å­å¨PHPç®æä»£ç ï¼æ¯æç®åä¸ä¼ ï¼å é¤ï¼åè¡¨åè½ãæ¯æç½æï¼è¾è®¯ï¼ä¸çï¼UCloudåå®¶API

April 20, 2019

Chromeæ©å±: åå«è·¨åï¼å®å¶HTTPè¯·æ±ååºå¤´
ä½¿ç¨ç¸åçLaravelå®è£è¿è¡å¤ä¸ªç½ç«ï¼åæ¶ä¿æç§æ·ç¹å®æ°æ®åç¦»ï¼ä»¥å®ç°å®å¨ç¬ç«çå¤åè®¾ç½®

April 19, 2019

PHPä¸­çBDD
wordpress theme rizhuti æ¥ä¸»é¢ ä¸è¦é± éæç¨

April 18, 2019

è¿æ¯GitHub Actions main.workflowæä»¶çè¯­è¨è§èåå®æ¹è§£æå¨ãå®ä½ä¸ºGitHub Actionsçä¸é¨åå¨çäº§ä¸­è¿è¡ãå®æ¯ç¨Goç¼åçã
ä½¿æ¯ä¸ªäººé½è½å¤æå»ºå¼æ­¥è½¯ä»¶
z  - è·³æ¥è·³å»
ä¸GitHub API v3é®å¥çäº¤äº
laravel-adminä½¿ç¨iframe-tabæå¼å¤é¡µé¢
ä¸ä¸ªæ°é²åè½»éçº§çJavaScriptæ¸¸æå¼æ
Laravel idcardéªè¯å¨
ripgrepéå½å°å¨ç®å½ä¸­æç´¢æ­£åè¡¨è¾¾å¼æ¨¡å¼
ð Java Android è¿å å¹´æå¨é¢çææ¯ç¹ä»¥åé¢è¯é¢ ä¾èªå·±å­¦ä¹ ä½¿ç¨
Laravel Eloquentæ¨¡åçç¹æ§ï¼å¯ä»¥è®©æ¨åéæ¨¡ååå¶å³ç³»ï¼åæ¬æä»¶ãçè³å°å¦ä¸ä¸ªæ°æ®åºã
éªè¯è¡¨åå¼æ­¥
ä¸ä¸ªå¨æ å¢é¿å·¥ç¨å¸çç»æé¡¹ç®é. 
[å]ç¨äºåå¼åçLaravel Testing Helper
ä¸ºLaravelå¼åæµè¯å©æ
Frps ä¸é®å®è£èæ¬ï¼Frpc Windows ä¾¿æ·èæ¬ï¼Frp è¿ç¨æ¡é¢ï¼
Linux å¹³å°ä¸åºäº Rust + GTK å¼åçç½æäºé³ä¹æ­æ¾å¨
Sileræ¯ä¸ç»éç¨çé«çº§æ½è±¡ï¼æ¨å¨ç¨äºPHPä¸­çå£°ææ§ç¼ç¨APIã
åä¸ä¸ª swoole
æ¸çä¸å¼å¾ä¿¡ä»»çHTMLç¨æ·è¾å¥
ð³ WeChat Playground - å¼æºå¾®ä¿¡è°è¯å·¥å·
PHPè®¾è®¡æ¨¡å¼çä½¿ç¨
PHPå®å¨éç½®æ£æ¥å¨

April 17, 2019

ä»æ··ä¹±çç½ç»ä¸­æååå®¹ã
è·¨å¹³å°ï¼GPUå éçç»ç«¯ä»¿çå¨
åç«¯æ§è½çæ§ç³»ç»,æ¶æ¯éå,é«å¯ç¨,éç¾¤ç­ç¸å³æ¶æ
xhprof: PHP7 support
é«æçåºäºä»¤çæ¡¶çéçéå¶å¨åã
ç¨äºæå»ºKubernetesåºç¨ç¨åºçSDKãæä¾é«çº§APIï¼æç¨çæ½è±¡åé¡¹ç®èææ¶ã
Goåç¨äºè½»æ¾åç°JSONï¼XMLï¼äºè¿å¶æ°æ®åHTMLæ¨¡æ¿ååºã
Beatsæ¯ç¨Goç¼åçè½»éçº§æ°æ®åéå¨ï¼å¯ä»¥å®è£å¨æå¡å¨ä¸ä»¥æè·åç§æä½æ°æ®ï¼èèæ¥å¿ï¼ææ æç½ç»æ°æ®åæ°æ®ï¼ãBeatsç´æ¥æéè¿Logstashå°æä½æ°æ®åéå°Elasticsearchï¼å æ­¤å¯ä»¥ä½¿ç¨Kibanaè¿è¡å¯è§åã
Goç¼ç¨è¯­è¨çèªå¨å®æå®æ¤ç¨åº
éç¨äºLaravel 5.xçSweetAlert2
åºäºWebçæä»¶ç®¡çå¨å¨åä¸ªPHPæä»¶ä¸­ï¼ä½¿ç¨Tiny File Manageré«æï¼è½»æ¾å°ç®¡çæä»¶
ä»¥åææªæçéåº¦æå»ºLaravel Webåºç¨ç¨åºï¼æäºå®è£ï¼æ éå®å¶ã
å§¬é¿ä¿¡APIä¸ä¸ªå¼æºåè´¹ä¸éå¶æä¾çæ´»å¸¸ç¨,åºè¡æå¡,å¼åå·¥å·,éèæå¡,éè®¯æå¡åå¬çå¤§æ°æ®çå¹³å° 
ãChromeæä»¶å¼åå¨æ»ç¥ãéå¥å®æ´Demo
ä¸ä¸ªè½»éçå·¥å·éå
Python - 100å¤©ä»æ°æå°å¤§å¸
SOLIDåå - ç®åææçè§£é
ä½¿ç¨Dockerè¿è¡Laravelé¡¹ç®å¹¶ä½¿ç¨Kubernetesè¿è¡é¨ç½²
æ¥å£åæ½è±¡ç±» - ç®åææçè§£é
â¨ç¨äºmacOSçFinderå·¥å·æ åºç¨ç¨åºï¼ç¨äºæå¼Terminalï¼iTermæHyperä¸­çå½åç®å½ã

April 16, 2019

PHP-FPMç¶æé¡µé¢CLI
DHç®æ³çAPIç«¯ï¼DHæ¯ä¸ç§å©ç¨éå¯¹ç§°ååå¯¹ç§°å¯é¥çäº¤æ¢ç®æ³ï¼ä»é¿åäºå¯¹ç§°å¯é¥äºå¬ç½æ¥åä¼ éçé®é¢ã
ä¸ä¸ªä¸»è¦ç¨äºä¿¡æ¯æéçå·¥å·éï¼ä¸»è¦æ¯ç¨äºå¯¹ç½ç«å­ååãå¼æ¾ç«¯å£ãç«¯å£æçº¹ãcæ®µå°åãææç®å½ç­ä¿¡æ¯è¿è¡æ¹éæéã
ç¨æ·åå¥½çå½ä»¤è¡shellã
ð» è®¡ç®æºéæè¯¾ | Crash Course å­å¹ç» (å¨40é 2018-5-1 ç²¾æ ¡å®æ)
èªå¨å®æè½¯ä»¶åå¸çç¹çä»»å¡ãæå¿«å°åå¸ååå¸æ¨çGitå­å¨åºï¼npmåï¼GitHubåGitLabçæ¬ï¼æ´æ¹æ¥å¿ç­ç­ï¼
ðå®ç°è¿æ»¤ææè¯æ±ðï¼åºäºç¡®å®æç©·èªå¨æº(DFA)ç®æ³ï¼æ¯æcomposerå®è£æ©å±
Golangçå®æé¡¹ç®ï¼å­¦ä¹ ç¬è®°ï¼ä»£ç ä¾ç¨æ±æ»ã
éç¨äºYii2åºç¨ç¨åºçOAuth2åè£å¨
Yii2 Webpack2èµäº§ç®¡ç
ä¸ç»å¹éä¸­å½å¤§éææºå·ç çæ­£åè¡¨è¾¾å¼ã
zipline æ¯å¼æºéåå¹³å°ï¼ä½æ¯å½åzipline å¹¶ä¸æ¯æAè¡çæµè¯ï¼å¾å¤å¨çº¿å¹³å°å¦ä¼ç¿ï¼èå®½ç­é½æ¯åºäºziplineï¼æ¬é¡¹ç®æ¹è¿ziplineï¼ä½¿å¾ziplineæ¯æAè¡æµè¯

April 15, 2019

ä¸ä¸ªæç®åå­æ± å®ç°
 è¿é·å¿«é¸ Linux ç 
Squeezer Framework  - æå»ºæ æå¡å¨çdApp
å·æAutoCompletionåè¯­æ³çªåºæ¾ç¤ºçMySQLç»ç«¯å®¢æ·ç«¯ã
Swoole å¼åçMySQLæ°æ®åºè¿æ¥æ± 
åºäºç¬è«çwebæ¼æ´æ«æå¨
ç»è®¡GitHubä¸æä»¶çä»£ç è¡æ°
saber / httpåºæä¾äºå¤çhttpè¯·æ±åååºçå®ç¨ç¨åºã
Laravel Repositoriesæ¯Laravel 5çä¸ä¸ªåï¼ç¨äºæ½è±¡æ°æ®åºå±ãè¿ä½¿åºç¨ç¨åºæ´å®¹æç»´æ¤ã
ä¾èµæ³¨å¥å®¹å¨
ç¨äºInnoDBæä»¶æ ¼å¼çè§£æå¨ï¼å¨Rubyä¸­

April 14, 2019

ç¨äºæ´æ¹RustçRFC
ð¸å½ä»¤è¡æ¨¡ç³æ¥æ¾å¨
Ruståè®®ç¼å²åºçRustå®ç°
ç¨äºè·è¸ªåºç¨ç¨åºæ¥å¿çartisanå½ä»¤
ð¾ç¨äºQiniuå­å¨çFlysystemééå¨ã

April 13, 2019

å¾®ä¿¡æ¯ä»å®ä¸ªäººåç­¾æ¶æ¬¾ç³»ç»
åºäºä»¤çæ¡¶ç®æ³åæ¼æ¡¶ç®æ³æ¥å®ç°çéééæµï¼Golangå®ç°ã
ParsedownçMarkdowné¢å¤æ©å±
PHP DataMapper and ORM
Passbolt CEåç«¯ï¼ä¸ä¸ªç¨Cakephpç¼åçJSON API

April 12, 2019

å³äºè§è§ï¼ææ¬ï¼å¼ºåå­¦ä¹ ç­ä¸­çpytorchçä¸ç»ç¤ºä¾
äººæ§åçAPIè®¾è®¡
ManaPHP Framework
ç¨äºä½¿ç¨CSSç»å¶å¾æ¡çWebç»ä»¶ã
Googleæ¥å¿è®°å½æ¨¡åçC ++å®ç°
DokuWikiå¼æºWikiå¼æ
åºäºMDXçæ¼ç¤ºæç¨¿
éå¾è®¡ç®æºç§å­¦çåè´¹èªå­¦æè²ä¹è·¯ï¼
Markdown è¯­æ³ç®ä½ä¸­æç
Rustæ¯æ¥æ°é»
æ­¤ç»ä»¶æä¾PHP 7.3ä¹åççæ¬ä¸­ä¸å¯ç¨çåè½ã
PHPçFastCGIï¼FCGIï¼åè®®å®ç°
ð Mix CLI â è®© PHP å Golang ä¸æ ·å¼åå½ä»¤è¡ç¨åº (åæ§è¡æä»¶)
ãæ°ãå¾®ä¿¡æå¡å·+å¾®ä¿¡å°ç¨åº+å¾®ä¿¡æ¯ä»+æ¯ä»å®æ¯ä»
Gitæºä»£ç éå
Docker Desktop for Windowsçéè¯¯æ¥å

April 11, 2019

HTML5æ¡é¢åºç¨ç¨åºå¼åéç¨å·¥å·
æå³å¦ä½å¨keybase.ioä¸åå»ºGPGå¯é¥çåæ­¥æåï¼å°å¶æ·»å å°æ¬å°GPGè®¾ç½®å¹¶ä¸GitåGitHubä¸èµ·ä½¿ç¨ã
Keybase Go Library, Client, Service, OS X, iOS, Android, Electron
ç±ågooglersï¼ä¸ºågooglers  - ç±»ä¼¼ææ¯åæå¡çæ¥æ¾è¡¨
ä¸ä¸ªæ³å¸®ä½ æ»ç»ææç±»åçä¸ä¼ æ¼æ´çé¶åº
Laravelæ ¸å¿ä»£ç å­¦ä¹ 
è¿æ¥ï¼ä¿æ¤ï¼æ§å¶åè§å¯æå¡ã
ä¸ä¸ªè¿æ¥ï¼ç®¡çåä¿æ¤å¾®æå¡çå¼æ¾å¹³å°ã
ç¾å®é¨è·¨ååç¹ç»å½(SSO)æç¨å¯¹åºçç¤ºä¾å®æ´ä»£ç 
docker æç¨ t.me/dockertutorial
Goè¯­è¨å®æ: ç¼åå¯ç»´æ¤Goè¯­è¨ä»£ç å»ºè®®
996.ICU chrome æä»¶
Vanillaæ¯ä¸ä¸ªåè½å¼ºå¤§çç®åè®ºåï¼æ¨å¯ä»¥è½»æ¾èªå®ä¹ï¼ä½¿å¶ä¸æ¨çç¤¾åºä¸æ ·ç¬ç¹ã

April 10, 2019

è½»æ¾ä¸è½½markdownæä»¶ä¸­çææå¾å
ä»¤äººæå¿«ä¸ä»¥æ§è½ä¸ºä¸­å¿ççº¯CSSå è½½å¨ç»ã
Crypto 101ï¼å³äºå¯ç å­¦çå¥é¨ä¹¦ã
JavaScript ç®æ³ä¸æ°æ®ç»æ
å¯ä»¥æ¾å¨ææ¡£å¤´é¨çææåå®¹çåè¡¨
ä¸ä¸ªåºäºComposerçç®åPHPæ¡æ¶ï¼çèµ·æ¥åä¸ä¸ªå°å°çLaravelã
ðåºäºä¸ä¸ªå¯ä¸å­ç¬¦ä¸²çææ°æ®åºæ¥è¯¢
äººç±»çPythonå¼åå·¥ä½æµç¨ã
PHPä¸­çä¸ä¸ªç®åçPodcast RSSç¼è¾å¨
ä¸ä¸ªç®åçPHP GitHub APIå®¢æ·ç«¯
goçç°ä»£ææ¬ç´¢å¼åº
â¨å¼ºå¤§ãä¼éçå°ç¨åºå¼æ­¥åºð å°ç¨åºpromise
Apache Airflow
ä½¿ç¨Vue CLI 3åLaravelçç¤ºä¾é¡¹ç®
é¥¥äººè°·åºåï¼ä¸ä¸ªä¼å¨çç®åã
æ´çäºä¸äºå¨å¼åæå­¦ä¹ è¿ç¨ä¸­åçä»£ç çæ®µï¼å¹¶è¿è¡ç®ååç±»ã
æ´çäºä¸äºå¨å¼åæå­¦ä¹ è¿ç¨ä¸­åçä»£ç çæ®µï¼å¹¶è¿è¡ç®ååç±»ã
æä»¶ä¸ä¼ åå«éªè¯åå­å¨ç­ç¥
æååºäºCarbonçç¬ç«DateTimeåº
åè®¸è½»æ¾å°å°Ws Securityæ å¤´æ·»å å°SOAPè¯·æ±ä¸­
AutoRoute: èªå¨å°HTTPè¯·æ±æ å°å°PHPæä½ç±»ã
Query Translatoræ¯ä¸ä¸ªå·æASTè¡¨ç¤ºçæç´¢æ¥è¯¢è½¬æ¢å¨
Jeffçç®æ³æåï¼ç¬è®°ç­çéè¯¯è·è¸ª
å¨GitHubä¸èªå¨ä»æ ç­¾ï¼é®é¢ï¼æ ç­¾åæåè¯·æ±çææ´æ¹æ¥å¿ã
å¦ä½ç»´æ¤æ´æ°æ¥å¿
å¦ææ¨æå»ºè½¯ä»¶ï¼è¯·ä¿çæ´æ¹æ¥å¿ã
PHPå®å¨éç½®æ£æ¥å¨
TinyLara/framework
JavaScriptå¨ç»å¼æ

April 9, 2019

YApi æ¯ä¸ä¸ªå¯æ¬å°é¨ç½²çãæéååç«¯åQAçãå¯è§åçæ¥å£ç®¡çå¹³å°
YDoc æ¯ä¸ä¸ªæ´æä½ çææ¡£ç«æå»ºå·¥å·ï¼åºäº markdown è½»æ¾çæå®æ´éæç«ç¹
WebAsssemblyçç¬ç«JITæ ·å¼è¿è¡æ¶ï¼ä½¿ç¨Cranelift
WebAsssemblyçç¬ç«JITæ ·å¼è¿è¡æ¶ï¼ä½¿ç¨Cranelift
æå»ºActive Directoryåå¹¶è¿è¡é»å®¢æ»å»
Traefikæ¯ä¸ä¸ªç°ä»£HTTPååä»£çåè´è½½åè¡¡å¨ï¼å¯ä»¥è½»æ¾é¨ç½²å¾®æå¡ãTraefikä¸æ¨ç°æçåºç¡æ¶æç»ä»¶ï¼Dockerï¼Swarmæ¨¡å¼ï¼Kubernetesï¼Marathonï¼Consulï¼Etcdï¼Rancherï¼Amazon ECS ......ï¼éæï¼å¹¶èªå¨å¨æéç½®ãå¨æ¨çåè°å¨ä¸æåTraefikåºè¯¥æ¯æ¨éè¦çå¯ä¸éç½®æ­¥éª¤ã
Curl client for PHP HTTP
ThinkSNSçH5å®¢æ·ç«¯ææ¡£ã
èªç±é¨ææ°7.67ç-æ ç19.02æ­£å¼çä¸è½½
nginxæºç ä¸­ææ³¨éç
æºå¨å­¦ä¹ ãï¼è¥¿çä¹¦ï¼å¬å¼æ¨å¯¼è§£æ
å¯è½æ¯è®©ä½ åçåªæµçè±è¯­è¿é¶æå
é¾å®¶äºææ¿ç§æ¿å¨çº¿æ°æ®ï¼å­éæ¿äº¤ææå¡å¹³å°æ°æ®ï¼è¯¦ç»æ°æ®åææç¨

April 8, 2019

ãç¥ç»ç½ç»ä¸æ·±åº¦å­¦ä¹ ã
GitLab API client for PHP 
å°å·åè¬çæ¼¢å­æçæ¡æ¶
Markdown ç 100 ä¸ªéªæä½ï¼æ´æ° 100 å¹´ï¼
ä½¿ç¨BihamåKocherå·²ç¥çæææ»å»ç ´è§£ä¼ ç»çzipå å¯ã
èªå¨æ´æ°æ­£å¨è¿è¡çDockerå®¹å¨
MySQL Log Analysis
ç¬åsecwikiåxuanwu.github.io/sec.today,åæå®å¨ä¿¡æ¯ç«ç¹ãå®å¨è¶å¿ãæåå®å¨å·¥ä½èè´¦å·(twitter,weixin,githubç­)
ç¨äºWebShell Log Analysisçwebshelââlç¤ºä¾
v2rayçæ¨¡æ¿ä»¬
ð ä¸­ææç Composer å
è¯¥è½¯ä»¶ååè®¸æ¨ä½¿ç¨åºå®çªå£ç®æ³è½»æ¾åå»ºåéªè¯éçéå¶ã
ä¸ä¸ªjust-add-csséåçæ ·å¼ï¼ä½¿ç®åçç½ç«æ´å¥½ä¸ç¹
Frackeræ¯ä¸å¥å·¥å·ï¼å¯ä»¥è½»æ¾è·è¸ªååæPHPå½æ°è°ç¨ï¼å¶ç®æ æ¯å¨PHPåºç¨ç¨åºçæå¨å®å¨è¯ä¼°æé´åå©ç ç©¶äººåã
Cactiæ¯ä¸ä¸ªå®æ´çç½ç»å¾å½¢è§£å³æ¹æ¡ï¼
Cactiæ¯ä¸ä¸ªå®æ´çç½ç»å¾å½¢è§£å³æ¹æ¡
Kanboardæ¯ä¸æ³¨äºçæ¿æ¹æ³çé¡¹ç®ç®¡çè½¯ä»¶ã
TypiCMSæ¯ä¸ä¸ªä½¿ç¨Laravel 5.8æå»ºçæ¨¡ååå¤è¯­è¨åå®¹ç®¡çç³»ç»ãå¼ç®±å³ç¨ï¼æ¨å¯ä»¥ç®¡çé¡µé¢ï¼äºä»¶ï¼æ°é»ï¼å°ç¹ï¼èåï¼ç¿»è¯ç­ã
laravel-source-analysis/
swoole source reading æºç åæ
PHPä¸­çM3U8è§£æå¨/è½¬å¨å¨ã

April 7, 2019

éè¿æ«æMXè®°å½ï¼æ¯æ¥æ´æ°ï¼æ¸çåéªè¯çä¸æ¬¡æ§çµå­é®ä»¶ååè¡¨ã
PHPæ©å±ï¼ä»¥äºè§£åå­ä½¿ç¨æåµ
Synology Audio Station / DS Audioçæ­è¯æä»¶
Yii 2æ©å±åºï¼ç¨äºæ¾ç¤ºä¸Leafletçäº¤äºå¼å°å¾ã
Laragonæ¯ä¸ä¸ªå¯ç§»æ¤ï¼éç¦»ï¼å¿«éä¸åè½å¼ºå¤§çéç¨å¼åç¯å¢ï¼éç¨äºPHPï¼Node.jsï¼Pythonï¼Javaï¼Goï¼Rubyãå®å¿«éï¼ééè½»......
ç½ç»ä¿¡æ¯å®å¨ä»ä¸èé¢è¯æå
è®°å½2019å¹´ç¤¾æé¢è¯è¿ç¨ä¸­çä¸äºé®é¢ï¼ä¾å¤§å®¶åèï¼å¯ä»¥è¡¥ååææ­£ï¼ä¸èµ·æé¿ï½
Editor.jsçPHPåç«¯
å¨æ Vue + Laravel + Axios CRUDç¤ºä¾

April 6, 2019

BootstrapVueä¸ºVue.jsæä¾äºæå¨é¢çBootstrap 4ç»ä»¶åç½æ ¼ç³»ç»å®ç°ä¹ä¸ï¼å¹¶ä¸å·æå¹¿æ³çèªå¨...
Laravel-Vue SPAå¥é¨é¡¹ç®æ¨¡æ¿ã
ä¸ä¸ªé«åº¦èªä»¥ä¸ºæ¯çå¥é¨å¥ä»¶ï¼ç¨äºä½¿ç¨LaravelåVue.jsæå»ºåé¡µåºç¨ç¨åº
ä»PHPæ§å¶Chrome
PHP5.3 +è·¯ç±ç±»ãè½»å·§ä½æå¶çµæ´»ãæ¯æRESTï¼å¨æåååè·¯ç±ã
å¿«éçµæ´»çè·¯ç±å¨
ð­Lavaä¸­çLaravel Translatorè¯¾ç¨ï¼
ð©å·æLuaï¼Markdownï¼HTTP / 2ï¼QUICï¼RedisåPostgreSQLæ¯æçå°åèªåå«pure-Go Webæå¡å¨
Irisæ¯ï¼THISï¼å°çä¸æå¿«çç¤¾åºé©±å¨çç½ç»æ¡æ¶ãHTTP / 2ï¼MVCç­ãä¸ºææäººæä¾æ ä¸ä¼¦æ¯çåè´¹æ¯æãæ¨çèå¼Webæ¡æ¶å¯ä»¥åå°åï¼
Iris æ¯ä¸æ¬¾è¶å¿«ãç®æ´é«æç Go è¯­è¨ Webå¼åæ¡æ¶ã Iris åè½å¼ºå¤§ãä½¿ç¨ç®åï¼å®å°ä¼æ¯ä½ ä¸ä¸ä¸ªç½ç«ãAPI æå¡æèåå¸å¼åºç¨åºç¡æ¡æ¶çä¸äºä¹éã
Standard Notesæ¯ä¸ä¸ªç®åçç§äººç¬è®°åºç¨ç¨åºï¼å¯å¨å¤§å¤æ°å¹³å°ä¸ä½¿ç¨ï¼åæ¬Webï¼Macï¼Windowsï¼Linuxï¼iOSåAndroidã
â¨è¿å100å¤ä¸ªgopherå¾çååç´ å°å¸®å©æ¨æå»ºå ä¹ä»»ä½ä¸Go Programming Languageç¸å³çè®¾è®¡ï¼æ¼ç¤ºæç¨¿ï¼åå®¢æç¤¾äº¤åªä½ä¸­çå¸å­ï¼è¯¾ç¨ï¼è§é¢ç­ç­ã
ð¾å¿«éï¼ç®åï¼å¹²åçè§é¢ä¸è½½å¨

April 5, 2019

FastDFSæ¯ä¸ä¸ªå¼æºé«æ§è½åå¸å¼æä»¶ç³»ç»ï¼DFSï¼ãå®çä¸»è¦åè½åæ¬ï¼æä»¶å­å¨ï¼æä»¶åæ­¥åæä»¶è®¿é®ï¼ä»¥åé«å®¹éåè´è½½å¹³è¡¡çè®¾è®¡ã
qBittorrent BitTorrentå®¢æ·ç«¯
å®æ´èå¼ºå¤§çPSR-14 EventDispatcherè§èå®ç°ã
ä¸ä¸ªåºäºæµè§å¨ç«¯ JS å®ç°çå¨çº¿ä»£ç
ä¸ä¸ªç¨äºå¾åä¸­äººè¸æ£æµçå¼æºåºãäººè¸æ£æµéåº¦å¯è¾¾1500FPSã
Shopify GraphQLè®¾è®¡æç¨
ç¨äºå°æ è®°åçPHPæºä»£ç è½¬æ¢ä¸ºXMLï¼ä»¥åå¯è½çå¶ä»æ ¼å¼ï¼çå°ååº
éåæ¨é¡¹ç®çæ¼äº®ææ¡£å·¥å·ã

April 4, 2019

ãReact å­¦ä¹ ä¹éãThe Road to learn React (ç®ä½ä¸­æç)
ç¨äºPHPåSymfonyçæµè§å¨æµè¯åWebç¬ç½åº
PHPé¡¹ç®/åºçä»£ç è´¨éè§è§£
éç¨ç¬¬ä¸æ¹ç»å½SDKï¼æ¯æå¾®ä¿¡ï¼å¾®ä¿¡æ«ç ï¼QQï¼å¾®åç»å½ï¼æ¯ä»å®ç»å½ï¼Facebookï¼Lineï¼Twitterï¼Google
ç¨äºä¸UbiquitiçUniFi Controller APIäº¤äºçPHP APIå®¢æ·ç«¯ç±»
æä¾æå³PHPå¯¹è±¡å¾çæç¨æä½
ð±è´§å¸æ±çåº
Pythonèæ¬ãæ¨¡æç»å½ç¥ä¹ï¼ ç¬è«ï¼æä½excelï¼å¾®ä¿¡å¬ä¼å·ï¼è¿ç¨å¼æº
è®°å½åç§å­¦ä¹ ç¬è®°(ç®æ³ãJavaãæ°æ®åºãå¹¶å......)
ç¨äºè¿è¡WebAssemblyäºè¿å¶æä»¶çPHPæ©å±ã
åºç¨ç¨åºä»ªè¡¨æ¿åå¯å¨å¨
æåè¿çåç«¯ææ¾é¡µé¢æå»ºå¨ãä»¥åçºªå½çéåº¦åå»ºé«ç«¯ï¼åç´ å®ç¾çç½ç«ãä»»ä½ä¸»é¢ï¼ä»»ä½é¡µé¢ï¼ä»»ä½è®¾è®¡ã
pythonç¬è«æç¨ï¼å¸¦ä½ ä»é¶å°ä¸ï¼åå«jséåï¼selenium, tesseract OCRè¯å«,mongodbçä½¿ç¨ï¼ä»¥åscrapyæ¡æ¶
ç¨äºçæGoogleç«ç¹å°å¾XMLæä»¶çåº
OOPä»£çåè£å¨å®ç¨ç¨åº - çæåç®¡çå¯¹è±¡çä»£ç
li 3æ¯PHPçå¿«éï¼çµæ´»åæå¤§çRADå¼åæ¡æ¶ã
 Go! AOP PHP - é¢ååé¢ç¼ç¨çæ¡æ¶ï¼ç¨äºæ°çè½¯ä»¶å¼åæ°´å¹³
Parser Reflection API  - æä¾æºä»£ç åæï¼æ éå°ç±»å è½½å°PHPåå­ä¸­
åè®¸åæ å¯¹è±¡å±æ§ï¼åæ¬ç»§æ¿å±æ§åéå¬å±å±æ§
å¾®ä¿¡å¼åèå·¥å·(å¾®ä¿¡å°ç¨åº)linuxå®ç¾æ¯æ
å°ç±³è·¯ç±å¨Shellå·¥å·ç®±ï¼æ¬äººèªç¨ï¼ä¸»è¦åèäºå°ç±³çMisstar Toolså¶ä½ï¼ä»å­¦ä¹ ä¹ç¨ï¼
pharé¨ç½²çä¾å­
ä¸ä¸ªç»ææ¸æ°çï¼æäºç»´æ¤çï¼ç°ä»£çPHP Markdownè§£æå¨
GitHub èªå¨é¨ç½²æºå¨äºº
ç¨äºä»PHPå­æ¡£ï¼PHARï¼è¯»åphar.ioæ¸åä¿¡æ¯çç»ä»¶
å»ºç«åç®¡çPharsçç³è¯·ã
Lispå°PHPç¼è¯å¨
PHP ä¾èµæ³¨å¥ï¼ä»æ­¤ä¸åèèå è½½é¡ºåº

April 3, 2019

å¨è§¦æ§æ ä¸­æ¾ç¤ºmacOS Dock
èåé³ä¹Apiï¼æ¯æ node / android / ios / electron-render è°ç¨
electronè·¨å¹³å°é³ä¹æ­æ¾å¨ï¼å¯æç½æäºãQQé³ä¹ãè¾ç±³é³ä¹ï¼æ¯æQQãå¾®åç»å½ï¼äºæ­å; æ¯æä¸é®å¯¼å¥é³ä¹å¹³å°æ­å
èªå·±å¨ææé ä¸ä¸ªå±äºèªå·±çç´æ­é´ï¼è§é¢ç´æ­ãèå¤©å®¤ãå¼¹å¹ãå¤ç«¯ééï¼
èªå·±å¨ææé ä¸ä¸ªå±äºèªå·±çç´æ­é´ï¼è§é¢ç´æ­ãèå¤©å®¤ãå¼¹å¹ãå¤ç«¯ééï¼
å¨æ Webå¼åç¬è®°ã
çº¯ Go åçç´æ­æå¡å¨
æ­¤é¡¹ç®ç¨æ¥æåæ¶éä»¥å¾æ³é²çå¯ç ä¸­ç¬¦åæ¡ä»¶çå¼ºå¼±å¯ç 
C/C++é¢è¯åºç¡ç¥è¯æ»ç» 
ä¸ä¸ä»£lså½ä»¤
å¤§å­¦çç¥è¯å±äº«æ± 
awesome window manager
TPçæéæç«ç¹ç±»
åºäºRediså®ç°çå»¶æ¶éåæå¡ï¼æä¾éååå»ºãå é¤åæ¶æ¯åéãæ¥æ¶ãå é¤çæä½ã
phpstormæä»¶,ç¨äºthinkphp5æ¡æ¶çè§å¾,éç½®,è·¯ç±,æ°æ®åº,æ¨¡åæºè½æç¤ºåè·³è½¬
Webçä¸­å½èå
ä¸å¤© 30 ç§ â± ä¸æ®µä»£ç  âï¸ ä¸ä¸ªåºæ¯ ð¼
ä¸ä¸ªç®æ´ä¼éçå¾åè¯å«è½¬æ¢æå­çphpç±»åº, é¡»å®è£tesseract-ocr
Tesseractå¼æºOCRå¼æï¼ä¸»å­å¨åºï¼
æ°æ®å­å¸èªå¨çæææ¡£ 
ð ç°ä»£ Web å¼åï¼ç°ä»£ Web å¼åå¯¼è®º | åºç¡ç¯ | è¿é¶ç¯ | æ¶æä¼åç¯ | React ç¯ | Vue ç¯
CrawlerDetectæ¯ä¸ä¸ªPHPç±»ï¼ç¨äºéè¿ç¨æ·ä»£çæ£æµæºå¨äºº/ç¬è«/èè

April 2, 2019

ç«æ chromeåªä½åæ¢æä»¶
ä¸ä¸ªå¼ºå¤§çJavascriptåºï¼ç¨äºæè·é®çè¾å¥ãå®æ²¡æä¾èµå³ç³»ã
çæçæ­£çéæºç¨æ·ä»£ç
Mercure Componentåè®¸ä½¿ç¨Mercureåè®®è½»æ¾å°å°æ´æ°æ¨éå°Webæµè§å¨åå¶ä»HTTPå®¢æ·ç«¯ã
æµè¯ææ¯èµæº
RustçActoræ¡æ¶
è¿è¡ç»´åºç¾ç§çåä½ç¼è¾è½¯ä»¶ãè¿æ¯gerrit.wikimedia.orgçä¸é¢éå­ã
Flash OSæ åå°SDå¡åUSBé©±å¨å¨ï¼å®å¨ï¼è½»æ¾ã
PHPä¸­çMustacheå®ç°ã
Nmapæ«æãæ¼æ´å©ç¨èæ¬ 
å¼±å£ä»¤,ææç®å½,æææä»¶ç­æ¸éæµè¯å¸¸ç¨æ»å»å­å¸
ä¸ä¸ªå¼æºçç½åå¯¼èªç½ç«é¡¹ç®ï¼æ¨å¯ä»¥æ¿æ¥å¶ä½èªå·±çç½åå¯¼èªã
æ ¹æ®å³é®å­ä¸ hosts çæçå³é®è¯ï¼å©ç¨ github æä¾ç apiï¼çæ§ git æ³æ¼ã
æç½ä¸­æç½çæ§ç¬è«
éç¨äºPHPçè¾è®¯äºAPI 3.0 SDK
PHPä¸­å¼æ­¥ç¼ç¨çèµæºåè¡¨
çæidenticonå¤´å,å¤´åå¾ççæ
PHPå¼åäººåçä¸äºå·¥å·ã
 å®¢æ·ç®¡ççåæ²¿åæ°-æç©ºCRM
phpseclib  -  PHPå®å¨éä¿¡åº
ç±ç¾åºï¼ç¾åº¦äºç½çæç´¢å¼æï¼ç¬è«+ç½ç« 

April 1, 2019

Markdown ç®ä½ä¸­æä¸è¥¿ææ··æè¦ç¹
Beanbun æ¯ç¨ PHP ç¼åçå¤è¿ç¨ç½ç»ç¬è«æ¡æ¶ï¼å·æè¯å¥½çå¼æ¾æ§ãé«å¯æ©å±æ§ï¼åºäº Workermanã
åºäºåæ¹åè´·æ¹ååçä½é¢ä¼è®¡ï¼ç°¿è®°ï¼å¶åº¦
swoole phpå¤è¿ç¨ç®¡ç
ç¼ºå°å®çç½ç«çRSSæº
RSS-Bridgeæ¯ä¸ä¸ªPHPé¡¹ç®ï¼è½å¤ä¸ºæ²¡æç½ç«çç½ç«çæRSSåAtomæè¦ã
ä½¿ç¨REST APIåè£èªå®ä¹SQLæ°æ®åº
åä¸æäºåäºæ¥ é¢ï¼å¨åå°æ»¨ï¼ä¸ï¼ å¨è¿æ¯ä¸ä¸ªå¯å·åå¯å¯çå¤æ æçªèå¨æ¸©ææ²äººçè¢«å­é é£è¯ççæ¯ä¸ä¸ªè½»æµ®çæ¢¦å¢ä¸­ æé½è½æ¢¦è§ä¸ä¸ªç¾ä¸½çè±å­ ææ¢¦è§æçè³äº²ä»¬ ææ¢¦è§æçæåä»¬ ææ¢¦è§æçé£ä¸ªå¥¹ å¤§å®¶å¨è±å­é é½å¨å¬æçè³äº²ä»¬è°è®ºçä¸ä¸ªäºº è®²çä»å°æ¶åçå¯ç± è®²çä»ä¸­å­¦çç¨å«© å°é«ä¸­çåéä»¥åå¤§å­¦çæç å¤§å®¶é»é»å°å¬ç èå¥¹åªæ¯é»é»åå«èå°ç¬ç äº²äººä»¬é¢åæ æ¬¢ç¬å°è®²è¿°çè¿å¾ æåä»¬æè¯´æç¬å°ææ æä¸æ¯å¤ªå®½å¤§çè©è å¥¹ä¼¸æè½»æå°ææ æè¢«å¾®é£å¹æå¼çåä¸ æä¸é¢å¾®ç¬ç ä¸æèªç¶å°é å¨å¥¹çè©èä¸ è´´çå¥¹çè¸é¢ è§¦ç¢°çå¥¹çè³çä¸åæ¢¢ æä»¬ææ¦å°æ²æµ´å¨æéçä½æä¹ä¸­ æ²æµ¸å¨å¤å§¿å¤å½©çéåä¸ åªæææçå¤©ç©ºåå¨åçå æçå°è¿å¤çº¢è²ä¸è¤è²ç¸æ¥çå°æ¹ æä¸è½®çº¢è²çå¤ªé³ èº«åèçåé»çå¤©éä¸ â¦
ç¾åº¦äº/ç¾åº¦ç½çPythonå®¢æ·ç«¯
åç§èæ¬ -- å³äº è¾ç±³ xiami.com, ç¾åº¦ç½ç pan.baidu.com, 115ç½ç 115.com, ç½æé³ä¹ music.163.com, ç¾åº¦é³ä¹ music.baidu.com, 360ç½ç/äºç yunpan.cn, è§é¢è§£æ flvxz.com, bt torrent â magnet, ed2k æç´¢, tumblr å¾çä¸è½½, unzip
Babun  - ä½ ä¼åç±çWindows shell
restful-apié£æ ¼æ¥å£ APPæ¥å£ APPæ¥å£æé oauth2.0 æ¥å£çæ¬ç®¡ç æ¥å£é´æ

March 31, 2019

Linuxå½ä»¤å¤§å¨æç´¢å·¥å·ï¼åå®¹åå«Linuxå½ä»¤æåãè¯¦è§£ãå­¦ä¹ ãæéã
å½Â·Â·Â·æ¶åçäºä»ä¹ï¼
learning-rust
ä¸æ¬¾è½»éçº§ãåè½å¼ºå¤§çåç½ç©¿éä»£çæå¡å¨ãæ¯ætcpãudpæµéè½¬åï¼æ¯æåç½httpä»£çãåç½socks5ä»£çï¼åæ¶æ¯æsnappyåç¼©ãç«ç¹ä¿æ¤ãå å¯ä¼ è¾ãå¤è·¯å¤ç¨ãheaderä¿®æ¹ç­ãæ¯æwebå¾å½¢åç®¡çï¼éæå¤ç¨æ·æ¨¡å¼ã
Wizardæ¯åºäºLaravelå¼åæ¡æ¶å¼åçä¸æ¬¾å¼æºé¡¹ç®ï¼APIï¼ææ¡£ç®¡çå·¥å·ã
ä¸äºå¸¸ç¨ç docker éå 
ä¸ä¸ªPHPerçåçº§ä¹è·¯ 

March 30, 2019

Linters Runner for Goãæ¯gometalinterå¿«5åãæ¼äº®çå½©è²è¾åºãåªè½æ¥åæ°é®é¢ãè¯¯æ¥çè¾ä½ãYaml / tomléç½®ã
å°htmlè½¬æ¢ä¸ºå¾åï¼pdfæå­ç¬¦ä¸²
php èµæºæä»¶ç®¡ç
ð ðåè´¹å¼æºçç§å­¦ä¸ç½å·¥å·
ç¨äºreCAPTCHAçPHPå®¢æ·ç«¯åºï¼è¿æ¯ä¸é¡¹åè´¹æå¡ï¼å¯ä»¥ä¿æ¤æ¨çç½ç«åååå¾é®ä»¶åæ»¥ç¨ã
é¿éå·´å·´nacoséç½®ä¸­å¿-PHPå®¢æ·ç«¯
åäº¬å¸é¢çº¦æå·ç»ä¸å¹³å°æå·å°å©æ
Yasumiæ¯ä¸ä¸ªç®åçPHPåºï¼ç¨äºè®¡ç®å½å®åæ¥
ä¸ä¸ªè¶çº§ç®åçPHPè¶å¨å±åéç®¡çæ©å±
shellä»£ç é¨ç½²ç³»ç»
ç¨Cç¼åçç®åï¼é«æ§è½çPHPæ¡æ¶

March 29, 2019

ä¸æ¬¾ç®åæç¨ãåè½å¼ºå¤§çæ··æ²å®éªæ³¨å¥å·¥å·
RedisLock for PHPæ¯ä¸ç§åæ­¥æºå¶ï¼ç¨äºå¨æè®¸å¤exeçº¿ç¨çç¯å¢ä¸­å¼ºå¶éå¶å¯¹èµæºçè®¿é®...
RedisLock for PHPæ¯ä¸ç§åæ­¥æºå¶ï¼ç¨äºå¨å­å¨è®¸å¤æ§è¡çº¿ç¨çç¯å¢ä¸­å¼ºå¶éå¶å¯¹èµæºçè®¿é®ãéæ¨å¨å®æ½äºæ¥å¹¶åæ§å¶ç­ç¥ã
kubernetes1.13éç¾¤é¨ç½²ææ¡£ï¼åæ¬kubernetesãdashboardãcorednsãingressãmetricsãceph rbdãhelmãharborãjenkinsç­ç¸å³ç»ä»¶é¨ç½²ææ¡£
é»ç®±åºç¨æéæ³¨å¥åèµæºåç°çæ»å»æ¨¡å¼ååè¯­è¯å¸ã
ãææ¶é´å½ä½æåã
ãæä¹æè¯è¦è¯´ãââ æ®éäººçå½ä¼è®²è¯æè½
åºäºswooleå¼åçéä¿¡å¼æï¼å¨çº¿èå¤©å¹³å°ï¼åç«¯éælayerimæ¡æ¶ï¼swooleåºäºeayswooleæ¡æ¶ï¼å¼æ­¥è¿æ¥æ± ï¼å¤è¿ç¨ï¼å¼æ­¥ä»»å¡ï¼ç¬ç«httperserver apiï¼websocketæ¨éï¼éæä½¿ç¨swoft-cloud è¿è¡å¾®æå¡æ¶æ
phpå®ç°çaes, des, 3deså å¯è§£å¯ç±»
GitHub ä¸ä¸äºæè¶£ç HTML å°æ¸¸æè¿è¡äºæ±å
éè¿pythonèæ¬ä¿®æ¹æ¬æºidç ´è§£teamviewer(tvçæ¬éè¦æ¯14ä»¥ä¸)
é»è¹æé¿æç»´æ¤æºåEFIåå®è£æç¨æ´ç
Google Chromeæ©å±ç¨åºï¼ç¨äºä¿®æ¹Google Chrome 55+çé¡µé¢é»è®¤ç¼ç ã
è½»æ¾å¤ä¸ªç¾ä¸½çç®åï¼åé ä½ æå²ä»¥æ¥æå¥½çç®åï¼ç¨VueåLESSå¶ä½ã
ç§å­¦ä¸ç½æä»¶çç¦»çº¿å®è£åå¨å­å¨è¿é
Goodby CSVæ¯ä¸ç§é«åå­é«æï¼çµæ´»ä¸å¯æ©å±çå¼æºCSVå¯¼å¥/å¯¼åºåºã

March 28, 2019

go é¡¹ç®è®¾è®¡æä»¶
JsonMapper  - å°åµå¥çJSONç»ææ å°å°PHPç±»
ä¸ä¸ªè¿ä¸éçå¾åºå·¥å·ï¼æ¯æMacåWinãæ¯æåç¼©åä¸ä¼ ãæ·»å å¾çææå­æ°´å°ãå¤å¼ åæ¶ä¸ä¼ ãåæ¶ä¸ä¼ å°å¤ä¸ªäºãå³å»å¾çæä»¶ä¸ä¼ ãå¿«æ·é®ä¸ä¼ åªè´´æ¿æªå¾ãæä¾Mwebæ¥å£ï¼ç®åæ¯æçäºæï¼ä¸çãé¿éãè¾è®¯ãç½æãäº¬ä¸ãç¾åº¦ãåæãéäºãUcloudãsm.msãImgurï¼
å¸®å©åç°åå®è£å·¥å·
æ£æµPHPä»£ç ä¸­çè®¾è®¡æ¨¡å¼
å·æä»¤çæ¡¶ç®æ³çPHPéçéå¶åº
æ¬é¡¹ç®è´åäºæ¶éç½ä¸å¬å¼æ¥æºçå¨èææ¥ï¼ä¸»è¦å³æ³¨ä¿¡èªç±»å¨èææ¥ï¼å¦IP/ååç­ï¼ï¼ä»¥åäºä»¶ç±»å¨èææ¥ã
åºäºSQLiteæå»ºçè½»éçº§åå¸å¼å³ç³»æ°æ®åºã
Mojito æ¯ä¸ä¸ªåºäº Laravel, Vue, Elementæå»ºçåå°ç®¡çç³»ç»ã
Node.js åºç¨çº¿ä¸/çº¿ä¸æéãåæµé®é¢åæ§è½è°ä¼æåæåï¼æ´æ°ä¸­...ï¼
å¼æ­¥PHP
ä¸ä¸ªå¼æºçäºæ¬¡ååçç¤¾åºç¨åº
å¨bladeæ¨¡æ¿ä¸­è½»æ¾ä½¿ç¨è¿æ»¤å¨ã
ç½ç«åæåºç¨ç¨åº
ä¸ä¸ªç®åçç man æåã
code colaæ¯ä¸ä¸ªchromeæ©å±ï¼ç¨äºç´è§å°ç¼è¾å¨çº¿é¡µé¢çCSSæ ·å¼ã
tldr alfred workflow
PHP Client for tldr
the only cheat sheet you need cheat.sh
955 ä¸å ç­çå¬å¸åå
ä¸­æç Awesome VS Code
PHP Excel Helper  - åºäºPhpSpreadsheetä»¥ç®åçæ¹å¼ç¼ååè¯»åçµå­è¡¨æ ¼

March 27, 2019

éè¿ä¸GitHubåGitLabçwebhookéæå¢å¼ºComposer Satis
ç¨äºgolangçsocket.ioåºï¼ä¸ä¸ªå®æ¶åºç¨ç¨åºæ¡æ¶ã
Golang gRPCä¸­é´ä»¶ï¼æ¦æªå¨é¾æ¥ï¼èº«ä»½éªè¯ï¼æ¥å¿è®°å½ï¼éè¯ç­ã
ãFlutterå®æãçµå­ä¹¦
ä¸æ¬ä¾§éäºGoè¯­è¨è¯­æ³åè¯­ä¹çç¼ç¨è§£éåæå¯¼ä¹¦ 
â996âå·¥ä½å¶ï¼å³æ¯å¤©æ©9ç¹å°å²ï¼ä¸ç´å·¥ä½å°æä¸9ç¹ãæ¯å¨å·¥ä½6å¤©ã

March 26, 2019

Pornhubæ¨¡å¼æ å¿çæå¨
æ¬æä»ç»çæ¯å©ç¨å­¦çèº«ä»½å¯ä»¥äº«åå°çç¸å³å­¦çä¼æ æçï¼ä½ä¹å¸æåä½äº«åæå©çåæ¶ä¸è¦å¿è®°èªå·±çä¹å¡ï¼ä¸è¦å®åãè½¬æèªå·±çå­¦çä¼æ èµæ ¼ï¼ä½¿å¾å¶ä»åå­¦æ æ³åçã
CrazyCodes's blog
ç¨äºæ¶è´¹æ¥èªä»»ä½Brokerçæ¶æ¯çlib
Twillæ¯Laravelçå¼æºCMSå·¥å·åï¼å¯å¸®å©å¼åäººåå¿«éåå»ºç´è§ï¼å¼ºå¤§ä¸çµæ´»çèªå®ä¹ç®¡çæ§å¶å°ãå¨Spectrumä¸ä¸æä»¬åå¶ä»äººèå¤©ï¼
ç¨äºswarrotéæçsymfonyå
Debianï¼UbuntuåCentOSçOpenVPN road warriorå®è£ç¨åºã
ç¨äºç®¡çKongç½å³çä»ªè¡¨æ¿
èæ¬éï¼å³äºCSPï¼åå®¹å®å¨ç­ç¥ï¼çæ³æ³
Collections Abstraction Library
è°·æ­reCaptchaæ¨¡åå½¢æMagento2ã
åºäºFlexboxçç°ä»£CSSæ¡æ¶
å¾®å°çWebSockets
phpå¯ææ¬è¿æ»¤ç±»ï¼XSS Filter 
åç§å®å¨ç¸å³æç»´å¯¼å¾æ´çæ¶é
laravel å³æå³ç¨çb2cååæ©å±ã
è¿æ¯PHP CodeSnifferçä¸ç»åæ¢ï¼ç¨äºæ£æ¥PHPè·¨çæ¬å¼å®¹æ§ãå®å°åè®¸æ¨åæä»£ç ä»¥ä¸PHPçæ´é«çæ¬åæ´ä½çæ¬å¼å®¹ã
å¸¦æå¯ææåç«¯çJWTç»å½å¾®æå¡ï¼å¦OAuth2ï¼Googleï¼Githubï¼htpasswdï¼osiamï¼..
Netflix Eurekaæå¡å¨çPHPå®¢æ·ç«¯ãæ¯æææEureka RESTæä½ã
ï¼Spring Cloudï¼Netflix Eurekaæå¡æ³¨åååç°çPHPå®¢æ·ç«¯ãhttp://hamid.work
å¾è¯´è®¾è®¡æ¨¡å¼
ä¸ä¸ªå¥½ç©çWebå®å¨-æ¼æ´æµè¯å¹³å°
PHP7æ©å±å¼å ç³»åæç¨
å½ä½ sshæ¶å¸¦ä¸ä½ ç.bashrcï¼.vimrcç­
æ¯å¨ä¸ºä½ æä¾é«è´¨éçå³äºå°ç¨åºãh5ç­åç«¯é¢åçæç« åé¡¹ç®
åäº¬å¤§å­¦è¯¾ç¨èµææ´ç
åäº¬é®çµå¤§å­¦è®¡ç®æºèç ä¿¡æ¯æ±æ»

March 25, 2019

phanæ¯ä¸ä¸ªéæè¯­æ³å¼å®¹æ§å·¥å·ï¼å®å¯ä»¥åæè¯­æ³æ¯å¦ç¬¦åæå®phpçæ¬ï¼å¹¶å°ç»æè¾åºå°æå®æä»¶ã
ä¸æ¬¾ç¦»çº¿ï¼é«é¢å¼çðå·¥ä½è½¯ä»¶ï¼äºåäºåéä¸æ³¨åä¸ä»¶äºâ­ï¸ã
ç¨NodeJSè§£æçº¯çIPåº(QQwry.dat) æ¯æIPæ®µæ¥è¯¢
åç«¯å°æµç­é¢æ¶éä¸ç¨
GoAccessæ¯ä¸ä¸ªå®æ¶ç½ç»æ¥å¿åæå¨åäº¤äºå¼æ¥çå¨ï¼å¯ä»¥å¨* nixç³»ç»ä¸­çç»ç«¯æéè¿æµè§å¨è¿è¡ã
å°Nginx log_formatè½¬æ¢ä¸ºgoaccesséç½®æä»¶
èªå¨SQLæ³¨å¥åæ°æ®åºæ¥ç®¡å·¥å·
ç¨äºï¼åï¼åºååä»»ä½å¤ææ°æ®çåºï¼æ¯æXMLï¼JSONï¼YAMLï¼
äººäººé½è½å­¦ä¼ç WordPress å®æè¯¾
å¨å ç§éåè·å¾ä¸ä¸ªå¹²åçï¼éæ¶å¯ç¨çLinuxçå­ã
è®°å½èªå·±å­¦ä¹ TensorFlowçåèèµæãç¬è®°åä»£ç 
ä»¥å¾æå¾
å¾®ä¿¡ååæ¦æªæ£æµãQQååæ¦æªæ£æµã360ååæ¦æªæ£æµãååWhoisæ¥è¯¢
PhpBoot æ¯ä¸ºå¿«éå¼åå¾®æå¡/RESTful API è®¾è®¡çPHPæ¡æ¶ãå®å¯ä»¥å¸®å©å¼åèæ´èç¦å¨ä¸å¡æ¬èº«, èå°åæ¥å¼åä¸­ä¸å¾ä¸å, ä½åéå¤æ¯ç¥çäºæä¸¢ç»æ¡æ¶, æ¯å¦ç¼åæ¥å£ææ¡£ãåæ°æ ¡éªåè¿ç¨è°ç¨ä»£ç ç­ã

March 24, 2019

Ludwigæ¯ä¸ä¸ªåºäºTensorFlowæå»ºçå·¥å·ç®±ï¼å¯ä»¥è®­ç»åæµè¯æ·±åº¦å­¦ä¹ æ¨¡åï¼èæ éç¼åä»£ç ã
Webçä¸­å½èå
ä¸ä¸ªè½»éçº§çåæ¶æ¯
å¾®ä¿¡mac/ipadåè®®ï¼webapiå°è£å¥½çå®ç°æ¹æ¡ï¼åIISä¸é®é¨ç½²ã å¯å®ç°å¾®ä¿¡80%åè½ï¼æ¯æ62æ°æ®ç»å½ãæ«ç ç»å½ãæ¶åæååãæ¥çæååãå¾®ä¿¡å»ºç¾¤ãå¾®ä¿¡æäººè¿ç¾¤ãå¾®ä¿¡å¬ä¼å·éè¯»ãå¾®ä¿¡æ¶æ¯æ¶åãå¾®ä¿¡éè¿çäººå®ä½ãå¾®ä¿¡æ·»å å¥½åãå¾®ä¿¡çº¢åæ¥æ¶ãå¾®ä¿¡é²æ¤åãåäº«å°ç¨åºãå¾®ä¿¡å ç²ãå¾®ä¿¡æ¶èãå¾®ä¿¡æ ç­¾ç­
è½»æ¾å°å¼æ­¥è¿è¡ä»£ç 
è¯¥é¡¹ç®çç®çæ¯å¨PHPä¸­åå»ºDNSè®°å½çæ½è±¡å¯¹è±¡è¡¨ç¤ºãè¯¥é¡¹ç®åå«ä»£è¡¨DNSå¯¹è±¡çåç§ç±»ï¼å¦Zoneï¼ResourceRecordååç§RDataç±»åï¼ï¼ç¨äºå°BINDæ ·å¼ææ¬æä»¶è½¬æ¢ä¸ºPHPå¯¹è±¡çè§£æå¨ï¼ä»¥åç¨äºåå»ºç¾è§BINDè®°å½çæå»ºå¨ã
æ­¤ç»ä»¶ä¸ºIntlæ©å±ï¼IDNåè½ï¼æä¾é¨åæ¬æºPHPå®ç°ã

March 23, 2019

mac æç®çå¼åç¯å¢ valet
OBS Studio  - ç¨äºç´æ­åå±å¹å½å¶çåè´¹å¼æºè½¯ä»¶
éç¨äºLinuxï¼BSDåOSXçå¿«éè½»éçº§æ¥å¿å¤çå¨åè½¬åå¨
ð¦å¿«éï¼è½»éçº§åæ æ¶æçæç´¢åç«¯ãElasticsearchçæ¿ä»£æ¹æ¡ï¼å¯å¨å MBçRAMä¸è¿è¡ã
PHPå¾½ç« ï¼ä½¿ç¨åè£ä¿¡æ¯ä¸ºæ¨çèªè¿°æä»¶æä¾ä¸äºå¾½ç« ã
æ¶é&æ¨èä¼ç§ç Apps/ç¡¬ä»¶/æå·§/å¨è¾¹ç­
PHPçè°è¯æ 

March 22, 2019

Go è¯­è¨ä¸­æç½ | Golangä¸­æç¤¾åº | Goè¯­è¨å­¦ä¹ å­å° æºç 
GCTT Goä¸­æç½ç¿»è¯ç»ã
é¿éäºå®¹å¨æå¡æç»­äº¤ä»
è®°å½æé¿çè¿ç¨
rust åç¨åº
ä»markdownæä»¶åå»ºä¹¦ç±ãåGitbookä¸æ ·ï¼ä½å¨Rustä¸­å®ç°
è¿å¯è½æ¯yii2ä¸­æå¥½ç¨çå¾®ä¿¡SDK
å¨æ¸éæµè¯ä¸­å¿«éæ£æµå¸¸è§ä¸­é´ä»¶ãç»ä»¶çé«å±æ¼æ´ã
å¨çº¿å­ååä¿¡æ¯æ¶éå·¥å·
å¨çº¿å­ååä¿¡æ¯æ¶éå·¥å·
Laravel GraphQL Server
è¿æ¯ZipArchiveæ¹æ³çä¸ä¸ªç®ååè£å¨ï¼å¸¦æä¸äºæ¹ä¾¿çåè½
ð¦MacApp Storeå½ä»¤è¡çé¢
Hexoçç®¡ççé¢
Beanstalkéåæå¡å¨çç®¡çæ§å¶å°
ä»Laravelåºç¨ç¨åºåå»ºéæç«ç¹å
æ¨çåºç¡æ¶æä½ä¸ºGraphQLæå¡
æ ¹æ®Mixæ¸åæ·»å é¢å è½½åé¢åé¾æ¥
XHProfæ¯PHPçåè½çº§åå±åæå¨ï¼å·æç®åçåºäºHTMLçç¨æ·çé¢ã
PHPéä¾µå¥å¼çæ§å¹³å°- ä¼åæ§è½ï¼å®ä½Bugçç¥å¨ï¼å«åè®©ä½ çPHPç¨åºè£¸å¥ã
å¨MongoDBä¸æå»ºçXHProfæ°æ®çå¾å½¢çé¢
éç¨äºPHP 7çç°ä»£XHProfå¼å®¹PHP Profiler
ç¨äºmacOSä¸çv2ray-coreçGUI
V2rayU,åºäºv2rayæ ¸å¿çmacçå®¢æ·ç«¯,

March 21, 2019

ä¸ä¸ä»£åç«¯ç»ä¸æ¡æ¶ - æ¯ææ¡é¢Webãç§»å¨H5åå°ç¨åº
æ¢é¾å®å¨å¢éç¥è¯åº
ä¸ç§ç¨äºä¼ä¸èªæç®¡çå¼æºææ¡£ç®¡çå·¥å·ã
Pythonä¸­çå¼ éåå¨æç¥ç»ç½ç»ï¼å·æå¼ºå¤§çGPUå éåè½
ä¸­æè¿ä¹è¯å·¥å·å
ä½¿ç¨PHP Annotationså£°æGraphQL API
æäººåå®¢ï¼ååç«¯åç¦»ï¼Vue+Beego Restful api å¼ç®±å³ç¨ï¼é¨ç½²ç®åï¼åå°ç®¡çç³»ç»ç®æ´ç¾è§ã
Golangå®ç°çåºäºbeegoæ¡æ¶çæ¥å£å¨çº¿ææ¡£ç®¡çç³»ç»
æ ¹æ®Mixæ¸åæ·»å é¢å è½½åé¢åé¾æ¥
åç¡®ç99.9%çipå°åå®ä½åº
Sublime Texté¢è²æ¹æ¡å·²åå¤å¥½ç¨äºä¸ä¸ä»£JavaScriptè¯­æ³
ä¸­æå¼æºå­ä½é 
è½»æ¾å­å¨ä¸äºå¼
ä¸­å½è¿ç¨å·¥ä½èµæå¤§å¨
PHP 5.3+çé«åº¦èªä»¥ä¸ºæ¯çæ¨¡ææ¡æ¶
Yåéå­¦ä¹ Xç§è¯­è¨

March 20, 2019

PHPé¿éå·´å·´äºå®¢æ·ç«¯çå®æ¹å­å¨åº
Go æ¯æ¥éè¯»å Go å¤è¯» 
JIKEFM - å³å»çµå°ð»
phpå¼æºååç³»ç»ï¼åºäºswooleãeasyswooleæ¡æ¶å¼å
phalcon-oauth2-server
å¼æºSpotifyå®¢æ·ç«¯åº
easywechat for thinkphpæ¯æ
ä¸ä¸ªåè´¹ä¸ç¬¦åéå¾·æ åçç§çå±äº«å¹³å°ï¼ç±ActivityPubèåæä¾æ¯æã
ä½¿ç¨ç¸åçLaravelå®è£è¿è¡å¤ä¸ªç½ç«ï¼åæ¶ä¿æç§æ·ç¹å®æ°æ®åç¦»ï¼ä»¥å®ç°å®å¨ç¬ç«çå¤åè®¾ç½®ã
å»ºç«å¨laravel for allä¸ççµå­åå¡æ¡æ¶ï¼ç¨äºæå»ºåæ©å±æ¨çä¸å¡ã

March 19, 2019

Caffeï¼æ·±åº¦å­¦ä¹ çå¿«éå¼æ¾æ¡æ¶ã
ç¨æ·åå¥½çå½ä»¤è¡shellã
ä¸ä¸ªå®æ´çPHPæä½å·¥å·
*nixç³»ç»ç®¡çåæµè¯é®é¢åç­æ¡çéåã
å¾®ä¿¡å¬ä¼å·æçç¼è¾å¨ï¼è½¬æ¢ Markdown å°å¾®ä¿¡ç¹å¶ç HTML
ä¸ºæ¯ç¹å¸ç¤¾åºæä¾çä¸ç»èµæºã
ðä½¿ç¨HTMLæ¨¡æ¿çjQueryæ¥åæä»¶
LaraCMS åå°ç®¡çç³»ç»
LaraCMS Frameworkãââ LaraCMS æ ¸å¿åºç¡æ¡æ¶ï¼éå LaraCMS ä½¿ç¨ã
PHPé«çº§å·¥ç¨å¸é¢è¯é¢æ±æ»(2018.05)
åºäºswooleå®ç°çå¾®ä¿¡æºå¨äººï¼ä¾èµvbotåå¾®ä¿¡ç½é¡µççåè½ï¼å¸®å©ç®¡çå¾®ä¿¡ç¾¤/èå¤©/è¸¢äººç­
å¨Composerè¿è¡æ¶åå¹¶ä¸ä¸ªæå¤ä¸ªå¶ä»composer.jsonæä»¶
ðæ¬å°gitç»è®¡ä¿¡æ¯ï¼åæ¬ç±»ä¼¼GitHubçè´¡ç®æ¥åã
æ²¹ç´èæ¬ ç´æ¥ä¸è½½ç¾åº¦ç½çåç¾åº¦ç½çåäº«çæä»¶,ç´é¾ä¸è½½è¶çº§å é
åå»ºåå«ä¸ªäººæ°æ®çzipæä»¶
è¶çº§éæ¥è¡¨ - ç¼ç¨è¯­è¨ãæ¡æ¶åå¼åå·¥å·çéæ¥è¡¨ï¼åä¸ªæä»¶åå«ä¸åä½ éè¦ç¥éçä¸è¥¿ â¡ï¸
è¶èµç Linux è½¯ä»¶
tree-qlæ¯ä¸ä¸ªlaravelæ©å±,éè¿ç®åçéç½®æå»ºåºä¸å¥æå·æè¿°æ§,å¯è¯»æ§,ä¸æ²¡æä»»ä½åä½çé«æ§è½API.
å·æAutoCompletionåè¯­æ³çªåºæ¾ç¤ºçMySQLç»ç«¯å®¢æ·ç«¯ã
å¸¦æè¯¦ç»æ³¨éç yii2 2.0.3 ä»£ç ãåæ¬¢çè¯è¯·ç¹starï¼æ¬¢è¿å¤§å®¶ä¸èµ·æ¥è¡¥å
æå»ºèªå·±çPHPæ¡æ¶
A simple PHP framework æå»ºèªå·±çPHP æ¡æ¶ä»£ç ç¤ºä¾
NideShopï¼åºäºNode.js+MySQLå¼åçå¼æºå¾®ä¿¡å°ç¨åºååï¼å¾®ä¿¡å°ç¨åºï¼ nideshop.com
ä¼ä¸ä»åºç®¡çç³»ç»
phpä»åºè¿éå­

March 18, 2019

ClickHouseæ¯ä¸ä¸ªç¨äºå¤§æ°æ®çåè´¹åæDBMSã
å¨æµè§å¨ä¸­æ­æ¾çæé³ä¹çå¹³å°ã
Godot Engine  - å¤å¹³å°2Då3Dæ¸¸æå¼æ
ð°ç¨äºæ£æµä»£ç åæµè¯ä¸­çåå­æ³æ¼çPHPUnitæä»¶
roave / dontæ¯ä¸ä¸ªå°åçPHPè½¯ä»¶åï¼æ¨å¨å®ç°è®¾è®¡é²å¾¡æ§ä»£ç æ¶çè¯å¥½å®è·µ
Githubä¿¡æ¯æ³æ¼çæ§ç³»ç»
PHP7çç®æ´å¹¶è¡å¹¶åAPI
JSON-Schema +åæ°æ®çæå¨
å¤æ¡æ¶ç¼åå¨åºå®è£ç¨åº 
Composerå®è£ç¨åºæ©å±ç¨åº
æ¯æï¼Laravel / Lumen / PSR-15 / Swoft / Slim / ThinkPHPï¼ -  PHP CORSï¼è·¨æºèµæºå±äº«ï¼ä¸­é´ä»¶ã
ç±libsodiumæä¾æ¯æçé«çº§å å¯æ¥å£
apache/logging-log4php
ç¨äºæ£æµç¨æ·æµè§å¨çPHPç±»
ä¸ä¸ªè½»éçº§çPHPåé¡µå¨
éè¿çæåå«ææèªå¨å è½½æä»¶çåä¸ªPHPæä»¶æ¥ä¼åç±»å è½½æ§è½ã

March 17, 2019

è¾å¥æ£æ¥JSX for Rust
å°ç»ä¹ è®©ä½ ä¹ æ¯éè¯»åç¼åRustä»£ç ï¼
æè¿å¯¹Goè¯­è¨å¾æå´è¶£ï¼æä»¥æ´çç¸å³èµæï¼åµåµ
éåææäººçPHPæ°æ®åºè¿ç§»

March 16, 2019

OPNsense GUIï¼APIåç³»ç»åç«¯
åºäºLuaçè·¨å¹³å°æå»ºå®ç¨ç¨åº
Element UI ä¸­å½çå¸åºçº§èæ°æ®
linuxåæ ¸ç½ç»åè®®æ æºç éè¯»åææ³¨é--å¸¦è¯¦å°½ä¸­æåææ³¨éä»¥åç¸å³æµç¨åæè°ç¨æ³¨éï¼å¯¹çè§£åæåæ ¸åè®®æ æºç å¾æå¸®å©
å¼æºGraphQL CMS
æ¼å¤å¤API SDKãæ¼å¤å¤å¼æ¾å¹³å°ã
è¾è®¯AIå¼æ¾å¹³å° ãTencent AI open platformã
è¯¥åºæä¾äºå´ç»æ°å­¦è¿ç®çå·¥å·ã
phpçå¬å¼è§£éå¨
PHP Redis Cacheç¼å­ç­ç¥ææ¯
A web framework for Rust.
draw.ioæ¯ä¸ä¸ªå¨çº¿å¾è¡¨ç½ç«ï¼æä¾æ­¤é¡¹ç®ä¸­çæºä»£ç ã
ä¸ä¸ªç¨äºå¾åä¸­äººè¸æ£æµçå¼æºåºãäººè¸æ£æµéåº¦å¯è¾¾1500FPSã
ä»£ç ä¿¡æ¯çç»è®¡ç¨åº 

March 15, 2019

èªå­¦æ¯é¨æèº
WebSVN  - å¨çº¿subversionå­å¨åºæµè§å¨
ç¨äºå®ä¹ç¶æçè½»éçº§åº
ä½¿ç¨Vegaï¼æ¨å¯ä»¥ä½¿ç¨JSONæ ¼å¼æè¿°æ°æ®å¯è§åï¼å¹¶ä½¿ç¨HTML5 CanvasæSVGçæäº¤äºå¼è§å¾ã
ç¨äºä¸Pusher Channels HTTP APIäº¤äºçPHPåº
ð¦ å¾®åç³»ç»å®ç°
åºäº Laravel å¯çµæ´»èªå®ä¹ççç§äººå¾®ä¿¡æºå¨äººï¼è½å¤å®ç°å¦ï¼æå¹´ç¾¤åèªå¨åå¤ãæ¶æ¯è½¬åãé²æ¤åãæå·å å¥½åãçè³çè¨ç»è®¡ç­åè½
ç®åçéªåéç¥
å°PHPæ°æ®è½¬æ¢ä¸ºJavaScriptã
Lua http restful apiæ¡æ¶
MySQLå¥é¨æç¨ï¼MySQL tutorial bookï¼
PHP cronè¡¨è¾¾å¼è§£æå¨å¯ä»¥è§£æCRONè¡¨è¾¾å¼ï¼ç¡®å®å®æ¯å¦åºè¯¥è¿è¡ï¼è®¡ç®è¡¨è¾¾å¼çä¸ä¸ä¸ªè¿è¡æ¥æï¼ä»¥åè®¡ç®è¡¨è¾¾å¼çä¸ä¸ä¸ªè¿è¡æ¥æãæ¨å¯ä»¥è·³è¿nä¸ªå¹éæ¥ææ¥è®¡ç®è¿ææè¿å»çæ¥æã

March 14, 2019

ç»ç«¯çç³»ç»çæ§ä»ªè¡¨æ¿
Rediså¤çº¿ç¨å
PHP 7+ä»æ¬¾å¤çåºãå®æä¾äºå¤çä»æ¬¾æéçä¸åï¼ä¿¡ç¨å¡åå¼å°è´­ä¹°ï¼è®¢éï¼æ¯ä»ç­ - ç±Forma-Proæä¾
ç¨äºPHPçHTML to Markdownè½¬æ¢å¨
ä¸ä¸ªå³äºäººå·¥æºè½æ¸éæµè¯åæç³»å
weblogic æ¼æ´æ«æå·¥å·
ä¸ä¼ æ¼æ´fuzzå­å¸çæèæ¬
OpenCVçPHPæ©å±
OS Xçå¨å±é¼ æ æå¿
è¿æ¥ææKuberneteséç¾¤ï¼æ è®ºå®ä»¬å¨ä¸ççåªä¸ªä½ç½®ã
Markdownè§£æå¨ï¼åå¾å¯¹ã100ï¼CommonMarkæ¯æï¼æ©å±ï¼è¯­æ³æä»¶åé«é
å°ä»»ä½ä½¿ç¨STDIN / STDOUTçç¨åºè½¬æ¢ä¸ºWebSocketæå¡å¨ãåinetdä¸æ ·ï¼ä½å¯¹äºWebSocketsã
Overlordæ¯åå©åå©åºäºGoè¯­è¨ç¼åçmemcacheåredis&clusterçä»£çåéç¾¤ç®¡çåè½ï¼è´åäºæä¾èªå¨åé«å¯ç¨çç¼å­æå¡è§£å³æ¹æ¡ã
githubæ³é²æ«æç³»ç»
ä¸ºCentOS / Debian / Ubuntuèªå¨å®è£Shadowsocks Server
å³äºäº¤åç¼è¯Rustç¨åºéè¦äºè§£çä¸åï¼
è²ç±³ç²æ¯ä¸ä¸ªåºäºPHP+MySQL+å¾®ä¿¡å°ç¨åºææ¯æ çãæ¥æç¨æ·ç»å¥ãåå¸ãä¿®æ¹ãå é¤åè½¬åä¿¡æ¯ãä»¥åç§ä¿¡èå¤©æ¨¡åçä¿¡æ¯æµåºç¨ã
Laravel 5 ç³»åå¥é¨æç¨ https://github.com/johnlui/Learn-Laraâ¦
åºäºphpåbashçç¦»çº¿ä¸è½½ç¥å¨ http://goxz.gq
EleTeamå¼æºé¡¹ç®-çµåå¨å¥è§£å³æ¹æ¡ä¹PHPç-Shop-for-PHP-Yii2ãä¸ä¸ªç±»ä¼¼äº¬ä¸/å¤©ç«/æ·å®çååï¼æå¯¹åºçAPPæ¯æï¼ç±EleTeamå¢éç»´æ¤ï¼
è¦å¥ç¥¥çå­¦ä¹ ç¬è®°ï¼åç§å ååéå¥é¨çææ¡£
åå°éè¯»çä¹è¶£ -  Arc90çå¯è¯»æ§PHPç«¯å£
åºäºGITçåºç¨ç¨åºçç°ä»£ç¬è®°ï¼ä¸éè¦æ¬å°GITç¯å¢ãgitnoteapp.com
ãå¤§è¯è®¾è®¡æ¨¡å¼ãphpçæ¬
çº¯PHPå®ç°GraphQLåè®®
é¿æ³¢ç½11å·å¶å¯¼è®¡ç®æºï¼AGCï¼ä¸­æä»¤æ¨¡åï¼Comanche055ï¼åç»ææ¨¡åï¼Luminary099ï¼åå§ä»£ç ã

March 13, 2019

SQLä¼åå¨åéåå¨
ä¸ä¸ªç®åçè¾è®¯ä¼ä¸é®ç®±SDK
QueryPHP æ¯ä¸æ¬¾ç°ä»£åçé«æ§è½ PHP 7 å¸¸é©»æ¡æ¶
rust ç½ç»ä»£çåé§éï¼VPNï¼
ngx_php7  - ç¨äºnginxæ¨¡åçåµå¥å¼php7èæ¬è¯­è¨ãngx_phpçä¸»çº¿å¼åçæ¬ã
æ¨å¨éè¿åæä¼ä¸ä¿¡æ¯å®å¨å»ºè®¾è¿ç¨ä¸­çå¿è·¯åç¨
PSR-7åPSR-15 OpenAPIéªè¯ä¸­é´ä»¶
è½»æ¾å®å¨å°ç®¡çcrontabæä»¶
ä¸ä¸ä»£ShadowsocksX
å¼æºè¿ç»´å¹³å°ï¼å¸®å©ä¸­å°åä¼ä¸å®æä¸»æºãä»»å¡ãåå¸é¨ç½²ãéç½®æä»¶ãçæ§ãæ¥è­¦ç­ç®¡ç(
Jamlee/coroutine: php nonpreemptive multipletasking
rust ä¸ä¸ªæ¨¡ååå·¥å·åï¼ç¨äºä½¿ç¨RuståWasmæå»ºå¿«éï¼å¯é çWebåºç¨ç¨åºååº
rust ä»å½ä»¤è¡è½»æ¾å®å¨å°å±äº«æä»¶ãåè½é½å¨çFirefoxåéå®¢æ·ç«¯ã
TypeScript å¥é¨æç¨
ç²¾éæ¯ç¹å¸ï¼ç¬¬äºçï¼-- åºåé¾ç¼ç¨
ä½¿ç¨Nginx+Luaå®ç°èªå®ä¹WAF

March 12, 2019

ä½¿ç¨Yii 2çåµå¥éçé«çº§æ ç®¡çæ¨¡åã
ä¿æåºç¨ç¨åºè®¾ç½®åæ­¥ï¼OS X / Linuxï¼
shellåä¸é®--shellæç¨ï¼markdown çæ¬ï¼
SecurityManageFramworkæ¯ä¸æ¬¾éç¨äºä¼ä¸åç½å®å¨ç®¡çå¹³å°ï¼åå«èµäº§ç®¡çï¼æ¼æ´ç®¡çï¼è´¦å·ç®¡çï¼ç¥è¯åºç®¡ãå®å¨æ«æèªå¨ååè½æ¨¡åï¼å¯ç¨äºä¼ä¸åé¨çå®å¨ç®¡çã æ¬å¹³å°æ¨å¨å¸®å©å®å¨äººåå°ï¼ä¸å¡çº¿ç¹æï¼å¨æå·¡æ£å°é¾ï¼èªå¨åç¨åº¦ä½çç²æ¹ï¼æ´å¥½çå®ç°ä¼ä¸åé¨çå®å¨ç®¡ç
rust style and philosophy
PHPçè½»éçº§HTTPå®¢æ·ç«¯
éè¿SSHæ¦é¤å¹¶éæ°å®è£æ­£å¨è¿è¡çLinuxç³»ç»ï¼èæ ééæ°å¯å¨ãä½ ç¥éä½ æ³ã
å¤§å®¶ä¸èµ·è¢«æå§è®¡å
ç¼è¯å¨ãå¯¹äºPHP
PHPä¸­çPHP VMå®ç°
ç¨äºçæéæºæ°åå­ç¬¦ä¸²çåº
Easily manage git hooks in your composer config
å¨æ¨çcomposeréç½®ä¸­è½»æ¾ç®¡çgité©å­ãæ­¤å½ä»¤è¡å·¥å·å¯ä»¥è½»æ¾å®ç°gitæé©çä¸è´é¡¹ç®èå´ä½¿ç¨ã
ç¨äºPHPçASTå¯è§åå·¥å·
Medisæ¯ä¸æ¬¾ç¾è§ï¼æç¨çRedisæ°æ®åºç®¡çåºç¨ç¨åºã

March 11, 2019

Google Chromeï¼åChromiumï¼çæ©å±ç¨åºï¼å¯ä»¥åè½¬ç½ç«çäº®åº¦ã
å¨æ¬å°è¿è¡Kubernetes
ä¸ä¸ªç®åçæå¡å¨ï¼ç¨äºæ¯ä¸ªWebå¥æ¥å­å®æ¶åéåæ¥æ¶æ¶æ¯ãï¼åæ¬æ¶å°çweb-uiï¼
ç²¾éçåç«¯å¸¸è§é¢è¯é®é¢é
Boxåºç¨ç¨åºç®åäºPHARæå»ºè¿ç¨ã
CentOS 7 å®è£ LNMP ç¯å¢

March 10, 2019

å°Figmaå¸§è½¬æ¢ä¸ºGoogleå¹»ç¯çæ¼ç¤ºæç¨¿ð­
ä¸ä¸ªç®åçåè§£æPHPä¸­çGithub Flavored Markdown
Leptonæ¯ä¸ä¸ªåºäºGitHub Gistçç²¾ç®ä»£ç çæ®µç®¡çå¨
å·æå¤å­èæ¯æçPHPå­ç¬¦ä¸²æä½åº
3yååææ¯æç« å¯¼èª
Acme PHPæ¯ä¸ä¸ªç®åä½éå¸¸å¯æ©å±çCLIå å¯å¨CLIå®¢æ·ç«¯ï¼å¯å¸®å©æ¨è·ååç»­è®¢åè´¹çHTTPSè¯ä¹¦ã
PHPå¤çæ¬å®è£åç®¡ç
è¶çº§å¾®ä¿¡çµèå®¢æ·ç«¯ï¼æ¯æå¤å¼ãé²æ¶æ¯æ¤éãè¯­é³æ¶æ¯å¤ä»½...å¼æ¾WeChatSDK
YOURLSæ¯ä¸ç»PHPèæ¬ï¼åè®¸æ¨è¿è¡èªå·±çURL Shortenerãæ¨å¯ä»¥å®å¨æ§å¶æ°æ®ï¼è¯¦ç»ç»è®¡ä¿¡æ¯ï¼åæï¼æä»¶ç­ãå®æ¯åè´¹åå¼æºçã
å®æ¹GitHub APIçRubyå®¢æ·ç«¯ã
GitHub Desktop
SketchI18Næ¯Sketch.appçå¤è¯­è¨æä»¶

March 9, 2019

ðãNode.jså®æï¼ä½¿ç¨ Egg.js + Vue.js + Docker æå»ºæ¸è¿å¼ãå¯æç»­éæä¸äº¤ä»åºç¨ã æºç 
ç¬¬ä¸æ¹Jike app chromeæ©å±ã
2018 JDDCå¯¹è¯å¤§èµäºåè§£å³æ¹æ¡
æ¬¢è¿æ¥å°ä»¥å¤ªåWikiï¼
Opulenceæ¯ä¸ä¸ªPHP Webåºç¨ç¨åºæ¡æ¶ï¼å®ç®åäºåå»ºåç»´æ¤å®å¨ï¼å¯æ©å±çç½ç«çé¾åº¦é¨åã
ç®åå¿«éçHTMLè§£æå¨
ç½é¡µç PS
ä¸ä¸ªç®åçéæhttpæå¡å¨
ä½¿ç¨çµå­åvue.jså¶ä½çç®åRSSéè¯»å¨åºç¨ç¨åº
FEX é¢è¯é®é¢
GLPIæ¯ä¸ä¸ªåè´¹èµäº§åITç®¡çè½¯ä»¶åï¼ITILæå¡å°ï¼è®¸å¯è·è¸ªåè½¯ä»¶å®¡è®¡ã
åºäºç¤¾åºçGPLè®¸å¯ç½ç»çæ§ç³»ç»
Spalaï¼SPA + Lalavelï¼ãéç¨äºLaravelåVueå¼åäººåçç°ä»£è½»éçº§CMSï¼å¼æºé¡¹ç®ï¼ã
The most awesome Powerline theme for ZSH around!

March 8, 2019

è¯¥è½¯ä»¶åä¸ºLaravel 5.8æä¾äºä¸FFmpegçéæãæä»¶çå­å¨ç±LaravelçFilesystemå¤çã
æéåå¥é¨çlaravelåçº§æç¨
ç¨äºå¨æç¼è¾.envæä»¶çLaravelåã
ç¨äºå¨æç¼è¾.envæä»¶çLaravelåã
pythonåå¤§ç½ç«ç»éæ¹å¼ä¸ä¸äºç®åçç¬è«
NGiÐX config generator on steroids
åææ­£å¨è¿è¡çå®¹å¨çèµæºä½¿ç¨æåµåæ§è½ç¹å¾ã
HttpClientç»ä»¶æä¾äºåæ­¥æå¼æ­¥è·åHTTPèµæºçå¼ºå¤§æ¹æ³ã
é«ä»¿ä¹¦æå°è¯´ Flutterçï¼æ¯æiOSãAndroid
skl apiï¼ä¼ä¸çº§åå°APIå¼åå¹³å°ãä½¿ç¨beegoè¯­è¨æ¶æãå¼åå¹³å°ååµäºç¨æ·ãç¨æ·ç»ãæºæãè§è²ãæéãå¤è¯­è¨ãæä¸¾ãOAå¼æç­åè½æ¨¡åã
Welcomeï¼Hello YCY
MailEclipseâ¡ï¸è½»æ¾ç©ä½ çLaravel Mailablesï¼
âï¸äºè§£å¦ä½ç¨Cç¼ååå¸è¡¨
BetterAndBetter æ¯ä¸æ¬¾åå«å¾å¤åè½ç macOS è½¯ä»¶

March 7, 2019

çº¯bashèæ¬ï¼ç¨äºæµè¯åç­å¾TCPä¸»æºåç«¯å£çå¯ç¨æ§
åç§æ»å¨éªè¯ç è¯å« [è¾è®¯äº] [æç¾] [Vaptcha] [Geetest] [æéª] åç§ç½ç«ç ´è§£ lengyue.me
ä¸ç§å¼æºå¯ä¿¡äºæ¬æºæ³¨åè¡¨é¡¹ç®ï¼ç¨äºå­å¨ï¼ç­¾ååæ«æåå®¹ã
CentOS7æå¡å¨çä¸äºéç½®
ç»´æ¤çctagså®ç°
å·æGPLè®¸å¯è¯çé«æ§è½MySQLä»£çã
ä¸ä¸ªæç®çåºäºswooleå¸¸é©»åå­æ¡æ¶ï¼æ¯æå¨fpmä¸è¿è¡
å­¦ä¹ å¼ºå½ æäººå·åå·¥å· èªå¨å­¦ä¹ 
ä¸ä¸ªè§é¢æ­æ¾å¨ï¼å¼æºç potplayer ï¼ç¨äºå­¦ä¹ åäº¤æµé³è§é¢ææ¯
ä¸ºéè¿Composerç®¡ççæ¯ä¸ªPHPé¡¹ç®åå»ºç®åçphar
ä¸ä¸ªåºäºThinkPHP5.1+åAmazeUIçå¿«éåå°å¼åæ¡æ¶
Googletest  -  Googleæµè¯åæ¨¡ææ¡æ¶
Lua + libUV + jIT = pure awesomesauce

March 6, 2019

æ­£å¨æ­æ¶å­ ä½ä¸ºå¬å±åäº«èµæ
READMEçèºæ¯
PHP Protobuf  -  GoogleçPHPåè®®ç¼å²åº
PHP 7çå¼æ­¥åç¨ã
åè½ä¸°å¯çè·¨å¹³å°ä¼ è¾BitTorrentå®¢æ·ç«¯ã æ¯åç½®Web GUIæ´å¿«ï¼åè½æ´å¤ã
ä¸ä¸ªæäºä½¿ç¨çåºï¼ç¨äºä½¿ç¨InfluxDBåPHPã
ä¸ç§åç±»å¨ææ·»å æ¹æ³çç¹æ§
htrace.shæ¯ç¨äºhttp / httpsæéæé¤ååæçshellèæ¬ãå®ä¹æ¯å´ç»å ä¸ªå¼æºå®å¨å·¥å·çç®ååè£èæ¬ã
è®°å½ä¸ä¸SSçåä¸ä»çï¼ä»¥åä¸ä¸ªç®åçæç¨æ»ç»
è®°å½ä¸ä¸SSçåä¸ä»çï¼ä»¥åä¸ä¸ªç®åçæç¨æ»ç»
swover ä¸ä¸ªåºäºSwooleæ©å±çæå¡å¨æ¡æ¶
è¿ç¨è¿è¡VSä»£ç ãcoder.com
ä»¥å¼åäººåä¸ºä¸­å¿çHTTPå®¢æ·ç«¯ï¼éå¯¹å¤§å¤æ°å¸¸è§ç¨ä¾è¿è¡äºä¼åã

March 5, 2019

ð¥ è®©éè¯»åæä¸ä»¶ææä¹çäºãGolangå¥½ææ¨èï¼æ¶å½å¹³æ¶éè¯»å°çä¸äºGoç¸å³åçæ¯è¾å¥½ãè´¨éè¾é«çå¹²è´§æç« .
ä¸ºäºèç½ITäººæé çä¸­æçawesome-go
éç¨äºnpmåGitHubçåè´¹ï¼å¿«éï¼å¯é çå¼æºCDN
HTTPï¼HTTPSï¼WebSocketè°è¯ä»£ç
æºå¨å­¦ä¹ 100å¤©
ðç¨äºPHPçå¿«éçæå¯¹è±¡Hydrator
ä¸ºPHPå®ç°XDGåºæ¬ç®å½è§è
æ ¹æ®ç½æäºé³ä¹çæ­å, ä¸è½½flacæ æé³ä¹å°æ¬å°.ã
Go client for Redis
HTML5è§é¢éåº¦æ§å¶å¨ï¼éç¨äºè°·æ­æµè§å¨ï¼
Oracleæ°æ®åºçåºç¨ç¨åºåå·¥å·ä½¿ç¨ç¤ºä¾
PPGo_Jobæ¯ä¸æ¬¾å¯è§åçãå¤äººå¤æéçå®æ¶ä»»å¡ç®¡çç³»ç»ï¼éç¨golangå¼åï¼å®è£æ¹ä¾¿ï¼èµæºæ¶èå°ï¼æ¯æå¤§å¹¶åï¼å¯åæ¶ç®¡çå¤å°æå¡å¨ä¸çå®æ¶ä»»å¡ã
CamelCasePlugin for IDEA IDEs
EvaOAuth 1.0ï¼ç»ä¸æ¥å£ç OAuth ç»å½ PHP ç±»åº
EvaOAuth 1.0ï¼ç»ä¸æ¥å£ç OAuth ç»å½ PHP ç±»åº
EvaThumber : åºäºURLçå¾çå¤çåº (å¯å®ç°ç¼©ç¥å¾ | äºç»´ç  | æ°´å° | é¢é¨è¯å«ç­,åºäºPHP
Vitaï¼ç®åå¿«éçVPNç½å³
éåè®ºï¼è½¯ä»¶å¼åç®ä»
å¼æºæ°å­æ çè§£å³æ¹æ¡
å¾®ä¿¡è°è¯ãAPIè°è¯åAJAXçè°è¯çå·¥å·ï¼è½å°æ¥å¿éè¿WebSocketè¾åºå°Chromeæµè§å¨çconsoleä¸­

March 4, 2019

æä¾å¤æ¬¾ Shadowrocket è§åï¼å¸¦å¹¿åè¿æ»¤åè½ãç¨äº iOS æªè¶ç±è®¾å¤éæ©æ§å°èªå¨ç¿»å¢ã
ãå¤§è¯è®¾è®¡æ¨¡å¼ãphpçæ¬
ä¸ä¸ªç®åçèæ¬ï¼ç¨äºå¨PHPä¸­ç¼å­ç¬¬ä¸æ¹APIè°ç¨
è½»éçº§ï¼ç®åä½åè½å¼ºå¤§çPHP5ç¼å­ç±»ï¼å®ä½¿ç¨æä»¶ç³»ç»è¿è¡ç¼å­ã
ç¨åºåæè½å¾è°± 
jSearch(èæ) æ¯ä¸æ¬¾ä¸æ³¨åå®¹çchromeæç´¢æ©å±ï¼ä¸æ¬¡æç´¢èåå¤å¹³å°åå®¹ã
100è¡Pythonä»£ç å¿«éè·å¾ä¸ä¸ªä»£çæ± ï¼ä¸¤åéè·å¾æ°åä¸ªææä»£ç

March 3, 2019

Webpackçæ¼ç¤ºä¸è¯¾ç¨4
Goä¸­çDNSå®¢æ·ç«¯ï¼éè¿HTTPSæ¯æGoogle DNS
ð¥ä¸ä¸ªLua REPLåè°è¯å¨
search and download music ä»ç½æäºé³ä¹ãQQé³ä¹ãé·çé³ä¹ãç¾åº¦é³ä¹ãè¾ç±³é³ä¹ç­æç´¢åä¸è½½æ­æ²
An official read-only mirror of http://hg.nginx.org/unit
Live2D çæ¿å¨æä»¶ (fghrsh.net/post/123.html) ä¸ä½¿ç¨çåç«¯ API live2d.fghrsh.net
Live2D çæ¿å¨æä»¶ (fghrsh.net/post/123.html) çåç«¯ HTML æºç  live2d.fghrsh.net
å¨Goä¸­åéçµå­é®ä»¶çæä½³æ¹å¼ã
åºç¨äºæ¸çåæ¸çç½é¡µä»¥åå»ºå¤§éæ°æ®éã
ç¨Luaç¼åçNginxçPrometheusåº¦éåº
ð¦ð¦å®è£ç´æ¥å¨æµè§å¨ä¸­è¿è¡çnpmä¾èµé¡¹ãæ éBrowserifyï¼Webpackæå¯¼å¥å°å¾ã
åå¸å¼ç³»ç»è®²åº§ç³»åçè¯¾ç¨ææ
åå¸å¼ç³»ç»è®²åº§ç³»åçè¯¾ç¨ææ
ç¨äºæå»ºé«ææ°æ®ç§å­¦å·¥ä½æµçPythonåº
å³äºpythonçé¢è¯é¢
é¢å¶å·¥åéç¨fakeræ¹æ³å»ºè®®ï¼ä»¥æé«çäº§å
The Hoa\Fastcgi library. 
è¯¥æ­»çæåæ»å»çWebåºç¨ç¨åºï¼DVWAï¼
mailcow: dockerized æ­å»ºä¸ä¸ªæ»¡åçèªæé®ç®±æå¡

March 2, 2019

ç¨Luaç¼åçNginxçPrometheusåº¦éåº
PHP æä¼ç§èµæºçæ´çæ±é
ç½ç»èµäº§åç°å¼æ
PHPçå¾åå¤çåº
å¦æå°markdownè§ä½ä¸é¨ç¼ç¨è¯­è¨å¯ä»¥ååªäºæè¶£çäºæå¢?
é²äº®çé«é¥±åè²å½©ï¼ä¸æ³¨è§è§çå°ç¨åºç»ä»¶åº 
ä¸ªäººåå¤æ¸éæµè¯åå®å¨é¢è¯çç»éªï¼åé¨åååçé¢è¯é¢
ä¸ªäººåå¤æ¸éæµè¯åå®å¨é¢è¯çç»éªï¼åé¨åååçé¢è¯é¢
NexT æ¯ä¸ä¸ªé«è´¨éå¹¶ä¸ä¼éçHexo ä¸»é¢ãè¿æ¯ç²¾å¿å¶ä½ååºæ¥ç hexo ä¸»é¢ã
è¿æ¯ä¸ä¸ªwebshelââlå¼æºé¡¹ç®
è¿æ¯ä¸ä¸ªwebshelââlå¼æºé¡¹ç®
ä¸­å½è¿è¥åIPå°ååº-æ¯æ¥æ´æ°
Keybase Go Library, Client, Service, OS X, iOS, Android, Electron
æé ä¼è´¨åç«¯åå®¢ï¼æ¬¢è¿å³æ³¨æçå¬ä¼å·ï¼åç«¯å·¥å 
Delveæ¯Goç¼ç¨è¯­è¨çè°è¯å¨ã
Elasticsearch å¯è§åDashBoard, æ¯æEsçæ§ãå®æ¶æç´¢ï¼Index templateå¿«æ·æ¿æ¢ä¿®æ¹ï¼ç´¢å¼åè¡¨ä¿¡æ¯æ¥çï¼ SQL converts to DSLç­
Frpéç½®é¢æ¿ 
HTPC / Homelabæå¡ç®¡çå¨ - ç¨PHPç¼å
æ¥åPHPUnitæµè¯å¥ä»¶ä¸­è¿è¡ç¼æ¢çæµè¯
devdocs.ioçAlfredå·¥ä½æµç¨
éç¨äºDevDocs.ioçå¨åè½æ¡é¢åºç¨

March 1, 2019

ç¨äºJavaScriptçGitHub REST APIå®¢æ·ç«¯
ð[WIP] Laravel åºç¨é¨ç½²ä¸çº¿è¯¾ç¨ç³»åã
ç¨åºç¿æé¿è®¡å
ç¨äºGraphQLè®¢éçWebSocketå®¢æ·ç«¯+æå¡å¨
ââredis-full-checkæ¯é¿éäºRedis&MongoDBå¢éå¼æºçç¨äºæ ¡éª2ä¸ªredisæ°æ®æ¯å¦ä¸è´çå·¥å·ï¼éå¸¸ç¨äºredisæ°æ®è¿ç§»ï¼redis-shakeï¼åæ­£ç¡®æ§çæ ¡éªã
HTTPlugï¼PHPçHTTPå®¢æ·ç«¯æ½è±¡
Goä¸­çå¿«éé®å¼DBã
Gitter for GitHub - å¯è½æ¯ç®åé¢å¼æé«çGitHubå°ç¨åºå®¢æ·ç«¯
ä¸æ¬¾æå¿é©±å¨çè£å¾æä»¶
EventEmitter3æ¯ä¸ä¸ªé«æ§è½çEventEmitterãå®å·²éå¯¹åç§ä»£ç è·¯å¾è¿è¡äºå¾®ä¼åï¼ä½¿å¶æä¸ºNode.jsåæµè§å¨ä¸­æå¿«çEventEmitterä¹ä¸ã
certbot'renewing letencryptè¯ä¹¦æä»¶ - èªå¨éªè¯aliyun / tencentyun / godaddy dns
é²æ­¢éè¿è¡¨åæäº¤çåå¾é®ä»¶
ç¨äºéç½®ç»è£çComposeræä»¶
é¿éå¦å¦åç«¯å¢éåºåçå¼æºæ¥å£ç®¡çå·¥å·RAPç¬¬äºä»£
è¿æ¯ä¸ä¸ªç¨äºæ£æµåè§£ç QRç çPHPåºãè¿æ¯ç¬¬ä¸ä¸ªä¹æ¯å¯ä¸ä¸ä¸ªæ éæ©å±å³å¯å·¥ä½çQRç éè¯»å¨ã
Swoftä»å¥é¨å°å¾®æå¡è¯¾ç¨ä»£ç 
Symfonyä¹ä¸çå¼æºçµå­åå¡æ¡æ¶
å©ç¨curlmultiåç½®çIOäºä»¶å¾ªç¯å®ç°ï¼å·å¤é«æ§è½ãé«éç¨æ§ãé«æ©å±æ§ï¼å°¤å¶éåå¤æä¸å¡é»è¾å¤§æ¹éè¯·æ±çåºç¨åºæ¯ã
The best php curl library.

February 28, 2019

ä¸æ¬¾å±å¹ä¿æ¤è½¯ä»¶
Node.js RESTå¼åçæªæ¥
ä¸ä¸ªå¹¿æ³çJavaScriptåNode.jsæ°å­¦åº
å®å¶kubernetes YAMLéç½®
mageMagick 7
å¨ä¸å°30ç§çæ¶é´åè·å¾é¶ç¼ç çå®æ´èåREST APIï¼ä¸¥éï¼
Gojiæ¯ä¸ä¸ªç®çº¦çWebæ¡æ¶ï¼å®éè§å¯ç»åæ§åç®åæ§ã
â¡ï¸ç±Spray-canï¼Nettyï¼underowï¼jettyï¼Vert.xï¼Grizzlyï¼node.jsåGoå®ç°çé«æ§è½websocketæå¡å¨ãå®æ¯æ1,200,000ä¸ªææçwebsocketè¿æ¥
Laravelæå¥éå¤é®å¹¶æå¥å¿½ç¥
gRPC PHPå®¢æ·ç«¯åº
ç´è§çæ¥æ¾åæ¿æ¢CLIï¼sedæ¿ä»£ï¼
Package Repository Website 
UPX  -  eXecutablesçç»æåè£å·¥å·
Goæå¡å¨çå¹³æ»éå¯åé¶åæºæ¶é´é¨ç½²ã
ç¨RuståçJavascriptå¼æ
PHPå°JavaScriptè½¬æ¢å¨åç¨JavaScriptç¼åçVM
iOSä¸çNative App over HTTP
ä½¿ç¨kubeadmå¨AWSä¸çæ­£ä¾¿å®çKuberneteséç¾¤
äºèç½å¹¿åçé»æ´
è½»éçº§Kubernetesãæäºå®è£ï¼åå­çä¸åï¼ææäºè¿å¶æä»¶é½å°äº40mbã
ææPHPå½æ°ï¼éåä¸ºæåºå¼å¸¸èä¸æ¯è¿åfalse
PHPGGCæ¯ä¸ä¸ªunserializeï¼ï¼ææè´è½½åºï¼ä»¥åä¸ä¸ªä»å½ä»¤è¡æä»¥ç¼ç¨æ¹å¼çæå®ä»¬çå·¥å·ã
ç¨äºåä¸ç¨éçå¼æºçµå­åå¡laravelæ¡æ¶
ç¨äºåä¸ç¨éçå¼æºçµå­åå¡laravelæ¡æ¶
imagecolormatchï¼ï¼OOBå åå¥æ¼æ´
Laravelçæä»¶ç®¡çå¨
vue-laravel-file-manager
ç¼ºå°çSpotlightæä»¶ç³»ç»
Php JWT example.
PHPçä¸ä¸ªå°èå¼ºå¤§çREPLã

February 27, 2019

ç¨äºå¯ææ¬ç¼è¾çä¸çä¸ææµè¡çJavaScriptåºãå¯ç¨äºReactï¼VueåAngular
ç¨åºåå¦ä½ä¼éçæ£é¶è±é±
DDos/DoSå·¥å·é
Zeroæ¯ä¸ä¸ªç®åWebå¼åçWebæå¡å¨ã
å­å¨æ§è½å¼åå¥ä»¶
LumenåLaravel 5çåçµæºéåã
å¨æ¬å°è¿è¡Kubernetes
åºäº Flutter & scoped_model å®ç°çè§é¢ç±»Appå®¢æ·ç«¯
â¨è½»éçº§ä¾èµæ³¨å¥
è®©ä½ èªå®ä¹çæ¹æ³ä¹å¯ä»¥ä½¿ç¨ä¾èµæ³¨å¥.
ç±WebAssemblyæä¾æ¯æçéç¨äºè¿å¶æä»¶
éè¿Tensorflow JSå¨å®¢æ·ç«¯è¿è¡NSFWæ£æµ

February 26, 2019

libp2pç½ç»å æ libp2p.ioçææ¯è§è
æ¯ä¸ªè½¯ä»¶å¼åäººååºè¯¥ç¥éçï¼å¤§å¤æ°ï¼ææ¯äºé¡¹çéå
timeago.js æ¯ä¸ä¸ªéå¸¸ç®æ´ãè½»éçº§ãä¸å° 1kb çå¾ç®æ´ç Javascript åºï¼ç¨æ¥å° datetime æ¶é´è½¬åæç±»ä¼¼äº*** æ¶é´åçæè¿°å­ç¬¦ä¸²ï¼ä¾å¦ï¼â3 å°æ¶åâã
ð ä¸­å½ååï¼é´åï¼ä¸é³åï¼å¬åï¼è½¬æ¢ä¸æ¥è¯¢å·¥å·
å¤æ¡æ¶ç¼åå¨åºå®è£ç¨åºhttp://composer.github.com/installers
OSS Browser æä¾ç±»ä¼¼windowsèµæºç®¡çå¨åè½ãç¨æ·å¯ä»¥å¾æ¹ä¾¿çæµè§æä»¶ï¼ä¸ä¼ ä¸è½½æä»¶ï¼æ¯ææ­ç¹ç»­ä¼ ç­ã
hexoä¸»é¢çhubæ ·å¼å¤å¶
ShowDocæ¯ä¸ä¸ªéå¸¸éåITå¢éå¨çº¿å±äº«ææ¡£çå·¥å·
Rustç®±æä¾æå³çµæ± çè·¨å¹³å°ä¿¡æ¯ã
éå¯¹seniverse apiçApiä½¿ç¨æ¼ç¤ºhttp://www.seniverse.com/doc
æå®¢æ¶é´ï¼nginxæ ¸å¿ç¥è¯100è®²éç½®æä»¶ä¸ä»£ç åäº«
Swoole è¿ç¨è°è¯å¨
120ä¸ªå¸¸è§æ°æ®ç§å­¦é¢è¯é®é¢çç­æ¡ã
Istio knowledge map ç¥è¯å¾è°±
èªå¨å°å­å¹ä¸è§é¢åæ­¥ã
PHPä¸­çè®¾è®¡æ¨¡å¼ç¤ºä¾
Doctrine Inflectoræ¯ä¸ä¸ªå°ååºï¼å¯ä»¥å¯¹å¤§å/å°åååæ°/å¤æ°å½¢å¼çåè¯æ§è¡å­ç¬¦ä¸²æä½ã
PHPåºç¨ç¨åºçå³æ¶åçº§getrector.org
PHPä¸­å¼ºç±»åçæä¸¾æ¯æèªå¨å®æåéæ
PHPGGCæ¯ä¸ä¸ªunserializeï¼ï¼ææè´è½½åºï¼ä»¥åä¸ä¸ªä»å½ä»¤è¡æä»¥ç¼ç¨æ¹å¼çæå®ä»¬çå·¥å·ã
Htmlèåçæå¨

February 25, 2019

rust stackful coroutine library
åºäºBulmaçVue.jsçè½»éçº§UIç»ä»¶
åºäºçæå¨çPHPéå
Swoole ææ¡
ç®åï¼çµæ´»çå¤ä¸»æºå®¹å¨ç½ç»ç­ã
éç¨äºLinuxçéæ ·CPUåæå¨
IPv4åIPv6ç¨æ·ç©ºé´ç½ç»å æ 
é®å¥æ¶æ ¼å¼åè¾å¥ææ¬åå®¹...
éç¨äºiOS 11.0  -  12.1.2çunc0verè¶ç±
ä¸ä¸ªæ¡æ¶ä¸å¯ç¥çPHPåºï¼ç¨äºæå»ºèå¤©æºå¨äºº
ð ä¸ä¸ªä¸ºä»»ä½MySqlæ°æ®åºçæREST APIçå½ä»¤ã
è¾åºå¤æï¼çµæ´»çAJAX / RESTfulæ°æ®ç»æã
å°ä»»ä½æ°æ®åºè½¬æ¢ä¸ºAPIå¹³å°ã

February 24, 2019

ä¸ä¸ªåºäºYii2é«çº§æ¡æ¶çå¿«éå¼ååºç¨å¼æ 
ð¹macOS http://openemu.orgçå¤å¤è§é¢æ¸¸ææ¨¡æ
é²æ­¢Macè¿å¥ç¡ç ç¶æã
macOSçéç¨çº¯ææ¬ç¼è¾å¨ã

February 23, 2019

åºäºGoogle Material DesignçBootstrap 4ï¼Reactï¼Vue.jsï¼React NativeåSketchçåè´¹å¼æºUIå·¥å·å
macOSçåªè´´æ¿æ©å±åºç¨ç¨åºã
Spring Boot æç¨ãææ¯æ ç¤ºä¾ä»£ç ï¼å¿«éç®åä¸ææç¨ã
70ä¸æ¡å¯¹èæ°æ®åºã
æ¯ç§è§£æååå­èçJSON
å¹³æ»æ»å¨ç½é¡µ
å¸¸è§æ°æ®ç»æçCRDTï¼å¦mapï¼vecsï¼setsï¼textåJSON
ç»åå®éPHPé¢è¯éå°çé®é¢ï¼å°è¯æä¾ç®æ´åç¡®çç­æ¡
æ£æµæªä½¿ç¨çç¼åå¨ä¾èµé¡¹
ç¨äºåå»ºWebåºç¨ç¨åºçRustæ¡æ¶
èµæºæç´¢åè½¯ä»¶ macOS OSX magnet
å°ç±³ææºåæ ¸å¼æº
SmartisanOS kernel opensource contain T1Kernel, T2Kernel, U1Kernel(JianGuo), M1Kernel(M1 and M1L), U2ProKernel(JianGuo Pro)
å¯æ©å±çæ°æ®å­å¨åºï¼ç¨äºææ ï¼äºä»¶åå®æ¶åæ
â­ï¸ä¸ç³»åç²¾å½©çåè¡¨ï¼æåï¼åå®¢ï¼é»å®¢ï¼åè¡ï¼cli / webå·¥å·ç­ç­ã
TypeScript Webæå¡å¨ - æ¯Denoå¿«15å
ç¾åº¦ç½çä¸è½½ç¥å¨
ä¼ä¸çº§æç»­äº¤ä»åDevOpsèªå¨åå¼æºå¹³å°
ä¸ºä»»ä½Eloquentæ¨¡ååå¶å³ç³»åå»ºä¿®è®¢ç
ä¸­å½å¤§é 2018 å¹´ 12 æXXç«è®¿é®ç¾å¼ºæ¦å
The HTTP client for Vue.js
åºäºVueåWeUIçç§»å¨UIç»ä»¶
WebSocketsçå½ä»¤è¡å®¢æ·ç«¯
Pretzelæ¯Macæ¡é¢åºç¨ç¨åºï¼å¯æ ¹æ®æ¨å½åçåºç¨ç¨åºæ¾ç¤ºåæç´¢é®çå¿«æ·é®ã

February 22, 2019

å¨å ç§éååå»ºHTMLæ¼ç¤ºæç¨¿
ç°ä»£JavaScriptæç¨
ç¨äºç¼ç¨å·¥å·çå¢éè§£æç³»ç»
ãGo2ç¼ç¨æåãå¼æºå¾ä¹¦
ngx_php - ç¨äºnginxæ¨¡åçåµå¥å¼phpèæ¬è¯­è¨ã
ä¸ºè¯ç©åç°ï¼éå­åå­¦ï¼ææç§å­¦åçç©å­¦è¿è¡æ°ä¸»åæ·±åº¦å­¦ä¹ 
ç¼åçæºï¼å¯ç»´æ¤åå¯æ©å±Sassçæåã
ææäºæçé»æä¸»é¢ï¼
Goççæ³ç²¾ç¼Webæ¡æ¶ã
Rustä¸­ä¸ä¸ªç¸å¯¹ç®åçDatalogå¼æ
Googleå¸¸ç¨çJavaï¼C ++åJavaScriptåºï¼ç¨äºè§£æï¼æ ¼å¼ååéªè¯å½éçµè¯å·ç ã
MarkDownå¨çº¿ç®åå·¥å·ï¼å¯å¨çº¿é¢è§ãç¼è¾åçæPDFã[æ­¤é¡¹ç®å·²ä¸åç»´æ¤ï¼å»ºè®®ä½¿ç¨ cv.ftqq.com æ¿ä»£ ]
ç²¾éçè½¯ä»¶åæ¶æç¸å³è®¾è®¡æ¨¡å¼åè¡¨ã
è®¾è®¡æ¨¡å¼çè¶ç®åè§£é
å¨javascriptä¸­å®ç°çè®¾è®¡æ¨¡å¼çè¶ç®åè¯´æ
ä½¿ç¨JSæä»¶è½¬æ¢æ ·å¼
Rustçç±»åå®å¨ï¼ç¼è¯ç±»ä¼¼Jinjaçæ¨¡æ¿
æ¯ç§è§£æååå­èçJSON
IntelliJ IDEAç¤¾åºç
å°è®¾è®¡æ¨¡åè½¬æ¢ä¸ºéæç½ç«çç¥ç»ç½ç»
Rustä¸­æç¤¾åº rustlang-cn.org
Rustçå¨çº¿ç¤¾åºæºç 
Rustlangç¸å³åç§èµæï¼ï¼ï¼
æ¥çä»Laravelä¸­æåçPHPæ¨¡æ¿å¼æ
ä½¿ç¨Pythonè¿è¡ç§å­¦è®¡ç®çåºç¡åã
Rdebug  - çæ­£çè°è¯å¨
ä¸ºLaravelæµè¯æä¾å¿«éçæ°æ®åºè¿ç§»ã
ä¸ä¸ªç®åçJSONPå®ç°
jquery jsonpæä»¶

February 21, 2019

Lua redisåºäºcosocket APIçngx_luaå®¢æ·ç«¯é©±å¨ç¨åº
Node.js å¾®ä¿¡å¬ä¼å¹³å° API
å·¥ä½æ¥æ¯å¤©ä¸éåç«¯å¤§åé¢è¯é¢ï¼ç¥å¤§å®¶å¤©å¤©è¿æ­¥ï¼ä¸å¹´åä¼çå°ä¸ä¸æ ·çèªå·±ã
æ¬ä»åºç¨äºè®°å½ B3log ç³»åç«ç¹è¢«æ»å»çè®°å½ï¼ä¸å®ææ´æ°ã
PHPå¼æ­¥ç¼ç¨: åºäº PHP å®(chao)ç°(xi) NODEJS webæ¡æ¶ KOAã
50 ä¸ªæå¿åçå¼åèç»æçç²¾è±å kebox.cn
TinyPNG client for Mac
å¿«éPython 3.5+ HTTPå·¥å·åä¸åºäºuvloopåpicohttpparserçæµæ°´çº¿HTTPæå¡å¨éæã
Laravelä¸­çæ¨¡åç®¡ç
åºäºlaravelSålayimçèå¤©ç³»ç»
Go configuration with fangs
è¯¥é¡¹ç®åºäºCNN5 / DenseNet + BLSTM / LSTM + CTCå®ç°éªè¯ç è¯å«ã
GPUå éC ++ç¨æ·çé¢ï¼å·æWYSIWYGå¼åå·¥å·ï¼XMLæ¯æï¼åç½®æ°æ®ç»å®åMVVMåè½ã
âç¨äºäºå­å¨çrsyncâ -  Google Driveï¼Amazon Driveï¼S3ï¼Dropboxï¼Backblaze B2ï¼One Driveï¼Swiftï¼Hubicï¼Cloudfilesï¼Google Cloud Storageï¼Yande ......
ä»£ç å¯ä»¥å¸®å©æ¨å¯å¨ä¸ªäººç½ç«ï¼å±ç¤ºæ¨ä½ä¸ºè½¯ä»¶å¼åäººåçå·¥ä½ã
Laravelä»£çåç¨äºå¨è´è½½åè¡¡å¨æå¶ä»ä¸­ä»åé¢å¤çä¼è¯ã
ð¥ ãå¹²è´§éä¸­è¥ãæ¯ä¸æ¬¾æ³¨éä½éªç Gank.io å®æ¹å®¢æ·ç«¯
Gank api base â³ next.js (react&ssr)
ä½¿ç¨ Rust åå»º PHP æ©å±
è¾è®¯é²æ°´å¢
Chromeæä»¶è±éæ¦

February 20, 2019

æ¸éæµè¯/APTæ¨¡ææ»å»
Yargséè¿è§£æåæ°åçæä¼éçç¨æ·çé¢æ¥å¸®å©æ¨æå»ºäº¤äºå¼å½ä»¤è¡å·¥å·ã
å¯å¨åå§äººçå¬å¼æ¸åï¼âå¦æä½ è¢«å¬å±æ±½è½¦æå°ä¼æä¹æ ·ï¼
å¹³å°ä¸å¯ç¥å®å¨ä»¤ç
æ¯å®å¨æ ç¶æä»¤ççè§èååèå®ç°ã
ç±Laravel 5åSentryæä¾æ¯æçPHP CMS
Voten.coæ¯ä¸ä¸ªå¼æºï¼ç¾ä¸½ï¼é«åº¦å¯å®å¶ä½è´å½çç®åï¼æ¸©æçç¤¾åºã
ç¨äºäºè§£åºç¨ç¨åºå®å¨æ§çç²¾éèµæºåè¡¨
PHP 5.xæ¯ærandom_bytesï¼ï¼årandom_intï¼ï¼
ç°ä»£ç½ç»çå®å¨åå®¹ç®¡ç - âå¤©ç©ºåªæ¯å¼å§â
ä½¿ç¨Slim Frameworkæå»ºçä»ç¨äºå¬å±éå çåç±»å¸å¾®æå¡
ç±libsodiumæä¾æ¯æçé«çº§å å¯æ¥å£
PHPé¡¹ç®çå¿«éï¼å¯æç´¢çå­æ®µçº§å å¯
å¨åè½çåCSRFåº
å¨ç»è¿èº«ä»½éªè¯çå å¯ä¸­åè£Bcrypt-SHA2
GnuPGå å¯ççµå­é®ä»¶åå¾ç®å
ç¨äºphpseclibçç®åå®å¨åè£å¨
æäºä½¿ç¨çPDOåè£å¨ï¼éç¨äºPHPé¡¹ç®ã
å¼å¸¸åéè¯¯ä½¿ç¨æ·æ´åå¥½
å®å¨APIå·¥å·å
ä¸­æ man æåé¡µè®¡å
æ æ©å±PHPå¾å½¢ç¨æ·çé¢åº
ðLaravelNovaçè¯­è¨æ¯æãéææäº¤æ¨çè¯­è¨ææ´æ°ç°æè¯­è¨ï¼
å·æWeb UIçè·¨å¹³å°httpåæ¢å¨
ææå¨æå®æ´çä¸­å½çå¸å¿æ°æ®
CodeReviewæ¯ä¸ä¸ªGit GUIå·¥å·ï¼ç¨äºæ§è¡ç¨Python3åQt5ç¼åçä»£ç å®¡æ¥ï¼Diff Viewerï¼ã
åªä¸ªæ¯æå¿«çWebæ¡æ¶ï¼
å°æ¬å°ç«¯ç¹å¬å¼ç»Internet
èå¤©ééå¨æ¯ä¸æ¬¾åè´¹çæ°æ®ééåå¸ç¬è«è½¯ä»¶ï¼éç¨php+mysqlå¼å
Tracyï¼æäºä¸ºé·å¼åäººåè°è¯PHPä»£ç çä»¤äººä¸ç¾çå·¥å·ã åå¥½çè®¾è®¡ï¼æ¥å¿è®°å½ï¼åæå¨ï¼é«çº§åè½ï¼å¦è°è¯AJAXè°ç¨æCLIæ¯æã
ZoneMinderæ¯ä¸æ¬¾åè´¹çå¼æºé­è·¯çµè§è½¯ä»¶åºç¨ç¨åºï¼ä¸ä¸ºLinuxå¼åï¼æ¯æIPï¼USBåæ¨¡ææåæºã
SQLiteéè¿Emscriptenç¼è¯ä¸ºJavaScript
Cordova / PhoneGapæä»¶ï¼å¯å¨Androidï¼iOSåWindowsä¸ä½¿ç¨HTML5 / Web SQL APIæå¼åä½¿ç¨sqliteæ°æ®åº

February 19, 2019

easy-swoole/demo
Enterprise application cloud operating system(ä¼ä¸åºç¨äºæä½ç³»ç»)
ç¨äºC / C ++ / Golangçå¾®åè·¨å¹³å°webviewåºãä½¿ç¨WebKitï¼Gtk / Cocoaï¼åMSHTMLï¼Windowsï¼
ä¸ä¸ªåºäºLaravelçå¼æºè®ºåã
ç¨äºSpatie laravelè®¸å¯åºçLaravel Novaå·¥å·
Package Management for Golang
Quillæ¯ä¸ä¸ªç°ä»£WYSIWYGç¼è¾å¨ï¼ä¸ä¸ºå¼å®¹æ§åå¯æ©å±æ§èæå»ºã
WebRTC Webæ¼ç¤ºåç¤ºä¾
 ä¸ä¸ªå°å·§ãè½»éçæµè§å¨åæ ¸ï¼ç¨æ¥åä»£wkeålibcef
ç¨äºçæåéªè¯Googleèº«ä»½éªè¯å¨åå ç´ èº«ä»½éªè¯çPHPç±»
[å¨æ]å¦ä½æ­£ç¡®çå­¦ä¹ Node.js
PHP Protobuf  -  GoogleçPHPåè®®ç¼å²åº
è¯¥è½¯ä»¶åæä¾äºå¨Elasticsearchä¸­æç´¢åè¿æ»¤æ°æ®çé«çº§åè½ã
æ¦è¿°æºå¨å­¦ä¹ æ¦å¿µçæç»´å¯¼å¾ï¼ä»æ°æ®åæå°æ·±åº¦å­¦ä¹ ã
è¿æ¯ä¸ä¸ª Nginx æç®æç¨ï¼ç®çå¨äºå¸®å©æ°æå¿«éå¥é¨ Nginxã
ç¤¾å·¥åºåèªå¨å¤ç

February 18, 2019

nginxæºç ä¸­ææ³¨éç
IPIP.netæ­£å¼æ¯æIPæ°æ®åºipdbæ ¼å¼è§£æåº
ä½¿ç¨dockerå¿«éæ­å»ºåå¤§æ¼æ´å­¦ä¹ å¹³å°ï¼ç®åå¯ä»¥ä¸é®æ­å»º12ä¸ªå¹³å°ã
æµè§å¨ä¸­å¢å¼ºççµå­ä¹¦ã
.filesï¼åæ¬ã/ .macos  -  macOSçææºçé»å®¢é»è®¤å¼
æçdotfilesï¼ç±LARBSé¨ç½²ï¼
PostgreSQLçè¿ç¨è¯­è¨PHP
ð C/C++é¢è¯åºç¡ç¥è¯æ»ç»
[WIP] PHP Service Busï¼åå¸ - è®¢éæ¨¡å¼ï¼å®ç°

February 17, 2019

ä¸ç§å©ç¨æ·±åº¦å­¦ä¹ ææ¯è¯å«åäº¤æ¢å¾çãè§é¢ä¸­äººç©è¸é¨å¾åçå·¥å·
äº¤äºå¼UIç»ä»¶å¼ååæµè¯ï¼Reactï¼React Nativeï¼Vueï¼Angularï¼Ember
NAXSIæ¯NGINXçå¼æºï¼é«æ§è½ï¼ä½è§åç»´æ¤WAF
ç¨Goç¼åçæ¦å¿µè¯æOSåæ ¸
Kerasæ¨¡åä»æç»ç½ç«æ¨¡åçæHTMLä»£ç ãå®ç°å¾åå­å¹ä½ç³»ç»æä»¥ç»å¶æºå¾åã
Anki Vector  - å·æäº¤äºå¼AIææ¯çå®¶åº­æºå¨äººã
è¯¥é¡¹ç®éè¿pythonèæ¬ä»å·¨æ½®ç½ç»çæå¡å¨è·åä¸­å½è¡å¸ï¼sz,shï¼çå¬å(ä¸å¸å¬å¸åçç®¡æºæ),æå¬åä¿¡æ¯æ¾å°æ°æ®åºï¼å¬åæä»¶ä¸è½½å°æ¬å°ï¼å¹¶æ¯æç½é¡µæ¥è¯¢åè¯»åã
èªå¨åæ£æµå°å·¥å·ï¼ä¸»è¦å®ç°äºååæä¸¾ãé¾æ¥ç¬åãæ³¨å¥æ£æµãä¸»æºæ«æãç®å½æä¸¾ãææä¿¡æ¯æ£æµç­åè½~
Prometheusæä½æå 
ç¨äºæä½³å®å¨å®è·µçphp.iniæ«æç¨åº
PoCBox - æ¼æ´æµè¯éªè¯è¾å©å¹³å°
è§£æåè¯ä¼°ä»¥å­ç¬¦ä¸²å½¢å¼ç»åºçæ°å­¦å¬å¼ã
éç¨äºWordPress SEOçAll in One SEO Packæä»¶
Laravelä¸­çå¯æéè¡å¨
ä½¿ç¨Googleç¿»è¯èªå¨ç¿»è¯æ¨çè¯­è¨æä»¶
å°ååºç¼å­ä¸ºç£çä¸çéææä»¶ï¼ä»¥ä¾¿å¿«éå è½½é¡µé¢ã
Google å¼æºé¡¹ç®é£æ ¼æå (ä¸­æç) 

February 16, 2019

c++ é¡ºåºè¡¨ãé¾è¡¨ãéæé¾è¡¨ãéåãä¸åå¤é¡¹å¼ãæ±è¯ºå¡ãç«è½¦è°åº¦é®é¢ãæä½ç³»ç»è°åº¦é®é¢ãèåé®é¢ãæå¤§è¿ç»­å­ååé®é¢ãKMPç®æ³ãç¨çç©éµãå¹¿ä¹è¡¨ãå¹¶æ¥éãæ åå¾é»æ¥è¡¨ãæåå¾é»æ¥è¡¨ãKrusskalç®æ³ãPrimç®æ³ãæç­è·¯å¾Dijsktraç®æ³ãæç­è·¯å¾Bellman-Fordç®æ³ãæç­è·¯å¾Floydç®æ³ãæææåºãå³é®è·¯å¾ãä¼åçåæ³¡æåºãå¿«éæåºãç´æ¥æå¥æåºãæåæå¥æåºãé­æ£åå®ç°ãå¼æ£åå®ç°
èåé®é¢ä¹è®²
GoçTiny WebSocketåºã
ç¨äºJavascriptçç§å­éæºæ°çæå¨
APIææ¡£çæå¨
PHPçææ¡£çæå¨
Git for Windows. å½åç´æ¥ä»å®ç½ä¸è½½æ¯è¾å°é¾ï¼éè¦ç¿»å¢ãè¿éæä¾ä¸ä¸ªå½åçä¸è½½ç«ï¼æ¹ä¾¿ç½åä¸è½½
ä¸ä¸ªç®åèèªä»¥ä¸ºæ¯çåï¼ç¨äºåLaravelæä¾åºäºå­åçå¤ç§æ·
ç¤ºä¾äºæ¬æºåºç¨ç¨åºï¼åå«10ä¸ªå¾®æå¡ï¼å±ç¤ºäºKubernetesï¼Istioï¼gRPCåOpenCensusãæä¾ç¨äºè¯´æåæ¼ç¤ºç®çã
Macåºç¨ç¨åºï¼æ¾ç¤ºæææ­£å¨è¿è¡çè¿ç¨æ­£å¨ä½¿ç¨çæææå¼æä»¶åå¥æ¥å­ãå¾å¥½çGUIç¨äºlsofã
486è¡C ++ï¼ä¸ä¸ªå¨æ«çèæ´¾FPS
ç½ç»èå´çå¹¿ååè·è¸ªå¨é»æ­¢DNSæå¡å¨
ç¨äºå­¦ä¹ æä½ç³»ç»çç®ååæ ¸
JavaScriptä¸­çx86èæåï¼å¨æµè§å¨åNodeJSä¸­è¿è¡
ä¸­æææ¡æçæå
PHPåºåè®¸ä»URLæhtmlé¡µé¢çæç¼©ç¥å¾ï¼å¿«ç§æPDFã
ä½¿ç¨åºäºHTTPçAPIï¼éå¸¸ç®åçæéå¾åå¤çåºã
ä½¿ç¨ç¸åçLaravelå®è£è¿è¡å¤ä¸ªç½ç«ï¼åæ¶ä¿æç§æ·ç¹å®æ°æ®åç¦»ï¼ä»¥å®ç°å®å¨ç¬ç«çå¤åè®¾ç½®ã
Laravel 5  - ç¨äºæ½è±¡æ°æ®åºå±çå­å¨åº
å¾®åæ¹éæé»
Mockeryæ¯ä¸ä¸ªç®åèçµæ´»çPHPæ¨¡æå¯¹è±¡æ¡æ¶ï¼ç¨äºä½¿ç¨PHPUnitï¼PHPSpecæä»»ä½å¶ä»æµè¯æ¡æ¶è¿è¡ååæµè¯ã
PHPUnitä¸­æææ¡£
ç¨äºAPIçæ§åç®¡ççOpenResty / Nginxç½å³ã
ä¸ä¸ªéå¸¸å¼ºå¤§ååå¥½çnginxåºäºlua-nginx-moduleï¼openrestyï¼ï¼æä¾WAFï¼æ§å¶é¢æ¿åä»ªè¡¨æ¿ã
VeryNginx æ¯ä¸ä¸ªåè½å¼ºå¤§èå¯¹äººç±»åå¥½ç Nginx æ©å±ç¨åº.

February 15, 2019

å¨ä½¿ç¨Laravelåºç¨ç¨åºæ¶ä¿®æ¹åé
ç¨äºè®°å½ä¼ä¸å®å¨è§åï¼å»ºè®¾ï¼è¿è¥ï¼æ»é²çç¸å³èµæº 
èæ¯é³ä¹ï¼macOSé³é¢å®ç¨ç¨åºï¼èªå¨æåé³ä¹ï¼è®¾ç½®åä¸ªåºç¨ç¨åºçé³éåå½å¶ç³»ç»é³é¢ã
Kaggle é¡¹ç®å®æï¼æç¨ï¼ = ææ¡£ + ä»£ç  + è§é¢ï¼æ¬¢è¿åä¸ï¼
æ°æ®ç»æåç®æ³å¿ç¥å¿ä¼ç50ä¸ªä»£ç å®ç°
rust ç¨åºè®¾è®¡è¯­è¨ ä¸­æç
awesome-composer 
WDScannerå¹³å°ç®åå®ç°äºå¦ä¸åè½ï¼åå¸å¼webæ¼æ´æ«æãå®¢æ·ç®¡çãæ¼æ´å®ææ«æãç½ç«ç¬è«ãæé¾æ£æµãåé¾æ£æµãç½ç«æçº¹æéãä¸é¡¹æ¼æ´æ£æµãä»£çæéåé¨ç½²ãå¯ç å®åç ´è§£ãç¤¾å·¥åºæ¥è¯¢ç­åè½ã
ð¦ A composer package builder. http://overtrue.me/package-builder
Goçå¿«éèæ¬è¯­è¨
GeoLocationéå¶äºLaravelçè·¯çº¿
PHPçè½»éçº§HTTPå®¢æ·ç«¯
ç®åå®ç°äºç½ç»ç©ºé´èµäº§æ¢æµãæçº¹æ£ç´¢ãæ¼æ´æ£æµãæ¼æ´å¨çå½å¨æç®¡çãpocå®åæ£æµãæé¾æ£æµãæé©¬çæµãææå­æ£æµãDNSçæµãç½ç«å¯ç¨æ§çæµãæ¼æ´åºç®¡çãå®å¨é¢è­¦ç­ç­~
Webpackçä¼éåè£ï¼éç¨äº80ï¼çç¨ä¾ã

February 14, 2019

Docker + Node = Dockerodeï¼Dockerè¿ç¨APIçNode.jsæ¨¡åï¼
Hprose Server for Symfony
nginx cheatsheet
TensorFlowæç¨åææ°APIåå­¦èç¤ºä¾
ç¨äºç©èç½çè¶è½»éçº§JavaScriptå¼æ
ð¯åç«¯é¢è¯è¿é¶æå
èªå·±æç¼çå³äºãHTTPæå¨æåãæ¯ç« çç¥è¯ç¹æ»ç»ï¼
ç¨äºä»£ç çæçLaravelç»ä»¶
åå²ä¸æä¼å¤§çè½¯ä»¶å·¥ç¨å¸åè¡¨
æè¶£çæ³¨é
ç²¾éçé»å®¢æç¨ï¼å·¥å·åèµæºçç²¾éåè¡¨
ç¨åºåæå¼å¾å³æ³¨ç10ä¸ªCå¼æºé¡¹ç®
ç®¡çåèµæºçç²¾éåè¡¨ã
Google å¨ç IP å°ååº
å¼åèå·¥å·ç®±ï¼ free-for-dev
GitHubç§ç±
Git é£æ ¼æå
Octiconsæ¯ç±GitHubä¸ºGitHubæå»ºçä¸ç»SVGå¾æ ã
githubä¸çlighttpd2æ´æäºåä½ - ä¸»è¦çåè´­ä»ç¶å¨lighttpd.netä¸

February 13, 2019

C++åç®¡çå¨
ãGoè¯­è¨ååäºç« ç»ã
å¨GOä¸­å¤ç1M WebSocketsè¿æ¥
ç®åå¯é çç½ç«åæãä¸Golang&Preactä¸èµ·æå»ºã
æºå¨å­¦ä¹  (CS 229 Stanford)
å³æ¶æ¶æ¯æå¡å¨ï¼Goä¸­çåç«¯ï¼AndroidãWebå½ä»¤è¡å®¢æ·ç«¯ï¼èå¤©æºå¨äºº
sourcereråºç¨ç¨åºä»æ¨çGitHubåGitå­å¨åºçæä¸ä¸ªå¯è§éç½®æä»¶ã
openresty/openresty: Turning Nginx into a Full-Fledged Scriptable Web Platform
è¯´ææè¿°äºå¦ä½æé«nginxæ§è½ãå®å¨æ§åå¶ä»éè¦äºé¡¹ï¼
ç¨äºMacOSçMySQL/Mariadbæ°æ®åºç®¡ç
éèMacOSèåæ é¡¹ç®
ä¸æ¬¾åè½é½å¨çå®¢æ·ç«¯ï¼iOSãAndroidï¼ç åå©æï¼ä½ å¼å¾æ¥æã
ç½æäºé³ä¹å½ä»¤è¡çæ¬
Theiaæ¯ä¸ä¸ªç¨TypeScriptå®ç°çäºåæ¡é¢IDEæ¡æ¶ã
ä¸ä¸ªåé·åé«æçå½ä»¤è¡ GitHub å·¥å·
ç¨äºå¨MacOSçVSCodeä¸éèæ é¢æ å¹¶åèäº¤éç¯ï¼=çªå£æ§ä»¶ï¼çæ©å±ã
PouchDBæ¯ä¸ä¸ªå£è¢å¤§å°çæ°æ®åºã
Webçå®æ¶æ°æ®åº
ç¨äºåè½å¼ºå¤§çReactåReact Nativeåºç¨ç¨åºçé«æ§è½ååºæ°æ®åº
javascriptåµå¥/åå­æ°æ®åº
â¡ï¸lowledbæ¯ä¸ä¸ªç±Lodashæ¯æçå°åæ¬å°JSONæ°æ®åºï¼æ¯æNodeï¼Electronåæµè§å¨ï¼
æµè§å¨çæ æé®å¼å­å¨ã

February 12, 2019

ç¼ååä¼åGoä»£ç 
REST API application generator for Yii2, openapi 3.0 YAML -> Yii2
ä¸ä¸ªä¸æ­åå±çå¦ä½ä¿æ¤Linuxæå¡å¨çæåã
å¨å­¦é¢çä¹¦æ¶ä¸åç°äºä¸æ¬ä¸å¸¦èå­å°±è½çæçä¹¦ãPythonæ°æ®ææä¸å®æã
ElasticSearchçå®æ¹Goå®¢æ·ç«¯
ç¨PHPç¼åçCSSæä»¶çåæå¨ãåè®¸å°CSSæä»¶æåå°æ°æ®ç»æä¸­ï¼æä½æè¿°ç»æå¹¶è¾åºä¸ºï¼ä¼åçï¼CSS
è½»æ¾åå»ºAlfredå·¥ä½æµ
Chromeæ©å±ï¼å¨ä½¿ç¨åºç¨ç¨åºæ¶çæLaraveléææµè¯ã
ä¸ä¼ å¾çå°ç»ç«¯å¬å±cdn
ä½¿ç½ç«é¡µé¢å¨1åéåå³æ¶æ´æ°ï¼å¹¶å°è½¬æ¢çæé«1%
å®¢æ·æ²¡æä»æ¬¾ï¼å¢å ä¸éæåº¦çèº«ä½æ ç­¾ï¼å¹¶åå°å®æ¯å¤©ç´å°ä»ä»¬çç½ç«å®å¨æ¶å¤±ã
ä¸ä¸ä¸ªç¨äºWebæµè§å¨çå¼æºæä»¶ä¸è½½ç¨åº
ð©ð Windows 95 in Electron. Runs on macOS, Linux, and Windows.
å¤§è§æ¨¡ä¸­æèªç¶è¯­è¨å¤çè¯­æ
ç¤¾åºé©±å¨çåå®¹èåå¨
Global key-value store in the database
Immutable base object and value objects.
è¯­ä¹åçæ¬æ§å¶è§èï¼SemVerï¼
è¯­ä¹åçæ¬æ§å¶è§èï¼SemVerï¼

February 11, 2019

ç¨æ·±åº¦å­¦ä¹ å¯¹å¯¹èã

February 10, 2019

å¿«éæµè§ä»»ä½GitHubæä»¶çåå²è®°å½GitHistory.xyz

February 6, 2019

FastHubæ¯Androidçç»æGithubå®¢æ·ç«¯ã
åºäºç°ä»£ç½ç»çå¯æ©å±æ¡é¢é®ä»¶åºç¨ç¨åºã

February 5, 2019

video.jsåååºã
kubernetes cliä»¥é£æ ¼ç®¡çéç¾¤ï¼
ä¸­å½5çº§è¡æ¿åºåmysqlåº
A Node.js style checker and lint tool for Markdown/CommonMark files.
Collection of awesome podcasts
Helper functions I find super-duper handy

February 1, 2019

åºäºPHPçå¨åè½é¢ è¦é©å½æ§æ¡æ¶ï¼å¤§éè³ç®ãå¤§æè¥æ ãæ¬æ¡æ¶é¦å®ç»ä»¶åºï¼packagist.org

January 31, 2019

[å·²å¼ç¨] Dockerfileï¼åå«å®è£Magento 2æéçæ©å±ï¼éç½®åå½ä»¤
Goï¼Golangï¼åç»ææ°æ®çæå¨
éç¨äºWebç¤¾åºçAI OS

January 30, 2019

å¨è¯­èªå¨å¡«åå¨ï¼tabnine.com
Empireå®¢æ·ç«¯åºç¨ç¨åº
éç¨äºPHP 7çä½å¼ééæ ·åæå¨
åå¨19å¹´åçåç«¯ç¤¾æé¢è¯ç»å(ä¸¤å¹´ç»éª): èè å¤´æ¡ PingCAP
draw.ioæ¯ä¸ä¸ªå¨çº¿å¾è¡¨ç½ç«ï¼æä¾æ­¤é¡¹ç®ä¸­çæºä»£ç ã
å»æ­»å§ï¼996 godie996.com
å¸¦æWindows APIçæå°æ è¾¹æ¡çªå£
é¢åå¯¹è±¡çPHPé©±å¨ç¨åºï¼ç¨äºFFMpegäºè¿å¶æä»¶
å°curlå½ä»¤è½¬æ¢ä¸ºpythonï¼javascriptï¼phpï¼R
ç¨golangç¼åçè¿·ä½ SMTPæå¡å¨
ä¸äºåç½æ¸éTIPS
Hexoä¸çåæ­¥æä»¶
PHPçéç¨SOAPå®¢æ·ç«¯
æ¶éçä¸äºå½å¤è½æä¾æä¾å¨èææ¥çå¬å¸ï¼æ¶µçç½ç»å®å¨ãå·¥æ§å®å¨ãç»ç«¯å®å¨ãç§»å¨å®å¨ç­é¢å
ç¨Goï¼Golangï¼ç¼åçè½»éçº§MVCæ¡æ¶ã
Gitter for GitHub - å¯è½æ¯ç®åé¢å¼æé«çGitHubå°ç¨åºå®¢æ·ç«¯
å°è¯è§£æåºç¥ä¹å®æ¹æªå¼æ¾ç OAuth2 æ¥å£ï¼å¹¶æä¾ä¼éçä½¿ç¨æ¹å¼ï¼ä½ä¸º zhihu-py3 é¡¹ç®çæ¿ä»£èï¼ç®åè¿å¨å®éªé¶æ®µ
golangæç¤º
ð PHPççä»£ç æ´æ´ä¹é ä¸­æç¿»è¯

January 29, 2019

æ¥æ´çFlutterDemoåéï¼ä»å¤©ä½ fuäºå
PHPéä¾µå¥å¼çæ§å¹³å°- ä¼åæ§è½ï¼å®ä½Bugçç¥å¨ï¼å«åè®©ä½ çPHPç¨åºè£¸å¥ã
git commit --fixupï¼ä½æ¯èªå¨ç
Flutteråµå¥APIçæ¡é¢å®ç°
PHP SSO Platform çèç§æç»ä¸èº«ä»½è®¤è¯å¹³å°
open-source-mac-os-apps 
JavaScript web server
è¿å Tech Lead ä¹è·¯ã
elasticsearch-cn/elasticsearch-definitive-guide
çå°å¥³è£çé¡¹ç®çissueå»ºè®®å¦¹å­å»ºä¸ä¸ªç·è£çé¡¹ç®ï¼ä½æ¯èèå°githubçå¥³æ§ç¨æ· æ°éè²ä¼¼å¹¶ä¸è½è¾¾å°å¥³è£çææ2333æ»ä¹åå»ºä¸ä¸ªã
åºäºCLIåRESTæ¥å£çèªæç®¡ååºäºPHPçURLç¼©ç­ç¨åº
ç¨äºå¤§æ°æ®çåå¸å¼SQLæ¥è¯¢å¼æ
ä¾èµæ³¨å¥ç³»ç»
åç°éè¦éæçæä»¶ã
APIå¹³å°çæå¡å¨ç»ä»¶ï¼è¶åªä½åGraphQL APIï¼åªéå åé
PHPé¾æ¥æ£æ¥å¨
é¥¿äºä¹èé¸ééphpå¼åå
åä¸½çåºç¨ç¨åºï¼çº æ­£æ¨ä»¥åçæ§å¶å°å½ä»¤ã
ð¸ASCIIå¨çº¿è§é¢æµæ­å»ºèæ¬
å¯è§åGitHubéç½®æä»¶çå·¥å·
HTML5 / JavaScriptå¤äººæ¸¸æå®éª
ç»ä¸äºä½ æ¢¦ä¸­æäººï¼è³å°è¿æç¡¬çå¥³ç¥
è½¯ä»¶çæ¬æ§å¶å¯è§å
12306 å¾çéªè¯ç è¯å«æµè¯

January 28, 2019

PHP MySQLç±»çåè£å¨ï¼å®ä½¿ç¨MySQLiåé¢å¤çè¯­å¥ã
âå¨äºèç½ä¸å¯»æ¾æ æ¯ä¹å°â
macOSæä»¶å­æ¡£
Lanyrd's MySQL to PostgreSQL conversion script
æå¶å±æ§æå³ç³»å¯¹Eloquentæ¨¡åè®°å½è¿è¡æåº
GitHubåGitLabç¼ºå°IntelliSenseæç¤º
[Chromeæ©å±ç¨åº]å¨github.comæ´»å¨ä¿¡æ¯ä¸­å¿ä¸è¿æ»¤æ´»å¨ã

January 27, 2019

ä¸äº CSS å¸¸ç¨æ ·å¼
å°ä»»ä½ç½ç«è½¬ä¸ºæ æå¡å¨APIï¼æ¯æSPAï¼ï¼
Chrome æä»¶ï¼æ¥çå¼æºä¸­å½è½¯ä»¶æ´æ°èµè®¯ï¼ææ¡£å¯¼èªï¼GitHub è¶å¿æ¦ï¼linuxå½ä»¤ç´¢å¼ï¼æµè§åå²è®°å½åæ¶éé¡µé¢ã
ä»ç½æäºé³ä¹ãQQé³ä¹ãé·çé³ä¹ãç¾åº¦é³ä¹ãè¾ç±³é³ä¹ç­æç´¢åä¸è½½æ­æ²
ç¨åºåæ¾å·¥ä½é»åå
 è®ºæéè¯»ç¬è®°ï¼åå¸å¼ï¼èæåï¼å®¹å¨ï¼èªå¨æºå¨å­¦ä¹ ï¼
Odooãå¼æºåºç¨ç¨åºä»¥æå±æ¨çä¸å¡ã
ç¨äºæ¢ç´¢åç§è§£æå¨çæçASTçWebå·¥å·ã
ä½¿ç¨Macï¼iOSï¼tvOSåwatchOSçåçAPIæ¡¥æ¥.NETä¸çã
ä¸ä¸ªhttp apiç½å³

January 26, 2019

ä½¿ç¨Dockerå¨CIä¸­è¿è¡Lighthouse
æä»¶å±äº«å®éª
æä»¬ä¸èµ·æ¥è¿åå¾®ä¿¡ãå¸æéè¿ iWeChat è¿ä¸ªé¡¹ç®è½è¿å¾ååºå¾®ä¿¡çè®¾è®¡ï¼ä½¿ç¨å°çææ¯ææ®µç­
A Go (golang) Custom Flutter Engine Embedder for desktop
wudi/PHP-Interview-Best-Practices-in-China: ð PHP é¢è¯ç¥è¯ç¹æ±æ»ð PHP é¢è¯ç¥è¯ç¹æ±æ»
Suitable for Work (NSFW) classification

January 25, 2019

åä¸»è¦åå¸çäºèç½å¬å¸é»åå
ä¸ä¸ªéå¸¸åºæ§çï¼é«åº¦ä¸ªæ§åçèæ¬æ¥è®¾ç½®ä¸å°æ°çMacæºå¨ï¼å°±åæåæ¬¢å®ä¸æ ·ï¼
2018/2019/æ ¡æ/æ¥æ/ç§æ/ç®æ³/æºå¨å­¦ä¹ (Machine Learning)/æ·±åº¦å­¦ä¹ (Deep Learning)/èªç¶è¯­è¨å¤ç(NLP)/C/C++/Python/é¢è¯ç¬è®°
ç½é¡µçå¾®ä¿¡APIï¼åå«ç»ç«¯çå¾®ä¿¡åå¾®ä¿¡æºå¨äºº
è¿æ¯æä¸ºphpè®¿è°åå¤çä¿¡æ¯ãç¬è®°åæ¬phpï¼mysqlï¼linuxç­ã
Composer åç­¾çº¦æ¯ä»å®ä¸å¾®ä¿¡ï¼ç´æ¥å°ä¸ªäººè´¦æ·ï¼æç»­ç»´æ¤ï¼PHPå®ç°åç­¾çº¦æ¯ä»æ¥å£ï¼å¤æ­è®¢åå·ä¸å¤æ³¨ï¼èªå¸¦çå¬ã
æå¤§å­¦ä¸¤å¹´æ¥çç¬è®°ï¼å¸æå¯¹å¤§å®¶æäºäºå¸®å©ï¼ä»¥åä¼æç»­æ´æ°ï¼
A keygen for Navicat
PHPå®å¨éä¿¡åº
æç®ä¸»ä¹çVimæä»¶ç®¡çå¨

January 24, 2019

å¨ç´§æ¥æåµä¸ä¿å­æ¨çä»£ç 
fastaiæ·±åº¦å­¦ä¹ åºï¼ä»¥åè¯¾ç¨åæç¨
åçï¼é«æ§è½ï¼è·¨å¹³å°çæ¡é¢åºç¨ç¨åº - ä½¿ç¨Reasonæå»ºï¼
Futuriceå¼åäººåå¯¹Androidå¼åçæ³¨æäºé¡¹åæ³¨æäºé¡¹
ä¸­æç ãå¾®æå¡ï¼ä»è®¾è®¡å°é¨ç½²ã
éè¿é¢è§ï¼ç¼è¯ï¼èªå¨å®æï¼çè²ç­æé«LaTeXæçæçã
æå»ºGitHubåºç¨ç¨åºçæ¡æ¶ï¼ç¨äºèªå¨ååæ¹è¿æ¨çå·¥ä½æµç¨
ç®åï¼å¯æ©å±çç¶æç®¡çã
æå¾ç¥å¨ æ¶éäºæåä¸ä¸çæé¼æå¾è¡¨æåï¼å¨è¿éä½ å¯ä»¥å¿«éæ¾å°æ³è¦çè¡¨æ
Go by Example

January 23, 2019

ç¨äºå®æ¶å¯è§åçJavaScriptåº
ç¨äºmacOSï¼Windowsï¼Linuxåæç»Androidçä¸ä¸ä»£Braveæµè§å¨
ç»ç«¯æ¸¸ææµè¯gitæè½
å£°æç¨å¾å¥½çéè¯¯æ¶æ¯éªè¯æ¹æ³è¾å¥/è¾åºã
PHPæ©å±å¼åååæ ¸åºç¨
æ¾ç¤ºåæ§å¶æ¨çAndroidè®¾å¤
ç¼è¾å¨ä¸­ççå®æµè§å¨é¢è§ï¼æ¨å¯ä»¥è°è¯ã
å¨Laravelåºç¨ç¨åºä¸­æè·ä¼ å¥ççµå­é®ä»¶
åºç¨ç¨åºä»ªè¡¨æ¿åå¯å¨å¨
åºäºlaravel + reactjsçé®é¢è·è¸ªå·¥å·ï¼éç¨äºä¸­å°åä¼ä¸ï¼å¼æºååè´¹ï¼ç±»ä¼¼äºJiraã
ä¸ä¸ªæ¸è¿èå¨é¢çæ¡æ¶ï¼ç¨äºæå»ºåºäºç»ä»¶çç½ç«ï¼è·¨è¶åç«¯ååç«¯
é»ç®±åºç¨æéæ³¨å¥åèµæºåç°çæ»å»æ¨¡å¼ååè¯­è¯å¸ã
å¨çº¿æµè¯é©±å¨å¨ç¼ç¨å­ä½
ç¨äºè¿è¡OAuth2æå¡å¨çæ¼ç¤ºåºç¨ç¨åº
ç¨äºå®ç°OAuth2æå¡å¨çåè£å¨
oauth2-server-laravel 

January 22, 2019

ä»»å¡è¿è¡/ç®åä½¿ç¨Goç¼åæ¿ä»£
éç¨äºAndroidåºç¨çå­èç ä¼åå¨
å·¥ç¨å¸ç¥è¯ç®¡çç³»ç»ï¼åºäºgolang goè¯­è¨ï¼beegoæ¡æ¶ï¼ãæ¯ä¸ªè¡ä¸é½æèªå·±çç¥è¯ç®¡çç³»ç»ï¼EngineerCMSæ¨å¨ä¸ºåæ¨å·¥ç¨å¸ä»¬æé ä¸æ¬¾éç¨çåºäºwebçç¥è¯ç®¡çç³»ç»ã
èªå¨ç¼è¯js + css + html
åºäºè¿è¥è½¬æ¢ï¼OTï¼çå®æ¶æ°æ®åºåç«¯
git-subrepo
golangæ°æ®åº/ sqlçéç¨æ©å±
å»ºç«å¨èªç¶èç¹ä¸çNLPåºï¼å·æå®ä½æåï¼ææåæï¼èªå¨è¯­è¨è¯å«ç­åè½
PHPçKafkaå®¢æ·ç«¯
å°çº¢ä¹¦éä¿¡åè®®ç­¾å
æé³éä¿¡åè®®ç­¾å
å¿«æéä¿¡åè®®ç­¾å
Google APIçå¬å±æ¥å£å®ä¹ã
ä¸ä¸ªåºäºgolangçwebåºç¨å¿«éå¼åæ¡æ¶ï¼æä¾äºå¼æ¾å¹³å°åç¸å³open apiçå°è£ï¼å¯ä»¥å¿«éçå¼åå¾®æå¡ãwebåºç¨ãå¾®ä¿¡å¬ä¼å·ãä¼ä¸å¾®ä¿¡ãééãäºä¹å®¶ç­ç¬¬ä¸æ¹å¹³å°åºç¨
GitPythonæ¯ä¸ä¸ªç¨äºä¸Gitå­å¨åºäº¤äºçpythonåºã
ä¸º Sketch åå¤çæ¨¡ææ°æ®ä¸­æçï¼åå«ï¼ä¸­æå§åï¼ææºå·ï¼çä»½ï¼åå¸ï¼å°åºï¼å¬å¸åï¼é¶è¡åï¼ææå ï¼è¯¦æå°åï¼é®ç¼ï¼é®ç®±ï¼é¢è²ï¼å¹¿åè¯ç­ã
ä»¤äººæå¿«çJavaScriptæµè¯ã
PHPæºç å å¯æ¨¡å
Goçæç®ä¸»ä¹websocketæ¡æ¶
MISPï¼æ ¸å¿è½¯ä»¶ï¼ - å¼æºå¨èææ¥å¹³å°ï¼ä»¥åç§°ä¸ºæ¶æè½¯ä»¶ä¿¡æ¯å±äº«å¹³å°ï¼
Sileræ¯ä¸ç»éç¨çé«çº§æ½è±¡ï¼æ¨å¨ç¨äºPHPä¸­çå£°ææ§ç¼ç¨APIã
å¼æºå¾åæç®¡èæ¬
PHP Link Checker
å°äºè®¡ç®ï¼æ°æ®åæå¡æ ç¼æ©å±å°è¾¹ç¼è®¾å¤ã
ä½¿Chromeè½å¤å°markdownæä»¶åç°ä¸ºHTML

January 21, 2019

ç¨åºåç macOS æ­å»ºæå
V2Ray åºäº Nginx ç vmess+ws+tls ä¸é®å®è£èæ¬
ThinkPHP5 ç¤¾ä¼åç»å½ç»ä»¶
éç¨äºLinux-Gnomeæ¡é¢çMac OSä¸»é¢
å¾®ä¿¡ãæ¯ä»å®ãQQ ä¸åä¸æ¶æ¬¾äºç»´ç ï¼åé¡µçï¼
ä½¿ç¨åç¼©åç»è¿èº«ä»½éªè¯çå å¯å¯¹å½æ¡£ç¨åºè¿è¡éå¤æ°æ®å é¤ã
ä¸ºPHP 7æä¾å¤è¿ç¨çæ©å±
ð´ä¸ä¼ ç»ä»¶ï¼å¯è®©æ¨èçæ´å¤æ­æ¾LOLçæ¶é´ã
çæ­£ä¸æ³¨äºè®©ä¸å¥ä»£ç è¿è¡å¤ç«¯çå¼åæ¡æ¶ï¼æä¾æ åçMVVMæ¶æå¼åæ¨¡å¼ç»ä¸åç±»ç»ç«¯
ä¸ç³»åå¯æå°çåé¡µå¤å¿åï¼ç±Markdownä½¿ç¨PandocåLaTeXçæ
è¿æ¯æ¥èªéº»ççå·¥å­¦é¢ï¼æ¯å¦ç¦å¤§å­¦åæ®ææ¯é¡¿ç­ç¥åå¤§å­¦çåè´¹è¯¾ç¨çç²¾éæ¸åã
Pythonå¼æºWeb, CMFï¼å¯åå¾®ä¿¡å°ç¨åºåç«¯, ç½ç«åç«¯ç­.Restful Api 
ä½¿ç¨Goè¯­è¨å¼åççæ¬åå¸ç³»ç»
vue.js(elementæ¡æ¶)+golang(beegoæ¡æ¶)å¼åçè¿ç»´åå¸ç³»ç»,æ¯ægit,jenkinsçæ¬åå¸,go ssh,BTä¸¤ç§æä»¶ä¼ è¾æ¹å¼éæ©,æ¯æé¨ç½²ååå¤ä»»å¡åé¨ç½²åä»»å¡é©å­å½æ°
Mysql webç«¯sqlå®¡æ ¸å¹³å° 
TCPæ°æ®åçæ§åç»è®¡å·¥å·
 Layx æ°ä¸ä»£Webå¼¹çªç»ä»¶ã
å¨çº¿åä½ä¸ææ¡£ç®¡çç³»ç»
åºäºG6åReactçå¯è§åå¾å½¢ç¼è¾å¨
MM-Wiki ä¸ä¸ªè½»éçº§çä¼ä¸ç¥è¯åäº«ä¸å¢éååè½¯ä»¶ï¼å¯ç¨äºå¿«éæå»ºä¼ä¸ Wiki åå¢éç¥è¯åäº«å¹³å°ã
ä¸ä¸ªè®°ç¬è®°çåºç¨ç¨åºï¼æ´å¥½å°äºè§£ç¨åºååMarkdownã
 Teamcat è½¯ä»¶å·¥ç¨å¢éåä½å¹³å°ï¼
åèç¾åº¦æåºï¼ä½¿ç¨Beegoï¼Golangï¼å¼åçå¼æºæåºç³»ç»
TeaWeb-å¯è§åçWebä»£çæå¡ã
åºäºLuaçè·¨å¹³å°ç»ç«¯uiåº
éè¿ç®åçé¢åå¯¹è±¡çç±»ä¼¼domçAPIå¨ç»å¸ä¸ç»å¶å¾å½¢ãæ¯æVueï¼React / Preactã
ä½¿ç¨Three.jsæå»ºçå£°æå¼3D Globeæ°æ®å¯è§ååº
RedisPlusæ¯ä¸ºRediså¯è§åç®¡çå¼åçä¸æ¬¾å¼æºåè´¹çæ¡é¢å®¢æ·ç«¯è½¯ä»¶
å¨Goä¸­å¿«éå¼åå¾®æå¡çå¾®æå¡æ¡æ¶
é¿å¸éåäº¤æç³»ç»(è¡ç¥¨ï¼ææï¼æè´§ï¼æ¯ç¹å¸ï¼æºå¨å­¦ä¹ ) åºäºpythonçå¼æºéåäº¤æï¼éåæèµæ¶æ 
ç±TypeScriptæä¾æ¯æçé¿éå·´å·´ä»£è¡¨çå¯ç®¡çï¼å¯è¡¡éåå¯è¿½è¸ªçNode.jsåºç¨ç¨åºç®¡çå¨
éé¾çåºåé¾åºå±å¹³å°
scrapy

January 20, 2019

A Go (golang) Custom Flutter Engine Embedder for desktop
golangci-lint
ç¨äºå¨æµè§å¨ä¸­å¶ä½äº¤äºå¼é³ä¹çWeb Audioæ¡æ¶ã
macOSçå¼æºMarkdownç¼è¾å¨ã
phpspy 

January 19, 2019

Greenplumæ°æ®åº
å®æ¶æ§è½çæ§
å¨JavaScriptä¸­å®ç°çç®æ³åæ°æ®ç»æï¼åå«è§£éåè¿ä¸æ­¥è¯»æ°çé¾æ¥
JavaScript ç®æ³ä¸æ°æ®ç»æ
Prettieræ¯ä¸ä¸ªåºå®çä»£ç æ ¼å¼åç¨åºã
PrometheusçElasticsearchç»è®¡æ°æ®å¯¼åºå¨
ORM for TypeScriptåJavaScriptï¼ES7ï¼ES6ï¼ES5ï¼ãæ¯æMySQLï¼PostgreSQLï¼MariaDBï¼SQLiteï¼MS SQL Serverï¼Oracleï¼WebSQLæ°æ®åºãéç¨äºNodeJSï¼æµè§å¨ï¼Ionicï¼CordovaåElectronå¹³å°ã
Goçå¿«éèæ¬è¯­è¨
ä¸ä¸ªç®åçPHPæä»¶ç®¡çå¨ãä»£ç æ¯ä¸ä¸ªåç¬çphpæä»¶ã
A Lua VM in Go
åºäºæçå¾®ä¿¡æç´¢çå¾®ä¿¡å¬ä¼å·ç¬è«æ¥å£
Upload big files for Laravel ä¸ä¼ å¤§æä»¶çLaravelæ©å±
è¶è¿400å®¶æäºç³è¯·çè½¯ä»¶å·¥ç¨å¬å¸
ç¨Golangç¼åçé«æ§è½PHPåºç¨ç¨åºæå¡å¨ï¼è´è½½åè¡¡å¨åè¿ç¨ç®¡çå¨
swoftè¯¾ç¨ä»£ç 
material-ui 

January 18, 2019

ä¸ä¸ªç¨äºæ¸ééæµè¯æ¼ç»çWEBç³»ç»,ç¨äºæåå¯»æ¾ç½ç«è½å,ä¹å¯ä»¥ç¨äºwebå®å¨æå­¦
éè¿çæ§wifiä¿¡å·æ¥è®¡ç®ä½ å¨å´çäººæ°
æ·±åº¦å­¦ä¹ ä¹¦ä¸­æç¿»è¯
PHPåºå±åæ ¸æºç åæåæ©å±å¼å
Gitå¿«éç»è®¡æ¯ä¸ç§è®¿é®gitå­å¨åºä¸­åç§ç»è®¡ä¿¡æ¯çç®åèææçæ¹æ³ã
é«æ§è½åå°ç³»ç»æå»ºå·¥å·, ä½¿ç¨æå°ä»£ç å³å¯æå»ºåºåè½å®åçåå°ç³»ç»
ä¸ä¸ªéç¨äºiOSçåçç½ç»è°è¯å·¥å·
ç¨åºåçå¨æ èµæºéåã
ä¸ä¸ªåºäºYii2é«çº§æ¡æ¶çå¿«éå¼ååºç¨å¼æ
WeChat SDK for Yii2 , åºäº overtrue/wechat 4.x
ææ¯æ¨ææ¨ï¼ç½æé«çº§åç«¯å·¥ç¨å¸ï¼è·çææ¯å¨éç¹æ»åä¸ä¸ªåç«¯é¢è¯éé¾ç¹ã
çäº§çº§éè£ç®±è°åº¦åç®¡ç
å¦å¦åä¹ä¸ç¨æå¿æçç½æäºé³ä¹åç°äº
æ¯ç¹å¸æ ¸å¿éæ

January 17, 2019

ä»ç½æäºé³ä¹ãè¾ç±³é³ä¹ãQQé³ä¹ãé·çé³ä¹ãé·æé³ä¹ç­æç´¢åä¸è½½æ­æ²
Popcorn Time for music
Dead simple Object schema validation
Dockeréæ¥è¡¨
goç»æåå­æ®µéªè¯ï¼åæ¬è·¨å­æ®µãè·¨ç»æãæ å°ãåçåæ°ç»æ½æ°´
å°composeä¸­æè¿°çåºç¨ç¨åºé¨ç½²å°kuberneteséç¾¤ä¸
åå­ä¸­çé®ï¼ç¨äºgoçå¼å­å¨/ç¼å­ï¼ç±»ä¼¼äºmemcachedï¼åºï¼éç¨äºåæºå¨åºç¨ç¨åºã
æ¨çå³æ¶Emacså¼åç¯å¢ã
ä¸ç§ééå¨ä¸­é´ä»¶
é¿éäºç¿»è¯å°ç»ï¼ä¸ºç¤¾åºè¾åºä¼è´¨çææ¯æç« ã
èç¼ç³»åè½¯ä»¶ä¹ãèç¼äºçã
A RESTful Search Engine 
ç®åãå¼ºå¤§ãè·¨å¹³å°çSQLiteå®¢æ·ç«¯åORM
ä¸ä¸ªæµè§å¨åçIDEï¼ç¨äºæµè§GRAPHQLã
åºäºWebkit/Firefoxæµè§å¨ï¼è¾å©ç¨äº12306è®¢ç¥¨çå©æè½¯ä»¶ã
ä¸ºå½åç½ç«åäº«çç½çä¸è½½æä¾ä¾¿å©çå·¥å·
FastD Swoole åºç¡ç»ä»¶
ä¸ä¸ªé«æ§è½çPHP APIæ¡æ¶ã
Mobyé¡¹ç®-éè£ç®±çæç³»ç»ç»è£åºäºéè£ç®±ç³»ç»çåä½é¡¹ç®
PHPä»£ç å®¡è®¡åæ®µè®²è§£
1000ä¸ªPHPä»£ç å®¡è®¡æ¡ä¾(2016.7ä»¥åä¹äºå¬å¼æ¼æ´)
èªå¨åè¿ç»´å¹³å°: ä»£ç ååºç¨é¨ç½²CI/CDãèµäº§ç®¡çCMDBãè®¡åä»»å¡ç®¡çå¹³å°ãSQLå®¡æ ¸|åæ»ãä»»å¡è°åº¦ãç«åWIKI
åºäºæ¾å¼çå®æ¹åºç¨ç¨åºçAndroid Githubå®¢æ·ç«¯
Thor HTTPS æååæï¼å¼åè°è¯å©å¨ for iOS
è¿äºæ¯phpsormä¸­ç¨äºä»£ç å®æçå©ææä»¶ï¼æä½¿ç¨çæ¯ä¸äºå¼æºè½¯ä»¶ã
é«åº¦å®å¶çchromeé»è²ä¸»é¢
tensorflow
EXLcode - VS Code-based Online IDE Chrome Extension 
ç±Visual Studioä»£ç æ¯æçå¨çº¿IDE
ä¸ºWebåºç¨ç¨åºå¼åéèº«å®å¶çå¨çº¿ä»£ç ç¼è¾å¨
æè¿°HTTP / 3åQUICåè®®çææ¡£
å°ç»ç«¯ä¼è¯è®°å½ä¸ºSVGå¨ç»
Flink Forward China 2018 Slides
Pç¼ç¨è¯­è¨ã
ç¾åº¦AIå¼æ¾å¹³å° PHP SDK. 
ç®ä½ä¸­æçéæ­¥åºåé¾æç¨
TypeScriptçæå¨æå
MIMEç»ä»¶åè®¸æä½MIMEç±»åã
QORæ¯ä¸ç»ç¨Goç¼åçåºï¼å®æ½è±¡äºä¸å¡åºç¨ç¨åºï¼CMSåçµå­åå¡ç³»ç»æéçå¸¸ç¨åè½ã
 è¿æ¯ä¸ä¸ªå¾é·ç«çåç«¯ç½ç«æéå¨ï¼å¯¼èªç½
ç¨ä»»ä½ç¼ç¨è¯­è¨æå»ºå¼ºå¤§çç®¡éã
Ansibleæ¯ä¸ä¸ªæå¶ç®åçITèªå¨åå¹³å°ï¼å¯ä½¿æ¨çåºç¨ç¨åºåç³»ç»æ´æäºé¨ç½²ã
Node.jsæä½³å®è·µä¸­æåæé«çåå®¹çæ»ç»ååäº«

January 16, 2019

Go å­¦ä¹ ä¹è·¯ï¼Go å¼åèåå®¢ãGo å¾®ä¿¡å¬ä¼å·ãGo å­¦ä¹ èµæï¼ææ¡£ãä¹¦ç±ãè§é¢ï¼
Arduino framework for node.js
å¨æ¬å°è¿è¡æ¨çGitHubæä½
appsyncçæ æå¡å¨æä»¶
ð 33 concepts every JavaScript developer should know.
ðä»å¦çå¿«éæä»¶ç®¡çå¨ï¼ç¨bashç¼åï¼
Laravel 5.4+åå®¹ç®¡çæ¡æ¶
Laravel 5.4+åå®¹ç®¡çæ¡æ¶
PHP Telegram Bot.
ä¸ç¨äºå­¦ä¹ ä¸Node.jsç¸æ¯ï¼Golangçç¤ºä¾
TablePlus
Redis Desktop Manager For Mac OSX DMG 

January 15, 2019

A lightweight MVC framework written in Go (Golang).
æ¨çNoSQLæ°æ®åºç±Golangæä¾æ¯æ
éº»ççå·¥å­¦é¢æ·±åº¦å­¦ä¹ ç¸å³è¯¾ç¨çæç¨ï¼ä½ä¸åæ¯èµã
å¼æºåè´¹çç®æä¸­æåè¯ç³»ç»ï¼PHPåè¯çä¸ä¹ä¹éï¼
TiDBæ¯ä¸MySQLåè®®å¼å®¹çåå¸å¼HTAPæ°æ®åº
api-problemè§èçç®åå®ç°
åºäºSwooleæ©å±å¼åæ¸¸ææå¡å¨æ¡æ¶ï¼ç¤ºä¾å®ç°h5æ¸¸æå¼å
rust å¨ææç´¢å¼æ
ç¨goè¯­è¨ç¼åçMicrosoft SQLæå¡å¨é©±å¨ç¨åº
syncdæ¯ä¸æ¬¾å¼æºçä»£ç é¨ç½²å·¥å·ï¼å®å·æç®åãé«æãæç¨ç­ç¹ç¹ï¼å¯ä»¥æé«å¢éçå·¥ä½æç.
å¨ä¸å°30såå¾å°ä¸ä¸ªå¹²åçå¼ç®±å³ç¨çä¸´æ¶linuxç³»ç».
å¨Macä¸è®¡ç®ä½ åäºå¤å°è¡ä»£ç 
ç¨äºæ´æ¹ReactçRFC
Jupyterç¬è®°æ¬ç¨äºâæ·±åº¦å­¦ä¹ Pythonâä¸ä¹¦çä»£ç ç¤ºä¾
Babelæ¯ç¼åä¸ä¸ä»£JavaScriptçç¼è¯å¨ã
ð»PHPUnitçå¹¶è¡æµè¯
LiteSpeed Cache for WordPress 
LiteSpeed QUIC Client Library
litespeed - é«æ§è½ï¼è½»éçº§ï¼å¼æºçHTTPæå¡å¨
12306
å¼ºå¤§ï¼æ å¤ä¸å¨ä¸å¯å¤§è§æ¨¡æ©å±çJabber / XMPPå³æ¶æ¶æ¯å¹³å°
ð§å°å¾åä¸ä¼ å°å¬å±CDN
ä¸­è±æææè¯ãè¯­è¨æ£æµãä¸­å¤ææº/çµè¯å½å±å°/è¿è¥åæ¥è¯¢ãåå­æ¨æ­æ§å«ãææºå·æ½åãèº«ä»½è¯æ½åãé®ç®±æ½åãä¸­æ¥æäººååºãä¸­æç¼©ååºãæå­è¯å¸ãè¯æ±ææå¼ãåç¨è¯ãåå¨è¯è¡¨ãæ´æè¯è¡¨ãç¹ç®ä½è½¬æ¢ãè±ææ¨¡æä¸­æåé³ãæ±ªå³°æ­è¯çæå¨ãèä¸åç§°è¯åºãåä¹è¯åºãåä¹è¯åºãå¦å®è¯åºãæ±½è½¦åçè¯åºãæ±½è½¦é¶ä»¶è¯åºãè¿ç»­è±æåå²ãåç§ä¸­æè¯åéãå¬å¸åå­å¤§å¨ãå¤è¯è¯åºãITè¯åºãè´¢ç»è¯åºãæè¯­è¯åºãå°åè¯åºãåå²åäººè¯åºãè¯è¯è¯åºãå»å­¦è¯åºãé¥®é£è¯åºãæ³å¾è¯åºãæ±½è½¦è¯åºãå¨ç©è¯åºãä¸­æèå¤©è¯­æãä¸­æè°£è¨æ°æ®ãç¾åº¦ä¸­æé®ç­æ°æ®éãå¥å­ç¸ä¼¼åº¦å¹éç®æ³éåãbertèµæºãææ¬çæ&æè¦ç¸å³å·¥å·ãcocoNLPä¿¡æ¯æ½åå·¥å·
çµæ´»çZshæä»¶ç®¡çå¨ï¼å·æå¹²åçfpathï¼æ¥åï¼å®æç®¡çï¼turboæ¨¡å¼ï¼æå¡
Goçåºäºåå°çä¾èµæ³¨å¥å·¥å·åã
PHPä¸­çä¸ä¸ªç®åçPodcast RSSç¼è¾å¨
ç¨äºè¯­ä¹UIçæ¥åæ¨¡å

January 14, 2019

ç°ä»£ï¼ç¯çå¿«éï¼å¯é ï¼ç®åä¸åè½å¼ºå¤§çå¹³é¢æä»¶CMS
é«æå¾®ä¿¡å¬ä¼å·åå²æç« åéè¯»æ°æ®ç¬è«powered by scrapy
ä¸æ¬¾ä¸ä¸º deepin æé çå°é£æº
ðç¬è®°æ¬
js åè½å½æ°åº
ä¸ç³»åAndroidè¿é¶æç« 
å¨Cä¸­ä»å¤´å¼å§ç¼åsqliteåé
Fast3kB Reactéç¨ç¸åçç°ä»£APIæ¿ä»£åã ç»ä»¶åèæDOMã
flutter å¼åèå¸®å© APPï¼åå« flutter å¸¸ç¨ 130+ ç»ä»¶çä¸­æææ¡£ä¸ demo æ¼ç¤º
LeetCodeç»ä¹ , Goè¯­è¨çæ¬
ä¸ç§ç®åå¿«æ·çå¾åå¤çå·¥å·ã
ImgBotå¨GitHubä¸­æåææå¾åæä»¶ï¼å¹¶å¨åºç¨æ æåç¼©åæäº¤æåè¯·æ±ãè¿å°ä½¿æä»¶å¤§å°ä¸éï¼ä½ä¿æå°ºå¯¸åè´¨éåæ ·å¥½ã
Elasticsearch Web UI
ä½¿ç¨ç®åçHTMLåCSSæå»ºæ¼äº®çElectronåºç¨ç¨åºçæå¿«æ¹æ³
ä¼ªè£115æµè§å¨

January 13, 2019

ä¸ç§ææçæµè§å¨æ©å±ï¼å¯ä»¥é»æ­¢æ´ä¸ªç½ç»ä¸åºäºæµè§å¨çå å¯è´§å¸ææèã
ç¨Goç¼åçYouTubeä¸è½½åºåCLI
Goï¼Golangï¼ä¸­çææ°éé¿ç®æ³ã
ä¸æ¬¾å¥é¨çº§çäººè¸ãè§é¢ãæå­æ£æµä»¥åè¯å«çé¡¹ç®ã
åºäºaria2çè½»éçº§å¤çº¿ç¨ä¸è½½å¨ã
å¸®å©115å¯¼åºä¸è½½é¾æ¥å°aria2-rpc
éµå¾ªgRPC HTTPè§èçgRPCå°JSONä»£ççæå¨
å°githubè´¡ç®å¾è¡¨åµå¥å¾å
flutter å¼åèå¸®å© APPï¼åå« flutter å¸¸ç¨ 130+ ç»ä»¶çä¸­æææ¡£ä¸ demo æ¼ç¤º
å­¦ä¹ PHPçå¨çº¿ä¹¦ç±

January 12, 2019

ç¨äºOpenTracingçNGINXæä»¶
âçé­å·¥ä½å®¤--å®å¨åâ ç¥è¯æçåèµæºæ±æ»
ðãä¸ä¸ªãããTime æ¶åãããå¼ç¼ãããä¸å¸­ãããæ¢¨è§é¢ãããå¾®è½¯å¿åºè¯å¸ãããéå±±è¯å¸ãããè±ç£çµå½±ãããä¸­å¤®å¤©æ°ãããé­æå¤©æ°ãããæ¯æ¥ä¸æããã12306ãããéçãããå¿«é100ãããå¿«éãåºç¨ Apiã
åç«¯å³ç­æ 
æ å®æ¯ï¼å¯å¤è¯»ä¹¦èå¤ä¸ºä¹ï¼èªå·¥
è½¯ä»¶çæ¬æ§å¶å¯è§å
Powerlineæ¯vimçç¶æè¡æä»¶ï¼å¹¶ä¸ºå¶ä»å ä¸ªåºç¨ç¨åºæä¾ç¶æåæç¤ºï¼åæ¬zshï¼bashï¼tmuxï¼IPythonï¼AwesomeåQtileã
æºå¨å­¦ä¹ å¤å¿å½
Tiviæ¯ä¸æ¬¾æ­£å¨è¿è¡ä¸­ççµè§èç®è·è¸ªAndroidåºç¨ç¨åºï¼å®è¿æ¥å°Trakt.tvã
QQ é³ä¹æ¥å£ api
Guzzle Swoole Handler
Electron for PHP. Desktop GUI framework with HTML5 Chrome/IE engine. 
Electron for PHP. Desktop GUI framework with HTML5 Chrome/IE engine. 
php_desktop åå¼åç½ç«ä¸æ ·å¼åæ¡é¢åºç¨è½¯ä»¶
CRMEBæ¯ä¸æ¬¾å¾®ä¿¡å¬ä¼å·åå°ç¨åºççµåç³»ç»ï¼å¸¦åéãæ¼å¢ãç§æãç ä»·ãä¼æ å¸ãç§¯åç­åè½

January 11, 2019

a cron library for go
A theme that adds the dark Incognito Mode colour scheme to the normal mode of Chrome.
PythonåCLIçå¿«éï¼å¯æ©å±çè¿åº¦æ¡ã
ä¸ä¸ªçªå£åæ¢å¨ï¼åºç¨ç¨åºå¯å¨å¨ådmenuæ¿æ¢
ä¸ä¸ºç¨åºåç¼åçè±è¯­å­¦ä¹ æåãv1.0
ç¨äºç§»å¨ç½é¡µçè½»éçº§ï¼å¯æ©å±çåç«¯å¼åäººåå·¥å·ã
ç®æ³å®ç°å¨GoLang
ä¸ä¸ªåºäºLaravelçåå¸å¹³å°
kafka php client
ä¸­åäººæ°å±åå½å½å®¶æ å GB/T 2260 è¡æ¿åºåä»£ç 
è®°å½åç«¯å¼åä¸­çæå·§ä»¥åç®æ³ç¥è¯
pythonçæ¬ï¼é¢åç»åçä¸­æåè¯å·¥å·ï¼ç®åæç¨ï¼è·ç°æå¼æºå·¥å·ç¸æ¯æé«äºåè¯çåç¡®çã
CSS Inspirationï¼å¨è¿éæ¾å°å CSS ççµæ
ä½¿ç¨ç´æ¥SQLæ¥è¯¢ç¼åAPIæ²¡æéº»ç¦ï¼è®©æä»¬éæ°æèSQL
ä¸ä¸ªPHPåï¼ç¨äºåç¨æ·æ¾ç¤ºè¯»ååå®¹æéçæ¶é´ã

January 10, 2019

caliberæ¯ä¸åçµå­ä¹¦ç»çã å®å¯ä»¥æ¥çï¼è½¬æ¢ï¼ç¼è¾åç¼ç®ææä¸»è¦çµå­ä¹¦æ ¼å¼ççµå­ä¹¦ã
Pythonæä½³å®è·µæå
ä¸ä¸ªè½»éçº§åºï¼ç¨äºå°å¤æå¯¹è±¡è½¬æ¢ä¸ºç®åçPythonæ°æ®ç±»åã
Java 8 JaråAndroid APKéåå·¥ç¨å¥ä»¶
pytorch handbookæ¯ä¸æ¬å¼æºçä¹¦ç±ï¼ç®æ æ¯å¸®å©é£äºå¸æåä½¿ç¨PyTorchè¿è¡æ·±åº¦å­¦ä¹ å¼ååç ç©¶çæåå¿«éå¥é¨ï¼å¶ä¸­åå«çPytorchæç¨å¨é¨éè¿æµè¯ä¿è¯å¯ä»¥æåè¿è¡
JavaScriptä¸­çPFSå®ç°
Perunæ¯ä¸æ¬¾ä¸»è¦éç¨äºä¹æ¹å®æãæ¸éæµè¯äººååç²æ¹RedTeamçº¢éäººåçç½ç»èµäº§æ¼æ´æ«æå¨/æ«ææ¡æ¶
Goå­¦ä¹ ç¬è®°
æºå¨å­¦ä¹ åå­¦èå¬ä¼å·ä½å
æ¥æ¾åé¡¹ç®æ·»å æ°ä¾èµé¡¹çææ¬
å°åå®¢ç½ç«è½¬æ¢ä¸ºåå¹¶pdfçç¤ºä¾ç¨åºã
åè½å¨é¢çphpå½ä»¤è¡åºç¨åºãæä¾æ§å¶å°åæ°è§£æ, å½ä»¤è¿è¡ï¼é¢è²é£æ ¼è¾åº, ç¨æ·ä¿¡æ¯äº¤äº, ç¹æ®æ ¼å¼ä¿¡æ¯æ¾ç¤º 
100å¤©çMLç¼ç 
ç¨äºDOMæä½çæå°ç¬ç«JSåº
ä¸ä¸ªéæåå®¢åä½å®¢æ·ç«¯ 
ð 12306 è´­ç¥¨å©æï¼æ¯æåå¸å¼ï¼å¤è´¦å·ï¼å¤ä»»å¡è´­ç¥¨

January 9, 2019

Windows 10çmacOS Mojave Dynamic Desktopåè½ç«¯å£
ä¸æ¬¾ç¨ Java å®ç°çç°ä»£åç¤¾åºï¼è®ºå/BBS/ç¤¾äº¤ç½ç»/åå®¢ï¼å¹³å°ã
ç¦»çº¿å­å¨ï¼æ¹è¿ã ä½¿ç¨ç®åä½åè½å¼ºå¤§çAPIåè£IndexedDBï¼WebSQLælocalStorageã
å¨æä¹æ§å¼æä¹é´åæ­¥æ°æ®ï¼å°±åETLä¸æ ·ï¼åªæ¯ä¸ç¨³å®
æ°æµªå¾®åå¾åº Chrome æ©å±ï¼æ¯æåæ­¥å°å¾®ç¸å
ä½¿ç¨libgmpå¯¹å¤§æ´æ°è¿è¡ç®æ¯è¿ç®
ç¨äºä½¿ç¨URLè¯­æ³ä¼ è¾æ°æ®çå½ä»¤è¡å·¥å·ååºï¼æ¯æHTTPï¼HTTPSï¼FTPï¼FTPSï¼GOPHERï¼TFTPï¼SCPï¼SFTPï¼SMBï¼TELNETï¼DICTï¼LDAPï¼LDAPSï¼FILEï¼IMAPï¼SMTPï¼POP3ï¼RTSPå RTMPã libcurlæä¾äºæ æ°å¼ºå¤§çåè½
éè¿è®¾è®¡ç¨¿ä¸é®æºè½çæè§å¾ä»£ç ï¼ç®åæ¯æçæ VueãReactãHtml5ãWeex Rax ç­å¸¸è§ DSLã
Swooleæ¯æExpressiveåºç¨ç¨åº
è½»éãå¯é çå°ç¨åº UI ç»ä»¶åº
XPayä¸ªäººåç­¾æ¶æ¬¾æ¯ä»ç³»ç» å®å¨åè´¹ èµéç´æ¥å°è¾¾æ¬äººè´¦å· æ éå¤æ¡ æ éç­¾çº¦æ¯ä»å®å¾®ä¿¡ æ éææºAPP æ éæä»¶ æ éç¬¬ä¸æ¹æ¯ä»SDK æ éè¥ä¸æ§ç§èº«ä»½è¯ åªéæ¶æ¬¾ç  æå®æ¯ä»æµç¨ ç°å·²æ¯æç§»å¨ç«¯æ¯ä»
ç¨äºæå»ºä¼ç§ç¤¾åºçç®åè®ºåè½¯ä»¶ã
ç½ç»ç»ç«¯
Matomoæ¯Google Analyticsçé¢åå¼æ¾æ¿ä»£åï¼å¯è®©æ¨å®å¨æ§å¶æ°æ®ã Matomoå¯è®©æ¨è½»æ¾æ¶éæ¥èªç½ç«ï¼åºç¨åç©èç½çæ°æ®ï¼å¹¶å¯è§åè¿äºæ°æ®å¹¶æåè§è§£ã
ä»¥å¿«éï¼å¯æ©å±çæ¹å¼è¯»åçµå­è¡¨æ ¼æä»¶ï¼CSVï¼XLSXåODSï¼
ç¦é

January 8, 2019

ç°ä»£å¤å¶å°åªè´´æ¿ã
Linuxlinuxbrew.shçHomebrewåç®¡çå¨
ScreenToGifåè®¸æ¨å½å¶å±å¹çéå®åºåï¼ç¼è¾å¹¶å°å¶ä¿å­ä¸ºgifæè§é¢ã
PHP è·åå¿«éç©æµä¿¡æ¯
READMEæä»¶è¯­æ³è§£è¯»ï¼å³Github Flavored Markdownè¯­æ³ä»ç»
ç§æé¢è¯æ»ç»
Apache Dubboï¼å­µåï¼æ¯ä¸ä¸ªåºäºJavaçé«æ§è½å¼æºRPCæ¡æ¶ã
ä¸ä¸ªç®åçå®æ¤è¿ç¨ï¼åè®¸ä¼è¯è½¯ä»¶æ´æ°åºä»¶
ç°ä»£JavaScriptæ¥æå®ç¨ç¨åºåº
åºäºå¤å¶åç¿»è¯çå½å¤çº¸è´¨éè¯»åç¿»è¯å©æã
websocketå½ä»¤è¡å·¥å·
è®°å½å¹¶éæ­ç½ç»
å³æ¿å­å½¢æ¨æºåæä»¶
ðéé SDK â¢ ð·ââï¸2.0 å¼åä¸­
eSpeak NGæ¯ä¸ä¸ªå¼æºè¯­é³åæå¨ï¼æ¯æ101ç§è¯­è¨åå£é³ã
ä¸ç»å¹éä¸­å½å¤§éææºå·ç çæ­£åè¡¨è¾¾å¼ã
Pikaæ¯ä¸rediså¼å®¹çnosqlï¼ç±QihooçDBAååºç¡æ¶æå¢éå¼å
å¾®ä¿¡å°ç¨åºå¼åèµæºæ±æ» ð¯
ä½¿ç¨GTK + 3çLinuxå¹³éºç»ç«¯ä»¿çå¨
ä½¿ç¨å¼æ¾å¼Webææ¯æå»ºä»¤äººæå¹çåçåæ¸è¿å¼Webåºç¨ ä¸ä¸ªåºç¨ç¨åºå¨ææä¸è¥¿ä¸è¿è¡ð
Python èºæ¯äºç»´ç çæå¨
æ¶éæ´çè¿ç¨å·¥ä½ç¸å³çèµæ
ä¸ä¸ªç®åèä¼éçå®¢æ·ç«¯ï¼ç¨äºè®¿é®åæ§å¶Kuberneteséç¾¤
ç»ç«¯ä¼è¯è®°å½å¨
èªç±Â·è´è´£Â·åå¶ å»å¹¿å Hosts é¡¹ç®
åè´¹ä¸­æå­ä½
æ ¹æ®Diceçç³»æ°æ¾åºä¸¤ä¸ªå­ç¬¦ä¸²ä¹é´çç¸ä¼¼ç¨åº¦ï¼è¿ä¸ªç³»æ°å¤§å¤ä¼äºLevenshteinè·ç¦»ã
æ ¹æ®Diceçç³»æ°æ¾åºä¸¤ä¸ªå­ç¬¦ä¸²ä¹é´çç¸ä¼¼ç¨åº¦ï¼è¿ä¸ªç³»æ°å¤§å¤ä¼äºLevenshteinè·ç¦»ã
å¯é çUSBæ ¼å¼åå®ç¨ç¨åº
Darlingæ¯OS Xåºç¨ç¨åºçè¿è¡æ¶ç¯å¢ã
æ¶éiOSåºç¨ç¨åºä¸­æå¸¸è§çæ¼æ´
ä½¿ç¨Trilium Notesæå»ºæ¨çä¸ªäººç¥è¯åº
ç¨äºè½¯ä»¶åWebå¼åçåè´¹APIçéååè¡¨ã

January 6, 2019

ä¸ä¸ªå°åJavaScriptåºï¼ç¨äºè®¡ç®å¤ªé³/æäº®ä½ç½®åé¶æ®µã
AVHççgitæ©å±ï¼ä¸ºVincent Driessençåæ¯æ¨¡åæä¾é«çº§å­å¨åºæä½
The Kubernetes Package Manager 
GirlsInAI æ¯ä¸ä¸ªé¢åç¼ç¨é¶åºç¡å¥³å­©å­çAIç®æ³å·¥ç¨å¸å»æè®¡åã
Go package captchaå®ç°äºå¾ååé³é¢CAPTCHAççæåéªè¯ã
Here Music ä¸ä¸ª ä½¿ç¨ Electron + React å¼åçé³ä¹å®¢æ·ç«¯
ä½¿ç¨Github GISTå¨å¤å°è®¡ç®æºä¸åæ­¥Visual Studioä»£ç è®¾ç½®

January 5, 2019

éç¨äºiOS 11.4.1-iOS 12.1çæ¼æ´å©ç¨
walle - ç¦å å¼æºé¡¹ç®ä»£ç é¨ç½²å¹³å°
Go to JavaScriptä¸­çç¼è¯å¨ï¼ç¨äºå¨æµè§å¨ä¸­è¿è¡Goä»£ç 
æè½æ 
laravel5.5åvue.jsç»åçååç«¯åç¦»é¡¹ç®æ¨¡æ¿ã
å¾®æå¡çæ ååºãgokit.io
ç©èç½è®¾å¤çWebUIä»ªè¡¨æ¿åæ¬¢raspberry piã
12306æºè½å·ç¥¨ï¼è®¢ç¥¨
PhpStormçPHPè¿è¡æ¶åæ©å±å¤´æä»¶
JSONï¼CSVï¼XMLåYamlçä¸çå½å®¶ã

January 4, 2019

æå®¢æç±çå¨çº¿ææ¯å¹³å°
ðå¨ç¤¾äº¤ç½ç»ä¸­æ¥æ¾ç¨æ·å
å°ä½¿ç¨STDIN / STDOUTçä»»ä½ç¨åºè½¬æ¢ä¸ºWebSocketæå¡å¨ãåinetdä¸æ ·ï¼ä½å¯¹äºWebSocketsã
JavaScriptå½éåæ¡æ¶
ç¨Golangç¼åçé«æ§è½PHPåºç¨ç¨åºæå¡å¨ï¼è´è½½åè¡¡å¨åè¿ç¨ç®¡çå¨
WordPress.com for Desktop
ææåæè°¢ä½èè®¸å¯è¯ï¼SATAè®¸å¯è¯ï¼
Zipkinæ¯ä¸ä¸ªåå¸å¼è·è¸ªç³»ç»
è®ºæä¸ä»£ç ãææææåºãæ¯å¨æ´æ°ã
å³äºDetour Appè§åéç½®çç®åä»ç»
wingy-announcement
ð¾ Flysystem adapter for the oss storage.
ä¸ä¸ªå®éªæ§çç¹å¯¹ç¹Webæµè§å¨beakerbrowser.com
è·¨å¹³å°HTTPåGraphQLå®¢æ·ç«¯
A Simplenote React app packaged in Electron
éç¨åªè´´æ¿ç®¡çåºç¨ç¨åºï¼å¯ä»¥ä»ä»»ä½è®¾å¤ä¸çä»»ä½ä½ç½®è½»æ¾è®¿é®åªè´´æ¿ã
MacåWindowsä¸çVisual Dockerå®¹å¨ç®¡ç
ZeroNet  - ä½¿ç¨æ¯ç¹å¸å å¯åBitTorrentç½ç»zeronet.ioçåæ£å¼ç½ç«

January 3, 2019

ä»¥91ï¼çåç¡®çå»è´¥ææ°çæ¬ç
æå©äºç®¡çGitæç®¡çPHPé¡¹ç®çæ¬å·çåº
å¸¦æè§£æå¨çHTML5è§é¢æ­æ¾å¨å¯ä»¥èçæµé
æ´ä¸ªç¾åº¦ä½¿ç¨çå·¥ä¸çº§RPCæ¡æ¶ï¼æ¥æ1,000,000å¤ä¸ªå®ä¾åæ°åç§æå¡ï¼å¨ç¾åº¦åé¨ç§°ä¸ºâbaidu-rpcâã
tmuxæºä»£ç 
Oss storage filesystem for Laravel.
golang123 æ¯ä½¿ç¨ vueãnuxtãnode.js å golang å¼åçç¥è¯åäº«ç³»ç» golang123.com
zshçæä»¶ç®¡çå¨ã
ä¸ä¸ªç®åçèæ¬æ¥åå»ºgithub toc
ä½¿ç¨ç¸åçç°ä»£APIæ¿ä»£Moment.jsçä¸å¯åæ¥æåº
åºäºRaftæå»ºçåå¸å¼MySQL binlogå­å¨ç³»ç»
å®æ¹rediséç¾¤çPythonéç¾¤å®¢æ·ç«¯ã Redis 3.0+ã
ä¸ç³»åç²¾éçé¢è¯é®é¢åè¡¨ã
ðäºè§£å¦ä½ä½¿ç¨JSON Web Tokenï¼JWTï¼æ¥ä¿æ¤æ¨çä¸ä¸ä¸ªWebåºç¨ç¨åºï¼ï¼æç¨/æµè¯ç¤ºä¾!!ï¼
å©ç¨ç°ä»£æµè§å¨ææä¾çå¼ºå¤§ API å½å¶å¹¶åæ¾ä»»æ web çé¢ä¸­çç¨æ·æä½ã
æä¸º2019å¹´Webå¼åäººåçè·¯çº¿å¾

January 2, 2019

polarphp
PHPåºç¨ç¨åºçå³æ¶åçº§
Rediséç¾¤çOpenresty luaå®¢æ·ç«¯ã
æåå200ä½çæ·±åº¦å­¦ä¹ Githubå­å¨åºæææ°æåºã
æç¹å®æ¥æè·å¾çææ°æåºçå100ä¸ªè¶å¿æ·±åº¦å­¦ä¹ èµæºåºã
Golangå½ä»¤æç¨ä¸­æã
æçä¸æ âCore Golang  -  36è¯¾âçç¤ºä¾é¡¹ç®
awesome-go-China
é«æ§è½ï¼æç®ä¸»ä¹çGo webæ¡æ¶echo.labstack.com

January 1, 2019

ä¸­å½çå¸åºæ°æ®
Pythonåå½ä»¤è¡çä¸çä¸æç®åçé¢é¨è¯å«API
GitHubDaily åäº«åå®¹å®ææ´çä¸åç±»ãæ¬¢è¿æ¨èãèªèé¡¹ç®ï¼è®©æ´å¤äººç¥éä½ çé¡¹ç®ã
Visual Studio CodeçUNOFFICIALç½æé³ä¹æ©å±
éç¨äºComposerçå¿«éï¼å¯é ä¸å®å¨çNPM / Yarnæ¡¥æ¥å¨
ç§å­¦ä¸ç½çæè¶£é¡¹ç®éé¦ï¼æ¬¢è¿å¤§å®¶prèªå·±åæ¬¢çé¡¹ç®å°è¿éã
WebTorrent
webtorrent-desktop 
GitHub Dark as a userscript 
Stylus - Userstyles Manager 

December 31, 2018

ä¸ä¸ªcomposeråï¼ç¨äºéªè¯ä»¥åæ¯å¦ä½¿ç¨Have I Been Pwned APIå¨å¯ç ä¸­ä½¿ç¨äºå¯ç ã
å¾®ä¿¡å¬ä¼å·ç®¡çç³»ç»ï¼ä¹æ¯ä¸å¥å¾®ä¿¡å¬ä¼å·å¼åæ¡æ¶ãæ¯æç§»å¨ç®¡çï¼å ä¹éåå¾®ä¿¡åè½ï¼ç®æ´ãå¿«éä¸æãå¿«éå¼åå¾®ä¿¡åç§åæ ·åºç¨ã
PrestaShopæä¾å®å¨å¯æ©å±çå¼æºçµå­åå¡è§£å³æ¹æ¡ã
ð A PHP prober (ä¸æ¬¾ç²¾ç¾ç PHP æ¢é, ååXæ¢éãåæµ·æ¢é)
å»ºç«åç®¡çPharsçç³è¯·ã
æé®çæºæ§
ç§å­¦ä¸ç½çæè¶£é¡¹ç®éé¦ã

December 30, 2018

åè½é½å¨çä¸è½½ç®¡çå¨ã
ä¸ä¸ªç¨PHPåRedisç¼åçTwitterç©å·åéï¼å¨æ©æç¨äºä»ç»Redisæ°æ®ç±»åã
ç¨äºgolangçsocket.ioåºï¼ä¸ä¸ªå®æ¶åºç¨ç¨åºæ¡æ¶ã
ä¸°å¯çè¡¨æç¬¦å·åèµæºã
Sublime Text 2å3ä¸­PHPé¡¹ç®çæºè½ä»£ç å®æã
å¨ä¸ä¸ªå°æ¹ç®¡çä½ çgitå­å¨åºã
ç¨äºå¨æçæPDFææ¡£çPHPåºã
aveoåºäºLaravelæ¡æ¶çå¼æºç¥¨å¡ç³»ç»ã
ä¸ä¸ªå°åJavaScriptåºï¼å¯ä»¥ä»æ°å­çæç±»ä¼¼YouTubeçIDã å½æ¨ä¸å¸æåç¨æ·å¬å¼æ°æ®åºIDæ¶ä½¿ç¨å®ã

December 29, 2018

Spring Bootæç¨ã
ð° å¾®ä¿¡/æ¯ä»å®æ¶æ¬¾çæ§ï¼ä¸ªäººæ¶æ¬¾æ éç­¾çº¦æ¯ä»å®ãå¾®ä¿¡æ¯ä»ãä¸ºæ¯ä»å®ãå¾®ä¿¡æ¯ä»çä¸ªäººè´¦æ·ï¼æä¾å³æ¶å°è´¦æ¶æ¬¾æå¡ã
å¸¸ç¨äº¤äºå¼å½ä»¤è¡ç¨æ·çé¢çéåã
JavaScript ä»£ç è§èï¼èªå¸¦ linter & ä»£ç èªå¨ä¿®æ­£ã
ä»HTMLè¡¨åä¸­æåçPHPè¡¨åéªè¯ãå¨åä¸ä¸ªå°æ¹åä¸æ¬¡è¡¨æ ¼åéªè¯ï¼
ä¸ä¸ªWebä»£çå·¥å·ã
å°ArchLinuxå®è£ä¸ºWSLå®ä¾ã æ¯æå¤éå®è£ã
Laravelæ ¸å¿ä»£ç å­¦ä¹ ã
ä¸ä¸ªé®ä¸å³°åå®¢é£æ ¼çHexoä¸»é¢ã
ç¨äºé¿æç­æåå­ç½ç»ï¼LSTMï¼çå¯è§åå·¥å·ç®±ã
Tinker in your browserã
Gonumæ¯Goç¼ç¨è¯­è¨çä¸ç»æ°å­åºãå®åå«ç¨äºç©éµï¼ç»è®¡ï¼ä¼ååæ´å¤ã
åºäº PAYJS å¾®ä¿¡æ¯ä»ä¸ªäººæ¥å£å¼åç Laravel Packageï¼å¯ç´æ¥ç¨äºçäº§ç¯å¢ã
åºäº PAYJS å¾®ä¿¡æ¯ä»ä¸ªäººæ¥å£å¼åç Packageï¼å¯ç´æ¥ç¨äºçäº§ç¯å¢ã
ç¨äºå¿«éææ¬è¡¨ç¤ºååç±»çåºã
ä¸ä¸ªéå®¡æ ¸ãæ§è¡ãå¤ä»½åçæåæ»è¯­å¥äºä¸èº«çMySQLèªå¨åè¿ç»´å·¥å·ä¹æåé¨å
Goæ¨¡æ¿çæç¨æ¨¡æ¿å½æ°ã
PostgreSQLæ°æ®åºçè·¨å¹³å°å®¢æ·ç«¯ã
macOSçç®åSSHå¿«æ·èåã
å¡å®å°æç´¢æ¨¡ååå¶ä»æ¥æºã
 iBrand EC æ¯ä¸ä¸ªåè´¹çå¼æºçµå­åå¡è§£å³æ¹æ¡ï¼ä½¿ç¨ PHP åºäº Laravel æ¡æ¶è¿è¡ç¼åã
LaravelçWebå®è£ç¨åºã

December 28, 2018

çè¾°å«å­ï¼äºè¡ï¼ç®å½ã
ç¨äºå®å¨åå¯æ©å±çç½ç»æµéåæçæ¡æ¶ã
ä¸ä¸ªæ£æµç§»å¨è®¾å¤çç®åJSåºã
Laravel 5çæ°æ®æ¸çç¨åºåè¡¨åè¯·æ±è¾å¥å«çã
å·æGPLè®¸å¯è¯çé«æ§è½MySQLä»£çã
ä¸­å½ç/èªæ²»åº/ç´è¾å¸ãå¸/èªæ²»å·ãåº/å¿/ææ°æ®ï¼åå«åç§°ãæ¼é³ãæ¼é³é¦å­æ¯ãè¡æ¿ä»£ç ãåºå·ã
ç¨äºæå»ºJSON APIçè§èã
AliSQLæ¯ä¸ä¸ªæºèªé¿éå·´å·´éå¢çMySQLåæ¯ã
Laravel + go-micro + grpc + Zipkinã
Laravel + go-micro + grpc + Zipkin
å¨Symfony sylius.comä¹ä¸çå¼æºçµå­åå¡æ¡æ¶ã
Spreeæ¯ä¸ä¸ªå®æ´çï¼æ¨¡ååçï¼APIé©±å¨çå¼æºçµå­åå¡è§£å³æ¹æ¡ï¼éç¨äºRuby on Railsã
å¾®ä¿¡ä¸ªäººå·æ¥å£ãå¾®ä¿¡æºå¨äººåå½ä»¤è¡å¾®ä¿¡ï¼ä¸åè¡å³å¯èªå®ä¹ä¸ªäººå·æºå¨äººã
VM and compiler for Lua in Goã

December 27, 2018

 Segment Fault å¨çº¿è®²å  ä»£ç å·¥ç¨ã
ãå°é©¬å¥ææ¯å¨æ¥ã

December 26, 2018

PHP TensorFlowç»å®ã
ä¸ä¸ªå­ä½ç³»åï¼ä¸ºç¨åºåæä¾äºä¸ä¸ªå¾å¥½çç­å®½åä½ã
ðå­¦ä¹ æºå¨å­¦ä¹ çå®ç¨æ¹æ³ã
å¼æ­¥WebSocketå®¢æ·ç«¯ã
ÃvÃ©nementæ¯ä¸ä¸ªéå¸¸ç®åçPHPäºä»¶è°åº¦åºã
å¼ç®±å³ç¨çä¸­å°åç«¯/è®¾è®¡è§£å³æ¹æ¡ã
ant-design-mobile
æ·±å¥çè§£PHPåæ ¸ã
GitUp å¿«éï¼å®å¨ï¼æ å¤´çå°å·¥ä½ã ä½ ç»ç å¤±å»çGitçé¢ ç»äºå°æ¥äºã
å·æäº¤äºå¼TLSåè½çæ¦æªHTTPä»£çï¼éç¨äºæ¸éæµè¯äººååè½¯ä»¶å¼åäººåã
htopæ¯Unixç³»ç»çäº¤äºå¼ææ¬æ¨¡å¼è¿ç¨æ¥çå¨ã
go-internals æ¬ä¹¦æ¯å³äº Go ç¨åºè®¾è®¡è¯­è¨åé¨å®ç°åççééï¼å½åæ­£å¨è¿è¡ä¸­ã
Repo for gRPC PHPã

December 25, 2018

ç±Visual Studio Codeæä¾æ¯æçå¨çº¿IDEã
å°ç»ç«¯è®°å½è½¬æ¢ä¸ºGIFå¨ç»ã
å¨ Windows ä¸ç¨ WSL ä¼éå¼åã
LuaåOpenRestyçéªè¯åºï¼è¾å¥éªè¯åè¿æ»¤ï¼ã
Hproseåºäºswooleçå¼æ­¥å®¢æ·ç«¯åç¬ç«æå¡å¨ã
Cloud-Native APIç½å³åæå¡ç½æ ¼ã
PHP client/server for the telegram MTProto protocol 
ð A UI Design Languageã

December 24, 2018

åè½å¼ºå¤§çåè´¹è½¯ä»¶ï¼ä¹æ°å¥½æ¯å¼æºPythonã
ä¹¡æä¿¡æ¯ç³»ç»ï¼SIDï¼ã
 ss-panel-v3-modæ¯ä¸æ¬¾ä¸ä¸ºshadowsocksè®¾è®¡çwebåç«¯é¢æ¿ã
ä¸ä¸ªåç§æ¹å¼çªç ´Disable_functionsè¾¾å°å½ä»¤æ§è¡çshellã
æ¶éä¸äºå°åå®ç¨çå·¥å·ã
ä»é¶å¼å§åç½æ¸éå­¦ä¹ ã
èªå¨åæ¶élinuxä¿¡æ¯ã
Ginæ¯ä¸ä¸ªç¨Goï¼Golangï¼ç¼åçHTTP Webæ¡æ¶ã
python-webå¥åæåã

December 23, 2018

Flexihashæ¯ä¸ä¸ªå°åPHPåºï¼å¯å®ç°ä¸è´çhashingã
åºäºiViewçVue 2.0ç®¡çç³»ç»æ¨¡æ¿ã
éè¿å¨ç»QRç ä¼ è¾æ°æ®ã
PHPå¶ä½äºå å¯è´§å¸ã
Supervisordçæ§å·¥å·ã
ç¨Golangç¼åçé«æ§è½PHPåºç¨ç¨åºæå¡å¨ï¼è´è½½åè¡¡å¨åè¿ç¨ç®¡çå¨ã
è¿æ¯ZipArchiveæ¹æ³çç®ååè£å¨ï¼å¸¦æä¸äºæ¹ä¾¿çåè½ã
ç¨äºGit reposånpmåçCLIåå¸å·¥å·ã
PHPçäºä»¶é©±å¨ï¼éé»å¡I/Oã

December 22, 2018

éè¿LD_PRELOAç»è¿disable_functions
Rubix MLæ¯ä¸ä¸ªé«çº§æºå¨å­¦ä¹ åºï¼å¯è®©æ¨æå»ºä½¿ç¨PHPè¯­è¨ä»æ°æ®ä¸­å­¦ä¹ çç¨åºã
ä¸ä¸ªæ¹ä¾¿å®ç¨çå·¥å·ï¼ç¨äºå¨redisç»ä¹é´è¿ç§»æ°æ®ã
åºäºLaravelçAPIæå¡ç«¯æ¶æä»£ç ã
æ¶å°çCLIæç¤ºç¨æ·åå¥½ï¼ç´è§ä¸æäºåå»ºã
RedisDesktopManager-Windows å®è£ååç¼è¯æç¨ã
å»ºç«å¨yafçåºç¡ä¸ï¼éæäºSmartyå¼æï¼å å¥äºå°è£å¥½çåç§åè½ç±»ã
å¼æºNode.jsæ å¤´CMSï¼è½»æ¾æå»ºå¯å®å¶çAPIã
å­¦ä¹ Python 3ç¤ºä¾ä»£ç ã
ä¸ä¸ªç±»ä¼¼jqueryçpythonåºã
æç»­æ¶éå½ååè´¹ä¼è´¨APIã
ip2region - æèªç±çipå°åæ¥è¯¢åºï¼ipå°å°åºçæ å°åºï¼æä¾Binary,Bæ åçº¯åå­ä¸ç§æ¥è¯¢ç®æ³ï¼å¦å¦åä¹ä¸ç¨æå¿æçipå°åå®ä½ã
JavaScriptçâè­¦æ¥âçç¾ä¸½æ¿ä»£åã

December 21, 2018

oh-my-poshã
éç¨äºWordPressçGraphQL APIã
éº»ççå·¥å­¦é¢6.824åå¸å¼ç³»ç»ç±»çåºæ¬èµæºã
åºååé­åï¼å¿åå½æ°ï¼ã
ç²¾éä»¥å¤ªå ï¼ä¸­æçï¼ã
ç¨äºåå»ºå½©è²æ§å¶å°è¾åºçç®ååºã
ä¸ä¸ªç¾ä¸½çhexoåå®¢ä¸»é¢ä¸ææè®¾è®¡åååºè®¾è®¡ã
çµå­è¡¨æ ¼åæå¨åç¼åå¨ã
Java ç¼ç¨ææ³ã

December 20, 2018

Rails Girls Guidesã
è¾å¥SQLï¼è¾åºç´¢å¼ä¼åå»ºè®®ã
f-adminæ¯ä¸å¥åºäºLaravelæ¡æ¶å¼åçåºç¡æéåå°ç³»ç»ã
ç¨äº#golangï¼WIPï¼çå®éªæ§æ°HTTPå®¢æ·ç«¯APIã
å goconfig æ¯ä¸ä¸ªæäºä½¿ç¨ï¼æ¯ææ³¨éç Go è¯­è¨éç½®æä»¶è§£æå¨ï¼è¯¥æä»¶çä¹¦åæ ¼å¼å Windows ä¸ç INI æä»¶ä¸æ ·ã
ð«ä¸ç³»åç²¾å½©çåè¡¨ï¼æåï¼åå®¢ï¼é»å®¢ï¼åè¡ï¼cli / webå·¥å·ç­ç­ãç¹å«æ¯å¯¹äºç³»ç»åç½ç»ç®¡çåï¼DevOpsï¼Pentestersæå®å¨ç ç©¶äººåã
NumPyåPandasä¸å¤§æ°æ®çæ¥å£ã
PHP ä¸­æå·¥å·ç±»ï¼æ¯ææ±å­è½¬æ¼é³ãæ¼é³åè¯ãç®ç¹äºè½¬ã
Docker  - åå­¦è|ä¸­çº§|é«çº§ã
åºäºTP3.1çå¤ç¨æ·BTç¦»çº¿ä¸è½½ã
ftl-desktop ä¸è½½å¨ã
MongoDBå°Elasticsearchè¿æ¥å¨ã

December 19, 2018

ä¸ä¸ªæ´æ°é²çâå¨GitHubä¸åæâæ æ³¨ã
å°markdownææ¡£å¯è§åä¸ºæç»´å¯¼å¾ã
ç¨çº¯Pythonç¼åçè®¡ç®æºä»£æ°ç³»ç»ã
Golangå¥½ææ¨èï¼æ¶å½å¹³æ¶éè¯»å°çä¸äºGoç¸å³åçæ¯è¾å¥½ãè´¨éè¾é«çå¹²è´§æç« ã
memcachedåredisçå¿«éï¼è½»éçº§ä»£çã

December 18, 2018

GRPCæå¡çGUIå®¢æ·ç«¯ã
Github iOSå®¢æ·ç«¯ç¨RxSwiftåMVVMç¼åçå¹²åæ¶æã
PHPçDiffå®ç°ï¼ä»PHPUnitä¸­åè§£ä¸ºä¸ä¸ªç¬ç«çç»ä»¶ã
Soli PHPæ¡æ¶ã
MITè¯¾ç¨ãDistributed Systems ãå­¦ä¹ åç¿»è¯ã
ä¸­å½ä½çº¿åå¸ï¼æç§°ä¸åçº¿åå¸ï¼çæºä¼ã
Pharå®è£åéªè¯ç¯å¢ï¼PHIVEï¼ã
å¯¹æä»¶/ç®å½ä¸­çææPHPå½åç©ºé´è¿è¡åç¼ï¼ä»¥éç¦»PHARä¸­æç»çä»£ç ã
Navicat Keygenã
Laravel ç¤¾åºé¨æ·ç½ç«ã
çº¯Goä¸­çé«åº¦å¯æ©å±çGitå®ç°ã
Laravel Dusk åºäºlaravelæµè¯çæ¼äº®ä»ªè¡¨æ¿ã
Awesome Englishã
ä¸ç§æ´å¿«ï¼æ´ç®åçæ¹å¼æ¥é©±å¨æ¯æChrome DevToolsåè®®çæµè§å¨ã
Package Repo Searchã
php-lisp is a Lisp dialect written in PHP. 
GitHub Workflow for Alfred 3.
ç¨äºé²æ­¢ç¡ç çmacOSåºç¨ç¨åºã
å°æVPNã
ä¸ä¸ªå¯ä»¥è§çå½åä¸»æµè§é¢å¹³å°ææè§é¢çå®¢æ·ç«¯ï¼MacãWindowsãLinuxï¼

December 17, 2018

TinySSHæ¯å°åæå¡å¨ï¼å°äº100000å­çä»£ç ï¼ã
å¨Node.jsåæµè§å¨ä¸­çæå¤§éçå®çåæ°æ®ã
å¹¿åè¿æ»¤Adblockï¼uBlock Originï¼Adguardã
Linuxåæ ¸æºä»£ç ã
ç¨äºGraphiteï¼InfluxDBåPrometheusçæ¼äº®çæ§ååº¦éåæåä»ªè¡¨æ¿çå·¥å·ã
å¿«éè½»æ¾å°ç®¡çååæ¢å¤ä¸ªä»£çã
Go By Example ä¸­æçã
å¾½ç« ã
åºäº Vue.js çå°ç¨åºå¼åæ¡æ¶ï¼ä»åºå±æ¯æ Vue.js è¯­æ³åæå»ºå·¥å·ä½ç³»ã
Tideland GoLibã
ä¸ä¸ªå°åPHPåºï¼ç¨äºä»æ°å­çæç±»ä¼¼YouTubeçIDã å½æ¨ä¸å¸æåç¨æ·å¬å¼æ°æ®åºIDæ¶ä½¿ç¨å®ã
MinTTYçä¸äºéè²æ¹æ¡ã

December 16, 2018

Dockerå®æ¹æ ååè£PHPã
ç±Firebaseæä¾æ¯æçåä½ææ¬ç¼è¾å¨ã
ç§æç³»ç»è®¾è®¡ä¸å®ç°.äºèç½å·¥ç¨å¸è¿é¶ä¸åæã
ä¸ºPHPä»£ç è¦ççä¿¡æ¯æä¾æ¶éï¼å¤çååç°åè½çåºã
Dillingeræ¯ä¸æ¬¾æ¯æäºç«¯ï¼ç§»å¨å°±ç»ªçç¦»çº¿å­å¨ï¼AngularJSæ¯æçHTML5 Markdownç¼è¾å¨ã
Win32 port of OpenSSHã

December 15, 2018

HTTPè´è½½æµè¯å·¥å·ååºã
èªå¨çæ pptã
åºäºvegetaåboomçhttpåºåwebåºç¨ç¨åºã
å½å¶ç»ç«¯å¹¶çæå¨ç»gifå¾åæå±äº«ç½ç»æ­æ¾å¨ã
go æ¯æç§»å¨è®¾å¤ã
node.jså½ä»¤è¡çé¢åå¾ç®åã
CKEditor 5çå¼åç¯å¢ - æå¥½çåºäºæµè§å¨çå¯ææ¬ç¼è¾å¨ã

December 14, 2018

ä¸ä¸ªéç¨å­å¹æ¥æ¾å¨ï¼å¯ä»¥æ¥æ¾å­å¹å¹¶ä¸è½½ã
æ£æ¥ä¸­æ markdown ç¼åæ ¼å¼è§èçå½ä»¤è¡å·¥å·ï¼åºäº ASTï¼æ¹ä¾¿éæ ciï¼ååå®¢ / ææ¡£å¿å¤ã
å¨macOSåLinuxä¸æ´å¥½çå¾®ä¿¡ãç¨Electronå¶é ã
ä¸å¥å®æ´çå­¦ä¹ æåå¸®å©èªå·±åå¤ Google çé¢è¯ã
éç¨äºWindowsçè½¯ä»¶åè¡çåæå»ºå¹³å°ã
JSON-RPC 1/2ä¼ è¾å®ç°ã æ¯æpython 2/3åpypyã
å¨Androidä¸å®è£å¹¶è¿è¡GNU / Linuxã
WeHalo ç®çº¦é£ çå¾®ä¿¡å°ç¨åºçåå®¢ã

December 13, 2018

GitLab CE Mirrorã
Windowsçå½ä»¤è¡å®è£ç¨åºã
ä¸ä¸ªæ´ç°ä»£åçç»ç«¯ã
å¨PHPä¸­å®ç°Token Bucketç®æ³ã
Debianï¼UbuntuåCentOSçOpenVPN road warriorå®è£ç¨åºã
åå¸å¼å¯é é®å¼å­å¨ï¼ç¨äºåå¸å¼ç³»ç»çæå³é®æ°æ®ã
TiDBæ¯ä¸MySQLåè®®å¼å®¹çåå¸å¼HTAPæ°æ®åºã
DevHub: TweetDeck for GitHub - Android, iOS and Webã
åºäºDuerOSçä¸ªäººçæºè½è¯­é³å©æã
å¨åæ¢å¼å³ä¸­è½¬å¨å¤éæ¡ååéæé®ã
éç¨äºGoogleç¿»è¯çåè´¹ä¸æ éå¶çAPIã
Node.jsçå¯ç§»æ¤Unix shellå½ä»¤ã
å­¦ä¹ Golangã
åå¤å¥½ä½¿ç¨JSONPç«¯ç¹/ææè´è½½æ¥å¸®å©ç»è¿ä¸åç½ç«çåå®¹å®å¨ç­ç¥ã
HookPHPä¸æ¬¾åºäºCæ©å±æ­å»ºæ¯æAIå¨çº¿ç¼ç¨çPHPæ¡æ¶-å®å¨ç§æThinkPHP-æ§è½ç§Laravel-åè½ç§YAF-æç¨ç§Symfony-å¥é¨ç§Zend-ç»ä»¶ç§Yii-è¦åç§Phalcon ã

December 12, 2018

Pythonä»£ç çéæåæå¨ã
Hoaæ¯ä¸ä¸ªæ¨¡ååï¼å¯æ©å±åç»æåçPHPåºéã
Hoaæ¯ä¸ä¸ªæ¨¡ååï¼å¯æ©å±åç»æåçPHPåºéã
æ­¤å·¥å·å¯å¸®å©æ¨æµè¯socket.ioæå¡å¨ã
ClickHouseæ¯ä¸ä¸ªç¨äºå¤§æ°æ®çåè´¹åæDBMSã
å¬ä¼å· swoole4.0ä¹æé èªå·±çwebå¼åæ¡æ¶ ä»£ç ã
1 kBç¨äºæå»ºå£°ææ§Webåºç¨ç¨åºçJavaScriptå¾®æ¡æ¶ã
awesome design systemsã
åä½ çè´¡ç®èå±ç¤ºä¸äºç±ï¼æ¨çrepo READMEçå°é¨ä»¶ãæ¯å°æ¶å·æ°ä¸æ¬¡ã
Pythonå¼åå·¥ä½æµç¨ã
jsliang çææ¡£åº. éé¢åå«äºææçåç«¯æç« ï¼ä¾å¦ vueãreact,ãangularãå¾®ä¿¡å°ç¨åºãè®¾è®¡æ¨¡å¼ç­â¦â¦
â¡ï¸éè¿å¨ç©ºé²æ¶é´é¢åè§å£åé¾æ¥æ¥å è½½åç»­é¡µé¢å è½½ã
æå²ä»¥æ¥ä¸ºPHPåå»ºçææ£çéªè¯å¼æã
æ¶éå·¥å·åæ¹è¿ä½¿PhpStormæ´å¥½ä¸ç¹ã
Atomæä»¶ç¹å®çå¾æ ã

December 11, 2018

åºäºNodeJSçè·¨å¹³å°ï¼åè´¹åå¼æºå¯ç ç®¡çå¨ã
A proxyee-down extension for baiduyunã
Proxyee Downæ©å±å­å¨åºã
æ¼ç¤ºReacté¡¹ç®å¦ä½æ¥å¥Fundebugéè¯¯çæ§æå¡ã
Goçç®åæä»¶åµå¥å¨ã
The official Go package for NSQã
For macOS.ç¾åº¦ç½ç ç ´è§£SVIPãä¸è½½éåº¦éå¶~
OpenTracing API for PHPã
å°ä»»ä½èæ¬æç¨åºçè¾åºæ¾å¨Mac OS Xèåæ ä¸­ã
è¿ä¸ªjavascriptåºè§£æPHPä»£ç å¹¶å°å¶è½¬æ¢ä¸ºASTã
Chromeæ©å±ä»¥æ æ ¼å¼æ¾ç¤ºGitlabä»£ç ã
ä¸ä¸ªææåºï¼æ¯æGolangä¸­çACLï¼RBACï¼ABACç­è®¿é®æ§å¶æ¨¡åã
ä¸ä¸ºThinkPHP5.1å®å¶çCasbinçæ©å±åï¼Casbinæ¯ä¸ä¸ªåè½å¼ºå¤§ï¼é«æçå¼æºè®¿é®æ§å¶åºã
TomatoIDCèæä¸»æºéå®ç³»ç»ã
å¿«éï¼é«æä¸æäºä½¿ç¨çJSON pullè§£æå¨ã
Composeræ´æ°åæ¾ç¤ºæ´å¥½çæè¦ã
ä¸ä¸ªææåºï¼æ¯æPHP casbin.orgä¸­ç ACLï¼RBACï¼ABACç­è®¿é®æ§å¶æ¨¡åã
ä¸ä¸ªææåºï¼æ¯æPHP casbin.orgä¸­ç ACLï¼RBACï¼ABACç­è®¿é®æ§å¶æ¨¡åã
PHPçµå­é®ä»¶éªè¯å¨åºåå°ã
æ£æ¥ä»¥ä¸RFCççµå­é®ä»¶å°åï¼3696,1123,4291,5321,5322 isemail.info
Spotify Web APIçGoåè£å¨ã
ãGithub å¸®å©ææ¡£ã ä¸­æç¿»è¯ã

December 10, 2018

ä¸ºæ¯ä¸ªäººæä¾å®¢æ·ç«¯JavaScript PDFçæã
éæ°ç¼åï¼ä½¿ç¨react ï¼babelï¼webpackåå¶ä»ç°ä»£ä¸è¥¿ã
phpstormæä»¶,ç¨äºthinkphp5æ¡æ¶çè§å¾,éç½®,è·¯ç±,æ°æ®åº,æ¨¡åæºè½æç¤ºåè·³è½¬ã
è¾å¥git openæå¼æµè§å¨ä¸­å­å¨åºçGitHubé¡µé¢æç½ç«ã

December 9, 2018

æå»ºOAuthåOpenID Connectæå¡å¨çç»æPythonåºã åæ¬JWSï¼JWEï¼JWKï¼JWAï¼JWTã
åºäºworkermançPHPä¸­socket.ioçæå¡å¨ç«¯æ¿ä»£å®ç°ã
ä½¿ç¨ä¸ä¸ªå½ä»¤è®¾ç½®gitï¼vimï¼zshï¼SublimeTextï¼tmuxç­ã
éªè¯è¡¨åå¼æ­¥ã
eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee
å¨HOMEä¸­ä»¥çº¯PHPå½¢å¼å­å¨åç®¡çPHPçæ¬ã

December 8, 2018

éç¨äºGolangçç±»åå®å¨çRediså®¢æ·ç«¯ã
JavaScriptçBase64å®ç°ã
è°·æ­è®¿é®å©æç ´è§£çã
phpæ¡æ¶åºåæµè¯ï¼åæ¬laravelï¼symfonyï¼silexï¼lumenï¼slimï¼yii2ï¼tastphpç­ï¼
ä¸ºGitHub README.mdè½»æ¾åå»ºTOCã
ç¨å¨ç»çå½¢å¼åç°è§£LeetCodeé¢ç®çæè·¯ã
Tampermonkeyèæ¬ä»Stack Overflowç­å¤å¶ä»£ç ã
aria2æ¯ä¸ä¸ªè½»éçº§çå¤åè®®åå¤æºï¼è·¨å¹³å°ä¸è½½å®ç¨ç¨åºï¼å¨å½ä»¤è¡ä¸­è¿è¡ã
webui-aria2ã
æ´ä¼éçé©¾è½¦ä½éªã
Charles ç ´è§£å·¥å·ã
listen1 desktopã

December 7, 2018

Larastan - å¨ä¸è¿è¡ä»£ç çæåµä¸åç°ä»£ç ä¸­çéè¯¯ã
Goè®¾è®¡æ¨¡å¼ï¼é£è°±åä¹ è¯­çç²¾éåè¡¨ã
PHPçç®åå¤è¿ç¨ç®¡çå¨ï¼åºäºpcntlåposixã
PHPçå¯æ©å±å¾®æ¡æ¶ã
æçPythonç¤ºä¾ http://www.thegeekblog.co.uk
åºäºworkermançshadowocksçphpç«¯å£ã
Flutterå¯ä»¥è½»æ¾å¿«éå°æå»ºæ¼äº®çç§»å¨åºç¨ç¨åºã
PHPçåºæ¬CURLåè£å¨ã
easyProxyæ¯ä¸æ¬¾è½»éçº§ãé«æ§è½ãåè½æä¸ºå¼ºå¤§çåç½ç©¿éä»£çæå¡å¨ã

December 6, 2018

ç¨äºå¤çTumblråå®¢çå·¥å·ï¼Tumblrå¤ä»½ã
JSBox æ©å± demoã
jsboxãpin ä½¿ç¨æå·§ã 
å¨iOSè®¾å¤ä¸æ éè¶ç±å³å¯æ£ç´¢InfoPlistã
åºç¨ç¨åºä¸­å¼æ¾ç³»ç»è®¾ç½®çæ¼ç¤ºï¼iOS 10.2ï¼ã
å½ä»¤è¡çèºæ¯ã
åºäºæµè§å¨çä»£ç ç¼è¾å¨ã
ä¸ä¸ªç®åçæ¬å°å¾åï¼ç¨PHPç¼åçç¼©ç¥å¾çæèæ¬.
æçZSHéç½®ådotfilesã
One for all free music in china for Windows with fluent UI. https://github.com/oyrx/listen1_desktopã

December 5, 2018

golangåºç¨äºè¯»åMicrosoft Excelã
Dan Abramov çä¸ªäººåå®¢ã
Rules / è§åï¼Surge / Shadowrocket / Quantumultã
You-Dont-Know-JSä¸­æçã
è®¡ç®æºæä½ç³»ç»æè¯¾ç¬è®°ã
Laravelä¸ç¨OSSæ©å±åã
åºäºCçgRPCï¼C ++ï¼Pythonï¼Rubyï¼Objective-Cï¼PHPï¼Cï¼ï¼ã
å°JSONæ°æ®è½¬æ¢ä¸ºPHPç±»å¯¹è±¡ã
å¼æºä¹¦ç±ï¼ãShell ç¼ç¨èä¾ãï¼é¢åæä½å¯¹è±¡å­¦ Shellï¼
å»éªå³° learn javaã
æå®¢æ¶é´ï¼nginxæ ¸å¿ç¥è¯100è®²éç½®æä»¶ä¸ä»£ç åäº«ã
Laravel ç Websocketsã
é¡¹ç®ç®¡çç³»ç»æ¥å£ã
å¢å¤å°å¢åæ¬è¿å·¥ã
æç½ç½åå¤§å¨TORã
Tor Browserã
ä¸­ææç½ç¬è«ã
ä¸ä¸ªç®åçäº¤äºå¼Goè§£éå¨ã

December 4, 2018

åºäºWebææ¯æå»ºçç»ç«¯ã
åºäºUWPåWebææ¯çç»ç«¯ã
è°·æ­è»èè®¡åã
CLIç±å¥½èçç»ç«¯æ¡æ¶ï¼æä»¶åèµæºçç²¾éåè¡¨ã
ä½¿ç¨Hexoæå»ºæ¨èªå·±çç½ç«ã
å°MySQL binlogè§£æä¸ºæ¨æ³è¦çSQLã
ä¸ä¸ªåLaravelçddä¸æ ·æ¹ä¾¿è°è¯çåã
Golang é«æç¼ç å¼æã
ãThe Way to Goãä¸­æè¯æ¬ï¼ä¸­ææ­£å¼åãGo å¥é¨æåã
Training for Golangã
å¦ä½ä½¿ç¨golangæå»ºWebåºç¨ã
ä¸­æç awesome-goã
Golangæ ååºã

December 3, 2018

å¾®ä¿¡éé¢çé»ç§æã
äºè§£å¦ä½å°å¨ç»å¼å¥æ¨çWebé¡¹ç®ã

December 2, 2018

ðå°ç¨åºAndå¬ä¼å·ååï¼å¤å åå°ï¼åè½é½å¨ï¼
ð¬è±ç£çµå½±ä¼ éé¨ã

December 1, 2018

å¾®ä¿¡æ¯ä»åæä»¶çãä¸ä¸ªPHPæä»¶æå®å¾®ä¿¡æ¯ä»ç³»åãåæ¬åçæ¯ä»ï¼æ«ç æ¯ä»ï¼ï¼H5æ¯ä»ï¼å¬ä¼å·æ¯ä»ï¼ç°éçº¢åãä¼ä¸ä»æ¬¾å°é¶é±ç­ã
ä¸ä¸ªPHPæä»¶æå®æ¯ä»å®æ¯ä»ç³»åï¼åæ¬çµèç½ç«æ¯ä»ï¼ææºç½ç«æ¯ä»ï¼æ«ç æ¯ä»ï¼JSAPIæ¯ä»ãåç¬è½¬è´¦å°æ¯ä»å®è´¦æ·ãäº¤æç»ç®ï¼åè´¦ãåæ¶¦ï¼ãç½é¡µææè·åç¨æ·ä¿¡æ¯ç­ã
Laravelæä½³å®è·µã

November 30, 2018

Go WebçGo-Megaæç¨ã
åè´¹çKindleçµå­ä¹¦èµæºã
ç²¾éçåå®¢åè¡¨ã
Laravel Novaèµæºçç²¾éåè¡¨ã
å¼æºphpå å¯è¿è¡æ©å±ï¼åºäºscrewäºæ¬¡å¼åã
golang å­¦ä¹ ç¬è®°ã
Goè¯­è¨å­¦ä¹ ç¬è®°ã
ãGo Web ç¼ç¨ã 
ãGo å¥é¨æåã
beegoæ¯Goç¼ç¨è¯­è¨çå¼æºï¼é«æ§è½Webæ¡æ¶ã

November 29, 2018

ðéç¨äºJavaScriptçClean Codeæ¦å¿µã
ä¸ºPhpStormåIntelliJæ·»å PHPæ³¨éæ¯æã
Node.js CMSåWebåºç¨ç¨åºæ¡æ¶ã

November 28, 2018

Chrome æ©å±ï¼éº»éº»åä¹ä¸ç¨æå¿ Google API æ½é£äºã
è¿æ¯PHPçä¸ä¸ªå®ç°ï¼ç¨çº¯Goç¼åï¼å°½å¯è½ï¼ç°å¨pcreå¨pure goä¸­ä¸å­å¨å¹¶ä¸éè¦ä½¿ç¨libpcreï¼ã
åè½å¼ºå¤§ä¸æäºä½¿ç¨çPHPå¾®æ¡æ¶ï¼æ¨å¨å¸®å©æ¨å¿«éæå»ºå¨æï¼å¼ºå¤§çWebåºç¨ç¨åºï¼
æ­¤PHPç±»ä½¿ç¨FastCGIåè®®å¤çä¸FastCGIï¼FCGIï¼åºç¨ç¨åºçéä¿¡ã
ç¨äºå¤çäºè¿å¶ååå­è¿å¶æ°æ®çå·¥å·ç®±ãä¸NodeJS Bufferç±»ä¼¼ã
å°Laravelï¼LaraDock [Laravel + Docker]åPHPStormè¿æ¥å¨ä¸èµ·ã
ç±å¾®ä¿¡å¼åçé«æï¼å°åç§»å¨é®å¼å­å¨æ¡æ¶ãéç¨äºiOSï¼macOSåAndroidã
è·¨å¹³å°å¼æ­¥I / O http://libuv.org/ã
ç¨ electron çæç Shadowsocksrå®¢æ·ç«¯ã
MongoDBå¯¹è±¡ææ¡£æ å°å¨ï¼ODMï¼
ç¨äºå¨PHPä¸­ä½¿ç¨MongoDbã

November 27, 2018

91äºæå¡å¨ä¸é®æµè¯åã
ç¨Goï¼golangï¼ç¼åçå®æ´æ¯ç¹å¸è§£å³æ¹æ¡ã
Goçæ§è¡æ¥å¿ã
â²ï¸å®æ¶ä»»å¡èæ¬ï¼æ¨éåç«¯èµè®¯å°å¾®ä¿¡/Telegramã
çé±¼çåå®¢ï¼åï¼golang çä¸äºæç« ï¼ã
åºåé¾é±åææ¯æåã
éå®åºæä¾PHPä»£ç çåºååæ§è¡ã
Yii3 web application templateã
Yii Framework 3.0 coreã

November 26, 2018

Deepin wine for ubuntuã
Flash OSæ åå°SDå¡åUSBé©±å¨å¨ï¼å®å¨ï¼è½»æ¾ã
Chinese Identity Card package ï¼ä¸­å½å¤§éï¼å¬æ°èº«ä»½è¯ç±»ã
Linux åæ ¸æ­å¯ã
å¸¦æè¯¦ç»æ³¨éç Redis 3.0 ä»£ç ï¼annotated Redis 3.0 source codeï¼ã

November 25, 2018

æ·æ°å­ç¬¦ä¸²çå¤§æ¸åæ¯ä¸ä¸ªå­ç¬¦ä¸²åè¡¨ï¼å½ç¨ä½ç¨æ·è¾å¥æ°æ®æ¶å¾å¯è½å¯¼è´é®é¢ã
âä¸è¦ç¼åä½ çUIä»£ç ï¼ç»å®ï¼â
ä¸ä¸ªå°å¤è¿è¡çç§å¹»æ¡é¢ã

November 24, 2018

ä¸å¥ç¨äºLaravelçé«çº§Eloquentã
å»¶è¿éåã
æçæ²¹ç´èæ¬ã
æ¥ç Github å¶ä»ç¨æ·çæ¶é´è¡¨ã
å¦ä½æä¸ºä¸åç¨åºå ä¸­æçã

November 23, 2018

Tipaskæ¯ä¸æ¬¾å¼æ¾æºç çPHPé®ç­ç³»ç»ï¼åºäºLaravelæ¡æ¶å¼åï¼å®¹ææ©å±ï¼å·æå¼ºå¤§çè´è½½è½ååç¨³å®æ§ã
NGiÐXéç½®çæå¨ã
äº¬ä»·ä¿ï¼äº¬ä»·å®ï¼ââ ä¸ä¸ªå¸®å©ä½ èªå¨ç³è¯·äº¬ä¸ä»·æ ¼ä¿æ¤çchromeæå±ã

November 22, 2018

æ åå¾ä¹¦é¦ã
kafka phpå®¢æ·ç«¯ã
The Elements of Statistical Learning (ESL)çä¸­æç¿»è¯ãä»£ç å®ç°åå¶ä¹ é¢è§£ç­ã
æå¥½ç¨çPHPæ±å­è½¬æ¼é³ç±»ï¼æ¯æè·åæ±å­çæ¼é³ä»¥åæ¼é³çç¼©åï¼è½åç¡®å¹é6åå¤ä¸ªæ±å­ã
GitHub code treeã
macOS hosts æä»¶ç®¡çå¨ã
 Go è¯­è¨é«æ§è½åè¯ã
CLIç¨äºå°åç§ç½ç«çæµæåå°æ¨éæ©çè§é¢æ­æ¾å¨ã
Go Webæå¡å¨çå®æ¶éæ°å è½½å®ç¨ç¨åºã
GraphQLæ¯ä¸ç§ä¸ä»»ä½åç«¯æå¡ç¸å³èçæ¥è¯¢è¯­è¨åæ§è¡å¼æã
ä¸ä¸ªæµè§å¨æ©å±ï¼ä¸ºGitHubï¼Gitlabï¼Bitbucketï¼giteaågogsæä¾ä¸åçæä»¶ç±»åã
å¼å®¹çRedisåè®®NoSQLæ°æ®åºã
Kubernetesä¸­ææå/äºåçåºç¨æ¶æå®è·µæåã
å­¦ä¹ æ­£åã
ä¸ä¸ªå½ä»¤è¡å·¥å·ï¼ç¨äºæ´¾çbip32å°ååç§é¥ã
å¨äºç«¯åéæ¨çé¡¹ç®ã
ç½ç«è®¨è®ºå¹³å°composeråã
swooleéåã

November 21, 2018

ç´æ¥å¨CSVæTSVæä»¶ä¸è¿è¡SQLã
å¤éç¾¤ Kubernetes çWeb UIã
WeUIçè½»éçº§JavaScriptåºã
golangçç®æ³åæ°æ®ç»æã
ä½¿JSON / JSONPæäºéè¯»ã
ä¸ä¸ªJavaScript / Python / PHPå å¯è´§å¸äº¤æåºï¼æ¯æè¶è¿100ä¸ªæ¯ç¹å¸/ altcoinäº¤æ¢ã
ð W3School æç¨æ´ç http://www.w3cschool.cc
ä¸­è±æææè¯ãè¯­è¨æ£æµãä¸­å¤ææº/çµè¯å½å±å°/è¿è¥åæ¥è¯¢ãåå­æ¨æ­æ§å«ãææºå·æ½åãèº«ä»½è¯æ½åãé®ç®±æ½åãä¸­æ¥æäººååºãä¸­æç¼©ååºãæå­è¯å¸ãè¯æ±ææå¼ãåç¨è¯ãåå¨è¯è¡¨ãæ´æè¯è¡¨ãç¹ç®ä½è½¬æ¢ãè±ææ¨¡æä¸­æåé³ãæ±ªå³°æ­è¯çæå¨ãèä¸åç§°è¯åºãåä¹è¯åºãåä¹è¯åºãå¦å®è¯åºãæ±½è½¦åç&é¶ä»¶è¯åºãæ¶é´æ½åãè¿ç»­è±æåå²ãä¸­æè¯åéå¤§å¨ãå¬å¸åå­å¤§å¨ãå¤è¯è¯åºãITè¯åºãè´¢ç»è¯åºãæè¯­è¯åºãå°åè¯åºãåå²åäººè¯åºãè¯è¯è¯åºãå»å­¦è¯åºãé¥®é£è¯åºãæ³å¾è¯åºãæ±½è½¦è¯åºãå¨ç©è¯åºãä¸­æèå¤©è¯­æãä¸­æè°£è¨æ°æ®ã
çµæ´»èå¼ºå¤§çéç¨è·¯ç±è§£å³æ¹æ¡ã
å¼æºçæ¿ï¼ç¨Meteorå»ºé ï¼ã
å¼æ¾ä¸­æç¥è¯å¾è°±çschemaã

November 20, 2018

å¬å±ç»´æ¤çPholcusç¬è«è§ååºã
Swagger 2.0å®ç°goã
ä¸ä¸ªå¼æºçèªæç®¡æç»­éæåé¨ç½²ç³»ç»ã
åå°ææ¯æ /å¨æ å¼å/æ¶æå¸ä¹è·¯ï¼ç§æ/æ¥æ/æ ¡æ/é¢è¯ã
""ç»å·´""ä¸­æåè¯çNode.jsçæ¬ã
å¾®ä¿¡ipadãå¾®ä¿¡macåè®®ï¼å¯å®ç°å¾®ä¿¡80%åè½ï¼æ¯æ62æ°æ®ç»å½ãæ«ç ç»å½ãæ¶åæååãæ¥çæååãå¾®ä¿¡å»ºç¾¤ãå¾®ä¿¡æäººè¿ç¾¤ãå¾®ä¿¡å¬ä¼å·éè¯»ãå¾®ä¿¡æ¶æ¯æ¶åãå¾®ä¿¡éè¿çäººå®ä½ãå¾®ä¿¡æ·»å å¥½åãå¾®ä¿¡çº¢åæ¥æ¶ãå¾®ä¿¡é²æ¤åãåäº«å°ç¨åºãå¾®ä¿¡å ç²ãå¾®ä¿¡æ¶èãå¾®ä¿¡æ ç­¾ç­ã
æ·æ°å­ç¬¦ä¸²çå¤§æ¸åæ¯ä¸ä¸ªå­ç¬¦ä¸²åè¡¨ï¼å½ç¨ä½ç¨æ·è¾å¥æ°æ®æ¶å¾å¯è½å¯¼è´é®é¢ã
å¨æµè§å¨ä¸­è¿è¡SQLã
æ¯ä»å®ï¼èèéæï¼å¼æ¾å¹³å°ç¬¬ä¸æ¹ PHP SDKï¼åºäºå®æ¹ 3.3.0 çæ¬ï¼å©åæ¯ä»å®å°ç¨åºåç«¯å¼åã
PHPä¸­çç®åå å¯ã
Spring Boot æç¨ãææ¯æ ç¤ºä¾ä»£ç ï¼å¿«éç®åä¸ææç¨ã
åºäºSwiftçiTuâânesæä»¶ï¼ç¨äºå¨æ¡é¢ä¸æ¾ç¤ºæ­è¯ã
éç¨äºMacçTinyPNGå®¢æ·ç«¯.
ä½æ²å®¶å¹¶è¡å®è£æä»¶-å éåå®è£ã
Caddyæ¯ä¸æ¬¾å¯ç«å³æå¥çäº§çå¼æºWebæå¡å¨ï¼å®å¿«éï¼æç¨ï¼å¹¶ä¸å¯ä»¥æé«æ¨çå·¥ä½æçã
Certbotæ¯EFFçå·¥å·ï¼ç¨äºä»Let's Encryptè·åè¯ä¹¦ï¼å¹¶ä¸ï¼å¯éï¼å¨æ¨çæå¡å¨ä¸èªå¨å¯ç¨HTTPSãå®è¿å¯ä»¥åå½ä½¿ç¨ACMEåè®®çä»»ä½å¶ä»CAçå®¢æ·ç«¯ã
Laravel EchoçSocket.ioæå¡å¨ã
æ»ç»å³äºç§å­¦ä¸ç½çæ¦å¿µæ¹æ³åå·¥å·ã
è¿éå¯ä¸ä¸ä¸ªgfwlistã
å¾®å°çæ¬çgfwlistï¼ä»å³æ³¨å¸¸è§ç½ç«ã
å®æ¶ç½ç»çå¼æºæ°æ®åºã
thumboræ¯ä¸ä¸ªå¼æºçç§çç¼©ç¥å¾æå¡ã

November 19, 2018

è¡ç¥¨ææï¼RSUï¼ç¨æ¶éè¯»ã
HTTP ç¸å³ç RFC ä¸­æç¿»è¯ï¼ä¸­è±æå¯¹ç§ï¼ã
éæç½é¡µçæå¨å¤§åéæ±æ»ç½ç«ã
ä¸ä¸ªç¨äºå¨ MacOS ä¸å¹³æ»ä½ çé¼ æ æ»å¨æææåç¬è®¾ç½®æ»å¨æ¹åçå°å·¥å·, è®©ä½ çæ»è½®ç½å¦è§¦æ§æ¿ ã
ä½¿ç¨vueæå»ºelectronåºç¨ç¨åºã
Postmanä¸­æä½¿ç¨è¯´æã

November 18, 2018

ä½¿ç¨Go + HTML5æå»ºè·¨å¹³å°çç°ä»£æ¡é¢åºç¨ç¨åºã
iOS 12 æ·å¾åå»ºèã

November 17, 2018

Cloudflare CNAMEæ¥å¥ã
å°ç±³ç¬è®°æ¬PROå®è£macOS Mojave & High Sierra ä½¿ç¨è¯´æã
Goçå¾®ååå¯ææWebæ¡æ¶ã
PHPéæåæå·¥å· - åç°ä»£ç ä¸­çéè¯¯èä¸è¿è¡å®ï¼
å¯ç»åDockerç®¡çã
Compose setup for Portainerã

November 16, 2018

Golangå®ç°JSONç½ç»ä»¤çï¼JWTï¼ã
è½»æ¾çææ¡£ã
çµæ´»ä¸å¯æ©å±çCMSï¼å¯å¨ç½ç»ä¸åä»¥ååå»ºå®å¶çæ°å­ä½éªã

November 15, 2018

Docker UIç®¡çå¨ã
ç¨äºæå»ºä»£çä»¥ç»è¿ç½ç»éå¶çå¹³å°ã
æå¥½ç¨ç V2Ray ä¸é®å®è£èæ¬ & ç®¡çèæ¬ã
æºå¨äºº/æºå¨äºº/ç¬è«/å®å/èèä½¿ç¨çHTTPç¨æ·ä»£ççè¯­æ³æ¨¡å¼ã
ç¬¦åè§èï¼é»è®¤æåµä¸æ¯å®å¨çPHP OAuth 2.0æå¡å¨ã
swoole å¼åçmysqlæ°æ®åºè¿æ¥æ± ã
Goçè§£æå¨åºã

November 14, 2018

MySQL JSON Explain Analyzerã
å°Luaçå¼ºå¤§åè½åµå¥å°NGINX HTTPæå¡å¨ä¸­ã
PHPå¾åå¤çã
Laravelçå®æ¶ä¿¡ä½¿ã
å¿«éèå¼ºå¤§çWebæå¡å¨ååºç¨ç¨åºæå¡å¨ã
å¼ºå¤§çé³ä¹APIæ¡æ¶ã
ä¸ºæ¨çElectronåºç¨ç¨åºåå»ºä¸ä¸ªWindowsåã
Zephiræ¯ä¸ç§ç¼è¯çé«çº§è¯­è¨ï¼æ¨å¨ä¸ºPHPåå»ºCæ©å±ã
Goçå¿«éHTTPåãè°æ´ä¸ºé«æ§è½ãç­è·¯å¾ä¸­çé¶åå­åéãæ¯net / httpå¿«10åã
Rediså¨PHPä¸­åå¸éã
åºäºNode.jsçä¸­æåè¯æ¨¡åã
ä¸ä¸ä»£ShadowsocksXã

November 13, 2018

è·¨å¹³å°Goæ¥å¿åºã
ç¨ go å®ç° laravelã
zshçä¸ä¸ä»£æä»¶ç®¡çå¨ã
awesome-zsh-pluginsã
google ç ggrc-coreã
Goçç»æåå¯æå¥æ¥å¿è®°å½ã

November 12, 2018

Vue.jsçç§»å¨UIåç´ ã
PHPçä¸ä¸ªé¢åå¯¹è±¡çå¤è¿ç¨ç®¡çå¨ã
PHPä¸­åºäºWebçæä»¶ç®¡çå¨ï¼ä½¿ç¨Tiny File Manageré«æï¼è½»æ¾å°ç®¡çæä»¶ã
JetBrains ç³»åè½¯ä»¶æ±ååã

November 11, 2018

goçä¾èµå·¥å·ã
é²èç rime è¾å¥æ³éç½®ã
ãé¼ é¬ç®¡ãRime for macOSã

November 10, 2018

iHostséå¸¸éåå¨Mac OS Xä¸ç¼è¾/etc/hostsã
hostç®¡çchromeæä»¶ã
ðå¼åå·¥å·ï¼ç¨äºè®°å½laravelåºç¨ç¨åºçæææ¥è¯¢ã
ãç²¾éæ¯ç¹å¸2ãä¸­æçã
Dockerçç®åç®¡çUIã
å¨Laravelåºç¨ç¨åºä¸­è®°å½æ´»å¨ã
Photopeaæ¯å¨çº¿å¾åç¼è¾å¨ã
ä¸ä¸ªé¢åå¨å¹³å°çä»£çå®¢æ·ç«¯ã
ä¸ä¸ªClashçWindowsç¨æ·å¾å½¢çé¢ã

November 9, 2018

ä¸KeePasså¼å®¹çåè´¹è·¨å¹³å°å¯ç ç®¡çå¨ã
macOS  KeePass å®¢æ·ç«¯ã
KeePassæä»¶éè¿HTTPå®å¨å°å¬å¼å¯ç æ¡ç®ã
archiverã
å½ä»¤è¡JSONå¤çå·¥å·ð¥
for PHPçæç¥å¾åæ£åhttps://jenssegers.com

November 8, 2018

ä¸å»ç¤¾åºåç«¯ API æºç ã
ä¸å»ç¤¾åºåç«¯æºç ã
Chatteræ¯ä¸ä¸ªç®åçLaravelè®ºååã
dockerä¸­æææ¡£ã

November 7, 2018

é£å° - è®©åç«¯å¼åç®åèåå¥½ï¼æµ·éå¯å¤ç¨ç©æï¼éå¥æ¡é¢å·¥å·æéæå»ºåç«¯åºç¨ï¼æçæå 100% ã
Yiiçä¾èµæ³¨å¥ã
Gitbook çé«äº®æä»¶ã
SQLä¼åå¨åéåå¨ã
Goä¸­åºäºè®¾è®¡çAPIåå¾®æå¡ã
ç®åçPHPçæ¬ç®¡çã
ä¸ä¸ªç®åçHTML5ï¼YouTubeåVimeoæ­æ¾å¨ã
å®çç½è¯¾ç¨çå­¦ä¹ è·¯å¾ã
PHP API ææ¡£ã
ç¨äºæ¬å°å¼åçç°ä»£Docker LAMPå æ åMEANå æ ã
å¤ç«¯ç»ä¸å¼åæ¡æ¶ï¼æ¯æç¨ React çå¼åæ¹å¼ç¼åä¸æ¬¡ä»£ç ï¼çæè½è¿è¡å¨å¾®ä¿¡å°ç¨åº/ç¾åº¦æºè½å°ç¨åº/æ¯ä»å®å°ç¨åºãH5ãReact Native ç­çåºç¨ã
å°macOSâå¿«éæ¥çâåè½å¸¦å°Windowã
ð¥ ä»MongoDBå°Elasticsearchçæ°æ®éè¿ç§»å·¥å·ï¼åä¹äº¦ç¶ã
ä¸ºMongoDBçæéæºæ°æ®ã
ãä¸èµ·å­¦ Node.jsã
ç¾åº¦ç½çå®¢æ·ç«¯ - Goè¯­è¨ç¼åã
ä¸ºäºé³ä¹å®¢æ·ç«¯è§£å³ä¸å¯ç¨çæ­æ²ã
ç½æäºé³ä¹ç¬¬ä¸æ¹ã

November 6, 2018

JSSæ¯CSSçåä½å·¥å·ï¼å®ä½¿ç¨JavaScriptä½ä¸ºå®¿ä¸»è¯­è¨ã
PHP Curl Classå¯ä»¥è½»æ¾åéHTTPè¯·æ±å¹¶ä¸Web APIéæã
PHPçå¿«éè¯·æ±è·¯ç±å¨ã
Next Generation of ShadowsocksXã

November 5, 2018

HTTP API è®¾è®¡æåã
åºäºVue.js 2.0æå»ºçé«è´¨éUIå·¥å·åã
å¼æºé¡¹ç®æ£é±å®ç¨æåã
éæç½ç«çæå¨Hexoçç®åï¼ç²¾è´åç°ä»£ä¸»é¢ã
ä½¿ç¨tensorflow.jså¨æµè§å¨ä¸­è¿è¡é¢é¨æ£æµåé¢é¨è¯å«çJavaScript APIã
ð¤Alfred3å·¥ä½æµç¨çéåï¼å°éæ¼æ¨çä¸çã
Alfredå·¥ä½æµç¨çå¬å±éåãhttp://www.alfredworkflow.com
shortcuts workflow éåã
What-happens-when çä¸­æç¿»è¯ã
ä½¿ä»»ä½ç½é¡µæä¸ºæ¡é¢åºç¨ç¨åºã
ç®çº¦çVueé©±å¨çéæç«ç¹çæå¨ã
ä¸ä¸ªç¥å¥çææ¡£ç«ç¹çæå¨ã

November 3, 2018

æ·±åº¦å­¦ä¹ 500é®ï¼ä»¥é®ç­å½¢å¼å¯¹å¸¸ç¨çæ¦çç¥è¯ãçº¿æ§ä»£æ°ãæºå¨å­¦ä¹ ãæ·±åº¦å­¦ä¹ ãè®¡ç®æºè§è§ç­ç­ç¹é®é¢è¿è¡éè¿°ï¼ä»¥å¸®å©èªå·±åæéè¦çè¯»èã
è¦å¥ç¥¥çå­¦ä¹ ç¬è®°ï¼åç§å ååéå¥é¨çææ¡£ã
ä¸­å½è¿è¥åIPå°ååº-æ¯æ¥æ´æ°ã
ä½¿ç¨JavaScriptï¼HTMLåCSSæå»ºè·¨å¹³å°æ¡é¢åºç¨ç¨åºã
æå¿«çshellæä»¶ç®¡çå¨ã
ä¸ç§ä½¿ç¨Webææ¯æå»ºçå¼æºå±å¹å½åæºã
å¨ç»ç«¯ä¸­è·åLinuxæ¡é¢æªå¾çç³»ç»/ä¸»é¢ä¿¡æ¯ã

November 2, 2018

PHP 7ä¸­çæ­£ç¡®èå¥ï¼ä»»æç²¾åº¦çåè¿å¶æµ®ç¹è¿ç®ã
PHPç»ç«¯NESæ¨¡æå¨ã
Sentryæ¯è·¨å¹³å°åºç¨ç¨åºçæ§ï¼ä¸æ³¨äºéè¯¯æ¥åã
æµè§å¨ä¸­çMarkdownç¼è¾å¨ã
Binyæ¯ä¸ä¸ªç¨äºWebåºç¨ç¨åºçå°åé«æ§è½PHPæ¡æ¶ã
å°MySQL binlogè§£æä¸ºæ¨æ³è¦çSQLã
è¾å¥SQLï¼è¾åºç´¢å¼ä¼åå»ºè®®ã
éç¨äºmacOSçç°ä»£è§é¢æ­æ¾å¨ã
ä½¿æçmacOSä½éªæ´å æäººçåºç¨ç¨åºåå·¥å·åè¡¨ã
ä½¿æçiOSä½éªæ´å æäººçåºç¨ç¨åºåå·¥å·åè¡¨ã

November 1, 2018

ç¨åºååºè¯¥è®¿é®çæä½³ç½ç«ä¸­æçã
ä½¿ç¨Golangå®ç°PHPçå¸¸è§åç½®å½æ°ã
ãæ°ãå¾®ä¿¡å¼ï¼å¾®ä¿¡æå¡å·+å¾®ä¿¡å°ç¨åº+å¾®ä¿¡æ¯ä»ï¼ã
MIT-18.06-çº¿æ§ä»£æ°-å®æ´ç¬è®°ã
ãRedis Command Referenceãå¨æçä¸­æç¿»è¯çã
PHPéä¾µå¥å¼çæ§å¹³å°- ä¼åæ§è½ï¼å®ä½Bugçç¥å¨ï¼å«åè®©ä½ çPHPç¨åºè£¸å¥ã
SurgeãQuantumultãKitsunebiãShadowrocketãPepi(ShadowRay)ãSurfboard çéç½®è§åæä»¶ ã
Swaggeræ´åå°Laravel 5ã
APIæ¥å£è¾å©åºåï¼çæåæ ¡éªapiç­¾åã
ä»¥å¼åäººåä¸ºä¸­å¿çHTTPå®¢æ·ç«¯ï¼éå¯¹å¤§å¤æ°å¸¸è§ç¨ä¾è¿è¡äºä¼åã

October 30, 2018

 æ¶é PHP æä½³å®è·µãç¼ç è§èåæå¨å­¦ä¹ æåï¼æ¹ä¾¿ PHP å¼åèéè¯»åæ¥æ¾ã
ðä¸äºæç¨çç¨åºåç½ç«ã
ç¨ vue åå°ç¨åºï¼åºäº mpvue æ¡æ¶éå weuiã
CSSéç½®çç°ä»£æ¿ä»£æ¹æ¡ã
ç«å³å°JSONè½¬æ¢ä¸ºæµè§å¨ä¸­çGoç±»åï¼åå§ï¼ã
å­¦ä¹ å¦ä½è®¾è®¡å¤§åç³»ç»ã
ä¸ç§èªå¨ä¿®å¤PHPç¼ç æ åé®é¢çå·¥å·ã
ç¡®ä¿ä½ çé¡¹ç®æ²¡æä¾èµä¸äºå·²ç¥æåæ»å»çä¾èµã
ç¨äºå¨PHPåºç¨ç¨åºä¸­æ¥æ¾éè¯¯çéæåæå·¥å·ã
æäºä½¿ç¨çPDOåè£å¨ï¼éç¨äºPHPé¡¹ç®ã
å¯ç åå¸Argon2ï¼PHCçè·èèã
å¼å®¹PHP 5.5éå¸¦çpassword_ *å½æ°ã
PHPé¡¹ç®çèªå¨cacert.pemç®¡çã

October 29, 2018

ä¸ä¸ªç®åçJekyllä¸»é¢ã
SparkPHPæ¡æ¶ã
PHPä¸­å½æ°å¼ç¼ç¨ã
ç¾åº¦ç½çå½ä»¤è¡å·¥å·ã
PHPçææï¼å¿«éï¼ç¨³å®çæ¥å¿æ©å±ã
ð åå Â· ä¸­æçã
ç¨äºå°PHPåéè®°å½å°Google Chromeæ§å¶å°ã
å¨Google Chromeä¸­è¿ç¨æ§è¡PHPä»£ç ï¼å¤çPHPéè¯¯ï¼è½¬å¨åéã
ä¸ä¸ªéç¨äºçOpenWRTå¨çå¹³å°ä¸ªäººæåºç¿»å¢è·¯ç±æ¹æ¡ã
äºèç½å¬å¸ææ¯æ¶æï¼å¾®ä¿¡/æ·å®/å¾®å/è¾è®¯/é¿é/ç¾å¢ç¹è¯/ç¾åº¦/Google/Facebook/Amazon/eBayçæ¶æã
åç«¯æ¶æå¸ææ¯å¾è°±ã

October 26, 2018

vuejs Database Manageræ°æ®ç®¡çç³»ç»ââåç«¯ã
vuejs Database Manageræ°æ®ç®¡çç³»ç»ââåç«¯ã
A PHP framework for console artisansã
æ¶éæ´çä¸äºå¸¸ç¨çPHPç±»åºï¼èµæºä»¥åæå·§ã

October 25, 2018

å¾ç±ç ´è§£è®ºå ç±ç down.52pojie.cn é¡µé¢çæºä»£ç ã
å¾®ä¿¡ä¸ªäººå·æ¥å£ãå¾®ä¿¡æºå¨äººåå½ä»¤è¡å¾®ä¿¡ï¼ä¸åè¡å³å¯èªå®ä¹ä¸ªäººå·æºå¨äººã
åºäºyafå¼åçåè´¹ãå®å¨ãç¨³å®ãé«æçåå¡ç³»ç»ï¼å¼å¾æ¥æ! 
åºäºyafå¼åçå¨æ°ãåè´¹ãå¼æºãé«æå¥½ç¨çç¥è¯ä»è´¹å¹³å°ï¼èªç¨åï¼ã
åºäºSwooleçPHPä¸­çé«æ§è½Webæ¡æ¶ååºç¨ç¨åºæå¡å¨ã
éç¨äºWebå®¢æ·ç«¯çgRPCã
ç±»ä¼¼ä¸PHP Simple HTML DOM Parserï¼ä½æ¯æ¯å®å¿«å¥½å åã

October 24, 2018

Vagrant Manager for Windowsã
SQLä¼åå¨åéåå¨ã
å°å®æ¶æ®µè½ï¼åè¯åå­ç¬¦è®¡æ°æ·»å å°HTMLåç´ ã
è®©èªå·±è½»æ¾éæ©é¿éå·´å·´é£å³åç§°ï¼ååï¼è±åï¼ã
ææç®æ³é½å¨Pythonä¸­å®ç°ã
ä¸ªäººç½ç«å³æ¶å°è´¦æ¶æ¬¾è§£å³æ¹æ¡ã
éç¨äºPayPal RESTful APIçPHP SDKã
ç¾åº¦ç½çä¸ééä¸è½½ æ¯æWindowsåMacã
Laravelæ¡æ¶çä¼éè°è¯å©æã Telescopeå¯æ·±å¥äºè§£è¿å¥åºç¨ç¨åºçè¯·æ±ï¼å¼å¸¸ï¼æ¥å¿æ¡ç®ï¼æ°æ®åºæ¥è¯¢ï¼æéä½ä¸ï¼é®ä»¶ï¼éç¥ï¼ç¼å­æä½ï¼è®¡åä»»å¡ï¼åéè½¬å¨ç­ã

October 23, 2018

Nginxå¼åä»å¥é¨å°ç²¾éã
opcacheç¶æé¡µé¢ã
dcloudio æ¯ä»ç¸å³ã
DCloudå¼æºé¡¹ç®éé¦ http://www.dcloud.ioã
æ¯ä¸ª JavaScript å·¥ç¨å¸é½åºæç33ä¸ªæ¦å¿µã
swoft æ¡æ¶æä»¶ã
macOSçMySQL / MariaDBæ°æ®åºç®¡çã

October 22, 2018

åºåé¾3.0 -> è¶çº§è´¦æ¬hyperledger fabircæç¨ v1.1ã
Google Hostsã

October 21, 2018

ä¸äºç»å¸ä¸é«è´¨éççµå­ä¹¦åäº«ã
ä¸­å½ç¨åºåå®¹æåé³éè¯¯çåè¯ã
ä¸­åäººæ°å±åå½è¡æ¿åºåï¼ççº§ï¼çä»½ç´è¾å¸èªæ²»åºï¼ã å°çº§ï¼åå¸ï¼ã å¿çº§ï¼åºå¿ï¼ã ä¹¡çº§ï¼ä¹¡éè¡éï¼ã æçº§ï¼æå§ä¼å±å§ä¼ï¼ ï¼ä¸­å½çå¸åºéæäºçº§ä¸çº§åçº§äºçº§èå¨å°åæ°æ® Node.js ç¬è«ã
ð An elegant dashboard https://d2-projects.github.io/d2-admin/ã
.vimrcç®åéç½®ï¼æ²¡ææä»¶ã

October 20, 2018

å¨macOSä¸å®è£å¼åç¯å¢ã
å çå¯ç åå¸ï¼å¦ä½æ­£ç¡®ä½¿ç¨ã
Metabaseæ¯ä¸ä¸ªå¼æºçBIå·¥å·ï¼æå¤§çç¹ç¹æ¯å·æå¯è§åæä½çé¢çæ°æ®åæåæ¥è¯¢åè½ï¼è®©ä¸æSQLå¾ç¨æ·å¯è½å¤å¿«éææ¡ä¸å¡æ°æ®ï¼æ¯æå¢éå±äº«ä¸å¡æ°æ®ï¼å¹¶ä¸æ¯æMySQLãPostgresqlç­å¤ç§æ°æ®æºï¼é¨ç½²æ¹ä¾¿ï¼ä¸ºä¼ä¸æä¾äºä¸ä¸ªå¾ä¸éçBIè§£å³æ¹æ¡ã
å¨ Windows ä¸ç¨ WSL ä¼éå¼åã
éç¨äºå¼åäººåçæç¨Quick Lookæä»¶åè¡¨ã
Mysql webç«¯sqlå®¡æ ¸å¹³å°ã
WordPress ä¸»é¢ Pumaã
è¿æ¯ä¹¦ç±ãæ·±åº¦å­¦ä¹ æ¡æ¶PyTorchï¼å¥é¨ä¸å®è·µãçå¯¹åºä»£ç ï¼ä½æ¯ä¹å¯ä»¥ä½ä¸ºä¸ä¸ªç¬ç«çPyTorchå¥é¨æååæç¨ã
ä»¥åç§æ¹å¼ä½¿ç¨RabbitMQçæç¨ã
çº¯Python MySQLå®¢æ·ç«¯ã

October 19, 2018

Shadowsocks for Windowsã
Nginxå®è£ç»´æ¤å¥é¨å­¦ä¹ ç¬è®°ï¼ä»¥ååç§å®ä¾ã
ä¸­å½æå¤§çAPIæ¥å£ç®¡çå¹³å°ã
A PHP terminal NES emulatorã
æ¤ç½æ¯2018 easy_laravel Dockerç¯å¢ã
èé³å½±è§ - å¨çº¿å½±è§åºç¨ http://www.moeins.cnã
ä¸ä¸ªç®åçå¾ä¹¦ SDKï¼ä½ å¯ä»¥ä½¿ç¨å®ç¨äºè·åæå®ä¹¦ç±çåºæ¬ä¿¡æ¯ã
phpå¼æºååç³»ç»ï¼åºäºswooleãeasyswooleæ¡æ¶å¼å https://www.fashop.cnã

October 18, 2018

ç®æ³å­¦ä¹  Golang çã
é¿éå·´å·´mysqlæ°æ®åºbinlogçå¢éè®¢é&æ¶è´¹ç»ä»¶ ã
åæä¸æ­¥æ­¥é¨ç½² kubernetes éç¾¤ã
PHPConChina ç¸å³èµæºã
RedisãLuaãNginxãOpenRestyç¬è®°ã
MeepoPSæ¯Meepo PHP Socketçç¼©åï¼æ¨å¨æä¾ç¨³å®çSocketæå¡ãå¯ä»¥è½»æ¾æå»ºå¨çº¿å®æ¶èå¤©ãå³æ¶æ¸¸æãè§é¢æµåªä½æ­æ¾ç­ã

October 17, 2018

Git å¸¸è§é®é¢ãç¨æ³ã
å½å®¶æ åçè½¯ä»¶å¼åææ¡£ã
é®ä¸å³° - ææ¯åäº«å¨åï¼æ¯å¨äºåå¸ã

October 16, 2018

å¹³å¸¸å­¦ä¹ ä¸­æ¶éçæç¨æ´çã
Twitter ç Snowflake çPHPçã
åºäºæèµäºåæèµå¾®å°åºå®ç°ä¸ªäººæ¶æ¬¾è§£å³æ¹æ¡ã
PHPForkeræ¯ä¸ä¸ªPHPå¤è¿ç¨ç¼ç¨éª¨æ¶ï¼åé´äºWorkermanè¯¸å¤ä¼è¯ç¼ç¨ææ³ï¼å¥ç¦»äºå¶ä¸­çç½ç»äºä»¶åºæ½è±¡é¨åï¼éä¸­å´ç»å¤è¿ç¨ç¼ç¨ï¼ä¸ºäºä¾¿äºç´è§çè°è¯ä»¥åä¿ææè½»çå¤è¿ç¨éª¨æ¶ï¼æä»¥ç®åçååµäºä¸ä¸ªåºäºselectå¤è·¯å¤ç¨ææ¯ç TCP & UDP Serverã
lnmp ä¸é®å®è£åã

October 15, 2018

Yaf MVCæ¡æ¶éæäºä¸äºå¸¸ç¨ç±»åºã
Valitronæ¯ä¸ä¸ªç®åï¼ä¼éï¼ç¬ç«çéªè¯åºï¼æ²¡æä¾èµå³ç³»ã
å¤å¶GitHub Markdownæ ·å¼çæå°CSSéã

October 14, 2018

ä¸ä¸ªç»ææ¸æ°çï¼æäºç»´æ¤çï¼ç°ä»£çPHP Markdownè§£æå¨ã
OpenCV-Python-Tutorialã
è·¨åæ¬å°å­å¨ï¼å·ææéã
éè¿ç¼å­æ´ä¸ªååºæ¥å éLaravelåºç¨ç¨åºã
redis web å®¢æ·ç«¯ã

October 12, 2018

åç«¯æ¶æå¸ææ¯å¾è°±ã
ð´èç¯ææ°çæ¬ä¸è½½ã

October 11, 2018

IPsec VPN æå¡å¨ä¸é®å®è£èæ¬ã
æ¬ç¦å·¥ä¸é®æ­å»ºé¸é¸ Shad0ws0cks å¾ææç¨ã
ä¸ä¸ªå¯ä½éª Windows 95 çappã
ä»0å°1æå»ºåå¸å¼ç§æç³»ç»ï¼è±ç¦»æ¡ä¾è®²æ¶æé½æ¯èæµæ°ï¼æ°æ®åºï¼æå¡å¨æç« ï¼ã
æ¾å°ä¸ä¸ªå¥½ç¨çéªè¯ç ç¨åº(5ç§éªè¯ç )ã
Luosimao åæ°å¼åçäººæºéªè¯ï¼åå»äºå¤æçè¾å¥è¿ç¨ï¼å·ææ´å ä¼ç§çæä½ä½éªï¼æ´å ç¾è§çè®¾è®¡ï¼å¯æ´å¥½å°èå¥å°æ¨çç½ç«ä¸­ã
ä¸ä¸ªåºäºPHPçjQueryä¸­æç¹å»éªè¯ç æä»¶ ï¼php, jquery, captchaï¼ã
ckplayer (è¶é·ç½é¡µè§é¢æ­æ¾å¨),æ¯æhttpåè®®ä¸çflv,f4v,mp4,æ¯ærtmpè§é¢æµårtmpè§é¢åæ¾,æ¯æm3u8æ ¼å¼,æ¯ä½ åè§é¢ç´æ­,è§é¢ç¹æ­ççæ³æ­æ¾å¨ http://www.ckplayer.com
ð» HTML5æ­æ¾å¨ãM3U8ç´æ­/ç¹æ­ãRTMPç´æ­ãä½å»¶è¿ãæ¨æµ/æ­æµå°åé´æãä¼åæµè§å¨å¼å®¹æ§ï¼HLS+æ©å± http://github.tinywan.com/html5-dash-â¦
ä¸ä¸ªæ¯æèªå®ä¹UIå¸å±,æµå¼API, å å¯,ç´æ­ ,äº®åº¦,é³é,å¿«è¿ç­æå¿ ,å¹¿åè§é¢é¢è§,å¤ç§å è½½æ¨¡å¼ ,å¤ç§åè¾¨çåæ¢ ,å¤ç§å°é¢å¾, èªå®ä¹æ°æ®æº,åè¡¨æ­æ¾,åæ°æ­æ¾,è¾¹æ­åç¼å­ä¸æ¯ä½¿ç¨AndroidVideoCache,ç¦»çº¿æ­æ¾,ç¥å¥çæ­æ¾å¨ã
SGPlayer æ¯ä¸æ¬¾åºäº AVPlayerãFFmpeg çåªä½èµæºæ­æ¾å¨æ¡æ¶ãæ¯æ360Â°å¨æ¯è§é¢ï¼VRè§é¢ï¼RTMPãRTSP ç­ç´æ­æµï¼åæ¶æ¯æ iOSãmacOSãtvOS ä¸ä¸ªå¹³å°ã
äºæå¡ï¼æ©ç åæ³å¼æºçäºæå¡ç³»ç»ä¸»è¦ç±æå­¦ãç³»ç»ãè´¦æ·ä¸ä¸ªå¤§æ¨¡åç»æ http://www.yunjiaowu.cnã

October 10, 2018

ä¸æ¬¾åè½å¼ºå¤§ç macOS çå¾®ä¿¡å°å©æã
ç½æäºé³ä¹ Node.js API serviceã
æä¸ªäººæ¾ç»åè¿çææ¯åäº«... http://xiaorui.cc
ä¸­æç ãå¾®æå¡ï¼ä»è®¾è®¡å°é¨ç½²ãã
åºäºlaravelåè´¹çå¼æºITèµäº§/è®¸å¯è¯ç®¡çç³»ç»ã
è¾è®¯äºCOSå¯¹è±¡å­å¨ V5ã
è¿ç¨swooleå¨æµè§å¨æ´åå¥½çå®ç°vmstatã

October 9, 2018

Laravelä¸ºSentryæ´åã
ä¸­æäººåè¯­æåºãä¸­æå§å,å§æ°,åå­,ç§°å¼,æ¥æ¬äººå,ç¿»è¯äººå,è±æäººåã
Wooyunç¥è¯åºï¼ä¹äºç¥è¯åºã
ä¸ä¸ªè½å¤ Hook ç»å¤§å¤æ°å½æ°/ç±»ãé¨å opcode ç PHP7 æ©å±ã

October 8, 2018

æä¾ç¨äºè§èåcomposer.jsonçcomposeræä»¶ã

October 7, 2018

ç»ç«¯ä¸»é¢éè²ã
spf13-vimã

October 6, 2018

Vue.jsçå½éåæä»¶ã

October 5, 2018

æ¶éé£äºä¼ç§çè½¯ä»¶ï¼Windows & Macï¼ã

October 4, 2018

ãRedis è®¾è®¡ä¸å®ç°ãï¼ç½ç»çï¼çä¹¦ç¨¿æºç ã
Aria2GUI for macOSã

October 3, 2018

Laravel æ·±å¥æµåºæå ââ Laravel 5.7 æºä»£ç è§£æï¼æ°æè¿é¶æåã

October 2, 2018

GitHub èå Star åç½è¡å¨ã
Goå®æå¼åã

October 1, 2018

hitokotoæ¬å°æºã

September 30, 2018

å¨Bladeè§å¾ä¸­ä½¿ç¨èªå®ä¹htmlç»ä»¶ã
æçmacOSéç½®ï¼Zsh, Karabiner, VS Code, Sublime, Neovim, Nix, Hammerspoonã
Firaä»£ç ï¼å·æç¼ç¨è¿å­çç­å®½å­ä½ã
å·æç¼ç¨è¿å­çç­å®½å­ä½ã
åºäºLaravelå¼åçå¨çº¿ç¹æ­ç³»ç»ã

September 29, 2018

èç¯ææ°çæ¬ä¸è½½ã
æ¥èªLaravelçæç³»ç»çç²¾éèµæºå¤§å¨ï¼åæ¬ä¹¦ç­¾ãåãæç¨ãè§é¢ä»¥åå¶å®è¯¸å¤å¾é·çèµæºã
ç¨äºå¤ä»½Laravelåºç¨ç¨åºçè½¯ä»¶åã
ä¸ä¸ªç¨vueåçåå°æ¨¡æ¿

September 28, 2018

PHPå¼åç¥è¯ç»æã

September 27, 2018

åç«¯ç¬è¯é¢è¯é¢é¢åºã
å¿«åºç¨çä¾å­ã

September 26, 2018

ä½¿ç¨å¼æºLaravel Envoyå·¥å·æä¾åºæ¬çâé¶åæºâé¨ç½²ã
QRç çæå¨ã
VPN Chromeæ¯åºäºGoogle Chromiumçæµè§å¨ï¼å·æåç½®çVPNåè½ï¼å¯è®©ç¨æ·ä»¥å®å¨åç§å¯çæ¹å¼ä¸ç½ã
æ­¤å­å¨åºåå«ä½¿ç¨å¤§å¤æ°çº¯PHPçæ¯ç¹å¸å®ç°ã
Mineraæ¯ä¸ä¸ªç®¡çåçæ§æ¯ç¹å¸éç¿ç¡¬ä»¶çå®æ´ç³»ç»ã
ç¨äºä¸blockchain.info APIäº¤äºçå®æ¹PHPåºã
BitWaspæ¯ä¸ä¸ªå¼æºPHPé¡¹ç®ï¼åè®¸ä»»ä½äººå»ºç«ä¸ä¸ªç¬ç«äºå¶ä»éä¸­æå¡çå®å¨æ¯ç¹å¸å¸åºã
10 ä¸ªä½ åºè¯¥ç¥éç PHP æ¯ç¹å¸å¼æºé¡¹ç®ã

September 25, 2018

åç«¯åå±å¾å¿«ï¼ç°ä»£æµè§å¨åç API å·²ç»è¶³å¤å¥½ç¨ãæä»¬å¹¶ä¸éè¦ä¸ºäºæä½ DOMãEvent ç­åå­¦ä¹ ä¸ä¸ jQuery ç APIãåæ¶ç±äº ReactãAngularãVue ç­æ¡æ¶çæµè¡ï¼ç´æ¥æä½ DOM ä¸åæ¯å¥½çæ¨¡å¼ï¼jQuery ä½¿ç¨åºæ¯å¤§å¤§åå°ãæ¬é¡¹ç®æ»ç»äºå¤§é¨å jQuery API æ¿ä»£çæ¹æ³ï¼ææ¶åªæ¯æ IE10 ä»¥ä¸æµè§å¨
ClickHouseæ¯ä¸ä¸ªé¢åå¼æºåçæ°æ®åºç®¡çç³»ç»ï¼å¯ä»¥å®æ¶çæåææ°æ®æ¥åã
ç¤¾ä¼éæ±æ¶éå¨ - ä¸äºéææ¯æç« ã

September 24, 2018

åºäºPHPçåçæ¯åæ¨é©¬åæ¶æè½¯ä»¶è§£å³æ¹æ¡ã
ä¸ä¸ªç®åçå¾ä¹¦ SDKï¼ä½ å¯ä»¥ä½¿ç¨å®ç¨äºè·åæå®ä¹¦ç±çåºæ¬ä¿¡æ¯ã

September 23, 2018

éæ°å®ä¹å¾®ä¿¡å°ç¨åºçå¼åã
ä¸ä¸ªå®å¨çç§æèå¤©è½¯ä»¶ã
å¾®ä¿¡/æ¯ä»å®çæ§ä¸ªäººæ¶æ¬¾ï¼æ éç­¾çº¦æ¯ä»å®ãå¾®ä¿¡æ¯ä»ãä¸ºæ¯ä»å®ãå¾®ä¿¡æ¯ä»çä¸ªäººè´¦æ·æä¾å³æ¶å°è´¦æå¡ã
ç¬ç«çqrcodeçæï¼ä¸ä¾èµäºå¤é¨æå¡ï¼ã

September 22, 2018

PHP Server Monitoræ¯ä¸ä¸ªèæ¬ï¼ç¨äºæ£æ¥æ¨çç½ç«åæå¡å¨æ¯å¦å·²å¯å¨å¹¶æ­£å¨è¿è¡ãå®å¸¦æä¸ä¸ªåºäºWebçç¨æ·çé¢ï¼æ¨å¯ä»¥å¨å¶ä¸­ç®¡çæ¨çæå¡åç½ç«ï¼è¿å¯ä»¥ä½¿ç¨ææºå·ç åçµå­é®ä»¶å°åç®¡çæ¯ä¸ªæå¡å¨çç¨æ·ã
php-interview-2018: é¢è¯æ»ç»ã
YApi æ¯ä¸ä¸ªå¯æ¬å°é¨ç½²çãæéååç«¯åQAçãå¯è§åçæ¥å£ç®¡çå¹³å°ã
swooleåæ ¸åæï¼åºäºswoole2.0.13ã
åºäº Chrome å Vue.js å¼åçç¬¬ä¸æ¹å³å»éç¥æä»¶ã
githubå¾½ç« æå¡ã

September 21, 2018

Leetcode é¢è§£ (è·éæè·¯ä¸æ­¥ä¸æ­¥æ¸åºä»£ç ) åç»å¸ç®æ³å®ç°ã
SimPicæ¯ä¸ä¸ªå¼æºçPHPå¾åºã
è°è°ä¸äºæè¶£ç CSS è¯é¢ã
PHPæ¯ç¹å¸å¼åè¯¦è§£ï¼æ¬è¯¾ç¨é¢ååå­¦èï¼åå®¹å³æ¶µçæ¯ç¹å¸çæ ¸å¿æ¦å¿µã
Laravel çä¸­å¤§åå°æ¡æ¶æ§ | é»çåã
Gitlab å®è£åéç½®ã

September 20, 2018

Serialize closures (anonymous functions) https://opis.io/closureã

September 19, 2018

Laravel 5.7 blog application with Vue.js, Docker, Redis, Horizon and Pusherã
ç¬ç«å¼å/èªç±èä¸/è¿ç¨å·¥ä½èµæºåè¡¨ã

September 18, 2018

Laravel 5 ç³»åå¥é¨æç¨ã
ç½é¡µå¾®ä¿¡PHPç»å½çå®ç°ã
PHPåºå±åæ ¸æºç åæåæ©å±å¼åã

September 17, 2018

PHPä»£ç èä¸çæ¶¯ä¸­çä¸äºå°æå·§ðhttp://easy-tips.tigerb.cnã

September 16, 2018

æ·±åº¦æè¶£ - äººå·¥æºè½å®æé¡¹ç®åéã
ä¸ºäºèç½ITäººæé çä¸­æçawesome-goã
å¼æºä¹¦ç±å¤§æç½ã

September 15, 2018

åºäº Swoole å¼åçåç¨ PHP å¼åæ¡æ¶ï¼å¸¸é©»åå­ãåç¨å¼æ­¥ã
Golangæ ååºãå¯¹äºç¨åºåèè¨ï¼æ ååºä¸è¯­è¨æ¬èº«åæ ·éè¦ï¼å®å¥½æ¯ä¸ä¸ªç¾å®ç®±ï¼è½ä¸ºåç§å¸¸è§çä»»å¡æä¾å®ç¾çè§£å³æ¹æ¡ãä»¥ç¤ºä¾é©±å¨çæ¹å¼è®²è§£Golangçæ ååºã

September 14, 2018

åä¸ä¸ªLinux VPSæµè¯èæ¬ã
é«æ§è½, å¹¶åæ¢å é, å¹¶åéåéã
æ¯æå¤å®¶äºå­å¨çäºçç³»ç»ã

September 13, 2018

ä¸ä¸ªç½ç«é¨ç½²åã
RSSHub æ¯ä¸ä¸ªè½»éãæäºæ©å±ç RSS çæå¨ï¼å¯ä»¥ç»ä»»ä½å¥å¥æªæªçåå®¹çæ RSS è®¢éæºã

September 12, 2018

æç´¢äºå¨å°å¾ä»¥äºè§£ä»»ä½åå®¹ https://learn-anything.xyzã
ä¸å åä¸­çåçç±»åºãæ¡æ¶ã
åç«¯ç²¾è¯»å¨åã

September 11, 2018

2018åç«¯å¸¸è§é¢æ±æ»ï¼ä¸å®æ¶æ´æ°ã

September 10, 2018

Node.js API ä¸­æææ¡£ã

September 9, 2018

eoLinkeræ¯å½åæå¤§çå¨çº¿APIæ¥å£ç®¡çå¹³å°ï¼æä¾èªå¨çæAPIææ¡£ãAPIèªå¨åæµè¯ãMockæµè¯ãå¢éåä½ç­åè½ã
V2EX æé¼å¤§æã
ä¸æ¬¾åè½å¼ºå¤§ç macOS çå¾®ä¿¡å°å©æã

September 8, 2018

ð åè´¹çè®¡ç®æºç¼ç¨ç±»ä¸­æä¹¦ç±ã
å¯è½æ¯è®©ä½ åçåªæµçè±è¯­è¿é¶æåã
ç¨ PHP åå¼åç½ç«ä¸æ ·å¼åæ¡é¢åºç¨è½¯ä»¶ã

September 7, 2018

ä¸­åäººæ°å±åå½å±æ°èº«ä»½è¯å·ç éªè¯å·¥å·ã

September 6, 2018

php7.x æ°ç¹æ§ã
Goè¯­è¨é«çº§ç¼ç¨ (Advanced Go Programming)ã

September 4, 2018

ãGoè¯­è¨é«çº§ç¼ç¨ãå¼æºå¾ä¹¦ï¼æ¶µçCGOãGoæ±ç¼è¯­è¨ãRPCå®ç°ãProtobufæä»¶å®ç°ãWebæ¡æ¶å®ç°ãåå¸å¼ç³»ç»ç­é«é¶ä¸»é¢ã
PHP é¢è¯ç¥è¯ç¹æ±æ»ã
PHPå·¥ç¨å¸é¢è¯é¢ç®ã
ç¬è®°ãLaravelãPHPãé¢è¯é¢ãHTMLãCSSã

September 3, 2018

æ¶é&æ¨èä¼ç§ç Apps/ç¡¬ä»¶/æå·§/å¨è¾¹ç­ã

September 2, 2018

ä¸ä¸ªæ¶éå¨ GitHub ä¸ä½å¼ç¨æ·çé»ååé¡¹ç®
ä¸­åæ°åå­å¸æ°æ®åºãåæ¬æ­åè¯­ï¼æè¯­ï¼è¯è¯­ï¼æ±å­ãæä¾æ°åå­å¸APIã
å¤§åç³»ç»è®¾è®¡çåºç¡ç¥è¯
å½Â·Â·Â·æ¶åçäºä»ä¹ï¼
GitHub ä¸æç¥å¥çé¡¹ç®ä¹ä¸åºè¯¥æ¯è¿ä¸ªäºï¼ä¸è¡ä»£ç é½æ²¡ï¼ä½æ 2w+ starsã
Awesome macOS open source applications
ä½¿ç¨Microsoft StyleçGitHubä¸»é¢ã

August 30, 2018

awesome-chrome-devtools
clockwork-chrome - Clockworkæ¯ä¸ä¸ªæµè§å¨æ©å±ï¼æä¾è°è¯ååæPHPåºç¨ç¨åºçå·¥å·ï¼åæ¬è¯·æ±æ°æ®ï¼åºç¨ç¨åºæ¥å¿ï¼æ°æ®åºæ¥è¯¢ï¼è·¯ç±ï¼åºç¨ç¨åºè¿è¡æ¶çå¯è§åç­ã
remotedebug-gateway - åè®¸æ¨ä¸æ¬¡å°å®¢æ·ç«¯è¿æ¥å°å¤ä¸ªæµè§å¨
AwesomeList top

August 29, 2018

æµè°å¸¸è§çNoSQLææ¯æ¹æ¡åéå
A collection of awesome browser extensions for GitHub
composer èä¾å
PHP å¼åèè¯¥ç¥éç 5 ä¸ª Composer å°æå·§
github star æ´ç
pt-query-digest: ä»æ¥å¿ï¼è¿ç¨åè¡¨å tcpdump åæ MySQL æ¥è¯¢
MySQL çæåä¸çº§çæµè¯æ°æ®

",170
gosuri/uiprogress,Go,"uiprogress  
A Go library to render progress bars in terminal applications. It provides a set of flexible features with a customizable API.

Progress bars improve readability for terminal applications with long outputs by providing a concise feedback loop.
Features

Multiple Bars: uiprogress can render multiple progress bars that can be tracked concurrently
Dynamic Addition:  Add additional progress bars any time, even after the progress tracking has started
Prepend and Append Functions: Append or prepend completion percent and time elapsed to the progress bars
Custom Decorator Functions: Add custom functions around the bar along with helper functions

Usage
To start listening for progress bars, call uiprogress.Start() and add a progress bar using uiprogress.AddBar(total int). Update the progress using bar.Incr() or bar.Set(n int). Full source code for the below example is available at example/simple/simple.go
uiprogress.Start()            // start rendering
bar := uiprogress.AddBar(100) // Add a new bar

// optionally, append and prepend completion and elapsed time
bar.AppendCompleted()
bar.PrependElapsed()

for bar.Incr() {
  time.Sleep(time.Millisecond * 20)
}
This will render the below in the terminal

Using Custom Decorators
You can also add a custom decorator function in addition to default bar.AppendCompleted() and bar.PrependElapsed() decorators. The below example tracks the current step for an application deploy progress. Source code for the below example is available at example/full/full.go
var steps = []string{""downloading source"", ""installing deps"", ""compiling"", ""packaging"", ""seeding database"", ""deploying"", ""staring servers""}
bar := uiprogress.AddBar(len(steps))

// prepend the current step to the bar
bar.PrependFunc(func(b *uiprogress.Bar) string {
  return ""app: "" + steps[b.Current()-1]
})

for bar.Incr() {
  time.Sleep(time.Millisecond * 10)
}
Rendering Multiple bars
You can add multiple bars using uiprogress.AddBar(n). The below example demonstrates updating multiple bars concurrently and adding a new bar later in the pipeline. Source for this example is available at example/multi/multi.go
waitTime := time.Millisecond * 100
uiprogress.Start()

// start the progress bars in go routines
var wg sync.WaitGroup

bar1 := uiprogress.AddBar(20).AppendCompleted().PrependElapsed()
wg.Add(1)
go func() {
  defer wg.Done()
  for bar1.Incr() {
    time.Sleep(waitTime)
  }
}()

bar2 := uiprogress.AddBar(40).AppendCompleted().PrependElapsed()
wg.Add(1)
go func() {
  defer wg.Done()
  for bar2.Incr() {
    time.Sleep(waitTime)
  }
}()

time.Sleep(time.Second)
bar3 := uiprogress.AddBar(20).PrependElapsed().AppendCompleted()
wg.Add(1)
go func() {
  defer wg.Done()
  for i := 1; i <= bar3.Total; i++ {
    bar3.Set(i)
    time.Sleep(waitTime)
  }
}()

// wait for all the go routines to finish
wg.Wait()
This will produce

Incr counter
Bar.Incr() is an atomic counter and can be used as a general tracker, making it ideal for tracking progress of work fanned out to a lots of go routines. The source code for the below example is available at example/incr/incr.go
runtime.GOMAXPROCS(runtime.NumCPU()) // use all available cpu cores

// create a new bar and prepend the task progress to the bar and fanout into 1k go routines
count := 1000
bar := uiprogress.AddBar(count).AppendCompleted().PrependElapsed()
bar.PrependFunc(func(b *uiprogress.Bar) string {
  return fmt.Sprintf(""Task (%d/%d)"", b.Current(), count)
})

uiprogress.Start()
var wg sync.WaitGroup

// fanout into go routines
for i := 0; i < count; i++ {
  wg.Add(1)
  go func() {
    defer wg.Done()
    time.Sleep(time.Millisecond * time.Duration(rand.Intn(500)))
    bar.Incr()
  }()
}
time.Sleep(time.Second) // wait for a second for all the go routines to finish
wg.Wait()
uiprogress.Stop()
Installation
$ go get -v github.com/gosuri/uiprogress
Todos

 Resize bars and decorators by auto detecting window's dimensions
 Handle more progress bars than vertical screen allows

License
uiprogress is released under the MIT License. See LICENSE.
",1261
JiejayLan/CSC322_group_project,JavaScript,"Report and Documents
visit our Wiki Page

Getting started
I. clone repo
II. setup local and remote branch
III. using npm or yarn to install all dependencies on your machine
IV. setup .env.development and .env.test by heading to console of firebase

create .env.development and .env.test at root of project folder
open console of firebase
click Mini-eByMazon and click </>
setup key-value pair inside .env.development in following format

    FIREBASE_API=values copy from firebase without double quotes
    FIREBASE_AUTH_DOMAIN=values copy from firebase without double quotes
    FIREBASE_DATABASE_URL=values copy from firebase without double quotes
    FIREBASE_PROJECT_ID=values copy from firebase without double quotes
    FIREBASE_STORAGE_BUCKET=values copy from firebase without double quotes
    FIREBASE_MESSAGING_SENDER_ID=values copy from firebase without double quotes


click Mini-eByMazon Test and click </>
setup key-value pair inside .env.test in the same format in step 4 with values for Mini-eByMazon Test


Suggested Tools
React Developer Tools and Redux DevTools installed for Google Chrome

How to login
For login page, you dont't need to enter any username or password, because I set up a corrrect default username(""jay"") and password(""123"") in login-page react state.

Suggestion for development

""npm run deve"" for development //still can't set up the reload package to reload the page automatically
put component and pages into different folders
don't connet to firebase from client side.You should add a route controller on the server folder. You can take a look at how I write the login page

",4
ad-fidelitas/ctf-admin-website,Vue,"ctf-admin-website
Project setup
npm install

Compiles and hot-reloads for development
npm run serve

Compiles and minifies for production
npm run build

Run your tests
npm run test

Lints and fixes files
npm run lint

Customize configuration
See Configuration Reference.
",2
Tobybsmith/falppy_bird,Processing,"falppy_bird
",2
Pttn/rieMiner,Assembly,"rieMiner 0.9
rieMiner is a Riecoin miner supporting both solo and pooled mining. It was originally adapted and refactored from gatra's cpuminer-rminerd (https://github.com/gatra/cpuminer-rminerd) and dave-andersen's fastrie (https://github.com/dave-andersen/fastrie), though there is no remaining code from rminerd anymore.
Solo mining is done using the GetBlockTemplate protocol, while pooled mining is via the Stratum protocol. A benchmark mode is also proposed to compare more easily the performance between different computers.
Direct links to the latest official Windows x64 and Win32 standalone executables. Binaries built on Debian 9 with almost complete static linking also available (these should run on fresh Debian and Ubuntu installations): Deb64 and Deb32. Also note that 32 bits builds are much slower.
This README serves as manual for rieMiner, and you can also find a PDF version (without build instructions). I hope that this program will be useful for you!
The Riecoin community thanks you for your participation, you will be a contributor to the robustness of the Riecoin network. Happy mining!

I provide a Profitability Calculator here.
Minimum requirements
Only x64 systems with SSE are supported.

Windows 7 or later, or recent enough Linux;
x64 CPU with SSE instruction set;
1 GiB of RAM (the prime table limit must be manually set at a lower value in the options).

Recommended:

Windows 10 or Debian 9;
Intel Core i7 6700 or better, or AMD Ryzen R5 1600 or better;
8 GiB of RAM.

Compile this program
In Debian/Ubuntu x64
You can compile this C++ program with g++, as, m4 and make, install them if needed. Then, get if needed the following dependencies:

Jansson
cURL
libSSL
GMP

On a recent enough Debian or Ubuntu, you can easily install these by doing as root:
apt install g++ make m4 git libjansson-dev libcurl4-openssl-dev libssl-dev libgmp-dev
Then, just download the source files, go/cd to the directory, and do a simple make:
git clone https://github.com/Pttn/rieMiner.git
cd rieMiner
make
For other Linux, executing equivalent commands (using pacman instead of apt,...) should work.
If you get a warning after the compilation that there may be a conflict between libcrypto.so files, install libssl1.0-dev instead of libssl-dev.
In Windows x64
You can compile rieMiner in Windows, and here is one way to do this. First, install MSYS2 (follow the instructions on the website), then enter in the MSYS MinGW-w64 console, and install the tools and dependencies:
pacman -S make git
pacman -S mingw64/mingw-w64-x86_64-gcc
pacman -S mingw64/mingw-w64-x86_64-curl
Note that you must install the mingw64/mingw-w64-x86_64-... packages and not just gcc or curl.
Clone rieMiner with git like for Linux, go to its directory with cd, and compile with make.
Static building
The produced executable will only run in the MSYS console, or if all the needed DLLs are next to the executable. To obtain a standalone executable, you need to link statically the dependencies. Unfortunately, libcurl will give you a hard time, and you need to compile it yourself.
First, download the latest official libcurl code on their website, under ""Source Archives"", and decompress the folder somewhere (for example, next to the rieMiner's one).
In the MSYS MinGW-w64 console, cd to the libcurl directory. We will now configure it to not build unused features, then compile it:
./configure --disable-dict --disable-file --disable-ftp --disable-gopher --disable-imap --disable-ldap --disable-ldaps --disable-pop3 --disable-rtsp --disable-smtp --disable-telnet --disable-tftp --without-ssl --without-libssh2 --without-zlib --without-brotli --without-libidn2  --without-ldap  --without-ldaps --without-rtsp --without-psl --without-librtmp --without-libpsl --without-nghttp2 --disable-shared --disable-libcurl-option
make
Once done:

Create ""incs"" and ""libs"" folders in the rieMiner directory;
In the downloaded libcurl directory, go to the include directory and copy the ""curl"" folder to the ""incs"" folder;
Do the same with the file ""libcurl.a"" from the libs/.lib folder to the rieMiner's ""libs"" folder.

Now, you should be able to compile rieMiner with make static and produce a standalone executable.
Run and configure this program
You can finally run the newly created rieMiner executable using
./rieMiner
If no ""rieMiner.conf"" next to the executable was found, you will be assisted to configure rieMiner. Answer to its questions to start mining. If there is a ""rieMiner.conf"" file next to the executable with incorrect information that was read, you can delete this to get the assistant.
Alternatively, you can create or edit this ""rieMiner.conf"" file next to the executable yourself, in order to provide options to the miner. The rieMiner.conf syntax is very simple: each option is given by a line such
Option type = Option value

It is case sensitive, but spaces and invalid lines are ignored. A line starting with ""#"" will also be ignored. Do not put ; at the end or use other delimiters than = for each line, and do not confuse rieMiner.conf with riecoin.conf! If an option is missing, the default value(s) will be used. If there are duplicate lines, the last one will be used. Here is a sample configuration file for solo mining, with comments explaining the main available options.
# Mining mode: Solo for solo mining via GetBlockTemplate, Pool for pooled mining using Stratum, Benchmark for testing. Default: Benchmark
Mode = Solo

# IP and port of the Riecoin wallet/server or pool. Default: 127.0.0.1 (your computer), port 28332 (default port for Riecoin-Qt)
Host = 127.0.0.1
Port = 28332

# Username and password used to connect to the server (same as rpcuser and rpcpassword in riecoin.conf for solo mining).
# If using Stratum, the username includes the worker name (username.worker). Default: empty values
Username = user
Password = /70P$â¬CRâ¬7/

# Custom payout address for solo mining (GetBlockTemplate only). Default: this donation address
PayoutAddress = RPttnMeDWkzjqqVp62SdG2ExtCor9w54EB

# Number of threads used for mining. Default: 8
Threads = 8

# The prime table used for mining will contain primes up to the given number.
# Use a bigger limit if you have 16 GiB of available RAM or more, as this will reduce the ratio between the n-tuple and (n + 1)-tuple counts (but also the 1-tuple find rate).
# Reduce if you have less than 8 GiB of RAM (or if you want to reduce memory usage).
# It can go up to 2^64 - 1, but setting this at more than 2^33 will usually be too much and decrease performance. Default: 2^31
PrimeTableLimit = 2147483648

# Refresh rate of the stats in seconds. 0 to disable them and only notify when a long enough tuple or share is found, or when the network finds a block. Default: 30
RefreshInterval = 60

# For solo mining, submit not only blocks (6-tuples) but also k-tuples of at least the given length.
# Additionally, the base prime of such tuple will be shown in the Benchmark Mode. Default: 6
TupleLengthMin = 4

# For solo mining, add consensus rules in the GetBlockTemplate RPC call, each separated by a comma.
# Useful for softforks, for example, to mine SegWit transactions, you would need the following line. Default: no rule
# Rules = segwit

# Other options
# BenchmarkDifficulty = 1600
# BenchmarkTimeLimit = 0
# Benchmark2tupleCountLimit = 100000
# SieveBits = 25
# SieveWorkers = 0
# ConstellationType = 0, 4, 2, 4, 2, 4
# PrimorialNumber = 40
# PrimorialOffsets = 4209995887, 4209999247, 4210002607, 4210005967, 7452755407, 7452758767, 7452762127, 7452765487, 8145217177, 8145220537, 8145223897, 8145227257
# Debug = 0

It is also possible to use custom configuration file paths, examples:
./rieMiner config/example.txt
./rieMiner ""config 2.conf""
./rieMiner /home/user/rieMiner/rieMiner.conf
Benchmark Mode options

BenchmarkDifficulty : sets the testing difficulty (must be from 265 to 32767). Default: 1600;
BenchmarkTimeLimit : sets the testing duration in s. 0 for no time limit. Default: 0;
Benchmark2tupleCountLimit : stops testing after finding this number of 2-tuples. 0 for no limit. Default: 50000.

Advanced/Tweaking/Dev options
They can be useful to get better performance depending on your computer.

SieveBits : size of the segment sieve is 2^SieveBits bits, e.g. 25 means the segment sieve size is 4 MiB. Choose this so that SieveWorkers*SieveBits fits in your L3 cache. Default: 25;
SieveWorkers : the number of threads to use for sieving. Increasing it may solve some CPU underuse problems, but will use more memory. 0 for choosing automatically based on number of Threads and PrimeTableLimit. Default: 0.

These ones should never be modified outside developing purposes and research for now.

ConstellationType : set your Constellation Type, i. e. the primes tuple offsets, each separated by a comma. Default: 0, 4, 2, 4, 2, 4 (values for Riecoin mining);
PrimorialNumber : Primorial Number for the Wheel Factorization. Default: 40;
PrimorialOffsets : list of Offsets from the Primorial for the first number in the prime tuple. Same syntax as ConsType. Default: carefully chosen offsets;
Debug : activate Debug Mode: rieMiner will print a lot of debug messages. Set to 1 to enable, 0 to disable. Other values may introduce some more specific debug messages. Default : 0.

Some possible constellations types (format: (type) -> offsets to put for ConstellationType ; 3 first constellations (n + 0) which can be used for PrimorialOffsets, though some might not work)

5-tuples

(0, 2, 6,  8, 12) -> 0, 2, 4, 2, 4 ; 5, 11, 101,...
(0, 4, 6, 10, 12) -> 0, 4, 2, 4, 2 ; 7, 97, 1867,...


6-tuples

(0, 4, 6, 10, 12, 16) -> 0, 4, 2, 4, 2, 4 (Riecoin) ; 7, 97, 16057,...


7-tuples

(0, 2, 6,  8, 12, 18, 20) -> 0, 2, 4, 2, 4, 6, 2 ; 11, 165701, 1068701,...
(0, 2, 8, 12, 14, 18, 20) -> 0, 2, 6, 4, 2, 4, 2 ; 5639, 88799, 284729,...


8-tuples

(0, 2, 6,  8, 12, 18, 20, 26) -> 0, 2, 4, 2, 4, 6, 2, 6 ; 11, 15760091, 25658441,...
(0, 2, 6, 12, 14, 20, 24, 26) -> 0, 2, 4, 6, 2, 6, 4, 2 ; 17, 1277, 113147,...
(0, 6, 8, 14, 18, 20, 24, 26) -> 0, 6, 2, 6, 4, 2, 4, 2 ; 88793, 284723, 855713,...



Also see the constellationsGen tool in my rieTools repository (https://github.com/Pttn/rieTools).
Memory problems
If you have memory errors (Unable to allocate... or Bad Allocs), try to lower the PrimeTableLimit value in the configuration file.
Statistics
rieMiner will regularly print some stats, and the frequency of this can be changed with the RefreshInterval parameter as said earlier.
For solo mining, rieMiner will regularly show the primes per second speed, and the 1 to 2-tuples/s ratio. From this, it will also estimate the average time to find a block (note that all the ratios are the same, and the estimation should be fairly precise). Of course, even if the average time to find a block is for example 2 days, you could find a block in the next hour as you could find nothing during a week. The number of 2 to 6-tuples found since the start of the mining is also shown.
For pooled mining, the shares per minute metric and the numbers of valid and total shares are shown instead. As it is hard to get a correct earnings estimation from k-shares, no other metric is shown. The Benchmark Mode (or solo mining) can be used to get better figures for comparisons.
rieMiner will also notify if it found a k-tuple (k >= Tuples option value) in solo mining or a share in pooled mining, and if the network found a new block. If it finds a block or a share, it will tell if the submission was accepted (solo mining only) or not. For solo mining, if the block was accepted, the reward will be generated for the address specified in the options. You can then spend it after 100 confirmations. Note that orphaned blocks will be shown as accepted.
Solo mining specific information
Note that other ways for solo mining (protocol proxies,...) were never tested with rieMiner. It was written specifically for the official wallet and the existing Riecoin pools.
Configure the Riecoin wallet for solo mining
We assume that Riecoin Core is already working and synced. To solo mine with it, you have to configure it.

Find the riecoin.conf configuration file. It should be located in /home/username/.riecoin or equivalent in Windows;
Do not confuse this file with the rieMiner.conf!
An example of riecoin.conf content suitable for mining is

rpcuser=(username)
rpcpassword=(password)
rpcport=28332
port=28333
rpcallowip=127.0.0.1
server=1
daemon=1

If you feel the need, you can add more nodes manually with connect=(nodeip), (nodeip) after connect being a node's IP. You can find a list of the nodes connected the last 24 h here: https://chainz.cryptoid.info/ric/#!network.
If you wish to mine from another computer, add another rpcallowip=ip.of.the.computer, or else the connection will be refused. Choose a username and a password and replace (username) and (password).
Work control
You might have to wait some consequent time before finding a block. What if something is actually wrong and then the time the miner finally found a block, the submission fails?
First, if for some reason rieMiner disconnects from the wallet (you killed it or its computer crashed), it will detect that it has not received the mining data and then just stop mining: so if it is currently mining, everything should be fine.
If you are worried about the fact that the block will be incorrectly submitted, here comes the TupleLengthMin option. Indeed, you can send invalid blocks to the wallet (after all, it is yours), and check if the wallet actually received them and if these submissions are properly processed. When such invalid block is submitted, you can check the debug.log file in the same location as riecoin.conf, and then, you should see something like
ERROR: CheckProofOfWork() : n+10 not prime

Remember that the miner searches numbers n such that n, n + 2, n + 6, n + 10, n + 12 and n + 16 are prime, so if you set the TupleLengthMin option to for example 3, rieMiner will submit a n such that n, n + 2 and n + 6 are prime, but not necessarily the other numbers, so you can conclude that the wallet successfully decoded the submission here, and that everything works fine. If you see nothing or another error message, then something is wrong (possible example would be an unstable overclock)...
Also watch regularly if the wallet is correctly syncing, especially if the message Blockheight = ... did not appear since a very long time (except if the network is mining the superblock). In Riecoin-Qt, this can be done by hovering the check at the lower right corner, and comparing the number with the latest block found in a Riecoin explorer. If something is wrong, try to change the nodes in riecoin.conf or check your connection.
Pooled mining specific information
Existing pools:

XPoolX

Host = mining.xpoolx.com
Port = 5000
Owner: xpoolx - info@xpoolx.com
They also support Solo mining via Stratum with a 5% fee


uBlock.it

Host = mine.ublock.it or mine.blockocean.com
Port = 5000
Owner: ziiip - netops.ublock.it@gmail.com



The miner will disconnect if it did not receive anything during 3 minutes (time out).
Benchmarking
rieMiner provides a way to test the performance of a computer, and compare with others. This feature can also be used to appreciate the improvements when trying to improve the miner algorithm. When sharing benchmark results, you must always communicate the difficulty, the prime table limit (PTL), the test duration, the CPU model, the memory speeds (frequency and CL), the miner version, and the OS. Also, do not forget to precise if you changed other options, like the SieveWorkers or Bits.
To compare two different platforms or settings, you must absolutely test with the same difficulty, during enough time. The proposed parameters, conditions and interpretations for serious benchmarking are:

Standard Benchmark

Difficulty of 1600;
PTL of 2^31 = 2147483648;
No time limit;
Stop after finding 50000 2-tuples or more;
The computer must not do anything else during testing;
The system must not swap. Else, the result would not make much sense. Ensure that you have enough memory when benchmarking.



The test will be fairly long, but similar to the real mining conditions. Once the benchmark finished itself (not by the user), it will print something like:
100000 2-tuples found, test finished. rieMiner 0.9, difficulty 1600, PTL 2147483648
BENCHMARK RESULTS: 233.354130 primes/s with ratio 28.955020 -> 0.990626 block(s)/day

Generally speaking, the block(s)/day metric is the one that should be shared or used to compare performance, though it is always good to also take in consideration the other ones. Moreover, for a given difficulty and PTL, the ratio should be the same, and the more precise primes/day metric can be used instead for comparisons.
The precision will be about 2 significant digits for the block(s)/day. To get 3 solid digits, about 1 million of 2-tuples would need to be found, which would be way too long to be practical for the Standard Benchmark.
A run with valid parameters for the Standard Benchmark will additionally print the message
VALID parameters for Standard Benchmark

Which should appear if you want to share your results.
You could stop before 50000 2-tuples, for example at 10000, if you just want a rough estimation of the performance. However, even after this long, the values are often still very imprecise, and can lead to confusion, like a slightly slower computer getting better results. This remark is critical for people wanting to optimize the miner.
A few results
Done with rieMiner 0.9, 100000 2-tuples except otherwise said. Unit: primes/s

AMD Ryzen R7 2700X @4 GHz, DDR4 3200 CL14, Debian 9: 235.856209
AMD Ryzen R7 2700X @4 GHz, DDR4 2400 CL15, Debian 9: 233.354130
AMD Ryzen R7 2700X @3 GHz, DDR4 2400 CL15, Debian 9: 177.234506
Intel Core i7 6700K @3 GHz, DDR4 2400 CL15, Debian 9: 89.288621
Intel Core 2 Quad Q9650 @3 GHz, DDR3 1067 CL6, Debian 9: 40.673097
Intel Pentium D 925 @3 GHz, DDR3 1000 CL6, Debian 9: 7.466797 (10000 2-tuples)

As said, we should use the primes/s metric for fixed difficulty and PTL. The ratio for the Standard Benchmark is about 28.9.
For a given architecture, the performance is basically proportional to the number of cores and frequency. However, we notice that much better RAM doesn't really matter.
Miscellaneous
Unless the weather is very cold, I do not recommend to overclock a CPU for mining, unless you can do that without increasing noticeably the power consumption. My 2700X computer would draw much, much more power at 4 GHz/1.2875 V instead of 3.7 GHz/1.08125 V, which is certainly absurd for a mere 8% increase. To get maximum efficiency, you might want to find the frequency with the best performance/power consumption ratio (which could also be obtained by underclocking the processor).
If you can, try to undervolt the CPU to reduce power consumption, heat and noise.
Developers and license

Pttn, author and maintainer, contact: dev at Pttn dot me

Parts coming from other projects and libraries are subject to their respective licenses. Else, this work is released under the MIT license. See the LICENSE or top of source files for details.
Notable contributors

Michael Bell: assembly optimizations, improvements of work management between threads, and some more.

Versioning
The version naming scheme is 0.9, 0.99, 0.999 and so on for major versions, analogous to 1.0, 2.0, 3.0,.... The first non 9 decimal digit is minor, etc. For example, the version 0.9925a can be thought as 2.2.5a. A perfect bug-free software will be version 1. No precise criteria have been decided about incrementing major or minor versions for now.
Contributing
Feel free to do a pull request or open an issue, and I will review it. I am open for adding new features, but I also wish to keep this project minimalist. Any useful contribution will be welcomed.
By contributing to rieMiner, you accept to place your code in the MIT license.
Donations welcome:

Bitcoin: 1PttnMeD9X6imTsRojmhHa1rjudW8Bjok5
Riecoin: RPttnMeDWkzjqqVp62SdG2ExtCor9w54EB
Gapcoin: GgCyVr6y6beBbTofmTLJHvGc1NCWynQyvw
Ethereum: 0x32de6b854b6a05448b4f25d4496990bece8a2862

Quick contributor's checklist

Your code must compile and work on recent Debian based distributions, and Windows using MSYS;
If modifying the miner, you must ensure that your changes do not cause any performance loss. You have to do proper and long enough before/after benchmarks;
rieMiner must work for any realistic setting, at least try these in the Benchmark Mode (and do some actual mining):

Difficulty 304, PTL 2^20 (Testnet mining conditions);
Difficulty 800, PTL 2^27;
Difficulty 1600, PTL 2^31 (Standard Benchmark, similar to real mining conditions);
Difficulty 3200, PTL 2^31 or more (we will eventually reach such Difficulties someday...).


Ensure that your changes did not break anything, even if it compiles. Examples (if applicable):

There should never be random (or not) segmentation faults or any other bug, try to do actual mining with Gdb, debugging symbols and Debug Mode enabled during hours or even days to catch possible bugs;
Ensure that valid work is produced (pools and Riecoin-Qt must not reject submissions);
Mining must stop completely while disconnected and restart properly when connection is established again.


Follow the style of the rest of the code (curly braces position, camelCase variable names, tabs and not spaces, spaces around + and - but not around * and /,...).

Resources

rieMiner thread on Riecoin-Community.com forum
My personal website about Riecoin
Get the Riecoin wallet
Fast prime cluster search - or building a fast Riecoin miner (part 1), nice article by dave-andersen explaining how Riecoin works and how to build an efficient miner and the algorithms. Unfortunately, he never published part 2...
Riecoin FAQ and technical aspects
Bitcoin Wiki - Getblocktemplate
BIP141 (Segwit)
Bitcoin Wiki - Stratum

",2
vinta/awesome-python,Python,"Awesome Python 
A curated list of awesome Python frameworks, libraries, software and resources.
Inspired by awesome-php.

Awesome Python

Admin Panels
Algorithms and Design Patterns
Audio
Authentication
Build Tools
Built-in Classes Enhancement
Caching
ChatOps Tools
CMS
Code Analysis
Command-line Tools
Compatibility
Computer Vision
Concurrency and Parallelism
Configuration
Cryptography
Data Analysis
Data Validation
Data Visualization
Database Drivers
Database
Date and Time
Debugging Tools
Deep Learning
DevOps Tools
Distributed Computing
Distribution
Documentation
Downloader
E-commerce
Editor Plugins and IDEs
Email
Environment Management
Files
Foreign Function Interface
Forms
Functional Programming
Game Development
Geolocation
GUI
Hardware
HTML Manipulation
HTTP
Image Processing
Implementations
Interactive Interpreter
Internationalization
Job Scheduler
Logging
Machine Learning
Miscellaneous
Natural Language Processing
Network Virtualization
Networking
News Feed
ORM
Package Management
Package Repositories
Permissions
Processes
Queue
Recommender Systems
RESTful API
Robotics
RPC Servers
Science
Search
Serialization
Serverless Frameworks
Specific Formats Processing
Static Site Generator
Tagging
Template Engine
Testing
Text Processing
Third-party APIs
URL Manipulation
Video
Web Asset Management
Web Content Extracting
Web Crawling & Web Scraping
Web Frameworks
WebSocket
WSGI Servers


Services

Code Quality
Continuous Integration


Resources

Podcasts
Twitter
Websites
Weekly


Other Awesome Lists
Contributing


Admin Panels
Libraries for administrative interfaces.

ajenti - The admin panel your servers deserve.
django-grappelli - A jazzy skin for the Django Admin-Interface.
django-suit - Alternative Django Admin-Interface (free only for Non-commercial use).
django-xadmin - Drop-in replacement of Django admin comes with lots of goodies.
flask-admin - Simple and extensible administrative interface framework for Flask.
flower - Real-time monitor and web admin for Celery.
wooey - A Django app which creates automatic web UIs for Python scripts.

Algorithms and Design Patterns
Python implementation of algorithms and design patterns.

algorithms - Minimal examples of data structures and algorithms in Python.
PyPattyrn - A simple yet effective library for implementing common design patterns.
python-patterns - A collection of design patterns in Python.
sortedcontainers - Fast, pure-Python implementation of SortedList, SortedDict, and SortedSet types.

Audio
Libraries for manipulating audio and its metadata.

Audio

audioread - Cross-library (GStreamer + Core Audio + MAD + FFmpeg) audio decoding.
dejavu - Audio fingerprinting and recognition.
mingus - An advanced music theory and notation package with MIDI file and playback support.
pyAudioAnalysis - Python Audio Analysis Library: Feature Extraction, Classification, Segmentation and Applications
pydub - Manipulate audio with a simple and easy high level interface.
TimeSide - Open web audio processing framework.


Metadata

beets - A music library manager and MusicBrainz tagger.
eyeD3 - A tool for working with audio files, specifically MP3 files containing ID3 metadata.
mutagen - A Python module to handle audio metadata.
tinytag - A library for reading music meta data of MP3, OGG, FLAC and Wave files.



Authentication
Libraries for implementing authentications schemes.

OAuth

authlib - JavaScript Object Signing and Encryption draft implementation.
django-allauth - Authentication app for Django that ""just works.""
django-oauth-toolkit - OAuth 2 goodies for Django.
oauthlib - A generic and thorough implementation of the OAuth request-signing logic.
python-oauth2 - A fully tested, abstract interface to creating OAuth clients and servers.
python-social-auth - An easy-to-setup social authentication mechanism.


JWT

pyjwt - JSON Web Token implementation in Python.
python-jose - A JOSE implementation in Python.
python-jwt - A module for generating and verifying JSON Web Tokens.



Build Tools
Compile software from source code.

BitBake - A make-like build tool for embedded Linux.
buildout - A build system for creating, assembling and deploying applications from multiple parts.
PlatformIO - A console tool to build code with different development platforms.
pybuilder - A continuous build tool written in pure Python.
SCons - A software construction tool.

Built-in Classes Enhancement
Libraries for enhancing Python built-in classes.

dataclasses - (Python standard library) Data classes.
attrs - Replacement for __init__, __eq__, __repr__, etc. boilerplate in class definitions.
bidict - Efficient, Pythonic bidirectional map data structures and related functionality..
Box - Python dictionaries with advanced dot notation access.
DottedDict - A library that provides a method of accessing lists and dicts with a dotted path notation.

CMS
Content Management Systems.

wagtail - A Django content management system.
django-cms - An Open source enterprise CMS based on the Django.
feincms - One of the most advanced Content Management Systems built on Django.
Kotti - A high-level, Pythonic web application framework built on Pyramid.
mezzanine - A powerful, consistent, and flexible content management platform.
plone - A CMS built on top of the open source application server Zope.
quokka - Flexible, extensible, small CMS powered by Flask and MongoDB.

Caching
Libraries for caching data.

beaker - A WSGI middleware for sessions and caching.
django-cache-machine - Automatic caching and invalidation for Django models.
django-cacheops - A slick ORM cache with automatic granular event-driven invalidation.
dogpile.cache - dogpile.cache is next generation replacement for Beaker made by same authors.
HermesCache - Python caching library with tag-based invalidation and dogpile effect prevention.
pylibmc - A Python wrapper around the libmemcached interface.
python-diskcache - SQLite and file backed cache backend with faster lookups than memcached and redis.

ChatOps Tools
Libraries for chatbot development.

errbot - The easiest and most popular chatbot to implement ChatOps.

Code Analysis
Tools of static analysis, linters and code quality checkers. See: awesome-static-analysis.

Code Analysis

coala - Language independent and easily extendable code analysis application.
code2flow - Turn your Python and JavaScript code into DOT flowcharts.
prospector - A tool to analyse Python code.
pycallgraph - A library that visualises the flow (call graph) of your Python application.


Code Linters

flake8 - A wrapper around pycodestyle, pyflakes and McCabe.
pylint - A fully customizable source code analyzer.
pylama - A code audit tool for Python and JavaScript.
Code Formatters
black - The uncompromising Python code formatter.
yapf - Yet another Python code formatter from Google.


Static Type Checkers

mypy - Check variable types during compile time.
pyre-check - Performant type checking.


Static Type Annotations Generators

MonkeyType - A system for Python that generates static type annotations by collecting runtime types



Command-line Tools
Libraries for building command-line application.

Command-line Application Development

cement - CLI Application Framework for Python.
click - A package for creating beautiful command line interfaces in a composable way.
cliff - A framework for creating command-line programs with multi-level commands.
clint - Python Command-line Application Tools.
docopt - Pythonic command line arguments parser.
python-fire - A library for creating command line interfaces from absolutely any Python object.
python-prompt-toolkit - A library for building powerful interactive command lines.


Terminal Rendering

asciimatics - A package to create full-screen text UIs (from interactive forms to ASCII animations).
bashplotlib - Making basic plots in the terminal.
colorama - Cross-platform colored terminal text.


Productivity Tools

cookiecutter - A command-line utility that creates projects from cookiecutters (project templates).
doitlive - A tool for live presentations in the terminal.
howdoi - Instant coding answers via the command line.
PathPicker - Select files out of bash output.
percol - Adds flavor of interactive selection to the traditional pipe concept on UNIX.
thefuck - Correcting your previous console command.
tmuxp - A tmux session manager.
try - A dead simple CLI to try out python packages - it's never been easier.


CLI Enhancements

httpie - A command line HTTP client, a user-friendly cURL replacement.
kube-shell - An integrated shell for working with the Kubernetes CLI.
mycli - A Terminal Client for MySQL with AutoCompletion and Syntax Highlighting.
pgcli - Postgres CLI with autocompletion and syntax highlighting.
saws - A Supercharged aws-cli.



Compatibility
Libraries for migrating from Python 2 to 3.

python-future - The missing compatibility layer between Python 2 and Python 3.
python-modernize - Modernizes Python code for eventual Python 3 migration.
six - Python 2 and 3 compatibility utilities.

Computer Vision
Libraries for computer vision.

OpenCV - Open Source Computer Vision Library.
pytesseract - Another wrapper for Google Tesseract OCR.
SimpleCV - An open source framework for building computer vision applications.

Concurrency and Parallelism
Libraries for concurrent and parallel execution. See awesome-asyncio.

concurrent.futures - (Python standard library) A high-level interface for asynchronously executing callables.
multiprocessing - (Python standard library) Process-based parallelism.
eventlet - Asynchronous framework with WSGI support.
gevent - A coroutine-based Python networking library that uses greenlet.
uvloop - Ultra fast implementation of asyncio event loop on top of libuv.
scoop - Scalable Concurrent Operations in Python.

Configuration
Libraries for storing and parsing configuration options.

configobj - INI file parser with validation.
configparser - (Python standard library) INI file parser.
profig - Config from multiple formats with value conversion.
python-decouple - Strict separation of settings from code.

Cryptography

cryptography - A package designed to expose cryptographic primitives and recipes to Python developers.
paramiko - A Python (2.6+, 3.3+) implementation of the SSHv2 protocol, providing both client and server functionality.
passlib - Secure password storage/hashing library, very high level.
pynacl - Python binding to the Networking and Cryptography (NaCl) library.

Data Analysis
Libraries for data analyzing.

Blaze - NumPy and Pandas interface to Big Data.
Open Mining - Business Intelligence (BI) in Pandas interface.
Orange - Data mining, data visualization, analysis and machine learning through visual programming or scripts.
Pandas - A library providing high-performance, easy-to-use data structures and data analysis tools.
Optimus - Cleansing, pre-processing, feature engineering, exploratory data analysis and easy Machine Learning with a PySpark backend.

Data Validation
Libraries for validating data. Used for forms in many cases.

Cerberus - A lightweight and extensible data validation library.
colander - Validating and deserializing data obtained via XML, JSON, an HTML form post.
Dash - Built on top of Flask, React and Plotly aimed at analytical web applications.

awesome-dash


jsonschema - An implementation of JSON Schema for Python.
schema - A library for validating Python data structures.
Schematics - Data Structure Validation.
valideer - Lightweight extensible data validation and adaptation library.
voluptuous - A Python data validation library.

Data Visualization
Libraries for visualizing data. See: awesome-javascript.

Altair - Declarative statistical visualization library for Python.
Bokeh - Interactive Web Plotting for Python.
bqplot - Interactive Plotting Library for the Jupyter Notebook
ggplot - Same API as ggplot2 for R.
Matplotlib - A Python 2D plotting library.
Pygal - A Python SVG Charts Creator.
PyGraphviz - Python interface to Graphviz.
PyQtGraph - Interactive and realtime 2D/3D/Image plotting and science/engineering widgets.
Seaborn - Statistical data visualization using Matplotlib.
VisPy - High-performance scientific visualization based on OpenGL.

Database
Databases implemented in Python.

pickleDB - A simple and lightweight key-value store for Python.
tinydb - A tiny, document-oriented database.
ZODB - A native object database for Python. A key-value and object graph database.

Database Drivers
Libraries for connecting and operating databases.

MySQL - awesome-mysql

mysqlclient - MySQL connector with Python 3 support (mysql-python fork).
PyMySQL - A pure Python MySQL driver compatible to mysql-python.


PostgreSQL - awesome-postgres

psycopg2 - The most popular PostgreSQL adapter for Python.
queries - A wrapper of the psycopg2 library for interacting with PostgreSQL.


Other Relational Databases

pymssql - A simple database interface to Microsoft SQL Server.


NoSQL Databases

cassandra-driver - The Python Driver for Apache Cassandra.
happybase - A developer-friendly library for Apache HBase.
kafka-python - The Python client for Apache Kafka.
py2neo - Python wrapper client for Neo4j's restful interface.
pymongo - The official Python client for MongoDB.
redis-py - The Python client for Redis.


Asynchronous Clients

motor - The async Python driver for MongoDB.
Telephus - Twisted based client for Cassandra.
txpostgres - Twisted based asynchronous driver for PostgreSQL.
txRedis - Twisted based client for Redis.



Date and Time
Libraries for working with dates and times.

Chronyk - A Python 3 library for parsing human-written times and dates.
dateutil - Extensions to the standard Python datetime module.
delorean - A library for clearing up the inconvenient truths that arise dealing with datetimes.
moment - A Python library for dealing with dates/times. Inspired by Moment.js.
Pendulum - Python datetimes made easy.
PyTime - A easy-use Python module which aims to operate date/time/datetime by string.
pytz - World timezone definitions, modern and historical. Brings the tz database into Python.
when.py - Providing user-friendly functions to help perform common date and time actions.
maya - Datetimes for Humans, Maya is mostly built around the headaches and use-cases around parsing datetime data from websites.

Debugging Tools
Libraries for debugging code.

pdb-like Debugger

ipdb - IPython-enabled pdb.
pdb++ - Another drop-in replacement for pdb.
pudb - A full-screen, console-based Python debugger.
wdb - An improbable web debugger through WebSockets.


Tracing

lptrace - strace for Python programs.
manhole - Debug service that will accept unix domain socket connections and present the stacktraces for all threads and an interactive prompt.
pyringe - Debugger capable of attaching to and injecting code into Python processes.
python-hunter - A flexible code tracing toolkit.


Profiler

line_profiler - Line-by-line profiling.
memory_profiler - Monitor Memory usage of Python code.
profiling - An interactive Python profiler.
py-spy - A sampling profiler for Python programs. Written in Rust.
pyflame - A ptracing profiler For Python.
vprof - Visual Python profiler.


Others

icecream - Inspect variables, expressions, and program execution with a single, simple function call.
django-debug-toolbar - Display various debug information for Django.
django-devserver - A drop-in replacement for Django's runserver.
flask-debugtoolbar - A port of the django-debug-toolbar to flask.
pyelftools - Parsing and analyzing ELF files and DWARF debugging information.



Deep Learning
Frameworks for Neural Networks and Deep Learning. See: awesome-deep-learning.

caffe - A fast open framework for deep learning..
keras - A high-level neural networks library and capable of running on top of either TensorFlow or Theano.
mxnet - A deep learning framework designed for both efficiency and flexibility.
pytorch - Tensors and Dynamic neural networks in Python with strong GPU acceleration.
SerpentAI - Game agent framework. Use any video game as a deep learning sandbox.
tensorflow - The most popular Deep Learning framework created by Google.
Theano - A library for fast numerical computation.

DevOps Tools
Software and libraries for DevOps.

ansible - A radically simple IT automation platform.
cloudinit - A multi-distribution package that handles early initialization of a cloud instance.
cuisine - Chef-like functionality for Fabric.
docker-compose - Fast, isolated development environments using Docker.
fabric - A simple, Pythonic tool for remote execution and deployment.
fabtools - Tools for writing awesome Fabric files.
honcho - A Python clone of Foreman, for managing Procfile-based applications.
OpenStack - Open source software for building private and public clouds.
pexpect - Controlling interactive programs in a pseudo-terminal like GNU expect.
psutil - A cross-platform process and system utilities module.
saltstack - Infrastructure automation and management system.
supervisor - Supervisor process control system for UNIX.

Distributed Computing
Frameworks and libraries for Distributed Computing.

Batch Processing

PySpark - Apache Spark Python API.
dask - A flexible parallel computing library for analytic computing.
luigi - A module that helps you build complex pipelines of batch jobs.
mrjob - Run MapReduce jobs on Hadoop or Amazon Web Services.
Ray - A system for parallel and distributed Python that unifies the machine learning ecosystem.


Stream Processing

faust - A stream processing library, porting the ideas from Kafka Streams to Python.
streamparse - Run Python code against real-time streams of data via Apache Storm.



Distribution
Libraries to create packaged executables for release distribution.

dh-virtualenv - Build and distribute a virtualenv as a Debian package.
Nuitka - Compile scripts, modules, packages to an executable or extension module.
py2app - Freezes Python scripts (Mac OS X).
py2exe - Freezes Python scripts (Windows).
PyInstaller - Converts Python programs into stand-alone executables (cross-platform).
pynsist - A tool to build Windows installers, installers bundle Python itself.

Documentation
Libraries for generating project documentation.

sphinx - Python Documentation generator.

awesome-sphinxdoc


pdoc - Epydoc replacement to auto generate API documentation for Python libraries.
pycco - The literate-programming-style documentation generator.

Downloader
Libraries for downloading.

s3cmd - A command line tool for managing Amazon S3 and CloudFront.
s4cmd - Super S3 command line tool, good for higher performance.
you-get - A YouTube/Youku/Niconico video downloader written in Python 3.
youtube-dl - A small command-line program to download videos from YouTube.

E-commerce
Frameworks and libraries for e-commerce and payments.

alipay - Unofficial Alipay API for Python.
Cartridge - A shopping cart app built using the Mezzanine.
django-oscar - An open-source e-commerce framework for Django.
django-shop - A Django based shop system.
merchant - A Django app to accept payments from various payment processors.
money - Money class with optional CLDR-backed locale-aware formatting and an extensible currency exchange solution.
python-currencies - Display money format and its filthy currencies.
forex-python - Foreign exchange rates, Bitcoin price index and currency conversion.
saleor - An e-commerce storefront for Django.
shoop - An open source E-Commerce platform based on Django.

Editor Plugins and IDEs

Emacs

elpy - Emacs Python Development Environment.


Sublime Text

anaconda - Anaconda turns your Sublime Text 3 in a full featured Python development IDE.
SublimeJEDI - A Sublime Text plugin to the awesome auto-complete library Jedi.


Vim

jedi-vim - Vim bindings for the Jedi auto-completion library for Python.
python-mode - An all in one plugin for turning Vim into a Python IDE.
YouCompleteMe - Includes Jedi-based completion engine for Python.


Visual Studio

PTVS - Python Tools for Visual Studio.


Visual Studio Code

Python - An extension with rich support for the Python language, with features including linting, IntelliSense, formatting, refactoring, debugging, unit tests, and jupyter support.


IDE

PyCharm - Commercial Python IDE by JetBrains. Has free community edition available.
spyder - Open Source Python IDE.



Email
Libraries for sending and parsing email.

envelopes - Mailing for human beings.
flanker - A email address and Mime parsing library.
imbox - Python IMAP for Humans.
inbox.py - Python SMTP Server for Humans.
lamson - Pythonic SMTP Application Server.
Marrow Mailer - High-performance extensible mail delivery framework.
modoboa - A mail hosting and management platform including a modern and simplified Web UI.
Nylas Sync Engine - Providing a RESTful API on top of a powerful email sync platform.
yagmail - Yet another Gmail/SMTP client.

Environment Management
Libraries for Python version and environment management.

pipenv - Sacred Marriage of Pipfile, Pip, & Virtualenv.
poetry - Python dependency management and packaging made easy.
pyenv - Simple Python version management.
venv - (Python standard library in Python 3.3+) Creating lightweight virtual environments.
virtualenv - A tool to create isolated Python environments.

Files
Libraries for file manipulation and MIME type detection.

mimetypes - (Python standard library) Map filenames to MIME types.
path.py - A module wrapper for os.path.
pathlib - (Python standard library) An cross-platform, object-oriented path library.
PyFilesystem2 - Python's filesystem abstraction layer.
python-magic - A Python interface to the libmagic file type identification library.
Unipath - An object-oriented approach to file/directory operations.
watchdog - API and shell utilities to monitor file system events.

Foreign Function Interface
Libraries for providing foreign function interface.

cffi - Foreign Function Interface for Python calling C code.
ctypes - (Python standard library) Foreign Function Interface for Python calling C code.
PyCUDA - A Python wrapper for Nvidia's CUDA API.
SWIG - Simplified Wrapper and Interface Generator.

Forms
Libraries for working with forms.

Deform - Python HTML form generation library influenced by the formish form generation library.
django-bootstrap3 - Bootstrap 3 integration with Django.
django-bootstrap4 - Bootstrap 4 integration with Django.
django-crispy-forms - A Django app which lets you create beautiful forms in a very elegant and DRY way.
django-remote-forms - A platform independent Django form serializer.
WTForms - A flexible forms validation and rendering library.

Functional Programming
Functional Programming with Python.

Coconut - Coconut is a variant of Python built for simple, elegant, Pythonic functional programming.
CyToolz - Cython implementation of Toolz: High performance functional utilities.
fn.py - Functional programming in Python: implementation of missing features to enjoy FP.
funcy - A fancy and practical functional tools.
Toolz - A collection of functional utilities for iterators, functions, and dictionaries.

GUI
Libraries for working with graphical user interface applications.

curses - Built-in wrapper for ncurses used to create terminal GUI applications.
Eel - Little library for making simple Electron-like offline HTML/JS GUI apps, with full access to Python capabilities and libraries.
enaml - Creating beautiful user-interfaces with Declaratic Syntax like QML.
Flexx - Flexx is a pure Python toolkit for creating GUI's, that uses web technology for its rendering.
Gooey - Turn command line programs into a full GUI application with one line.
kivy - A library for creating NUI applications, running on Windows, Linux, Mac OS X, Android and iOS.
pyglet - A cross-platform windowing and multimedia library for Python.
PyGObject - Python Bindings for GLib/GObject/GIO/GTK+ (GTK+3).
PyQt - Python bindings for the Qt cross-platform application and UI framework, with support for both Qt v4 and Qt v5 frameworks.
PySide - Python bindings for the Qt cross-platform application and UI framework, supporting the Qt v4 framework.
PySimpleGUI - Wrapper for tkinter, Qt, WxPython and Remi that creates a unified, easy to understand & more Python-like interface for beginner and intermediate level custom GUIs.
pywebview - A lightweight cross-platform native wrapper around a webview component that allows to display HTML content in its own native dedicated window.
Tkinter - Tkinter is Python's de-facto standard GUI package.
Toga - A Python native, OS native GUI toolkit.
urwid - A library for creating terminal GUI applications with strong support for widgets, events, rich colors, etc.
wxPython - A blending of the wxWidgets C++ class library with the Python.

Game Development
Awesome game development libraries.

Cocos2d - cocos2d is a framework for building 2D games, demos, and other graphical/interactive applications. It is based on pyglet.
Harfang3D - Python framework for 3D, VR and game development. Manage and display complex 3D scenes, with physics, video, sound and music, access VR devices. All written in C++.
Panda3D - 3D game engine developed by Disney and maintained by Carnegie Mellon's Entertainment Technology Center. Written in C++, completely wrapped in Python.
Pygame - Pygame is a set of Python modules designed for writing games.
PyOgre - Python bindings for the Ogre 3D render engine, can be used for games, simulations, anything 3D.
PyOpenGL - Python ctypes bindings for OpenGL and it's related APIs.
PySDL2 - A ctypes based wrapper for the SDL2 library.
RenPy - A Visual Novel engine.

Geolocation
Libraries for geocoding addresses and working with latitudes and longitudes.

django-countries - A Django app that provides country choices for use with forms, flag icons static files, and a country field for models.
GeoDjango - A world-class geographic web framework.
GeoIP - Python API for MaxMind GeoIP Legacy Database.
geojson - Python bindings and utilities for GeoJSON.
geopy - Python Geocoding Toolbox.
pygeoip - Pure Python GeoIP API.

HTML Manipulation
Libraries for working with HTML and XML.

BeautifulSoup - Providing Pythonic idioms for iterating, searching, and modifying HTML or XML.
bleach - A whitelist-based HTML sanitization and text linkification library.
cssutils - A CSS library for Python.
html5lib - A standards-compliant library for parsing and serializing HTML documents and fragments.
lxml - A very fast, easy-to-use and versatile library for handling HTML and XML.
MarkupSafe - Implements a XML/HTML/XHTML Markup safe string for Python.
pyquery - A jQuery-like library for parsing HTML.
untangle - Converts XML documents to Python objects for easy access.
WeasyPrint - A visual rendering engine for HTML and CSS that can export to PDF.
xmldataset - Simple XML Parsing.
xmltodict - Working with XML feel like you are working with JSON.

HTTP
Libraries for working with HTTP.

grequests - requests + gevent for asynchronous HTTP requests.
httplib2 - Comprehensive HTTP client library.
requests - HTTP Requests for Humansâ¢.
treq - Python requests like API built on top of Twisted's HTTP client.
urllib3 - A HTTP library with thread-safe connection pooling, file post support, sanity friendly.

Hardware
Libraries for programming with hardware.

ino - Command line toolkit for working with Arduino.
keyboard - Hook and simulate global keyboard events on Windows and Linux.
mouse - Hook and simulate global mouse events on Windows and Linux.
Pingo - Pingo provides a uniform API to program devices like the Raspberry Pi, pcDuino, Intel Galileo, etc.
PyUserInput - A module for cross-platform control of the mouse and keyboard.
scapy - A brilliant packet manipulation library.
wifi - A Python library and command line tool for working with WiFi on Linux.

Image Processing
Libraries for manipulating images.

hmap - Image histogram remapping.
imgSeek - A project for searching a collection of images using visual similarity.
nude.py - Nudity detection.
pagan - Retro identicon (Avatar) generation based on input string and hash.
pillow - Pillow is the friendly PIL fork.
pyBarcode - Create barcodes in Python without needing PIL.
pygram - Instagram-like image filters.
python-qrcode - A pure Python QR Code generator.
Quads - Computer art based on quadtrees.
scikit-image - A Python library for (scientific) image processing.
thumbor - A smart imaging service. It enables on-demand crop, re-sizing and flipping of images.
wand - Python bindings for MagickWand, C API for ImageMagick.

Implementations
Implementations of Python.

CLPython - Implementation of the Python programming language written in Common Lisp.
CPython - Default, most widely used implementation of the Python programming language written in C.
Cython - Optimizing Static Compiler for Python. Uses type mixins to compile Python into C or C++ modules resulting in large performance gains
Grumpy - More compiler than interpreter as more powerful CPython2.7 replacement (alpha).
IronPython - Implementation of the Python programming language written in C# targeting the .NET Framework and Mono.
Jython - Implementation of Python programming language written in Java for the Java virtual machine (JVM).
MicroPython - MicroPython - a lean and efficient Python programming language implementation for microcontrollers and constrained systems
Numba - Python JIT compiler to LLVM aimed at scientific Python.
PeachPy - x86-64 assembler embedded in Python. Can be used as inline assembler for Python or as a stand-alone assembler for Windows, Linux, OS X, Native Client and Go.
Pyjion - A JIT for Python based upon CoreCLR.
PyPy - Implementation of the Python programming language written in RPython and translated into C. PyPy focuses on speed, efficiency and compatibility with the original CPython interpreter. The interpreter uses black magic to make Python very fast without having to add in additional type information.
PySec - Hardened version of python that makes it easier for security professionals and developers to write applications more resilient to attacks and manipulations.
Pyston - A Python implementation built using LLVM and modern JIT techniques with the goal of achieving good performance.
Stackless Python - An enhanced version of the Python programming language which allows programmers to reap the benefits of thread-based programming without the performance and complexity problems associated with conventional threads.

Interactive Interpreter
Interactive Python interpreters (REPL).

bpython - A fancy interface to the Python interpreter.
Jupyter Notebook (IPython) - A rich toolkit to help you make the most out of using Python interactively.

awesome-jupyter


ptpython - Advanced Python REPL built on top of the python-prompt-toolkit.

Internationalization
Libraries for working with i18n.

Babel - An internationalization library for Python.
PyICU - A wrapper of International Components for Unicode C++ library (ICU).

Job Scheduler
Libraries for scheduling jobs.

APScheduler - A light but powerful in-process task scheduler that lets you schedule functions.
django-schedule - A calendaring app for Django.
doit - A task runner and build tool.
gunnery - Multipurpose task execution tool for distributed systems with web-based interface.
Joblib - A set of tools to provide lightweight pipelining in Python.
Plan - Writing crontab file in Python like a charm.
schedule - Python job scheduling for humans.
Spiff - A powerful workflow engine implemented in pure Python.
TaskFlow - A Python library that helps to make task execution easy, consistent and reliable.
Airflow - Airflow is a platform to programmatically author, schedule and monitor workflows.

Logging
Libraries for generating and working with logs.

Eliot - Logging for complex & distributed systems.
logbook - Logging replacement for Python.
logging - (Python standard library) Logging facility for Python.
raven - Python client for Sentry, a log/error tracking, crash reporting and aggregation platform for web applications.

Machine Learning
Libraries for Machine Learning. See: awesome-machine-learning.

H2O - Open Source Fast Scalable Machine Learning Platform.
Metrics - Machine learning evaluation metrics.
NuPIC - Numenta Platform for Intelligent Computing.
scikit-learn - The most popular Python library for Machine Learning.
Spark ML - Apache Spark's scalable Machine Learning library.
vowpal_porpoise - A lightweight Python wrapper for Vowpal Wabbit.
xgboost - A scalable, portable, and distributed gradient boosting library.

Microsoft Windows
Python programming on Microsoft Windows.

Python(x,y) - Scientific-applications-oriented Python Distribution based on Qt and Spyder.
pythonlibs - Unofficial Windows binaries for Python extension packages.
PythonNet - Python Integration with the .NET Common Language Runtime (CLR).
PyWin32 - Python Extensions for Windows.
WinPython - Portable development environment for Windows 7/8.

Miscellaneous
Useful libraries or tools that don't fit in the categories above.

blinker - A fast Python in-process signal/event dispatching system.
boltons - A set of pure-Python utilities.
itsdangerous - Various helpers to pass trusted data to untrusted environments.
pluginbase - A simple but flexible plugin system for Python.
tryton - A general purpose business framework.

Natural Language Processing
Libraries for working with human languages.

General

gensim - Topic Modelling for Humans.
langid.py - Stand-alone language identification system.
nltk - A leading platform for building Python programs to work with human language data.
pattern - A web mining module for the Python.
polyglot - Natural language pipeline supporting hundreds of languages.
pytext - A natural language modeling framework based on PyTorch.
PyTorch-NLP - A toolkit enabling rapid deep learning NLP prototyping for research.
spacy - A library for industrial-strength natural language processing in Python and Cython.
stanfordnlp - The Stanford NLP Group's official Python library, supporting 50+ languages.


Chinese

jieba - The most popular Chinese text segmentation library.
pkuseg-python - A toolkit for Chinese word segmentation in various domains.
snownlp - A library for processing Chinese text.
funNLP - A collection of tools and datasets for Chinese NLP.



Network Virtualization
Tools and libraries for Virtual Networking and SDN (Software Defined Networking).

mininet - A popular network emulator and API written in Python.
pox - A Python-based SDN control applications, such as OpenFlow SDN controllers.

Networking
Libraries for networking programming.

asyncio - (Python standard library) Asynchronous I/O, event loop, coroutines and tasks.

awesome-asyncio


pulsar - Event-driven concurrent framework for Python.
pyzmq - A Python wrapper for the ZeroMQ message library.
Twisted - An event-driven networking engine.
napalm - Cross-vendor API to manipulate network devices.

News Feed
Libraries for building user's activities.

django-activity-stream - Generating generic activity streams from the actions on your site.
Stream Framework - Building newsfeed and notification systems using Cassandra and Redis.

ORM
Libraries that implement Object-Relational Mapping or data mapping techniques.

Relational Databases

Django Models - A part of Django.
SQLAlchemy - The Python SQL Toolkit and Object Relational Mapper.

awesome-sqlalchemy


dataset - Store Python dicts in a database - works with SQLite, MySQL, and PostgreSQL.
orator -  The Orator ORM provides a simple yet beautiful ActiveRecord implementation.
peewee - A small, expressive ORM.
pony - ORM that provides a generator-oriented interface to SQL.
pydal - A pure Python Database Abstraction Layer.


NoSQL Databases

hot-redis - Rich Python data types for Redis.
mongoengine - A Python Object-Document-Mapper for working with MongoDB.
PynamoDB - A Pythonic interface for Amazon DynamoDB.
redisco - A Python Library for Simple Models and Containers Persisted in Redis.



Package Management
Libraries for package and dependency management.

pip - The Python package and dependency manager.

PyPI
pip-tools - A set of tools to keep your pinned Python dependencies fresh.


conda - Cross-platform, Python-agnostic binary package manager.

Package Repositories
Local PyPI repository server and proxies.

warehouse - Next generation Python Package Repository (PyPI).
bandersnatch - PyPI mirroring tool provided by Python Packaging Authority (PyPA).
devpi - PyPI server and packaging/testing/release tool.
localshop - Local PyPI server (custom packages and auto-mirroring of pypi).

Permissions
Libraries that allow or deny users access to data or functionality.

django-guardian - Implementation of per object permissions for Django 1.2+
django-rules - A tiny but powerful app providing object-level permissions to Django, without requiring a database.

Processes
Libraries for starting and communicating with OS processes.

delegator.py - Subprocesses for Humansâ¢ 2.0.
sarge - Yet another wrapper for subprocess.
sh - A full-fledged subprocess replacement for Python.

Queue
Libraries for working with event and task queues.

celery - An asynchronous task queue/job queue based on distributed message passing.
huey - Little multi-threaded task queue.
mrq - Mr. Queue - A distributed worker task queue in Python using Redis & gevent.
rq - Simple job queues for Python.

Recommender Systems
Libraries for building recommender systems.

annoy - Approximate Nearest Neighbors in C++/Python optimized for memory usage.
fastFM - A library for Factorization Machines.
implicit - A fast Python implementation of collaborative filtering for implicit datasets.
libffm - A library for Field-aware Factorization Machine (FFM).
lightfm - A Python implementation of a number of popular recommendation algorithms.
spotlight - Deep recommender models using PyTorch.
Surprise - A scikit for building and analyzing recommender systems.
tensorrec - A Recommendation Engine Framework in TensorFlow.

RESTful API
Libraries for developing RESTful APIs.

Django

django-rest-framework - A powerful and flexible toolkit to build web APIs.
django-tastypie - Creating delicious APIs for Django apps.


Flask

eve - REST API framework powered by Flask, MongoDB and good intentions.
flask-api-utils - Taking care of API representation and authentication for Flask.
flask-api - Browsable Web APIs for Flask.
flask-restful - Quickly building REST APIs for Flask.
flask-restless - Generating RESTful APIs for database models defined with SQLAlchemy.


Pyramid

cornice - A RESTful framework for Pyramid.


Framework agnostic

apistar - A smart Web API framework, designed for Python 3.
falcon - A high-performance framework for building cloud APIs and web app backends.
hug - A Python3 framework for cleanly exposing APIs over HTTP and the Command Line with automatic documentation and validation.
restless - Framework agnostic REST framework based on lessons learned from Tastypie.
ripozo - Quickly creating REST/HATEOAS/Hypermedia APIs.
sandman - Automated REST APIs for existing database-driven systems.



Robotics
Libraries for robotics.

PythonRobotics - This is a compilation of various robotics algorithms with visualizations.
rospy - This is a library for ROS (Robot Operating System).

RPC Servers
RPC-compatible servers.

SimpleJSONRPCServer - This library is an implementation of the JSON-RPC specification.
SimpleXMLRPCServer - (Python standard library) Simple XML-RPC server implementation, single-threaded.
zeroRPC - zerorpc is a flexible RPC implementation based on ZeroMQ and MessagePack.

Science
Libraries for scientific computing.

astropy - A community Python library for Astronomy.
bcbio-nextgen - Providing best-practice pipelines for fully automated high throughput sequencing analysis.
bccb - Collection of useful code related to biological analysis.
Biopython - Biopython is a set of freely available tools for biological computation.
cclib - A library for parsing and interpreting the results of computational chemistry packages.
Colour - A colour science package implementing a comprehensive number of colour theory transformations and algorithms.
NetworkX - A high-productivity software for complex networks.
NIPY - A collection of neuroimaging toolkits.
NumPy - A fundamental package for scientific computing with Python.
Open Babel - A chemical toolbox designed to speak the many languages of chemical data.
ObsPy - A Python toolbox for seismology.
PyDy - Short for Python Dynamics, used to assist with workflow in the modeling of dynamic motion.
PyMC - Markov Chain Monte Carlo sampling toolkit.
QuTiP - Quantum Toolbox in Python.
RDKit - Cheminformatics and Machine Learning Software.
SciPy - A Python-based ecosystem of open-source software for mathematics, science, and engineering.
statsmodels - Statistical modeling and econometrics in Python.
SymPy - A Python library for symbolic mathematics.
Zipline - A Pythonic algorithmic trading library.
SimPy -  A process-based discrete-event simulation framework.

Search
Libraries and software for indexing and performing search queries on data.

elasticsearch-py - The official low-level Python client for Elasticsearch.
elasticsearch-dsl-py - The official high-level Python client for Elasticsearch.
django-haystack - Modular search for Django.
pysolr - A lightweight Python wrapper for Apache Solr.
whoosh - A fast, pure Python search engine library.

Serialization
Libraries for serializing complex data types

marshmallow - A lightweight library for converting complex objects to and from simple Python datatypes.
pysimdjson - A Python bindings for simdjson.
python-rapidjson - A Python wrapper around RapidJSON.

Serverless Frameworks
Frameworks for developing serverless Python code.

python-lambda - A toolkit for developing and deploying Python code in AWS Lambda.
Zappa - A tool for deploying WSGI applications on AWS Lambda and API Gateway.

Specific Formats Processing
Libraries for parsing and manipulating specific text formats.

General

tablib - A module for Tabular Datasets in XLS, CSV, JSON, YAML.


Office

openpyxl - A library for reading and writing Excel 2010 xlsx/xlsm/xltx/xltm files.
pyexcel - Providing one API for reading, manipulating and writing csv, ods, xls, xlsx and xlsm files.
python-docx - Reads, queries and modifies Microsoft Word 2007/2008 docx files.
python-pptx - Python library for creating and updating PowerPoint (.pptx) files.
unoconv - Convert between any document format supported by LibreOffice/OpenOffice.
XlsxWriter - A Python module for creating Excel .xlsx files.
xlwings - A BSD-licensed library that makes it easy to call Python from Excel and vice versa.
xlwt / xlrd - Writing and reading data and formatting information from Excel files.


PDF

PDFMiner - A tool for extracting information from PDF documents.
PyPDF2 - A library capable of splitting, merging and transforming PDF pages.
ReportLab - Allowing Rapid creation of rich PDF documents.


Markdown

Mistune - Fastest and full featured pure Python parsers of Markdown.
Python-Markdown - A Python implementation of John Gruberâs Markdown.


YAML

PyYAML - YAML implementations for Python.


CSV

csvkit - Utilities for converting to and working with CSV.


Archive

unp - A command line tool that can unpack archives easily.



Static Site Generator
Static site generator is a software that takes some text + templates as input and produces HTML files on the output.

mkdocs - Markdown friendly documentation generator.
pelican - Static site generator that supports Markdown and reST syntax.
lektor - An easy to use static CMS and blog engine.
nikola - A static website and blog generator.

Tagging
Libraries for tagging items.

django-taggit - Simple tagging for Django.

Template Engine
Libraries and tools for templating and lexing.

Jinja2 - A modern and designer friendly templating language.
Genshi - Python templating toolkit for generation of web-aware output.
Mako - Hyperfast and lightweight templating for the Python platform.

Testing
Libraries for testing codebases and generating test data.

Testing Frameworks

pytest - A mature full-featured Python testing tool.
hypothesis - Hypothesis is an advanced Quickcheck style property based testing library.
nose2 - The successor to nose, based on `unittest2.
Robot Framework - A generic test automation framework.
unittest - (Python standard library) Unit testing framework.


Test Runners

green - A clean, colorful test runner.
mamba - The definitive testing tool for Python. Born under the banner of BDD.
tox - Auto builds and tests distributions in multiple Python versions


GUI / Web Testing

locust - Scalable user load testing tool written in Python.
PyAutoGUI - PyAutoGUI is a cross-platform GUI automation Python module for human beings.
Selenium - Python bindings for Selenium WebDriver.
sixpack - A language-agnostic A/B Testing framework.
splinter - Open source tool for testing web applications.


Mock

doublex - Powerful test doubles framework for Python.
freezegun - Travel through time by mocking the datetime module.
httmock - A mocking library for requests for Python 2.6+ and 3.2+.
httpretty - HTTP request mock tool for Python.
mock - (Python standard library) A mocking and patching library.
Mocket - Socket Mock Framework plus HTTP[S]/asyncio/gevent mocking library with recording/replaying capability.
responses - A utility library for mocking out the requests Python library.
VCR.py - Record and replay HTTP interactions on your tests.


Object Factories

factory_boy - A test fixtures replacement for Python.
mixer - Another fixtures replacement. Supported Django, Flask, SQLAlchemy, Peewee and etc.
model_mommy - Creating random fixtures for testing in Django.


Code Coverage

coverage - Code coverage measurement.


Fake Data

mimesis - is a Python library that help you generate fake data.
fake2db - Fake database generator.
faker - A Python package that generates fake data.
radar - Generate random datetime / time.


Error Handler

FuckIt.py - FuckIt.py uses state-of-the-art technology to make sure your Python code runs whether it has any right to or not.



Text Processing
Libraries for parsing and manipulating plain texts.

General

chardet - Python 2/3 compatible character encoding detector.
difflib - (Python standard library) Helpers for computing deltas.
ftfy - Makes Unicode text less broken and more consistent automagically.
fuzzywuzzy - Fuzzy String Matching.
Levenshtein - Fast computation of Levenshtein distance and string similarity.
pangu.py - Paranoid text spacing.
pyfiglet - An implementation of figlet written in Python.
pypinyin - Convert Chinese hanzi (æ¼¢å­) to pinyin (æ¼é³).
textdistance - Compute distance between sequences. 30+ algorithms, pure python implementation, common interface, optional external libs usage.
unidecode - ASCII transliterations of Unicode text.


Slugify

awesome-slugify - A Python slugify library that can preserve unicode.
python-slugify - A Python slugify library that translates unicode to ASCII.
unicode-slugify - A slugifier that generates unicode slugs with Django as a dependency.


Unique identifiers

hashids - Implementation of hashids in Python.
shortuuid - A generator library for concise, unambiguous and URL-safe UUIDs.


Parser

ply - Implementation of lex and yacc parsing tools for Python.
pygments - A generic syntax highlighter.
pyparsing - A general purpose framework for generating parsers.
python-nameparser - Parsing human names into their individual components.
python-phonenumbers - Parsing, formatting, storing and validating international phone numbers.
python-user-agents - Browser user agent parser.
sqlparse - A non-validating SQL parser.



Third-party APIs
Libraries for accessing third party services APIs. See: List of Python API Wrappers and Libraries.

apache-libcloud - One Python library for all clouds.
boto3 - Python interface to Amazon Web Services.
django-wordpress - WordPress models and views for Django.
facebook-sdk - Facebook Platform Python SDK.
google-api-python-client - Google APIs Client Library for Python.
gspread - Google Spreadsheets Python API.
twython - A Python wrapper for the Twitter API.

URL Manipulation
Libraries for parsing URLs.

furl - A small Python library that makes parsing and manipulating URLs easy.
purl - A simple, immutable URL class with a clean API for interrogation and manipulation.
pyshorteners - A pure Python URL shortening lib.
webargs - A friendly library for parsing HTTP request arguments, with built-in support for popular web frameworks, including Flask, Django, Bottle, Tornado, and Pyramid.

Video
Libraries for manipulating video and GIFs.

moviepy - A module for script-based movie editing with many formats, including animated GIFs.
scikit-video - Video processing routines for SciPy.

WSGI Servers
WSGI-compatible web servers.

bjoern - Asynchronous, very fast and written in C.
gunicorn - Pre-forked, partly written in C.
uWSGI - A project aims at developing a full stack for building hosting services, written in C.
waitress - Multi-threaded, powers Pyramid.
werkzeug - A WSGI utility library for Python that powers Flask and can easily be embedded into your own projects.

Web Asset Management
Tools for managing, compressing and minifying website assets.

django-compressor - Compresses linked and inline JavaScript or CSS into a single cached file.
django-pipeline - An asset packaging library for Django.
django-storages - A collection of custom storage back ends for Django.
fanstatic - Packages, optimizes, and serves static file dependencies as Python packages.
fileconveyor - A daemon to detect and sync files to CDNs, S3 and FTP.
flask-assets - Helps you integrate webassets into your Flask app.
webassets - Bundles, optimizes, and manages unique cache-busting URLs for static resources.

Web Content Extracting
Libraries for extracting web contents.

html2text - Convert HTML to Markdown-formatted text.
lassie - Web Content Retrieval for Humans.
micawber - A small library for extracting rich content from URLs.
newspaper - News extraction, article extraction and content curation in Python.
python-readability - Fast Python port of arc90's readability tool.
requests-html - Pythonic HTML Parsing for Humans.
sumy - A module for automatic summarization of text documents and HTML pages.
textract - Extract text from any document, Word, PowerPoint, PDFs, etc.
toapi - Every web site provides APIs.

Web Crawling & Web Scraping
Libraries to automate data extraction from websites.

cola - A distributed crawling framework.
feedparser - Universal feed parser.
grab - Site scraping framework.
MechanicalSoup - A Python library for automating interaction with websites.
portia - Visual scraping for Scrapy.
pyspider - A powerful spider system.
robobrowser - A simple, Pythonic library for browsing the web without a standalone web browser.
scrapy - A fast high-level screen scraping and web crawling framework.

Web Frameworks
Full stack web frameworks.

Django - The most popular web framework in Python.

awesome-django


Flask - A microframework for Python.

awesome-flask


Pyramid - A small, fast, down-to-earth, open source Python web framework.

awesome-pyramid


Sanic - Web server that's written to go fast.
Vibora - Fast, efficient and asynchronous Web framework inspired by Flask.
Tornado - A Web framework and asynchronous networking library.

WebSocket
Libraries for working with WebSocket.

autobahn-python - WebSocket & WAMP for Python on Twisted and asyncio.
crossbar - Open-source Unified Application Router (Websocket & WAMP for Python on Autobahn).
django-channels - Developer-friendly asynchrony for Django.
django-socketio - WebSockets for Django.
WebSocket-for-Python - WebSocket client and server library for Python 2 and 3 as well as PyPy.

Services
Online tools and APIs to simplify development.
Continuous Integration
See: awesome-CIandCD.

CircleCI - A CI service that can run very fast parallel testing. (GitHub only)
Travis CI - A popular CI service for your open source and private projects. (GitHub only)
Vexor CI - A continuous integration tool for private apps with pay-per-minute billing model.
Wercker - A Docker-based platform for building and deploying applications and microservices.

Code Quality

Codacy - Automated Code Review to ship better code, faster.
Codecov - Code coverage dashboard.
CodeFactor - Automated Code Review for Git.
Landscape - Hosted continuous Python code metrics.

Resources
Where to discover new Python libraries.
Podcasts

From Python Import Podcast
Podcast.init
Python Bytes
Python Testing
Radio Free Python
Talk Python To Me

Twitter

@codetengu
@getpy
@importpython
@planetpython
@pycoders
@pypi
@pythontrending
@PythonWeekly
@TalkPython
@realpython

Websites

/r/CoolGithubProjects
/r/Python
Awesome Python @LibHunt
Django Packages
Full Stack Python
PyPI Ranking
Python 3 Wall of Superpowers
Python Hackers
Python ZEEF
Python å¼åç¤¾åº
Real Python
Trending Python repositories on GitHub today

Weekly

CodeTengu Weekly ç¢¼å¤©çé±å
Import Python Newsletter
Pycoder's Weekly
Python Weekly
Python Tricks

Contributing
Your contributions are always welcome! Please take a look at the contribution guidelines first.
I will keep some pull requests open if I'm not sure whether those libraries are awesome, you could vote for them by adding ð to them. Pull requests will be merged when their votes reach 20.

If you have any question about this opinionated list, do not hesitate to contact me @vinta on Twitter or open an issue on GitHub.
",67185
X-CASH-official/XCASH_proof_of_stake_consensus_node,C,"X-CASH Proof of stake - consensus node
More details will be released on the consensus node soon!
Installation
This program will only run on a Linux/Unix OS at this time. We recommend installing this on a Ubuntu VPS/Server (16.04 or 18.04) for the best compatibility.
You will also need to run an X-CASH Daemon and X-CASH RPC wallet on the server. You can either download the latest X-CASH release or build from source
Compiling X-CASH Proof of stake - consensus node from source
Dependencies
The following table summarizes the tools and libraries required to build.



Dependencies
Min. version
Ubuntu package




GCC
4.7.3
build-essential


CMake
3.0.0
cmake


pkg-config
any
pkg-config


OpenSSL
any
libssl-dev


Git
any
git


MongoDB
4.0.3
install from binaries


MongoDB C Driver (includes BSON libary)
1.13.1
build from source



Installing MongoDB from binaries
Visit https://www.mongodb.com/download-center/community
Then choose your OS, and make sure the version is the current version and the package is server. Then click on All version binaries. Now find the current version to download. You do not want the debug symbols or the rc version, just the regular current version.
Once you have downloaded the file move the file to a location where you want to keep the binaries, then run this set of commands
tar -xf mongodb-linux-x86_64-*.tgz && rm mongodb-linux-x86_64-*.tgz && sudo mkdir -p /data/db && sudo chmod 770 /data/db && sudo chown $USER /data/db
Building the MongoDB C driver from source
Visit the offical websites installation instructions at http://mongoc.org/libmongoc/current/installing.html
You will need to follow the instructions for Building from a release tarball or Building from git since you need the header files, not just the library files.
After you have built the MongoDB C driver from source, you will need to run
sudo ldconfig
Adding MongoDB to your PATH
You will probably want to add MongoDB to your path so you can run MonogDB by typing mongod at any terminal.
To add MongoDB to your PATH (replace ""MongoDB_folder"" with the location of the bin folder in the folder you installed MongoDB in
echo -e '\nexport PATH=MongoDB_folder:$PATH' >> ~/.profile && source ~/.profile
Cloning the repository
$ git clone https://github.com/X-CASH-official/XCASH_proof_of_stake_consensus_node.git
Build instructions
X-CASH Proof of stake - consensus node uses a Make file.
After cloning the repository, navigate to the folder
cd XCASH_proof_of_stake_consensus_node
Then use the make file to build the binary file
make clean ; make
Running MongoDB
To run MongoDB you will need to navigate to the folder you downloaded the binaries to, and in the bin folder run mongod by running
./mongod
If you have already added MongoDB to your path, you can just type in any terminal
mongod
Setting up the xcashd and xcash-wallet-RPC
First you will need to run xcashd in the background. Navigate to the folder that contains the xcash binaries, then run
./xcashd
Next you need to run a xcash-wallet-rpc. Depending on if this is the consensus node or the consensus backup node, you will need to the run the wallet that contains the public address in the Proof of stake for the CONSENSUS_NODE_PUBLIC_ADDRESS or CONSENSUS_BACKUP_NODE_PUBLIC_ADDRESS
To run the rpc wallet you can run
./xcash-wallet-rpc --wallet-file NAME_OF_WALLET_FILE --password WALLET_FILE_PASSWORD --rpc-bind-port 18285 --confirm-external-bind --daemon-port 18281 --disable-rpc-login --trusted-daemon
Just replace NAME_OF_WALLET_FILE with the name of your wallet file and WALLET_FILE_PASSWORD with the password of that wallet file. Make sure to use port 18285 as this is the port that is used in the program.
We suggest you use the screen command to run the program in the background, this way you can still maintenance the server. To do this run
screen -dmS Daemon ./xcashd
You can also run the RPC wallet this way as well
screen -dmS RPC-Wallet ./xcash-wallet-rpc --wallet-file NAME_OF_WALLET_FILE --password WALLET_FILE_PASSWORD --rpc-bind-port 18285 --confirm-external-bind --daemon-port 18281 --disable-rpc-login --trusted-daemon
To bring the screen from the bacground process to the active process run
screen -x NAME_OF_BACKGROUNDS_SCREEN
Where NAME_OF_BACKGROUNDS_SCREEN would be Daemon or RPC-Wallet in the above examples.
To exit a screen if it is the active process, you can press Control + C. To exit a screen that is a background process you can run
screen -XS NAME_OF_BACKGROUNDS_SCREEN quit
Running X-CASH Proof of stake - consensus node test
It is recomeneded to run the X-CASH Proof of stake test before you run the main program. The test will ensure that your system is compatbile, and that you have setup your system correctly.
To run the X-CASH Proof of stake test, Navigate to the folder that contains the binary, then run
./xcash_proof_of_stake_consensus_node --test
The test will return the number of passed and failed test on the bottom of the console. The failed test need to be 0 before you run the node. If the output is not showing 0 for failed test, then you need to scroll through the testing output and find what test failed (It will be red instead of green). If this is a system compatibility test, then you will need to fix the system. If this is a core test that has failed, then you need to possibly rebuild, or contact us with your OS version, and we can look into it.
Running X-CASH Proof of stake - consensus node
Then you will need to run the xcash_proof_of_stake_consensus_node. Navigate to the folder that contains the binary, then run
./xcash_proof_of_stake_consensus_node
We suggest you use the screen command to run the program in the background, this way you can still maintenance the server. To do this run
screen -dmS xcash_proof_of_stake_consensus_node ./xcash_proof_of_stake_consensus_node
To bring the screen from the bacground process to the active process run
screen -x NAME_OF_BACKGROUNDS_SCREEN
Where NAME_OF_BACKGROUNDS_SCREEN would be xcash_proof_of_stake_consensus_node in the above example.
To exit a screen if it is the active process, you can press Control + C. To exit a screen that is a background process you can run
screen -XS NAME_OF_BACKGROUNDS_SCREEN quit
",2
AngelKitty/review_the_national_post-graduate_entrance_examination,C++,"å¤ä¹ èç çé£äºäºå¿ï½ï½
è¿éæå°è®°å½æèç çå¨è¿ç¨ï¼åæ¬çè¿çä¹¦ï¼åè¿çç¬è®°ï¼è¯»è¿çæå¿ï¼æ¨èççªå§ï¼çµå½±ï¼ä»¥åæå¨çæ´»ä¸­ä¸äºé¶ç¢çè®°å½åæèã
ä¹è®¸è¿ä¸åå¯¹ä½ ä»¬å¯è½ä¸æ æ¯å¤ï¼ä½å¯¹æèè¨ï¼è¿å°ä¼æ¯äººçä¸­æå®è´µçä¸æ®µåå¿ï¼æå¸æä»¥è¿ç§æ¹å¼è®°å½ä¸æ¥ï¼æä»¥å¨ Github ä¸å¼äºæ­¤é¡¹ç®ã
ç½ä¸å¾å¤upä¸»é½åæ¬¢éè¿ææ vlog è¿ç§å½¢å¼æ¥è®°å½èªå·±çæ¥å¸¸ï¼æå°±çªåå¥æ³ï¼è½ä¸è½å¨è¿ä¸ªè¯åºç¡ä¸ç¨å¾®ä¿®æ¹ä¸ä¸ãäºæ¯æå°±æ³å°äºä¸ä¸ªéå¸¸ nice çè¯ï¼èªå·±åä¸ä¸ªåå« plog (Page weblogï¼plogä¼¼ä¹æä»£çææå¾å¤ï¼ä½æ¯å¤§å¤é½æ¯åæ¥å¿ç³»ç»æå³å§ï¼æä»¥æè¿ä¸ªç¿»è¯åºè¯¥ä¸ç®å¾åé¨å§23333)
å½ç¶ä¹æ¬¢è¿ä½ ä»¬å å¥å°æä»¬çå¤ä¹ éä¼ä¸­ï¼æå¥½çççµå½±ãçªå§æ¨èæèä¸äºæææçä¹¦ç±ï¼è¯· fork æ¬é¡¹ç®å°æ¨çä»åºåï¼åè¿è¡ pull requestã
æ¬é¡¹ç®åä¸ºå¦ä¸ä¸ä¸ªé¨åï¼

books_and_notesï¼å­æ¾çæå¤ä¹ æ¶åçè¿çä¹¦ä»¥åç¬è®°
examï¼ä¸äºæå¤ä¹ çæ¶ååè¿çä¸äºé¢ç®
plogï¼è®°å½çææ¯å¨çä¸äºæ¥å¸¸ã

å¦ä½è·åæ­¤é¡¹ç®ï¼
æ¬é¡¹ç®å¯ä»¥ç´æ¥éè¿ä»¥ä¸æ¹å¼è·åï¼
# clone
git clone git@github.com:AngelKitty/review_the_national_post-graduate_entrance_examination.git

çæå£°æ

æ¬ä½åéç¨ç¥è¯å±äº«ç½²å-éåä¸æ§ä½¿ç¨-ç¸åæ¹å¼å±äº« 4.0 å½éè®¸å¯åè®®è¿è¡è®¸å¯ã
The Star And Thank Author License
",25
owlboy/greatpug-public,None,"
The Great Pug
A Bar in the Metaverse (VRChat)
thegreatpug.com
This Repository
This repository is the public sister repository to the private repository for The Great Pug.
Bug Reports and Feature Requests
Feel free to use the issues feature of this repository to report bugs or make feature requests relating to The Great Pug.
Support On-going Development
You can support on-going maintenance, events, and expansion to The Great Pug by joining my Patreon.
You can also donate crypto currency at the following addresses:

Etherium (ETH): 0xa2e7aBB300728afc7564874B12975D2f311687a6
Bitcoin (BTC): 16tWrVpZWJcw64aE5su8bRQJgyAVhBeNZQ
Litecoin (LTC): MCjYc1wm2r1f8uM5FPTyqZbKxnxwvNf7UQ

 
Change Log
5/11/19 (65mb)

Reduced draw called depending on your POV
Simplified some colliders
Rebaked lighting
Rebaked Occlusion
Fixed UV unwraps on some models
Adjusted some audio clip sizes

5/10/19 (71mb)

Reduced Draw Calls by a few depending on your POV
Updated calendar (10 days late!)
Rebaked lighting
Reduced material count by a few
Fixed a few incorrect materials
Safety and Security fixes

5/02/19 (69.82mb)

Removed 33.78mb from the build(!!!) (Huge thanks to TCL!)
Fixed an incorrect texture on the light over the notice board #18 (Thanks @HugoZink!)
Disabled the live audio player temporarily

04/27/19 (103.6 mb)

Fixed inconsistent and broken Pickup Respawners
Fixed the Pillows in The Roost
Fixed UV1 on meshes above main bar

04/24/19 (103.6 mb)

Possibly removed extranious refrences to unused objects
Adjusted texture sizes
Adjusted texture filtering to be trilinear on almost all textures
Removed extrainous material slots on some meshes
Removed extrainous some extrainous geometry
Rebaked Occlusion
Power Water and Kirito are back from holiday
(Also did lots of Quest work)

04/10/19 (104.98 mb)

Reduced overdraw on walls in main bar
Reduced overdraw on winndows in main bar
Updated the calendar (10 days late!)
Removed a few extranious materials

03/27/19 (106.89 mb)

Fixed the milky water (Thanks Meme_man!)
Fixed the Desaturated White Russian (Thanks Meme_man!)
Added photos from Saint Patrick's at The Pug 2019
Fixed texture on the lamp in The Roost

03/21/19 (106.78 mb)

Updated lamp and fixture emissive maps
Rebaked lighting
Rebaked Occlusion
Added bells to each floor

03/19/19 (106.52 mb)

Adjusted lighting down a bit in the main bar
Tweaked The Bucket
Adjusted PPV transition falloff for the kitchen coolers
Adjusted compression on some textures
Fixed the high gloss on the banners

03/18/19 (106.26 mb)

Took down the decorations
Updated lighting in many areas
Improved lightmap UVs on booth backs
Improved overdraw in the bathrooms

03/16/19 (108.52 mb) (444)

Saint Patrick's at The Pug 2019!
Thanks to Polopo for the help getting the Leprachaun avatar optimized!
Thanks to Zarniwoop and ShutUpSargent for suggesting hidden Leprecauns!

03/05/19 (105.32 mb)

Fixed the seat toggle for the chairs near the corner booth on the first floor (Thanks Zarniwoop!)
Turned off dithering in the material shaders. Dithering is still applied by the Post Processing Stack (Thanks Poplopo, HugoZink!)
Fixed an incompatibility between the liquid shader and an upcoming patch (Thanks TCL!)
Fixed the fireplace chimney being visible through the window in The Roost
Fixed the visible floating square in the sky
Fixed a gap behind the fireplace
Updated Calendar (5 days late!)
Put up Saint Patrickâs Day promotional decorations

02/21/19 (106.01 mb)

Fixed stage mic not respawning
Fixed misaligned collider near the lamp in The Roost
Rebaked lighting in the main hallway
Updated Patron flyers

02/15/19 (105.61 mb)

Stoves are ready for Udon ð
Updated Patron flyers

01/31/19 (104.5 mb)

Fixed the Night View bar lock
Updated Lightmaps on various objects in The Roost
Updated wood grain on various objects in The Roost
Fixed Z-Fighting on the table behind the couch in The Roost
Fixed Z-Fighting on Night View bar
Fixed low resolution texture on the sword in The Roost
Updated Light Probes in the main bar to be more consistent
Updated calendar (one day early!)
SDK Bump: VRCSDK-2018.12.19.17.03_Public

01/16/19 (103mb)

Rebaked Lighting
Updated Patron flyers
Updated Specular proxy objects

01/03/19 (103mb)

Adjustments to the live audio setup
Adjustments to textures and meshes to reduces the download size a bit
Fixes to reflection probes (Thanks Zarniwoop!)
Fixed house music

01/02/19 (107mb)

Took down holiday decorations
Adjusted bloom a bit
Fixed texture on the solo stool in The Roost
Adjusted collision on the stage edge

12/31/18 (113mb)

New Years decorations and Music

(Thanks CubedParadox for lending me your Record Player!)
(Radio Soulwax - Under the Covers)


Clamped bloom more aggressively
Drywall is now uniformly scaled and oriented
Updated the calendar
Misc fixes

12/28/18 (107mb)

Fixed the missing colliders in the women's bathroom (Thanks @SplitScream#8411!)
Removed the invisible collider in the first-floor hallway (Thanks @Sheppard#1998!)
Fixed missing collider along the doorway to the back stairs (Thanks @Sheppard#1998!)
Implemented a new ""lightmap method"" on some objects. Notably the bar in Night View.
Fixed hole in the ceiling near the kitchen door
Fixed floating baseboard in the back staircase
Improved lightmaps on various objects
Added a new lamp!
Padded the seat backs on the chairs in Night View (The Roost will follow later)
Rounded the Globes on the tables in Night View
Brightened up Night View a bit
Repainted the ceiling in Night View
Updated stools in the main bar so they can hold pickups
Misc fixes
Switched to Post Processing Stack v2

Flashing light from broken geometry should no longer happen
Bloom is clamped to prevent malicious emission values
Testing Post Processing Volumes with the kitchen coolers
Testing auto-exposure



12/24/18 (106mb)

Finished the refactor on the corner booth and near by booths
Fixed wood grain on the trim of the lower landing of the stairs to Night View
Added wood trim along the red wall on the first run of stairs to Night View
Added baseboard to wall near the main bar mirror
Added tiles to the walls that were missing them in the bathrooms
Improved light maps on many meshes
Cleaned up the geometry of some meshes

12/23/18 (108mb)

The Yule Goat has risen! ð
Fixed the floor from the hallway sticking into the womens bathroom

12/20/18 (105mb)

Refactored parts of the booths around the corner booth on the first floor to fix lightmapping and lower draw calls
Lowered the intensity of the specular light proxy objects (Thanks Korro Bravin!)
Adjusted the live stream audio sources
Fixed hazy materials on some objects

12/19/18 (105mb)

Tweaked reflection probles
Tweaked specular on many objects
Improved normals on beer taps
Improved normals on trash taps
Improved fake mirrors in light of the new specular profile
Improved light mapping on various small objects
Reduced download size a bit

12/18/18 (109mb)

Added a few more holiday decorations
Added a new sculpture to The Roost (Thanks Poplopo!)
Fixed dark table tops
Fixed lightmapping throughout The Pug
Improved specular response throughout The Pug. - Still needs tweaking (Thanks SeraRealm!)

12/12/18 (93mb)

Rebaked lightmap - fixed many issues/errors from the 5.6-2017.4 upgrade
Restored holiday banners

12/11/18 (91mb)

Fixed regressions (Reapplied the last update)
Updated patron flyers
Added a few holiday decorations to Night View and The Roost
Added new textures for the red phone
SDK Bump: 2018.12.04.10.25
Engine Bump: 2017.4.15f1

12/07/18 (92mb) - Final FIVE SIX update

Updated the Calendar (7 days late!)
Updated Patron flyers
Fixed the floor in Night View (Thanks laugexd!) [ Issue #10 ]
Started decorating for the holidays
Rebaked Occlusion

11/15/18

Unity 2017 shenanigans.

11/09/18 (96mb)

Adjusted a broken trigger in the Mr. Whiskers Puzzle to hopefully fix it (Thanks Naelstof)
Tweaked live stream playback component
Added a toggle to disable interaction with seats in The Roost
Adjusted some seats in The Roost so they are a bit easier to interact with for desktop users
Fixed missing seats on side couch in The Roost
Updated various materials
Rebaked Occlusion

11/08/18 (97mb)

Added a toggle to disable interaction with seats in the main bar - it is in the back room
Fixed ObjectRespawners on some more objects, including the Pillows in The Roost - Caused by this bug: http://bit.ly/vrc-teleportTo-hierarchy
Fixed missing Corner Booth seat stations
Fixed offset seat stations on stools near the bar mirror (Thanks Zarniwoop!)
Updated some parts of the Mr. Whiskers puzzle to use Custom Triggers
Shined up the booth table legs
Reduced drawcalls by 1 or 2

11/06/18 (98mb)

Fixed ObjectRespawners - Caused by this bug: http://bit.ly/vrc-teleportTo-hierarchy
Fixed Mr. Whiskers Puzzle - Caused by this bug: http://bit.ly/vrc-teleportTo-hierarchy
Fixed unsightly seams on the new booth models
Fixed a missing booth barrier in the Bar mirror (thanks Sheppard#1998!)
Fixed some lightmap issues on the Night View Bar (more need fixing)
Fixed some lightmap issues with the stools on the first floor
Fixed light leaks near the ceiling on the stairs to The Roost
Fixed light leak from the back staircase into the back hallway
Fixed tall baseboard along the tall windows in Night View - you can't walk on it anymore.
Fixed the taps, they were still hooked up to the Halloween kegs
Fixed disappearing White Russian liquid
Improved framing on Halloween 2018 Photo
Removed a draw call or two in Night View
Updated drink menu models
Updated textures the on the ceiling vents
Updated Patron flyers
Rebaked Occlusion
SDK Bump: 2018.11.05.17.42

11/02/18 (102mb)

Reduced a couple more draw calls throughout the map
Rebuilt the meshes for the booths near the mirror on the first floor
Updated all of the drywall materials
Improved colliders near corner stool on the first floor
Improved colliders along the base of the tall windows in Night View
Improved lightmap on the stairs to The Roost (Dark upper border should be gone)
Fixed missing light near the back exit
Added a group photo from Halloween at The Pug 2018 to the wall on the stairs
Readded tags: bar, stage, hangout, social, classic

11/01/18 - 2 (97mb)

Reduced draw calls on various objects around the main bar a bit.
Updated fishbowl water - hopefully fixing the flickering.
Rebaked occlusion
Removed a few stray Halloween remnants
Added tags: bar, stage, hangout, social, classic
SDK Bump: 2018.10.31.10.45

11/01/18 (96mb)

Removed Halloween Decor
Updated calendar
Updated patron flyers
Trigger adjustments to the Mr. Whiskers puzzle

10/27/18 (102mb)

ð Halloween at The Pug 2018

10/17/18 (90mb)

Adjusted liquid shaders some more
Fixed the missing colors from the red/blue/green pints (Thanks Hystericmikey!)
Removed additional superflus objects and materials

10/16/18 (90mb)

Reduced draw calls by 0-4 in main bar area and stage area
Fixed sorting issues with liquid and glass (Hopefully)
Fixed the shifted fireplace light
Removed some un-needed disabled objects

10/15/18 (90mb)

Updated Patron flyers
Updated liquid shader
Updated the glass material on the clocks

10/10/18 (91mb)

Adjusted the liquid shader (hopefully the weird refraction rendering is gone)
Removed a draw call on the rose in The Roost
Fixed a seat on the fireplace couch in The Roost that had a very long interaction distance (Thanks Pan Diman!)
Fixed the oversized interaction boxes on the fireplace couch in The Roost
Adjusted the glass on the mirrors
Removed a draw call on the clocks

10/09/18 (90mb)

Fixed the performance issue with the new glass shader (Thanks CubedParadox!)
Added table tents

10/08/18

New glass shader (Thanks CubedParadox!)
Banners for the Halloween Party are up

10/03/18 (350) (89mb)

Updated the SDK - VRCSDK-2018.10.02.10.29_Public
Updated the Calendar (3 days late)
Fixed some occlusion errors
Patron poster updates

09/20/18 (88mb)

Fixed a Patron poster
Fixed eject buttons in the bar (Thanks Meme Man!)
Fixed a phone receiver that was made of cloth
Fixed some reflection probe placements
Rebaked lighting

09/19/18 (88mb)

Adjusted some light probe placements
Updated/fixed respawn timers on a few objects
Updated Patron posters
Deleted some extranious objects that I found hiding in nooks and crannies

09/18/18 (87mb)

Cleaned the darkness off the Orchid on the welcome desk
Worked around a bug with onTimer triggers (hopefully)
Fixed weird geometry on the main staircase
Improved wood grain direction on the main staircase
Improved lightmap on walls on the main staircase
Improved wood grain direction on the sleeping platform in The Roost
Rounded up the plates
Patched some holes in The Roost ceiling (again)
Solidified the top of the stools in Night View (Thanks Poplopo!)
Removed a weird onInteract trigger near the entrance (Thanks Meme Man!)
Removed some errant animations on the Yellow Spotlight on the Stage
Updated Patron posters
Minor fixes

09/13/18 (86mb)

Updated patron posters
Added steamer pans
Minor fixes

09/9/18 (86mb)

Fixed weirdly shiny materials on main staircase and stage
Fixed leaky faucets in the men's bathroom
Fixed the issue with the sinks being missing in the bathroom mirrors
Added a lot more brushed steel in the kitchen

09/7/18 (85mb)

Loaded up a new Calendar (7 days late)
Sanded down the bathroom sinks to round them out, then re-polished them
Fixed the issue with the Whiskey being a vampire (Thanks Exiled!)
Fixed the issue with teleporting booth seats (Thanks Jordo!) [ Issue #8 ]
Fixed the issue with the missing wall collider near the bar mirror (Thanks Misaki and others!)
Updated TheArchitects poster - He does more than homeworlds now!

08/31/18 (89mb)

Added a new bottle label for Presence
Updates to stage controls for performers
Tweaked the tap triggers to be less square
Rebaked occlusion to fix up the stage
Tweaked toilet sounds so they should be audible again

08/30/18 (89mb)

Moved stage speakers off the stage and added monitors fulfilling Issue #3
Fixed the missing animation on the toilet water
Updated toilet and tap timers to (hopefully) work around a current bug with timers
Reduced range of toilet flush sound (hopefully)
Updated models and materials on stage equipment to reduce the draw calls a bit
Updated the live performer controls
Updated the meshes/materials on ceiling lights in Night View to reduce the draw calls a bit

08/29/18 (89mb)

Peformed some plumbing; The toilets may or may not ""work"" now
Hooked up the beer taps in the Night View bar
Added timers to the beer taps so they turn off after being left on - they were wasting so much beer!
Took down the open sign for Night View (it's always open these days!)
Adjusted the basement door so it is more logical when open, and when being handled
Adjusted lights near the main staircase and first-floor hallway entrance
Fixed the issue causing a teleport if you walked under the back stairs on the first floor (Thanks Exiled!)
Fixed texture tiling on toilets
Fixed more descended canister lights
Adjusted draw calls a tiny bit in the main bar area
Adjusted they way some sound effects play
Restored the MIP Maps on the posters

This exists now: The Great Pug - Steam Group
08/28/18 (91mb)

Made refinements to the Night View shelving meshes
Made refinements to the lightmap on the Night View bar
Made the main staircase a bit brighter at the first-floor landing (Thanks Exiled!)
Fixed the light canisters that were descending on the main staircase (Thanks Garret!)
Updated the Security Colliders; they should be a little more forgiving now (Thanks Korro!)

08/24/18 (91mb)

Fixed the flickering doors in the buffet in The Roost
Updated the textures on the clock and banners
Tweaked some baked lights
Made some minor draw call optimizations
Other minor tweaks

08/23/18 (91mb)

Removed some legacy VRC Chair scripts I found hiding around the map
Minor tweaks

08/22/18 (91mb)

That missing door frame returned home and apologized. It just needed some time away from all the people.
Re-jiggered texture compression on some things
Re-jiggered audio compression on some things
Made adjustments to the lighting
Further adjusted the Post Processing stack
A very Rigid Body was found in The Roost and removed.

08/21/18 (100mb)

Bloomified the fire in The Roost for a more cozy glow
Added a new menu model â more to come down the road here
Material adjustments
More draw call optimizations in the main bar area; 5-10 draw calls depending on the direction you are looking
Patched up the hole in the ceiling near the kitchen door

08/20/18 (97mb)

Fixed Basement occlusion issues
Fixed collider sticking into the main bar from the basement
More draw call optimizations in the main bar area; 1-12 draw calls depending on the direction you are looking
Adjusted the post-processing stack
Minor collider adjustments
The Devil Bucket should be easier to pick up now

08/18/18 (99mb)

Refactored the basement meshes

08/17/18 (99mb)

Fixed collider above the table behind the couch in The Roost
The VRCHAT ARCHIVES advert has gotten a bit dirty in the past year and a half. (Thanks Zarniwoop!)
Material updates
More materials are now using the Dithering Shader

08/16/18 (100mb)

Fixes/Adjustments for the live show audio
Adjustments to shadow casters in The Roost and on the stage
At least 1 draw call removed.

08/12/18

Fixed the missing/shifted colliders on the upstairs bar
Fixed the missing colliders on the downstairs bar cooler
Adjusted the Dithering Shader a bit

08/11/18

Updated the Dithering Shader to v.1.calm.0.0.pseudology.1534016371.7
Many wood materials updated
Bloom is back to its previous level
Light Probes should no longer bleed out of the cooler into the back stairway as easily
Fixed weird light fixture placements throughout the first floor
LOD adjustments for various signs
Fire extinguishers should no longer be inside the wall
Bar Two has slightly better UV unwrapping now
Reflection Probes adjusted down
Removed 3 draw calls from the bar cooler.

08/08/18

THE BELL WORKS AGAIN!
Fixed issues with the beta Dithering Shader by Xiexe (Thanks TCL!)
Fixed the weird sheen on the First Dollar plaque (Thanks Exiled!)
Shaved 1-2 draw calls off of a couple items
Fixed the weird ceilings in The Roost staircase
Fixed light baking issues in a few places
Fixed the ghost chairs by the Corner Booth on the first floor
Fixed the floor material in the bathrooms
Removed references to non-existent chair placement scripts by CubedParadox (Thanks Cubed!)

08/07/18

Calendar Update (7 days late)
Many shaders changed to a beta version of a Dithering Shader by Xiexe (Thanks Xiexe!)
Shaved 1-2 draw calls off stage props

07/27/18

Additions to the live streaming audio support
Minor fixes

07/19/18

SDK Bump - 2018.06.21.13.02
Added experimental live streaming audio support
Made some Minor LOD tweaks

07/03/18 (314)

LOD Tweaks
Reflection Probe fixes
Metalic tables fixed

07/02/18 (312)

Collider blocking stairs fixed

06/29/18 (311)

Bell should be fixed
Lightmap fixes
Gap below short wall at the top of the roost stairs fixed
New Brushed Metal material
Minor optimizations
LOD setup on many items, we will see how that goes.
Collision changes
Reflection probe adjustments

06/29/18 (310) (110mb)

Implemented minor draw call optimizations
Updated lightmaps on back hallway, no more light leaks near the exit sign
Greatly reduced lightmap artifacts on main stairs leading to Night View
Overall lightmap filesize dropped

06/28/18 (308) (116mb)

Implemented additional minor draw call optimizations
Updated the wine bottle labels
Reflection probe resolution changes to reduce download size

06/22/18 (307) (122mb)

Texture resolution increases
Texture compresion changes
Reduced overall download size by 6mb

06/08/18 (306)

Made draw call optimizations
Added missing baseboards in Night View
Reflection Probe Adjustments
Stools have shadows again!
Boxes under the Night View bar are now walkthrough (thanks Meme Man)

06/07/18 (305)

Updated the appearance of the lampshades
Made some minor draw call optimizations
Modified lightmap settings

06/05/18 (303)

Made some minor draw call optimizations
Updated some meshes to have better geometry and normals

06/04/18 (302)

Made some minor draw call optimizations
Fixed a missing collider near the bar mirror

06/03/18 (300)

Made a few draw calls optimizations
Changed the near clipping plane distance on the reference camera (the far clip was not changed)
Rebaked occlusion
Updated the meshes for the sink, Roost shelves, stair railings, booth base/backing, and other minor meshes
Made minor Trigger broadcast type adjustments
Re-painted the wall near the main bar
Added a new Patron flyer

Quick Fix (301)

Fixed some mis-aligned colliders that were out of place.

06/01/18 (298)

Made some draw call optimizations!
Made changes to the Object Respawing behavior to attempt to address lag when a new user joins the world.
Mixed Lights now are forced off when you are not in view of them. This is being done as a precaution because Occlusion Culling may not have been doing the job in all cases.
Rebuilt the shelves under the bar
Updated the Calendar
Tweaked the lighting
Changed the material on the dynamic towel
Fixed a gap in the ceiling in The Roost
Tweaks to various trigger broadcast types
Made some chair upgrades

05/24/18

House Music placement/falloff changes
Stage Lighting Updates
New Stage Lighting Control Board
Addition of Dynamic Event Posters for Spork of Love
Minor Updates to the Event Posters for MckMuze
Bulletin Board Updates

05/10/18

Administration controls added to lock and unlock the stage in a basic manner. (Issue #2 - MckMuze)

More work still needs to be done to fully satisfy the bounty to my satisfaction.


Stage lighting has been improved
Dynamic lights in Night View have been improved
Mesh updates for the stage - Rounder!
Material updates to the sage, Night View Floor, and Bars
This change log had dome embarrassing typoss

05/07/18

Reflection Probe Updates
SDK Bump - 2018.05.01.20.38
Flyers Added

04/24/18

New Bulletin boards

04/19/18

Bathrooms should be back to normal

04/14/18

You should no longer stick to the walls when using the main stairway or the stairs in The Roost
Mckmuze setlist lighting has been fixed
Missing lightmap on painting has been found and reapplied
New decorations in Night View and The Roost
New furniture in The Roost
Hopefully fixed some lag issues related to triggers

04/11/18

Weird, the basement door kept staying opened. - Fixed

04/08/18

Coasters added around The Pug to keep the finish on the wood nice
Eggs removed

03/30/18

Cleaned up straggling Saint Patrick's Day decorations
Improved Resolution on wireframe posters
Possible fix for the flickering hub portal
Eggs.

03/19/18

Removed Saint Patrick's Day decorations

03/17/18

Saint Patrick's at The Pug - 2018
UV fixes for the shelves in the wall behind the main bar
New wall art
Fixes to the glass roof in The Roost
Duplicated mesh fixes
Security Improvements

03/13/18

Calendar Update
Moon Fix

02/24/18

St. Patrickâs Day 2018 - Promotional Table Tents
Enhanced appearance of Night View stage spotlights and floor lights
Multiple spawns
Minor draw call optimizations
Lightmap fixes
Rose added in The Roost - Thanks Poplopo!
New shelves in Night View
Improved the readability of the bulletin board flyers
Fixed typo on bulletin board
Humoungously improved the wall near the back storage room
Security Improvements
SDK Bump

Thanks for the help testing Zarniwoop, Poplopo, and Zircronswift!
02/06/18

Removed birthday decorations
Removed portal to the prototype

02/02/18

Birthday decorations
Temporary portal to the prototype

02/01/18

Added a delightful painting above the fireplace. It was painted by Dicidius. Thanks, Dicidius!
A matching sword is on display
New shelf along the back wall in The Roost
Telephone ring volume lowered a bit
Calendar updated
Moon and city lights properly restored for real this time
Bulletin board updated

01/05/18 (268)

Added security colliders to prevent trolling from outside the map.
SDK Bump

01/02/18

New Years Decorations Removed
Moon and city lights restored
Phone Ring distance adjusted - hopefully, the beds are usable now

12/31/17

Far Back Staircase/Fire Escape
Most objects should Respawn when left lying on the floor, in weird places or outside of the map.
Exterior Meshes
Woodgrain direction fixes
Mesh improvements on the bar
Ambient Lighting Tweaks
Bathroom Stalls now have handles and latches
Skybox uses fewer draw calls
Hole in Phone base fixed
Material(s) consolidated on the phone base
General draw call optimizations
Lighting tweaks
Christmas Decor Removed
Calendar Updated
Disc for 2018 added
Champagne for New Years
Decorations for New Years

12/22/17

Seat Fixes

12/14/17

SDK Bump - VRCSDK-2017.12.12.13.36_Public
Martini added (941101501153505281)
Occlusion Settings Reverted
Lightmap tweaks
Material fixes

12/12/17

Downstairs beer taps should work correctly now
Christmas Decoration Updates
Draw Call Optimizations
Light Probe Improvements
Mesh Updates on the Night View bar
Material Tweaks
Toilet seat fixes
Dining chairs should be easier for desktop users to use
Occlusion changes

12/01/17

Calendar Updated
Lightmap Tweaks
Christmas Decorations
Material Optimizations
Thanksgiving meal put in storage

11/22/17

The Roost is Open
Added Thanksgiving Food
Improved Night View Hall sign (Thanks Poplopo)
Adjusted audio volume falloff on sink taps
Updated Meshes in The Roost
Added fireplace in The Roost
Added seating area in front of the fireplace in The Roost
Added table and chairs in The Roost
Fixed Grain Direction on various objects
Updated Proximity Dance Club Portal

11/16/17 (200)

Lighting Tweaks
UV Fixes on the 2nd Floor floor
Mesh Updates on Booth's backs
UV Fixes on Booth bases
Increased Red Phone ring frequency

11/15/17

Adjustments to the way pickups reset, hopefully fixing them
Patched over Z-Fighting at the top of the stairs
""Un-Fixed"" the Devil Bucket
The Red Phone should now randomly ring
Audio played from the phones should be easier to hear now

11/14/17

First attempt at making pickups reset when idle in undesirable locations.

11/09/17

Calendar Added
Red Phone Added
Various Materials Improved
Lighting Tweaks
Lightmap Resolution Changes
Minor Fixes
VRCSDK Updated to 2017.10.26.17.36

11/07/17

Material Updates
Material Fixes
Minor Fixes

11/06/17

Material Updates
Bar Mesh Updates
More Face Weighted Normals
Minor Fixes

11/04/17

Small Ceiling Vents Added
Face Weighted Normals on various objects
Faucets in the bathrooms now work
Toilets have been scrubbed
Minor Fixes

10/30/17

Post Halloween Party restore

10/24/17

Reflectiopn probe fixes
Halloween prep

10/13/17

VRCSDK Update to 2017.10.04.13.58

10/12/17

Halloween Promotional signs put up
WebPanel disabled
Minor Fixes

09/22/17

Lighting Tweaks
Material Updates (Albedo Checks)
Minor Fixes

09/19/17

Lighting Updates
Minor Fixes

09/12/17

Lighting Updates
Birthday Cake Optimizations
Minor Fixes

09/11/17

Bathroom Collider Fixes
Martial Swaps
Major Light Probe Overhaul
Minor Fixes

09/09/17

Bathroom ceiling now reflects in the bathroom mirrors

09/05/17

Minor Fixes

09/01/17

Bottle Liquid Fixes
Bathroom Walls Fixed

08/31/17

Updated Materials
Optimization for Bathroom Mirrors
Minor Fixes

08/30/17

Five Six

08/17/17

Karaoke added for Karaoke night

08/10/17

Karaoke functionality testing

07/12/17

SnailLock testing

06/30/17

Fireworks added
Minor fixes

06/22/17

Lighting updates
Trigger updates

06/21/17

Minor changes

06/20/17

Dance lights / floor lights added to Night View
Stage lights updates
Overall nightview light added

06/19/17

Sleeping roost updates
Minor fixes

06/14/17

Rounded edges on the lower bar
Added door latches

06/13/17

Refinements to the stairs
Fixes to the Night View floor

06/10/17

Basement optimizations
Sleeping Roost started

06/01/17

Additions for Contact
56 - Stage Lights
Reload button added for the YouTube panel

05/23/17

Texture size optimizations
Floor UV fixes
Adjusted seats for desktop users
Light probes reduced in overall count

05/19/17

Event board typo fixed

05/18/17

Collider fixes
Combined various meshes

05/17/17

Optimized SmÃ¶rgÃ¥stÃ¥rta
Added SmÃ¶rgÃ¥stÃ¥rta under glass to the back room
Texture fixes
Mesh fixes

05/16/17

Occlusion fixes
Baseboards added in various places
Coffee added
A large number of mesh colliders have been replaced with box colliders

05/15/17

Doorbell updates
Occlusion changes
Backroom additions
Security camera added and removed

05/12/17

Doorbell added
Cans of fish added
Lighting updates
SmÃ¶rgÃ¥stÃ¥rta.

04/21/17

White Russians
Light probe fixes
Booth fixes
Lighting changes
Tapster locks added
Switched to using Euan's video player

04/19/17

Eggs removed
Sink handles added
Event board updates

04/15/17

Minor fixes

04/14/17

Event board added
Easter eggs added for easter
Lighting changes
Wine bottles added
Wine glasses added

04/13/17

YouTube panels trigger fix
Stage Prop updates
Trigger updates
MckMuze setlist added
Stage updates
Occlusion fixes in the basement

04/12/17

Lightmap resolution adjustments

04/10/17

Corner booth fixes
Booth seat fixes
Upstairs gate fixes
Lighting fixes
Basement Door added
Basement wall issues fixed
Texture storage size optimizations

04/07/17

Basement
New chairs
YouTube panel fixes
Minor fixes

04/06/17

Mckmuze decor updates
Bar Two - Tigger and button fixes

04/05/17

Bar Two - Improvements
Trigger updates (groan)
Podium added to Night View

04/04/17

Mirror fixes
Metal material updates
Bar top fixes

04/03/17

Bar Two - shelves added
Lighting and light probe changes
Upstairs security changes

04/02/17

Video screen fixes
Brighter lighting

03/31/17

Second bar added in Night View
Stage lights added
New back panel controls

03/30/17

Foot pedals and amp added to the stage

03/29/17

YouTube panels added to the stage
Minor fixes

03/24/17

Corner booth implemented (it's too small!)
PhysSound added
Music fixed

03/23/17

Materials updated
LOD enabled on booth backs

03/22/17

Minor fixes

03/21/17

Decorations taken down
Minor mesh updates
Taps now dispense normal beer

03/17/17

St Patrick's Day Decorations
Taps are now interactable
Speakers
Party Music Player - Thanks Cubedparadox for the youtube playlist sync!

03/13/17

Trigger fixes (grumble)

03/12/17

bathroom Updates
Material atlasing
Security updates

03/10/17

Optimized Meshes
Added St Patrick's Day table tents
Minor Fixes

03/09/17

Added lights to the St Patrick's Day posters
Updated Materials

03/08/17

St Patrick's Day Posters added
Bar height adjusted
Measuring sticks added

03/07/17

Added a Clock
Updated those fancy liquid shaders
Minor fixes

03/06/17

Added fancy liquid shaders
Minor fixes

03/03/17

Added Your Favorite Beer Neon Sign
Updated Materials
Added lights above the bar top
Minor fixes

02/27/17

Implemented Security for the Bar
Added Your Favorite Beer
Optimized Meshes
Optimized Objects
Minor Fixes

02/24/17

Added the back room and it's keypad
Minor fixes

02/23/17

Added MckMuze signs
Minor fixes

02/21/17

Fixed the bar mirror
Optimized Geometry
Optimized Materials
Optimized Occlusion
Minor fixes

02/20/17

Smaller Light Maps
Lighting Changes
Added Gates to the bar
Added Staff Only Sign
Added more canister lights in the Ceiling
Added photo of Q sleeping

02/19/17

Fish Bowl Added
Light bake fixes

02/17/17

Posted my Liquor License
Mesh optimizations

02/01/17

Initial Release
VRCSDK version 2016.12.01.18.02

",12
jimboy3100/jimboy3100.github.io,JavaScript,"Legend Mod
Mod for Agar.io multiplayer action browser game.

Author: jimboy3100@hotmail.com
Website: www.legendmod.ml
<iframe width=""800"" height=""452"" src=""https://www.youtube.com/embed/CnIfNSpCf70?rel=0"" frameborder=""0"" allow=""autoplay; encrypted-media"" allowfullscreen></iframe>
Legend mod GitHub Library
Feature Highlights

10% extra zoom-out (see enemies from further)
Fast feed shortcut (hit viruses and feed team mates faster)
Double split shortcut
Triple split shortcut (for tricksplits)
Minimap (find your team mates, avoid getting cornered etc)
15 configurable shortcut keys to send messages to your team quickly

Other Features

Updates automatically
Unlimited FPS unlocked (quicker than Vanilla)
Old Skins
Animated Skins
UserScripts Manager (URL or pasted)
Language Packs
Direct PARTY / FFA / EXP / TEAM server by using tokens/sips or connector
Search engine for player name / clan / tag / leaderboard / ip / token
Integrated Chat, minimap and teamboard. Chat rooms per server/per team password(or public)
New Template / skins / animations / zoom / respawn / helpers / hud controls and many extras
Themes for quite all textures and map (Basic / Menu / Hud / chat / minimap / graphics and cursor)
Banners for many clans (Email me your symbol and weblink for updates)
60++ Macros / Events / Hotkeys (Script does many calculations)
Tools for quests / youtubers / timers / coin auto digger/youtube video player
Send message pictures, videos and also various message commands directly to teammate's script
Change various textures, add photos on huds and clan's pictures and url links
Dying Light Expansion
Discord webhook handler's for sending IP, and many more...

Legend Mod libraries
Github,
Greasyfiork,
Agarioscripts Chrome Extension
Installation

Install Tampermonkey browser extension on Chrome , Opera
Install Legend Express script here Â 

Screenshots
Welcome Screen - Copy Token, Leaderboard, IP

Searching

Youtube

Features

Big Names (visible to legend/ogario users only)

Banners and website anchors for many clans

Old Skins

Legend mod is based on many scripts (ogario, kitty, turtle clan scripts and others that can be found on greasyfork website).
",5
ZkHaider/Figure,Swift,"Figure
Figure is a elegant declarative UI library, utilizing the Final Tagless solution to the expression problem.
Installation
Carthage
Add github ""ZkHaider/Figure"" ""master"" to your Cartfile, and run Carthage.
Requirements

Deployment target iOS 10.0+
Swift 4+
Xcode 10+

Usage
A view is declared simply by:
let view: iOSRenderer = .view()
You can then render that view like so:
let renderedView: UIView = view.render()
You can simply create a var in your UIViewController as your root view, like so:
import FigureiOS

final class ViewController: UIViewController {

    // MARK: - View 

    var rootView: iOSRenderer {
        return .view()
    }
    
    // MARK: - Init
    
    // ...
    
    // MARK: - Lifecycle 
    
    override func loadView() {
        self.view = self.rootView.render()
    }

}
Notice we declaratively create the view in rootView and then render it by calling render() in loadView(). Alternatively you can subclass your UIViewController with RenderViewController and override the rootView property. RenderViewController handles your view rendering automatically, so even less boilerplate to write.
import FigureiOS

final class ViewController: RenderViewController {

    // MARK: - View 

    override var rootView: iOSRenderer {
        return .view()
    }
    
}
Declare view hierarchies like so:
let myNestedView: iOSRenderer = .view(
    config: [.backgroundColor(.red)],
    .view(
        layout: [.set(width: 100.0, height: 100.0)],
        .view(layout: [.fill]),
        .view(),
        .view()
    )
)

let view: UIView = myNestedView.render()
The above will create a root view which has a red background with 1 subview which has a width of 100.0 and a height of 100.0 which itself should have 3 subviews where 1 of those subviews fills the frame of it's parent view.
Contributions
Figure welcomes both fixes, improvements, and feature additions. If you'd like to contribute, open a pull request with a detailed description of your changes.
As a rule of thumb, if you're proposing an API breaking change or a change to existing functionality, consider proposing it by opening an issue, rather than a pull request; we'll use the issue as a public forum for discussing whether the proposal makes sense or not.
Maintainers
Haider Khan

https://github.com/ZkHaider

Timothy Kautz

https://github.com/littleowl

",2
zacanger/z,Shell,"$HOME
Please feel free to use anything you like!
Unless otherwise noted, everything here is under the MIT license.
I keep this repo at /home/z/Dropbox/z and symlink a lot of stuff to /home/z,
so there may be a few references to those paths scattered around.
Notes:

Professionaly, I write Node, shell, and lots and lots of config. A lot of my
setup is oriented around quick editing of text and quick navigation.
This is shared between some laptops running Ubuntu, Debian, and (work) macOS.
I use nvim, but init.vim config probably works fine with Vim 8 (if renamed to .vimrc)
dwm on Linux, chunkwm on Mac
Bash 4 and 5, Python 3 mostly, Node latest, Neovim.
The files called *.list (under /misc) are to keep track of what I need on a fresh computer.

apt.list: generated with apt-mark showmanual
npm.list: npm i -g all these things, generated with global-packages-cli
pip.list: Python 3
go.list: go get -u this stuff


On fresh computers, I sync Dropbox first, then run either new-mac.sh (and
symlink all the things) or new-linux.sh.

",7
TomYang1993/javacs,Java,"Data structures and algorithm code
",6
bergerhealer/BKCommonLib,Java,"BKCommonLib
Spigot Resource Page | Dev Builds
To build BKCommonLib you will (probably) need to run Build Tools beforehand.
Otherwise tests will fail and maven will complain. No actual server code is linked during compiling, hence the dependency is type test.
This is a library-plugin system, introducing a lot of utility classes
It also simplifies coding:

PluginBase: allows quick registering and monitoring of plugins being enabled
(Async)Task: allows quick task starting and dynamic in-code creation
Utilities for virtually every needed task ahead, from mathematics to obtaining an entity by UUID
Custom node-based configuration extension
BlockLocation, BlockMap and BlockSet to safely use blocks in maps and sets
ItemParser class to generate a parser from user and use it during item transactions
Nanosecond StopWatch class for performance monitoring
Operation class to handle entities, players, chunks and worlds the way you want it

License
Copyright (C) 2013-2015 bergerkiller
Copyright (C) 2016-2017 Berger Healer
Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ""Software""), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, and/or sublicense the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
",41
mchehab/zbar,C,"ZBAR BAR CODE READER
ZBar Bar Code Reader is an open source software suite for reading bar
codes from various sources, such as video streams, image files and raw
intensity sensors. It supports EAN-13/UPC-A, UPC-E, EAN-8, Code 128,
Code 93, Code 39, Codabar, Interleaved 2 of 5, QR Code and SQ Code.
Included with the library are basic applications for decoding captured bar
code images and using a video device (eg, webcam) as a bar code scanner.
For application developers, language bindings are included for C, C++,
Python 2 and Perl as well as GUI widgets for Qt, GTK and PyGTK 2.0.
Zbar also supports sending the scanned codes via dbus, allowing its
integration with other applications.
Check the ZBar home page for the latest release, mailing lists, etc.:

https://github.com/mchehab/zbar

License information can be found in COPYING.
BUILDING
See INSTALL.md for generic configuration and build instructions.
The scanner/decoder library itself only requires a few standard
library functions which should be available almost anywhere.
The zbarcam program uses the video4linux API (v4l1 or v4l2) to access
the video device.  This interface is part of the linux kernel, a 3.16
kernel or upper is recommended for full support.  More information is
available at:

http://www.linuxtv.org/wiki/

pkg-config is used to locate installed libraries.  You should have
installed pkg-config if you need any of the remaining components.
pkg-config may be obtained from:

http://pkg-config.freedesktop.org/

The zbarimg program uses ImageMagick to read image files in many
different formats.  You will need at least ImageMagick version 6.2.6
if you want to scan image files.  ImageMagick may be obtained from:

http://www.imagemagick.org/

The Qt widget requires Qt4 or Qt5. You will need Qt if you would like to
use or develop a Qt GUI application with an integrated bar code
scanning widget. Qt4 may be obtained from:

https://www.qt.io/

The GTK+ widget requires GTK+-2.x.  You will need GTK+ if you would
like to use or develop a GTK+ GUI application with an integrated bar
code scanning widget.  GTK+ may be obtained from:

http://www.gtk.org/

The PyGTK 2.0 wrapper for the GTK+ widget requires Python 2, PyGTK.
You will need both if you would like to use or develop a PyGTK GUI
application with an integrated bar code scanning widget.  PyGTK may be
obtained from:

http://www.pygtk.org/

The Python bindings require Python 2.  You will need Python and PIL
if you would like to scan images or video directly using Python.
Python is available from:

http://python.org/

The Perl bindings require Perl (version?).  You will need Perl if you
would like to scan images or video directly using Perl.  Perl is
available from:

http://www.perl.org/

If required libraries are not available you may disable building for
the corresponding component using configure (see configure --help).
The Perl bindings must be built separately after installing the
library.  see:

perl/README

RUNNING
make install will install the library and application programs.  Run
zbarcam-qt or zbarcam to start the video scanner. Use zbarimg <file>
to decode a saved image file.
Check the manual to find specific options for each program.
DBUS TESTING
In order to test if dbus is working, you could use:
$ dbus-monitor --system interface=org.linuxtv.Zbar1.Code

or build the test programs with:
$ make test_progs

And run:
$ ./test/test_dbus
With that, running this command on a separate shell:
$ ./zbarimg/zbarimg examples/code-128.png
CODE-128:https://github.com/mchehab/zbar
scanned 1 barcode symbols from 1 images in 0.01 seconds

Will produce this output at test_dbus shell window:
Waiting for Zbar events
Type = CODE-128
Value = https://github.com/mchehab/zbar

REPORTING BUGS
Bugs can be reported on the project page:

https://github.com/mchehab/zbar

Please include the ZBar version number and a detailed description of
the problem.  You'll probably have better luck if you're also familiar
with the concepts from:

http://www.catb.org/~esr/faqs/smart-questions.html

",22
wobblui/wobblui,Python,"wobblui
(experimental project)
Wobblui is a versatile & easy-to-use UI framework for Python 3!
Why wobblui is awesome:

Cross-platform: Works on Windows, Linux, and
Android
Easy: simple API & versatile auto-scaling box layouts
Efficient: 3d accelerated, on-demand redraw/relayout ('lazy') and more!

It also has a consistent look on all platforms and supports styling,
including freeform UI scaling!
This is how easy wobblui is to use:
from wobblui import event_loop
from wobblui.label import Label
from wobblui.window import Window

w = Window()
w.add(Label(""Hello World! This is a wobblui example!""))

event_loop()

See the Quickstart Guide for more!
Installation
You'll need SDL2 and some SDL2-related libraries as prerequisite,
see the Installation Guide.
Afterwards, just install from pip:
pip install --user -U wobblui

(make sure to use a Python 3.X pip! Python 2 is NOT supported)
Documentation
Jump into the documentation here!
License
Wobblui is open-source under various licenses (due to some included
3rd-party components), but most of it is zlib-licensed.
See the LICENSE.md document for full details!
",3
ronalfy/highlight-and-share,PHP,"Highlight and Share for WordPress
A WordPress plugin for highlighting text and sharing it via Twitter or Facebook (Now available on WordPress.org!).
SA WordPress plugin for highlighting text and sharing it via Twitter and Facebook and other services including LinkedIn, Email, Xing, and WhatsApp.
Sharing selectable text is only possible via Twitter, Facebook, and WhatsApp. However an option to share the post via LinkedIn, Pinterest, and E-mail are also present when highlighting text as a convenience.
If you have a feature request, please add an issue.
Features

Override which content is selectable (using jQuery class notation without the dots).
Enable or disable Facebook sharing.
Enable or disable Twitter sharing.
Customize the Twitter username used.

Advanced customization is allowed via hooks.  See the Plugin Filters section.
Recommended Plugins

Better Font Awesome - Enables Twitter/Facebook sharing icons
WordPress SEO - For Facebook OpenGraph data
JetPack - for URL Shortlinks

Installation
Simply install as a WordPress plugin.
Head to the plugin settings and customize the content area and the Twitter username to use.
Tested on:
The latest versions of Firefox, Chrome, and Safari.  IE testing is coming soon.
Themes tested on:

TwentyFourteen
TwentyThirteen

Plugin Filters
The plugin filters are demonstrated in the code below.
//Example filter usage for highlight and share
//https://github.com/ronalfy/highlight-and-share

/* The following filters take and return booleans (true, false)*/
/* Call WordPress functions __return_false or __return_true */
add_filter( 'has_show_facebook', '__return_true' ); //Disable or enable facebook sharing
add_filter( 'has_show_twitter', '__return_true' ); //Disable or enable twitter sharing
add_filter( 'has_load_css', '__return_true' ); //Disable or enable plugin's CSS - Use your own
add_filter( 'has_enable_content', '__return_true' ); //Disable or enable main post content
add_filter( 'has_enable_excerpt', '__return_true' ); //Disable or enable excerpt content
add_filter( 'has_enable_mobile', '__return_true' ); //Disable or enable on mobile devices

/* Override the Facebook share text (default is Share) */
add_filter( 'has_facebook_text', 'has_override_facebook_text' );
function has_override_facebook_text( $default ) {
	return 'Facebook';
}

/* Override the Twitter share text (default is Tweet) */
add_filter( 'has_twitter_text', 'has_override_twitter_text' );
function has_override_twitter_text( $default ) {
	return 'Twitter';
}

/* Override the JavaScript classes (assuming jQuery class format with no periods) */
add_filter( 'has_js_classes', 'has_override_js_classes' );
function has_override_js_classes( $content ) {
	return 'entry-content,type-page,type-post';
}

/* Add JS IDs */
add_filter( 'has_js_ids', 'has_override_js_ids' );
function has_override_js_ids( $content = array() ) {
	if ( !is_array( $content ) ) $content = array();
	$new_arr = array( 'content', 'comments' );
	$content = array_merge( $content, $new_arr );
	return $content;
}

/* Add JS elements */
add_filter( 'has_js_elements', 'has_override_js_elements' );
function has_override_js_elements( $content = array() ) {
	if ( !is_array( $content ) ) $content = array();
	$new_arr = array( 'blockquote' );
	$content = array_merge( $content, $new_arr );
	return $content;
}

/* Override the Twitter username (no @ symbol needed) */
add_filter( 'has_twitter_username', 'has_override_twitter_username' );
function has_override_twitter_username( $username ) {
	return 'wordpress';
}
Some examples are below:
Disable sharing on a static front page.
 add_action( 'wp', function() {
	if ( is_front_page() ) {
		add_filter( 'has_show_facebook', '__return_false' );
		add_filter( 'has_show_twitter', '__return_false' );
	}
} );
Modify the Content URL
add_filter( 'has_content_url', function( $url, $post_id ) {
	return 'https://wordpress.org';
}, 10, 2 );
Modifying jQuery Selectors
The following demonstrates how to override the jQuery selectors used in choosing which content to share:
//Demonstrates how to select paragraph text only

add_filter( 'has_js_selectors', 'hs_custom_selectors', 10, 5 );
function hs_custom_selectors( $selectors, $content = array(), $classes = array(), $ids = array(), $elements = array() ) {
	//With $content, $classes, $ids, $elements, you can build your own selectors
	//Or just override $selectors (a string) with your own custom ones
	return '.has-content-area p, .has-excerpt-area p';
}
Credit
This script was originally observed on Vogue.com and was ported over for use in WordPress.
",12
Lombiq/Hastlayer-Hardware-Framework---Xilinx,VHDL,"Hastlayer Hardware Framework - Xilinx readme
This document is a guideline which provides a brief description of the Hastlayer Hardware Framework for Xilinx FPGAs. The aim of this document is to help the reader to reconstruct and test the Hastlayer FPGA firmware design and to give a hand when you run into a problem.
If you're not familiar with Hastlayer take a look at https://hastlayer.com/.
Table of contents

Prerequisite requirements
Getting started
Running hardware designs
Release notes
Version control
Upgrading the project to the latest Vivado version
Design reproduction steps
Testing custom IP cores
AXI Lite interface slave registers
Adding custom library functions to the design
Debugging with an ILA core

",2
SquirtleSquadProgramming/ScarkSource,C#,"Scark
Scark is a text-based roleplaying game.
A stable and completed release of the game isn't fully completed as we are in early stages of development. If anyone passing by wishes to play the game, bare in mind bugs and loopholes are inevitable and the story isn't very long.
Scark is programmed in C# using the layout of a C# console app.
You can view the wiki for more information on game dynamics and storyline.
Please review the code of conduct for information about what our community values are for contributing.
Please also read the formatting guidelines for information regarding how code should be formatted within the project.
Programmed, written and created by Squirtle Squad.
Credit to https://www.asciiart.eu/ for use of some great ASCII art. A list of all peoples' artwork featured within this project can be found here.
Also thanks to patorjk's brilliant text to ASCII program which was used in the title screen.

",4
IgoRode/QuimicaEZ,HTML,"QuimicaEZ
trabalho de tcc meu e do meu querido amigo Ronan orientado por nada mais nada menos que o grande Arvaro(Alvaro)
https://igorode.github.io/QuimicaEZ/
",2
Holo-Host/DeepKey,Rust,"DeepKey

Circle CI: 
Summary
This is a core hApp. The DeepKey is used for Key Management for hApps in Holochain.
Tests:
hc test
Documentation


DeepKey hApp specs


Built With

Holochain v0.0.13-alpha1

Authors

Joel Ulahanna - zo-el

License

Copyright (C) 2017, The MetaCurrency Project (Eric Harris-Braun, Arthur Brock, et. al.)
This program is free software: you can redistribute it and/or modify it under the terms of the license provided in the LICENSE file (GPLv3). This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
Note: We are considering other 'looser' licensing options (like MIT license) but at this stage are using GPL while we're getting the matter sorted out.
",4
gentoo/musl,Shell,"This is the overlay for Gentoo build with musl.  musl is a new C Standard Library
which aims to be lightweight, fast, simple, free, and strives to be correct in the
sense of standards-conformance and safety.
http://www.musl-libc.org/
Maintainers

Anthony G. Basile blueness@gentoo.org
Aric Belsito lluixhi@gmail.com
Felix Janda felix.janda@posteo.de

Repoman Status

",52
gentoo/musl,Shell,"This is the overlay for Gentoo build with musl.  musl is a new C Standard Library
which aims to be lightweight, fast, simple, free, and strives to be correct in the
sense of standards-conformance and safety.
http://www.musl-libc.org/
Maintainers

Anthony G. Basile blueness@gentoo.org
Aric Belsito lluixhi@gmail.com
Felix Janda felix.janda@posteo.de

Repoman Status

",52
simon300000/vtbs.moe,Vue,"vtbs.moe
ä½ å¥½åâ_â
æ¬¢è¿æ¥å° https://vtbs.moe ç Github é¡¹ç®ä¸»é¡µ
ååç«¯åæ¬æ°æ®åºé½å¨è¿ä¸ª repository
ä»ç»
è¿æ¯æèªå¨±èªä¹ååºæ¥ç Bilibili èæä¸»æ­ç¶æè®°å½é¡µé¢ï¼ç®ååªå¨NGAå®£ä¼ è¿
ç°å¨ vtb.simon3k.moe å vtbs.moe ä¸¤ä¸ªå°åé½è½ç¨ï¼åå®¹æ²¡æåºå«ï¼æ¨èç¨ vtbs.moe
ç½ç«ç¨å°çé¨åå¼æºè½¯ä»¶:

åç«¯æ¶æ: Vue.js

Vue CLI
Vuex


ç»ä»¶åº: Element
å¾è¡¨: ECharts

v-charts


æ°æ®åº: level
æ°æ®éé: Bili-api
ååç«¯APIéè®¯: socket.io
ä¸è½ç: Node.js

å¼å
å®è£ä¾èµ:
npm install

åç«¯
Compiles and hot-reloads for development
npm run serve

Compiles and minifies for production
npm run build

Customize configuration
See Configuration Reference.
åç«¯API
node index


Socket æå¡ç«¯å£: 8001
Vtuber/Vup åè¡¨ è§ api/vtbs.js

å¶ä»


æ£æ¥ vtbs.js åè¡¨ææ²¡æéå¤çæä»¤: npm run repeat


ææ°æ®åºå¯¼åºä¸º json æä»¶: node script/db2json


è´¡ç®
æ³è¦å ä»ä¹å¤§åè½å¯ä»¥åå issue è®¨è®ºè®¨è®ºï¼å¶ä»çæ¯å¦vtbåè¡¨è¡¥å¨ï¼ä¿®BUGä»ä¹çå¯ä»¥ç´æ¥ Pull request
æä»ä¹é®é¢å¯ä»¥å¼ issue
èå¤©ä¹å¯ä»¥å¼ issue â_â
",13
mstubinis/Serenity,C++,"Serenity
A game engine focused on producing stunning visual effects and supporting custom user made rendering and logic code.
Features


Physically based rendering using deferred rendering
Several post-processing effects (Depth of Field, HDR, SSAO, Bloom, Fog, God Rays
Entity-Component based game logic
Custom logic and rendering code via functors
Bullet Physics world
Multi-threading using boost::asio worker pool and functor based jobs
Resource loading (3d meshes, textures, sounds, fonts
Optimized render calls using Render Graphs


Installing & Building - Visual Studio
The project uses several library dependencies. The current solution file is designed to be used in Visual Studio 2017 with the libraries being built statically and not dynamically, on a Windows OS. The dependencies are:


Assimp
Bullet Physics
SFML
freeglut
GLEW
glm
Boost (filesystem, iostreams, systems)


Most of these libs are already included in the dependencies folder. The project will point to use them, but if you have them already you can point to your own. Boost is not included (for obvious reasons), you will have to have that installed yourself. For more information on how to build boost, visit The getting started guide
The solution contains 3 projects: the engine itself, which will be built into Serenity.lib, and 2 sample applications that will be built into .exe's.
In order for the exe's to run, the SerenityLib/Engine/data folder will have to be copied over to SerenityLib/Builds folder, which will be generated upon compiling the solution.
In the future, the engine will receive an overhaul with the intention of opening it up to client usage. Part of this endeavour will be a wiki section with API documentation as well as continued refactoring of the engine code for readability and understanding.
",3
azu/parse-github-event,TypeScript,"parse-github-event 
Small library to parse Event Types from Github API response.
Feature

Parse event json and built message and html_url without addtional request
Create human-readable message like GitHub's timeline from event json

Installation
npm install parse-github-event
Usage
Response json object of GitHub Events API.
{
    ""id"": ""2070416128"",
    ""type"": ""PullRequestEvent"",
    ""actor"": {
        ""id"": 1062518,
        ""login"": ""pivotal-brian-croom"",
        ""gravatar_id"": ""92d36bd6d9b53539fcec282452872710"",
        ""url"": ""https://api.github.com/users/pivotal-brian-croom"",
        ""avatar_url"": ""https://avatars.githubusercontent.com/u/1062518?""
    },
    ""repo"": {
        ""id"": 708684,
        ""name"": ""pivotal/cedar"",
        ""url"": ""https://api.github.com/repos/pivotal/cedar""
    },
    ""payload"": {
        ""action"": ""opened"",
        ""number"": 231,
        ""pull_request"": {
            ""url"": ""https://api.github.com/repos/pivotal/cedar/pulls/231"",
            ""body"": ""- Common code consolidated into CDROTestRunner and CDROTestIPhoneRunner\r\n- CDROTestIPhoneRunner subclasses CDROTestRunner\r\n[#67878220]\r\n\r\nThoughts?\r\n@idoru, @jeffh"",
            ""created_at"": ""2014-04-24T05:01:39Z"",
            ""updated_at"": ""2014-04-24T05:01:39Z"",
    ...
}
Parse response
var parseGithubEvent = require(""parse-github-event"");
// responseJSON is come from https://developer.github.com/v3/activity/events/
var parsed = parseGithubEvent.parse(responseJSON);
/*
{
    text: 'opened issue on %%repository%%',
    data: { repository: 'pivotal/cedar' },
    html_url : 'https://github.com/pivotal/cedar/pull/231'
}
*/
Create message
It's bonus method.
var parseGithubEvent = require(""parse-github-event"");
var result = parseGithubEvent.compile(json);
// pivotal-brian-croom opened issue on pivotal/cedar
UseCase
Create one-line message and html_url from event response.

azu/github-to-twitter-lambda: Lambda bot that fetch own GitHub notifications/events and post to Twitter.
azu/faao: Faao is a GitHub issue/pull-request client on Electron.
lawvs/buddy-github-events: View broadcast/received GItHub events from other people or organizations.

Contributing

Fork it!
Create your feature branch: git checkout -b my-new-feature
Commit your changes: git commit -am 'Add some feature'
Push to the branch: git push origin my-new-feature
Submit a pull request :D

License
MIT
Thanks for alindeman/github-timeline-widget.
Use these as a reference

https://github.com/FenrirUnbound/github-feed/tree/FixPath/test/mocks
https://github.com/limbo0312/gitBox/tree/master/ioctocat2/iOctocatUnitTests/Fixtures
https://github.com/octokit/go-octokit/tree/master/fixtures
https://github.com/chamerling/QuickHubApp
https://github.com/linyows/octospy/tree/master/spec/fixtures
https://github.com/octokit/octokit.objc/tree/master/OctoKitTests/Stubs
https://github.com/octokit/octokit.net/tree/master/Octokit.Tests/Fixtures

",5
maticzav/gimb-events,TypeScript,"Gimb Dogodki

Ticketing system for Gimnazija BeÅ¾igrad

Installation
npm install
npm run bootstrap
npm run dev
Required Environment variables

APP_SECRET
PRISMA_ENDPOINT
PRISMA_SECRET
SENDGRID_KEY

To see the page in action, go to http://localhost:3001
",3
VeNoMouS/cloudscraper,Python,"cloudscraper




A simple Python module to bypass Cloudflare's anti-bot page (also known as ""I'm Under Attack Mode"", or IUAM), implemented with Requests. Cloudflare changes their techniques periodically, so I will update this repo frequently.
This can be useful if you wish to scrape or crawl a website protected with Cloudflare. Cloudflare's anti-bot page currently just checks if the client supports Javascript, though they may add additional techniques in the future.
Due to Cloudflare continually changing and hardening their protection page, cloudscraper requires a JavaScript interpreter to solve Javascript challenges. This allows the script to easily impersonate a regular web browser without explicitly deobfuscating and parsing Cloudflare's Javascript.
Note: This only works when regular Cloudflare anti-bots is enabled (the ""Checking your browser before accessing..."" loading page). If there is a reCAPTCHA challenge, you're out of luck (At this stage... however we will be adding in Anti-CAPTCHA 3rd party support). Thankfully, the Javascript check page is much more common.
For reference, this is the default message Cloudflare uses for these sorts of pages:
Checking your browser before accessing website.com.

This process is automatic. Your browser will redirect to your requested content shortly.

Please allow up to 5 seconds...

Any script using cloudscraper will sleep for ~5 seconds for the first visit to any site with Cloudflare anti-bots enabled, though no delay will occur after the first request.
Installation
Simply run pip install cloudscraper. The PyPI package is at https://pypi.python.org/pypi/cloudscraper/
Alternatively, clone this repository and run python setup.py install.
Dependencies

Python 2.7 - 3.x
Requests >= 2.9.2
Brotli >= 1.0.7
requests_toolbelt >= 0.9.1

Have the ability to choose between Javascript Interpreters.

js2py >=0.60
Node.js

Your computer or server may already have it (check with node -v). If not, you can install it with apt-get install nodejs on Ubuntu. Debian requires nodejs-legacy. Otherwise, please read Node's installation instructions.



python setup.py install will install the Python dependencies automatically. Node is the only application you need to install yourself.
Updates
Cloudflare modifies their anti-bot protection page occasionally, So far it has changed maybe once per year on average.
If you notice that the anti-bot page has changed, or if this module suddenly stops working, please create a GitHub issue so that I can update the code accordingly.

Many issues are a result of users not updating to the latest release of this project. Before filing an issue, please run the following command:

pip show cloudscraper

If the value of the version field is not the latest release, please run the following to update your package:
pip install cloudscraper -U

If you are still encountering a problem, open an issue and please include:

The full exception and stack trace.
The URL of the Cloudflare-protected page which the script does not work on.
A Pastebin or Gist containing the HTML source of the protected page.
The version number from pip show cloudscraper.

Usage
The simplest way to use cloudscraper is by calling create_scraper().
import cloudscraper

scraper = cloudscraper.create_scraper()  # returns a CloudScraper instance
# Or: scraper = cloudscraper.CloudScraper()  # CloudScraper inherits from requests.Session
print scraper.get(""http://somesite.com"").content  # => ""<!DOCTYPE html><html><head>...""
That's it...
Any requests made from this session object to websites protected by Cloudflare anti-bot will be handled automatically. Websites not using Cloudflare will be treated normally. You don't need to configure or call anything further, and you can effectively treat all websites as if they're not protected with anything.
You use cloudscraper exactly the same way you use Requests. CloudScraper works identically to a Requests Session object, just instead of calling requests.get() or requests.post(), you call scraper.get() or scraper.post().
Consult Requests' documentation for more information.
Options
Existing session
If you already have an existing Requests session, you can pass it to create_scraper() to continue using that session.
session = requests.session()
scraper = cloudscraper.create_scraper(sess=session)
Unfortunately, not all of Requests' session attributes are easily transferable, so if you run into problems with this, you should replace your initial sess = requests.session() call with sess = cloudscraper.create_scraper().

Debug
scraper = cloudscraper.create_scraper(debug=True)
Or
scraper = cloudscraper.create_scraper()
scraper.debug = True

Delays
Normally, when a browser is faced with a Cloudflare IUAM challenge page, Cloudflare requires the browser to wait ~5 seconds before submitting the challenge answer. If a website is under heavy load, sometimes this may fail. One solution is to increase the delay (perhaps to 10 or 15 seconds, depending on the website). If you would like to override this delay, pass the delay keyword argument to create_scraper() or CloudScraper().
There is no need to override this delay unless cloudscraper generates an error recommending you increase the delay.
scraper = cloudscraper.create_scraper(delay=10)
or
scraper = cloudscraper.create_scraper()
scraper.delay = 10

JavaScript Interpreters
Cloudscraper currently supports two JavaScript Interpreters

js2py
Node.js

The default interpreter is set to js2py,  you can set which to use by defining the interpreter parameter.
scraper = cloudscraper.create_scraper(interpreter='nodejs')
or
scraper = cloudscraper.create_scraper()
scraper.interpreter = 'nodejs'

Brotli Support
We have added in Brotli decompression support in, and it is enabled by default, the only way to disable it, is by passing the allow_brotli parameter set toFalse to create_scraper()
scraper = cloudscraper.create_scraper(allow_brotli=False)
Integration
It's easy to integrate cloudscraper with other applications and tools. Cloudflare uses two cookies as tokens: one to verify you made it past their challenge page and one to track your session. To bypass the challenge page, simply include both of these cookies (with the appropriate user-agent) in all HTTP requests you make.
To retrieve just the cookies (as a dictionary), use cloudscraper.get_tokens(). To retrieve them as a full Cookie HTTP header, use cloudscraper.get_cookie_string().
get_tokens and get_cookie_string both accept Requests' usual keyword arguments (like get_tokens(url, proxies={""http"": ""socks5://localhost:9050""})).
Please read Requests' documentation on request arguments for more information.

User-Agent Handling
The two integration functions return a tuple of (cookie, user_agent_string).
You must use the same user-agent string for obtaining tokens and for making requests with those tokens, otherwise Cloudflare will flag you as a bot.
That means you have to pass the returned user_agent_string to whatever script, tool, or service you are passing the tokens to (e.g. curl, or a specialized scraping tool), and it must use that passed user-agent when it makes HTTP requests.

Integration examples
Remember, you must always use the same user-agent when retrieving or using these cookies. These functions all return a tuple of (cookie_dict, user_agent_string).

Retrieving a cookie dict through a proxy
get_tokens is a convenience function for returning a Python dict containing Cloudflare's session cookies. For demonstration, we will configure this request to use a proxy. (Please note that if you request Cloudflare clearance tokens through a proxy, you must always use the same proxy when those tokens are passed to the server. Cloudflare requires that the challenge-solving IP and the visitor IP stay the same.)
If you do not wish to use a proxy, just don't pass the proxies keyword argument. These convenience functions support all of Requests' normal keyword arguments, like params, data, and headers.
import cloudscraper

proxies = {""http"": ""http://localhost:8080"", ""https"": ""http://localhost:8080""}
tokens, user_agent = cloudscraper.get_tokens(""http://somesite.com"", proxies=proxies)
print tokens
# => {
         'cf_clearance': 'c8f913c707b818b47aa328d81cab57c349b1eee5-1426733163-3600',
         '__cfduid': 'dd8ec03dfdbcb8c2ea63e920f1335c1001426733158'
     }

Retrieving a cookie string
get_cookie_string is a convenience function for returning the tokens as a string for use as a Cookie HTTP header value.
This is useful when crafting an HTTP request manually, or working with an external application or library that passes on raw cookie headers.
import cloudscraper

cookie_value, user_agent = cloudscraper.get_cookie_string('http://somesite.com')

print 'GET / HTTP/1.1\r\nCookie: {}\r\nUser-Agent: {}\r\n'.format(cookie_value, user_agent)

# GET / HTTP/1.1\r\n
# Cookie: cf_clearance=c8f913c707b818b47aa328d81cab57c349b1eee5-1426733163-3600; __cfduid=dd8ec03dfdbcb8c2ea63e920f1335c1001426733158
# User-Agent: Some/User-Agent String

curl example
Here is an example of integrating cloudscraper with curl. As you can see, all you have to do is pass the cookies and user-agent to curl.
import subprocess
import cloudscraper

# With get_tokens() cookie dict:

# tokens, user_agent = cloudscraper.get_tokens(""http://somesite.com"")
# cookie_arg = 'cf_clearance={}; __cfduid={}'.format(tokens['cf_clearance'], tokens['__cfduid'])

# With get_cookie_string() cookie header; recommended for curl and similar external applications:

cookie_arg, user_agent = cloudscraper.get_cookie_string('http://somesite.com')

# With a custom user-agent string you can optionally provide:

# ua = ""Scraping Bot""
# cookie_arg, user_agent = cloudscraper.get_cookie_string(""http://somesite.com"", user_agent=ua)

result = subprocess.check_output(
    [
        'curl',
        '--cookie',
        cookie_arg,
        '-A',
        user_agent,
        'http://somesite.com'
    ]
)
Trimmed down version. Prints page contents of any site protected with Cloudflare, via curl.
Warning: shell=True can be dangerous to use with subprocess in real code.
url = ""http://somesite.com""
cookie_arg, user_agent = cloudscraper.get_cookie_string(url)
cmd = ""curl --cookie {cookie_arg} -A {user_agent} {url}""
print(
    subprocess.check_output(
        cmd.format(
            cookie_arg=cookie_arg,
            user_agent=user_agent,
            url=url
        ), 
        shell=True
    )
)
",53
rustlang-cn/rustlang-cn,None,"Rustlang-cn  
ä¸ãåä¸ Rust ä¸­æéè¯»æç¨¿

Rust ä¸­æè´åäº Rust ç¼ç¨è¯­è¨ä¸­æç½ç»å»ºè®¾ï¼æå¾ä½ çåä¸å Rust ä¸­æéè¯»æç¨¿.

è¯´æï¼æç« æç¨¿å¯ä»¥ç´æ¥PRæ¬ä»åºï¼ä¹å¯ä»¥æéæç« é¾æ¥ï¼è¯·éç¨æä½¿ç¨çæ ¼å¼ï¼å¦ï¼Markdownï¼ãæ¬ä¸æ é»è®¤ MIT åè®®ï¼å¦ä½ çæç« æå¶ä»è¦æ±å¯æ³¨æã
äºãåä¸ Rust ä¸­æç½ç«å»ºè®¾

å ä¸ºæ¬ä»åºçä¿®æ¹ä¼èªå¨åå¸å° rustlang-cn ç½ç«ï¼è¯·åä¸æ¶éµå¾ªä»¥ä¸æ­¥éª¤ï¼å¹¶ç¡®ä¿æå»ºä¸ºæåç¶æã

A. åä¸ææ¡£
å¦æä½ åªæ³ä¿®æ¹æä»¶ï¼ä¸ç¨æä½ä¸é¢æ·»å æä»¶çæ­¥éª¤ï¼ä½ å¯ä»¥ä¿®æ¹ docs ç®å½åçä»»ä½ .md æä»¶ã
B. åä¸ç½ç«
å¦æä½ æ³æ·»å æ´å¤æä»¶ææ¹åä¸»é¢ç»æå¸å±ï¼è¯·éµå¾ªä»¥ä¸æ­¥éª¤ã


Fork å¹¶åéæ¬ä»åºï¼
$ git clone https://github.com/<YOUR_GITHUB_ID>/rustlang-cn
$ cd rustlang-cn
$ npm install


æµè¯ï¼å¯ä»¥å¨ç»ç«¯æ¥çæµè¯è¾åºï¼
$ npm run dev
æå¼æµè§å¨ http://localhost:8080 æ¥çé¡µé¢ææã


ä¿®æ¹/æ·»å  docs ç®å½åçæä»¶, ä¿è¯æ­¥éª¤äºæµè¯è¿è¡æ²¡æéè¯¯ã


Push å°ä½ ç GitHub ä»åºï¼ç¶åæäº¤ PR å°æ¬ä»åºã


",130
bergerhealer/Mountiplex,Java,"Mountiplex
Dev Builds
General Purpose Java Reflection Library
Mountiplex delivers a two-hit solution for accessing the internals of a hidden implementation in Java.
A type conversion engine allows dynamic type changing, which can be used to translate between hidden and API
types. A reflection template engine allows a way to declare the internal structure of the implementation.
An example template declaration that shows most of what is possible:
package some.secret.project;

import my.api.wrapper.Secret;

class SecretService {
#if version >= 1.1
    private int secretCount;
#else
    private int secretCount:nSecrets;
#endif

    public (Secret) TSecret getSecret(String name);
    public String getStatus();

    public String getSecretName(String name) {
        return instance.getSecret(name).getName();
    }

    <code>
    public void clearSecretCount() {
        setSecretCount(0);
    }
    </code>
}
At runtime this same declaration file will be parsed, preprocessing macros are executed and then the whole thing is loaded into a compiletime generated abstract model of the SecretService called SecretServiceHandle. Using this handle it is possible to interact with the implementation safely, using the name/type translations as declared in the template file.
The handle implementation is fully generated at runtime, avoiding reflection where possible to allow for maximum performance code execution.
Mountiplex is primarily used by BKCommonLib to interact with the Minecraft Server internals.
This product includes software developed by the Apache Software Foundation (http://www.apache.org/)
",2
jeffrey-hokanson/PSDR,Jupyter Notebook,"PSDR: Parameter Space Dimension Reduction Toolbox



Author: Jeffrey M. Hokanson, Postdoctoral Fellow at the University of Colorado Boulder (jeffrey@hokanson.us)
Introduction
Given a function mapping some subset of an m-dimensional space to a scalar value



parameter space dimension reduction seeks to identify a low-dimensional manifold
of the input along which this function varies the most.
Frequently we will choose to use a linear manifold
and consequently identify linear combinations of input variables along
which the function varies the most.
We emphasize that this library is for parameter space dimension reduction
as the term 'dimension reduction' often appears in other contexts.
For example, model reduction is often referred to as dimension reduction
because it reduces the state-space dimension of a set of differential equations,
yielding a smaller set of differential equations.
Simple example
One basic use of the library is to identify an active subspace using
the outer product of gradients:
import psdr, psdr.demos
fun = psdr.demos.Borehole()    # load a test problem
X = fun.domain.sample(1000)    # sample points from the domain with uniform probabilty
grads = fun.grad(X)            # evaluate the gradient at the points in X
act = psdr.ActiveSubspace()    # initialize a class to find the Active Subspace
act.fit(grads)                 # estimate the active subspace using these Monte-Carlo samples
print(act.U[:,0])              # print the most important linear combination of variables

>>> array([ 9.19118904e-01, -2.26566967e-03,  2.90116247e-06,  2.17665629e-01,
        2.78485430e-03, -2.17665629e-01, -2.21695479e-01,  1.06310937e-01])
We can then create a shadow plot showing the projection of the input to this function
onto a one-dimensional subspace spanned by the important linear combination identified above
import matplotlib.pyplot as plt
fX = fun(X)                    # evaluate the function at the points X
act.shadow_plot(X, fX)         # generate the shadow plot
plt.show()                     # draw the results



We say this function is has low-dimensional structure since the output of the function
is well described by the value of this one linear combination of its input parameters.
Documentation
For further documentation, please see our page on Read the Docs:
Documentation.
Contributing
I welcome contributions to this library,
particularly of test functions similar to those in psdr.demos.
Please submit a pull request along with unit tests for the proposed code.
If you are submitting a complex test function that requires calling code outside of Python,
please submit a Docker image along with a docker file generating that image
(see the OpenAeroStruct demo function for an example of how to do this).
",3
TheIllusiveC4/Curios,Java,"Curios API   
Overview
Curios is a flexible and expandable accessory/equipment API for users and developers. The purpose is to provide functionality for developers to add extra accessory/equipment slots in a convenient and compatible manner, as well as to give users the ability to configure these slots to their preferences. By default, Curios does not add any content except for an inventory GUI. There are no slots and only two items, the latter only being available through the Creative menu and primarily serving as examples for developers to use when coding their own integration.
Features

Expandable equipment slots through a central library. New equipment slots can be made and managed easily through an identifier registry. Identical identifiers will be merged together to avoid functional redundancies and provide maximum compatibility to potential items, while unique identifiers can still be used to mark special types when appropriate.
Slots are only made on-demand. There are no slots included by default, all slots are created only as needed. This reduces instances where one or more superfluous slots are present without any suitable items to go into the slot.
Slots are completely customizable and manipulable. Slots can have custom backgrounds, different sizes, and can even be disabled or hidden by default. But how would a player even access disabled slots? Through the API, developers can access functions to enable/disable a player's slots or add/remove a certain number of slots of a given type.
Flexible item->curio relations using the vanilla tag system. Potential curios are selected through the vanilla tag system, which means that categorizing items into curio types is as easy as creating a .json file in the data/curios/tags folder. Items can be categorized into as many curio types as you want as long as they're tagged in the appropriate files, and these settings can even be overridden entirely. For more information, see the vanilla tag system.
Complete integration with other inventory mechanics. Mending and Curses will work with all applicable items equipped in the curio slots. There are also various minor features for developers that make it simpler to integrate their current items or mechanics into the curio system.
Accessible from a single GUI. Curios comes with its own GUI accessible from the inventory that shows all of the available slots to a player. This allows players to see all of the extended equipment slots in a central location without needing to access different inventory GUIs. However, developers can still provide their own GUIs for their mod-specific slots if they want. The default keybinding for the GUI is 'g'.

Documentation

How to Use: Users
How to Use: Developers
Commands

Adding to Your Project:
Add the following to your build.gradle file:
repositories {
    maven {
        url = ""https://maven.theillusivec4.top/""
    }
}

dependencies {
    compile fg.deobf(""top.theillusivec4.curios:curios:${version}"")
}

Replace ${version} with the version of Curios that you want to use.
",3
JordanMartinez/learn-halogen,PureScript,"Learn Halogen

Learn purescript-halogen, (v5.0.0-rc.4) from a bottom-up approach
Requirements
Before learning Halogen via this project, you will need to install the following. (If you don't have them already installed, see my purescript learning repo's Install Guide

purescript (v0.12.5)
spago (v0.7.5.0)
parcel (v1.12.3)
dhall-to-json

Instructions

Git clone this project
Run spago build
Run spago docs (and refer to the docs via the ./generated-docs/index.html file)
Read through each folder using the same rules that I use in my learning repo (described in the third bullet point here

License
This project is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International license: (Human-readable version), (Actual License)

",20
bqi343/USACO,C++,"README
Introduction
In competitive programming contests, one must solve well-defined problems by writing computer programs under specified constraints (Wikipedia). Typically, the most popular language is C++, followed by Java and Python.
Notes
I am currently not updating the following pages:

README's for most implementations
tables and solutions for non-platinum USACO contests

If you would like to contribute, provide feedback, or encourage me to update something, please email me at bqi343@gmail.com or submit a pull request. If you have a question, it may be answered by another file in this folder.
Getting Started
I recommend that you use C++, even if you already know some other language such as Java or Python (see notes). A solid foundation in math (ex. AIME qualification) can help greatly.

C++ Tutorial.
CodeFights

good way to practice syntax


Schedule for Beginners
E869120 Tutorial

Assuming you know how C++ input/output works, you should soon be able to advance from USACO Bronze. After that, you can start doing past USACO Silver problems as well as the USACO training pages. Also, participate in other contests such as AtCoder Beginner.
How do you train for USACO Platinum?

Do as many (high-quality) contests as possible.

Make sure to upsolve after the contest ends!


Work through past problems. See Contests -> README:Problems.
Use the tags to learn new topics as necessary.

see implementation / USACO categories
A2OJ
Problem Topics (Morass)



",289
ZDfordream/FlutterTianYue,Dart,"Language: English | ä¸­æç®ä½
Flutterå¼åä¸æ¬¾è·¨å¹³å°çå¼æºæ¼«ç»App (æ¾æ¢èæ­¥ï¼ç»ä¸ªstar)
ä»¿è¾è®¯å¨æ¼«ï¼æé³è§é¢æ­æ¾ææï¼å°è¯´éè¯»ï¼æçæ³ï¼ä½ æéè¦çææï¼æ­¤é¡¹ç®å¤§è´é½æï¼é¡¹ç®æç»­æ´æ°ä¸­...
screen shot






Setup

Clone the repo

$ git clone https://github.com/ZDfordream/FlutterTianYue.git
$ cd FlutterTianYue
$ flutter packages get


Running:

$ flutter run
$ æç¤ºï¼å¦æåºç°buildå¤±è´¥ï¼åæ§è¡ä¸æ¬¡

ä¸»è¦å®ç°çåè½æï¼

å¨æ¼«ï¼ä»¿è¾è®¯å¨æ¼«mç«ï¼åµå¥æ»å¨
å è½½ç¶æè§å¾
flutter ä¸ native ååéä¿¡
å¯å±é¡µ-è½®æ­å¾
ä¸æå·æ°-ä¸æå è½½æ´å¤
AndroidViewåµå¥åçè§å¾
ä»¿æé³è§é¢æ­æ¾
å¶ä»flutterå¸¸è§ææï¼æ­¤é¡¹ç®é½æ

ç¬¬ä¸æ¹æ¡æ¶



åº
åè½




dio
ç½ç»æ¡æ¶


shared_preferences
æ¬å°æ°æ®ç¼å­


fluttertoast
toast


device_info
è®¾å¤ä¿¡æ¯


iconfont
å­åºå¾æ 


share
ç³»ç»åäº«


flutter_webview_plugin
å¨å±çwebview


video_player
è§é¢æ­æ¾



å¦ææ¨è§å¾è¿å¯ä»¥çè¯ï¼ç»ä¸ªStarç½~
é»è®¤æ¡çº¦
æ­¤é¡¹ç®ä»ä¾å¤§å®¶äº¤æµæ²éä½¿ç¨ï¼ä¸å¾ç¨äºä»»ä½åä¸ä»¥åå©çæ´»å¨ã
LICENSE
licensed under the Apache License 2.0

A permissive license whose main conditions require preservation of copyright and license notices.
Contributors provide an express grant of patent rights.
Licensed works, modifications, and larger works may be distributed under different terms and without source code.

",30
hzuapps/web-wechat-2019,CSS,"é«çº§ç½é¡µè®¾è®¡ï¼å¾®ä¿¡å°ç¨åºå¼åè®²è§£ï¼
å®éªè¦æ±
https://github.com/hzuapps/web-wechat-2019/issues?q=is%3Aissue+is%3Aopen+label%3ALab
å¨çº¿æ¥çå®éªç»æ
https://infoaas.com/web-wechat-2019/
å¾®ä¿¡å°ç¨åºå¼åææ¡£
https://mp.weixin.qq.com/debug/wxadoc/dev/index.html?t=2017830
WeUI-wxssåº
https://github.com/Tencent/weui-wxss
å¾®ä¿¡å°ç¨åºæ³¨åç½ç«
https://mp.weixin.qq.com
è¯¾ç¨ç½ç«
http://zeng.shaoning.net/web/
éè¿å®¡æ ¸å¹¶åå¸çå°ç¨åºåè¡¨
https://github.com/hzuapps/web-wechat-2017/list.md
https://github.com/hzuapps/html5-2018/labels/Example
èç³»èå¸

",4
aws-quickstart/quickstart-microsoft-wapadfs,PowerShell,"quickstart-microsoft-wapadfs
Web Application Proxy on the AWS Cloud
This Quick Start deploys Web Application Proxy and Active Directory Federation Services (AD FS) on the AWS Cloud.
AD FS is a Windows Server role that authenticates users and provides security tokens to applications or federated partner applications that trust AD FS.
The Web Application Proxy role on Windows Server makes AD FS accessible to external users by proxying requests without requiring VPN connectivity. You can also use Web Application Proxy to selectively publish and pre-authenticate connections to internal web applications, allowing users outside your organization to access those applications over the Internet.
The Quick Start offers two deployment options:

Deploying Web Application Proxy and AD FS into a new virtual private cloud (VPC) on AWS
Deploying Web Application Proxy and AD FS into an existing VPC on AWS

You can also use the AWS CloudFormation templates as a starting point for your own implementation.

For architectural details, best practices, step-by-step instructions, and customization options, see the
deployment guide.
To post feedback, submit feature ideas, or report bugs, use the Issues section of this GitHub repo.
If you'd like to submit code for this Quick Start, please review the AWS Quick Start Contributor's Kit.
",5
anhad13/F1testing,Python,"F1testing
testing F1 from ON_LSTM on different datasets
",2
Auralcat/my-dotfiles,Emacs Lisp,"My dotfiles.
Influences:

https://github.com/shiroyasha/dotfiles
https://github.com/thoughtbot/dotfiles

Why share your dotfiles
",3
gocn/news,None,"news
GoCN æ¯æ¥æ°é»
",317
chan-sccp/chan-sccp,C,"Welcome to Chan_SCCP







.
Chan_SCCP is free software. Please see the file COPYING for details.
For documentation, please see the files in the doc subdirectory.
For building and installation instructions please see the INSTALL file.
Prerequisites
Make sure you have the following installed on your system:

c-compiler:

gcc >= 4.4  (note: older not supported, higher advised)
clang >= 3.6  (note: older not supported, higher advised)


gnu make
libraries:

libxml2-dev
libxslt1-dev
gettext


pbx:

asterisk >= 1.6.2 (absolute minimum)
asterisk >= 11.21 or asterisk >= 13.7 recommended
including source headers and debug symbols (asterisk-dev and asterisk-dbg / asterisk-devel and asterisk-debug-info)
chan_skinny module is prevented from loading in /etc/asterisk/modules.conf


standard posix compatible applications like sed, awk, tr

Building from source
Using git (recommended)
Clone github repository (once)
git clone https://github.com/chan-sccp/chan-sccp.git chan-sccp
cd chan-sccp

Update to latest state
cd chan-sccp
git fetch
git pull

Using Released tar.gz
retrieve the tar.gz from latest release and save it to /tmp/chan-sccp_latest.tar.gz
mkdir chan-sccp
cd chan-sccp
tar xvfz /tmp/chan-sccp_latest.tar.gz

Configuring
./configure [....configure flags you prefer...]

Note: For more information about the possible configure flags, check:
./configure --help
Note: When you are making changes to configure.ac, autoconf / or Makefile.am files you should run:
./tools/bootstrap.sh
Build and Install
make -j2 && make install && make reload

Required Asterisk Modules
Make sure you have the following asterisk modules loaded before loading the chan_sccp
module:

app_voicemail
bridge_simple
bridge_native_rtp
bridge_softmix
bridge_holding
res_stasis
res_stasis_device_state

Binaries
We also provide prebuild binaries for:

Ubuntu Lauchpad (PPA)
Asterisk-11

Debian-8.0


Asterisk-13

Debian-9.0
Fedora-23
Fedora-24
Fedora-25
Fedora-26
Ubuntu-16.04
Ubuntu-16.10
Ubuntu-17.04


Asterisk-16

OpenSuSE-Leap_15.0
OpenSuSE-Leap_42.2
OpenSuSE-Leap_42.3
OpenSuSE-Factory
OpenSuSE-Factory_ARM



Wiki
You can find more information and documentation on our 
Mailinglist


chan-sccp Discussion:

Subscribe
Archive
Search



chan-sccp Releases:

Subscribe
Archive
Search



Chat

Donate
If you like our project, then please consider to

License

",76
CraftingAsAService/FFXIVCrafting,PHP,"FFXIV Crafting
Crafting As A Service
An online tool to help crafters in Final Fantasy XIV: A Realm Reborn.
Routine Updates
Image for Footer: http://na.finalfantasyxiv.com/lodestone/special/patchnote_log/
",30
webprofusion/OpenAudio,None,"Open Source Audio Plugins & Apps
A list of open source VST (and other format) plugin/app projects. The intention of this list is to catalog open source plugins or apps which are fully featured or are useful examples which have non-trivial features.
The main benefit of having Open Source plugins/apps is that the code itself is preserved for the future, so when the author(s) stop updating it the community can continue using and developing the software. Open Source projects are also a great way to learn how different audio FX/instruments are created.
https://openaudio.webprofusion.com
Please contribute links!
Audio Plugins



Plugin
Description
Type
Framework




airwindows
Various small and experimental effect plugins
Effect



Argotlunar
Real-time delay-line granulator
Effect
JUCE


Cocoa Delay
Warm and lively delay
Effect
wdl-ol


Dexed
DX7 FM plugin synth
Instrument
JUCE


Digits
Phase-distortion synth inspired by Casio CZ series
Instrument
VSTGUI


Dragonfly Reverb
Hall-style reverb based on freeverb3 algorithms
Effect
DPF


Eurorack
Diverse set of physical modeling sources, organic processors, wavetable oscillators, waveshapers, granular synthesizers, and utility modules
Misc



Flutterbird
Simple pitch fluctuation
Effect
iPlug 2


Helm
Polyphonic synth with lots of modulation
Instrument
JUCE


keithhearne/VSTPlugins
A collection of VST plugins
Effect
JUCE


LameVST
LameMP3 as an effect
Effect



mda
FX and virtual instruments for PC and Mac
Misc



Mika Micro
Simple subtractive synth
Instrument
wdl-ol


OwlBass
Additive bass synth
Instrument
JUCE


regrader
Degenerative delay
Effect
VSTGUI


Roth-AIR
Mixing tool for easily adding airy, crispy presence to audio
Effect
JUCE


ScorchCrafter Guitar FX
Audio DSP FX and plug-ins, mostly for guitar (amp sim) and other FX
Effect



Surge
Subtractive wavetable synth
Instrument
VSTGUI


Synister
Subtractive software synth
Instrument
JUCE


VCVRack
Virtual modular synthesizer
Misc
rtaudio



Collections

VCRack Library - a library of plugins compatible with VCV Plugin Manager

Open Source Audio Apps



Software
Source
Description




Ardour
Ardour/ardour
DAW


ASIO2WASAPI
levmin/ASIO2WASAPI
Universal ASIO driver for Windows


Audacity
audacity/audacity
Audio editor


FlexASIO
dechamps/FlexASIO
Universal ASIO driver for Windows


Guitarix
SourceForge â guitarix
GNU/Linux Virtual Amplifier


Helio Workstation
helio-fm/helio-workstation
Sequencer


OwlPlug
DropSnorz/OwlPlug
Audio plugin manager


VCV Rack
VCVRack/Rack
Modular synthesizer



Open Source Software Development Libraries



Name
Source




Cabbage
https://github.com/rorywalsh/cabbage


Csound
https://github.com/csound/csound


Faust
https://github.com/grame-cncm/faust


iPlug2
https://github.com/iplug2/iplug2


JUCE
https://github.com/WeAreROLI/JUCE


rtaudio
https://github.com/thestk/rtaudio


PortAudio
https://app.assembla.com/spaces/portaudio/git/source


wdl-ol
https://github.com/olilarkin/wdl-ol



Code Samples

KlangFalter â a convolution audio plugin (e.g. for usage as convolution reverb)
FFTConvolver â an audio convolution algorithm in C++ for real time audio processing

Open Data Resources
OpenAIR â the Open Acoustic Impulse Response Library (Convolution Reverb Impulse Responses to recreate reverb character of space and equipment/recordings)
",89
dry-python/stories,Python,"
 
  
 
 



The business transaction DSL

Source Code
Issue Tracker
Documentation
Discussion


Installation
All released versions are hosted on the Python Package Index.  You can
install this package with following command.
pip install stories

Usage
stories provide a simple way to define a complex business scenario
that include many processing steps.
from stories import story, arguments, Success, Failure, Result

class Subscribe:

    @story
    @arguments('category_id', 'user_id')
    def buy(I):

        I.find_category
        I.find_profile
        I.check_balance
        I.persist_subscription
        I.show_subscription

    def find_category(self, ctx):

        category = Category.objects.get(id=ctx.category_id)
        return Success(category=category)

    def find_profile(self, ctx):

        profile = Profile.objects.get(user_id=ctx.user_id)
        return Success(profile=profile)

    def check_balance(self, ctx):

        if ctx.category.cost < ctx.profile.balance:
            return Success()
        else:
            return Failure()

    def persist_subscription(self, ctx):

        subscription = Subscription(ctx.category, ctx.profile)
        subscription.save()
        return Success(subscription=subscription)

    def show_subscription(self, ctx):

        return Result(ctx.subscription)
>>> Subscribe().buy(category_id=1, user_id=1)
<Subscription object>
>>> _
This code style allow you clearly separate actual business scenario
from implementation details.

License
Stories library is offered under the two clause BSD license.
",64
DataBiosphere/leonardo,Scala," 
Leonardo
Leo provisions Spark clusters through Google Dataproc and installs Jupyter notebooks and Hail on them. It can also proxy end-user connections to the Jupyter interface in order to provide authorization for particular users.
For more information and an overview, see the wiki.
Swagger API documentation: https://notebooks.firecloud.org/
Project status
This project is under active development. It is not yet ready for independent production deployment. See the roadmap section of the wiki for details.
Configurability
Documentation on how to configure Leo is Coming Soonâ¢. Until then, a brief overview: there are two points at which Leonardo is pluggable.
Authorization provider
Leo provides two modes of authorization out of the box:

By whitelist
Through Sam, the Workbench IAM service

Users wanting to roll their own authorization mechanism can do so by subclassing LeoAuthProvider and setting up the Leo configuration file appropriately.
Service account provider
There are (up to) three service accounts used in the process of spinning up a notebook cluster:

The Leo service account itself, used to make the call to Google Dataproc
The service account passed to dataproc clusters create via the --service-account parameter, whose credentials will be used to set up the instance and localized into the GCE metadata server
The service account that will be localized into the user environment and returned when any application asks for application default credentials.

Currently, Leo uses its own SA for #1, and the same per-user project-specific SA for #2 and #3, which it fetches from Sam. Users wanting to roll their own service account provision mechanism by subclassing ServiceAccountProvider and setting up the Leo configuration file appropriately.
Building and running Leonardo
Clone the repo.
$ git clone https://github.com/DataBiosphere/leonardo.git 
$ cd leonardo

Run Leonardo unit tests
Ensure docker is running. Spin up MySQL locally:
$ ./docker/run-mysql.sh start leonardo  

Build Leonardo and run tests.
export SBT_OPTS=""-Xmx2G -Xms1G -Dmysql.host=localhost -Dmysql.port=3311""
sbt clean compile test

Once you're done, tear down MySQL.
./docker/run-mysql.sh stop leonardo

Building Leonardo docker image
To install git-secrets
brew install git-secrets

To ensure git hooks are run
cp -r hooks/ .git/hooks/
chmod 755 .git/hooks/apply-git-secrets.sh

To build jar, leonardo docker image, and leonardo-notebooks docker image
./docker/build.sh jar -d build

To build jar, leonardo docker image, and leonardo-notebooks docker image
and push to repos broadinstitute/leonardo and broadinstitute/leonardo-notebooks
tagged with git hash
./docker/build.sh jar -d push

To build the leonardo-notebooks docker image with a given tag
bash ./jupyter-docker/build.sh build <TAG NAME>

To push the leonardo-notebooks docker image you built
to repo broadinstitute/leonardo-notebooks
bash ./jupyter-docker/build.sh push <TAG NAME>

",16
JoepVanlier/JSFX,Lua,"JSFX
This is a small bundle of JSFX and scripts for reaper.
You can install
these by adding the link:
https://raw.githubusercontent.com/JoepVanlier/JSFX/master/index.xml
to your reapack (https://reapack.com/) list of repositories. If you run
into issues with these, feel free to open an issue here on github.
Tight Compressor

This peak compressor is based on a paper by Giannoulis et al, ""Digital Dynamic Range Compressor DesignâA Tutorial and Analysis"", Journal of the Audio Engineering Society 60(6). It seems to be a pretty decent at tight style compression, with pretty aggressive attack. The compression is continuously visualized to help you dial in the appropriate settings.
Stereo Bub II

A fairly basic stereo widening tool. Widens the sound, but makes sure that the mono-mix stays unaffected (unlike Haas). The crossover is basically a 12 pole HPF that cuts the bass of the widening to avoid widening the bass too much. The last slider allows you to mix in the original side channel (which can optionally also be run through the 12-pole highpass).
There are two basic modes of operation:

You can either add stereo sound from nothing, using the Strength slider. This adds a comb filtered version of the average signal with opposite polarity to the different channels. Be careful not to overdo it, or you get a flangey sound (unless that is what you want).
You can manipulate the existing side channel that's in the input. The gain of the original side channel is scaled by the old ""Old side"" knob. Depending on the button ""HP original side"" this signal route will be highpassed (mono-izing the low frequencies).

Filther, a waveshaping filter / distortion plugin with dynamic processing.

Filther is a waveshaping / filterbank plugin that allows for some dynamic processing as well.
You can find a full manual for Filther here: https://joepvanlier.github.io/FiltherManual/
What does it sound like?
All the distortion/filtering on that track was done with this filter (mostly nonlin Kr0g and Rezzy):
https://soundcloud.com/saike/ohnoesitsaboss2/s-zYCOt
It can also sound pretty destructive:
https://soundcloud.com/saike/sine/s-mbHJL
https://soundcloud.com/saike/fm-modes-filther/s-KXwEQ
The more experimental filters (such as ""Experimental"" and ""Phase Mangler"") can be used on pads to make eerie soundscapes: https://soundcloud.com/saike/filter-ambience/s-UxdLO
Here's a short tutorial on how to use it: https://www.youtube.com/watch?v=jtc8kp57xpI
For more information, or to contact the author, see the forum thread here: https://forum.cockos.com/showthread.php?t=213269
Waveshaping
Filther supports saturating soft clipping as well as drawing custom voltage curves using a spline. For the simpler filters, the distortion is simply applied before the filtering stage, but for some the filter is located in the filter scheme. In these cases, the distortion is either applied on the delayed or during solving the implicit equations for the supplied zero delay feedback filters (ZDF).
Filters
Filther contains two filter modules which can be automated by dynamics and LFO. The routing of the A and B filter can be altered (serial, parallel modes, plus control over the number of times the waveshaper is applied),
Filther contains a large variety of filters, each with their own advantages and drawbacks. Most of the filters behave non-ideal and are intended for creative purposes rather than fidelity to specification. Note that not all filters are stable for all combinations of resonance and waveshaping. Using very sharp transitions in the spline waveshaper can result in filter instability for the filters where waveshaping is part of the filter. Filther contains a large array of filters listed below:

Feedback section
There is an additional feedback section, which can be activated.  Feedback can be used to fatten up filters and in some cases regain control of the resonance. If you want some fatness/resonance fighting, keep the delay firmly placed at zero. The feedback delay chain has the exact opposite polarity of the resonance in most chains, so in this mode, it will fight with the resonance to sort of choke in on itself (see diode ladder or ms-20 for this effect). This can make the resonance less ringey, more chunky and a lot more pleasant to listen to. Note that the global feedback is not ZDF. Also note that using feedback, reduces the maximum number of spline nodes by two.
For phasey effects, use feedback with larger delays. Note however that then you're in the danger zone, because once resonance starts boosting resonance, things get real dicey. I would always recommend playing with this only if you have AGC on.
Automatic Gain Control
When tweaking, enable Automatic Gain Control to protect your ears from resonance issues. This rescales the volume so that the RMS value post filter is the same as the input level (meaning that you can leave the post fader at 0 dB). You can transfer the estimated gain to the post-gain fader with the outer mouse once you've honed in on a preset you like.
Dynamics
Filther also supports dynamically modifying the filter and waveshaping settings, by checking ""Filter"" and/or ""Shaping"" in the Dynamics section. Dynamics can be monitored in the dynamics window. Here you will see the input RMS (red curve), output RMS (blue curve), dynamic variable and threshold (click and drag to zoom). The dynamic variable (yellow curve) will start accumulating when the input RMS is above the threshold. The threshold can be dragged with the mouse or set in the dynamics panel. Averaging can be increased by modifying the RMS time. This will smoothen out the RMS values that you see (and the dynamics will respond accordingly). Alternatively, dynamics can be triggered by MIDI note events.
Waveshaping Dynamics
For waveshaping, Filther will interpolate between the non-waveshaped and waveshaped voltage response (1 being the fully waveshaped version).
Filter Dynamics
The extent of modulation on the filter can be set with the outer mouse button. This will showed a greyed area that will show the extent of the dynamics being applied. When the dynamics are at maximum, the parameter value will be at the full extent of this greyed area.
Tone Stacks

Based on the work of jatalahd and ~arph from diystompboxes.com forum.
See their plugin here: http://www.guitarscience.net/tsc/info.htm
I've made some bi-linearly transformed versions of these filters which emulate classic tone stacks.
Multi-channel spectral analyser with sonogram and time window
I needed a plugin that I could keep open on one screen to monitor things.
Hence I modified the stock Reaper spectral analyzer to allow for
multi-channel analysis and combine it with a sonogram and time window.

The JSFX comes with a lua script which sets up the routing appropriately
on a new FX track.
White/Black
Chooses background color.
Smoothing
Chooses size of spectral smoothing. Spectral smoothing is performed in
the frequency domain,
using larger smoothing for higher values. Note
that this is not an unbiased smoother.
More smoothing means that peaks
get wider and the spectrum becomes less accurate.  The noise
is also
suppressed however, which makes it easier to read when there are multiple
spectra.
Color map
Specifies colormap for spectral analyzer.
Scale
Scale indicators the zoom factor on the spectrum analyzer.
Integrate
Integrate spectrum over time. This makes the spectrum less noisy, but
less sensitive to short transients. Smoothness is a tradeoff between
smoothing (width), integration time (transients)
and noise (no smoothing
or integration time).
Floor
Specify where to put the noise floor.
Window
Window function. Defaults to Blackman-Harris for its resolution.
FFT
FFT window size. 8192 is pretty good. Higher is heavier on the CPU.
Log(Sonogram)
Enabling this shows the sonogram with a logarithmic frequency axis.
Disabling it means linear.
Sonogram/Time toggle
Determine whether you want to see the waveform or the sonogram.
Waveform is good for studying
transients. Sonogram is good for
studying frequencies over time.
Channel buttons
The next buttons indicate what channels are visualized. Enabling
or disabling them can be done
by clicking them with the left
mouse button. Clicking them with the right mouse button will make
them the active channel in the sonogram or time window. This way,
you can study the sonograms of  the channels separately.
Sum
Indicates the sum of the signal. This will show the left and right
channel in black and grey in the main graph. Enabling or disabling
can be done by left clicking. Clicking this with the outer mouse
button will show the signal in the sonogram or time window.
Ch1 - Ch16
The channels that are routed to the spectral analyser. Enabling or
disabling can be done by left
clicking. Clicking this with the outer
mouse button will show the signal in the sonogram or time
window.
Sonogram mode
Double-clicking the sonogram will toggle its size. Clicking and
dragging with the left mouse button
will change how bright it is.
Clicking with the right mouse button will switch colormap. The channel
you're viewing and the scale are shown on the top left. The colormap
on the bottom left. Switch with outer mouse button on the channel
button in the second row on the top. Mousewheel will change the
scaling
w.r.t. the frequency axis. Doubleclicking alters the sonogram size.
Time mode
Clicking and dragging or using the mouse wheel  will change the scale
of the graph. The channel you're
viewing is shown on the top left. Switch
with outer mouse button on the channel button in the second row on the top.
Doubleclicking alters the signal window size.
SideSpectrum Meter
A stereo spectral analyzer to study how much the left and right channel
differ.
StereoManipulator
A stereo width manipulator with a large number of filters.
Splits the channel into two via crossover filter. Both channels can then
be mono-ified separately. Use FIR filter for strong transients, but note
that this incurs N/2 delay of the signal. Larger filters are required for
cutting lower freq. Larger filters will also reduce aliasing. Use high
order IIR for less transient heavy stuff. This incurs no global delay
but may alter transients. FIRs are much more expensive than IIRs.
If you hear phase cancellation, set use channel to left or right rather
than mix. Note that widths other than 0 or 100% in this setting is not
recommended since this will create volume differences between left and right.
",6
Ferocia/snek,Ruby,"
ðâ¨Snek
Just like on the Nokia 3210

What
A programming game made with love for Railscamp in the tradition of treasure wars, brains, ant wars etc etc.

You are snake (snek).  Your want to be biggest snek.  Avoid other snek.  Walls too.


Rules
You spawn at a random location.
Every 1 second you get a chance to submit a move [""N"", ""S, ""E"", ""W""].  If you don't submit a move, you will move forward.
Every 5 ticks you will grown by one
If you hit a wall, your snek dies.  If you crash into yourself, your snek dies.  If you hit another snek, your snek dies.  If another snek hits you, that snek dies.  If you head on collide with another snek, both sneks die.
Become the biggest snek.
How to do it
You connect to the server via websockets - there's a sample client and utility code in /client
Quick start
You need to run 3 processes: the server, the client, and the game.
cd server
bundle && yarn && rake db:create db:schema:load
bundle exec rails server

[new tab]
cd server && bundle exec rake game:run

[new tab]
cd client
bundle && yarn
bundle exec ruby runner.rb

PR's Welcome!
If you feel like chipping in there's loads of things you could do.  Maybe:

Add some better obstacles to the map
Improve the styling of the front end
Make the snakes look better
Add food
Improve the error handling of the client code
Surely it needs sound effects right?

",2
polarphp/polarphp,C++,"
Read the English version of this document: English version Readme
éè¯»æ¬ææ¡£å¶ä»è¯­è¨çæ¬: English, ç®ä½ä¸­æ.
ä¸ºä»ä¹è¦å polarphp é¡¹ç®
éçGoåNodeJSçå¼ºå¿å´èµ·ï¼PHPçå¸åºä»½é¢éæ¸è¢«èé£ï¼èPHPå®æ¹ä»ç¶åå®å¨Webç¼ç¨é¢åï¼æäºä¸è¥¿è¶æ¯æ³å®ä½å°±è¶å®ä¸ä½ãpolarphpåé´NodeJSåGoçç¸å³ç¹æ§å¯¹zendVMéæ°å°è£ï¼å»æPHPä¸äºå¤èå¼ç¨çç¹æ§åå¼ºWebå±æ§ï¼éè¿å®ç°ä¸å¥æ°çè¿è¡æ¶æ¡æ¶libpdkï¼å°PHPè¯­è¨æé æä¸ºä¸é¨çæ­£çéç¨æ§èæ¬è¯­è¨ï¼èµè½PHPï¼è®©å¶æ¥æå¼æ­¥ç¼ç¨ï¼åç¨ï¼çº¿ç¨ï¼åç½®çunicodeæ¯æï¼æ åçæä»¶IOç­ç­ç¹æ§ï¼è®©PHPç¨åºåä¸ä»ä»è½åwebåºç¨ï¼ä¹è½ä»å®¹é¢å¯¹çæ­£çæå¡ç«¯åºç¨ãpolarphpä¸æ¯ä¸é¨æ°çè¯­è¨ï¼èæ¯PHPè¯­è¨çä¸ç§è¿è¡æ¶å®¹å¨ã
ä¸»è¦ç¹æ§

 å¼å®¹ææ°çPHPè¯­è¨æ åï¼ç§»é¤åºå¼è¯­è¨ç¹æ§
 åç½®unicodeå­ç¬¦æ åæ¯æ
 å¨åè½åè¿è¡æ¶åºæ¯æï¼æ¯æå¼æ­¥ç¼ç¨ï¼å¤çº¿ç¨ååç¨ç­ç­ç¼ç¨æ¨¡å¼
 åç½®åç®¡çå¨
 åç½®ææ¡£çæå¨

å¼åè®¡å
å ä¸ºå¼åèµæºæéï¼å¼åè®¡åæå®å¦ä¸ï¼

ä½¿ç¨cmakeå¯¹zend VMè¿è¡ç¼è¯ï¼çæpolarphpå®å¶ççPHPè¯­è¨èææº
è¯­è¨æ¯æé¡¹ç®ï¼è¯­è¨æµè¯æ¡æ¶ï¼ç§»æ¤LLVMé¡¹ç®çlitæµè¯æ¡æ¶
å®ç°polarphpé©±å¨ç¨åºï¼å®ç°ä»å½ä»¤è¡æ§è¡PHPä»£ç 
å¯¹polarphpèææºè¿è¡åå½æµè¯ï¼æå®è·éPHPçè¯­è¨èææºç¸å³åå½æµè¯
å®ç°polarphpçåç½®å½æ°
åå¸æ ¸å¿èææºçdockeréå
æ´ålibpdkè¿è¡æ¶æ¡æ¶
å®ç°äººæ§åå®è£ï¼å°½éä»¥æå°çæ­¥éª¤è¿è¡polarphpçå®è£
å®ç°åç®¡çå¨
å®ç°è¯­è¨éå¥å°å·¥å·ï¼æ¯å¦ææ¡£çæå·¥å·ç­ç­

å¼å§ä½éª
åépolarphpé¡¹ç®åº
git clone https://github.com/polarphp/polarphp.git
cd polarphp
git submodule init
git submodule update
git checkout v0.0.1-alpha

è¿è¡èæ¬
./devtools/scripts/build_polarphp.sh

è¿ä¸ªæ¶åèæ¬å¼å§ç¼è¯ç¸å³éåï¼èæ¶æ¯è¾é¿ï¼è¯·æ¨èå¿ç­å¾ãç­å¾ç¼è¯å®æï¼æ¨è¿è¡ï¼
docker images

è¿ä¸ªæ¶åè¯·ç¡®è®¤å¨è¾åºä¸­æå¦ä¸éåï¼

polarphp_base_env
polarphp_debug

å¦ææ²¡æé®é¢ï¼æä»¬å¼å§æµè¯polarphpæ¯å¦å¨éåä¸­æ­£å¸¸è¿è¡ã
docker run --rm -it polarphp_debug

è¿å¥å®¹å¨åï¼è¾å¥æä»¬çpolarphpå½ä»¤è¡ç¨åº
polar --version

å¦ææ¨å¾å°ä¸é¢çè¾åºï¼
polarphp 0.0.1-git (built: 2019-01-27 12:22)
Copyright (c) 2016-2018 The polarphp foundation (https://polar.foundation)
Zend Engine v3.3.0-dev, Copyright (c) 1998-2018 Zend Technologies

æ­åæ¨ï¼æ¨å·²ç»æåç¼è¯äºpolarphpè¿è¡æ¶ç¯å¢ã
å¨ç¼è¯éåçæ¶åï¼æä»¬å¨~/temp/æä»¶å¤¹ä¸­æ¾å¥äºä¸ä¸ªæµè¯èæ¬
if (function_exists('\php\retrieve_version_str')) {
    echo ""version str: "" . \php\retrieve_version_str() . ""\n"";
}

if (function_exists('\php\retrieve_major_version')) {
    echo ""major version: "" . \php\retrieve_major_version() . ""\n"";
}

if (function_exists('\php\retrieve_minor_version')) {
    echo ""minor version: "" . \php\retrieve_minor_version() . ""\n"";
}

if (function_exists('\php\retrieve_patch_version')) {
    echo ""patch version: "" . \php\retrieve_patch_version() . ""\n"";
}

æ¨å¯ä»¥è¿è¡ä¸ä¸å½ä»¤ï¼
polar ~/temp/main.php

å¦ææ²¡æéè¯¯ï¼æ¨å°å¾å°ä¸é¢çè¾åºï¼
version str: polarphp 0.0.1-git
major version: 0
minor version: 0
patch version: 1

æè°¢æ¨æµè¯polarphpï¼æä»ä¹é®é¢ï¼è¯·æ«æä¸é¢çå¾®ä¿¡äºç»´ç è¿ç¾¤äº¤æµã
ç¤¾åº
ç®åæä»¬ææ¶åªéå¯¹ä¸­å½çç¨æ·ï¼æä»¥éç¨äºå¾®ä¿¡åQQç¾¤çäº¤æµæ¹å¼ï¼ä¸é¢æ¯äºç»´ç ï¼æå´è¶£çåå­¦å¯ä»¥æ«ç å å¥ï¼

PSï¼æ«ç è¯·æ³¨ææ¥æï¼æ¯å¦ï¼å­¦ä¹ polarphpæèPHPç±å¥½è

















ç®åæä»¥ä¸å·¥ä½ç»

è¯­è¨æ ¸å¿å¢é
æ ååºå¢é
çæé¾é¡¹ç®å¢é
ææ¡£å¢é
å®æ¹ç½ç«ç»´æ¤å¢é

ææåè®®
polarphpå¨phpè¯­è¨é¡¹ç®ä¹ä¸è¿è¡äºæ¬¡å¼åï¼éµå®phpé¡¹ç®çåè®®ï¼è¯¦æè¯·çï¼é¡¹ç®åè®®
è´¡ç®ä»£ç å¼å¯¼
===========================

CODING_STANDARDS
README.GIT-RULES
README.MAILINGLIST_RULES
README.RELEASE_PROCESS

ç¹å«æè°¢





















",804
RT-Thread/rt-thread,C,"RT-Thread
ä¸­æé¡µ |






RT-Thread is an open source IoT operating system from China, which has strong scalability: from a tiny kernel running on a tiny core, for example ARM Cortex-M0, or Cortex-M3/4/7, to a rich feature system running on MIPS32, ARM Cortex-A8, ARM Cortex-A9 DualCore etc.
Overview
RT-Thread RTOS like a traditional real-time operating system. The kernel has real-time multi-task scheduling, semaphore, mutex, mail box, message queue, signal etc. However, it has three different things:

Device Driver;
Component;
Dynamic Module

The device driver is more like a driver framework, UART, IIC, SPI, SDIO, USB device/host, EMAC, MTD NAND etc. The developer can easily add low level driver and board configuration, then combined with the upper framework, he/she can use lots of features.
The Component is a software concept upon RT-Thread kernel, for example a shell (finsh/msh shell), virtual file system (FAT, YAFFS, UFFS, ROM/RAM file system etc), TCP/IP protocol stack (lwIP), POSIX (thread) interface etc. One component must be a directory under RT-Thread/Components and one component can be descripted by a SConscript file (then be compiled and linked into the system).
The Dynamic Module, formerly named as User Applicaion (UA) is a dynamic loaded module or library, it can be compiled standalone without Kernel. Each Dynamic Module has its own object list to manage thread/semaphore/kernel object which was created or initialized inside this UA. More information about UA, please visit another git repo.
Board Support Package
RT-Thread RTOS can support many architectures:

ARM Cortex-M0
ARM Cortex-M3/M4/7
ARM Cortex-R4
ARM Cortex-A8/A9
ARM920T/ARM926 etc
MIPS32
x86
Andes
C-Sky
RISC-V
PowerPC

License
RT-Thread is Open Source software under the Apache License 2.0 since RT-Thread v3.1.1. License and copyright information can be found within the code.
/*
 * Copyright (c) 2006-2018, RT-Thread Development Team
 *
 * SPDX-License-Identifier: Apache-2.0
 */

Since 9th of September 2018, PRs submitted by the community may be merged into the main line only after signing the Contributor License Agreement(CLA).
Usage
RT-Thread RTOS uses scons as building system. Therefore, please install scons and Python 2.7 firstly.
So far, the RT-Thread scons building system support the command line compile or generate some IDE's project. There are some option varaibles in the scons building script (rtconfig.py):

CROSS_TOOL the compiler which you want to use, gcc/keil/iar.
EXEC_PATH the path of compiler.

In SConstruct file:
RTT_ROOT This variable is the root directory of RT-Thread RTOS. If you build the porting in the bsp directory, you can use the default setting. Also, you can set the root directory in RTT_ROOT environment variable and not modify SConstruct files.
When you set these variables correctly, you can use command:
scons

under BSP directory to simplely compile RT-Thread RTOS.
If you want to generate the IDE's project file, you can use command:
scons --target=mdk/mdk4/mdk5/iar/cb -s

to generate the project file.
NOTE: RT-Thread scons building system will tailor the system according to your rtconfig.h configuration header file. For example, if you disable the lwIP in the rtconfig.h by commenting the #define RT_USING_LWIP, the generated project file should have no lwIP related files.
Contribution
Please refer the contributors in the github. Thank all of RT-Thread Developers.
",2553
Bistua/flutter_shop,Dart,"##1
flutter android ios google hybridæ¹æ¡
éè¦flutterææ°ç1.2
æèä½¿ç¨dev1.19çä¹è¡
##2
å¶å®çæ¬ä¸ç¡®å®æ¯å¦æ¯æhybrid
æ°å»ºç®å½â bristuaftshopâ

å¨â bristuaftshopâ ä¸­ cloneæ¬é¡¹ç®

æèï¼
ä¿®æ¹settings.gradle

å°'./bristuaftshop/flutter_lib/.android/include_flutter.groovy'ä¸­ç

bristuaftshopæ¹æä½ çç¶ç±»æä»¶å¤¹ç®å½

##3æ§è¡ä»¥ä¸å½ä»¤
cd flutter_lib
flutter build apk
google hybridæ¹æ¡ï¼https://github.com/flutter/flutter/wiki/Add-Flutter-to-existing-apps
ååå¾ï¼
https://fbw50t.axshare.com/#g=1
å¯ç ï¼201902
èå¾å°åï¼
https://lanhuapp.com/url/tzWeO
ç¾åº¦äºå°åï¼
https://pan.baidu.com/s/12gGDI8O5WicXhgkXaEdFMQ
å¯ç : nxms
ç¦é é¡¹ç®è·è¿ç³»ç»ï¼
pm.bristua.com
åå§å¯ç ï¼bristua123456
è´¦å·ï¼ä¸ªäººææºå·
",5
RT-Thread/rt-thread,C,"RT-Thread
ä¸­æé¡µ |






RT-Thread is an open source IoT operating system from China, which has strong scalability: from a tiny kernel running on a tiny core, for example ARM Cortex-M0, or Cortex-M3/4/7, to a rich feature system running on MIPS32, ARM Cortex-A8, ARM Cortex-A9 DualCore etc.
Overview
RT-Thread RTOS like a traditional real-time operating system. The kernel has real-time multi-task scheduling, semaphore, mutex, mail box, message queue, signal etc. However, it has three different things:

Device Driver;
Component;
Dynamic Module

The device driver is more like a driver framework, UART, IIC, SPI, SDIO, USB device/host, EMAC, MTD NAND etc. The developer can easily add low level driver and board configuration, then combined with the upper framework, he/she can use lots of features.
The Component is a software concept upon RT-Thread kernel, for example a shell (finsh/msh shell), virtual file system (FAT, YAFFS, UFFS, ROM/RAM file system etc), TCP/IP protocol stack (lwIP), POSIX (thread) interface etc. One component must be a directory under RT-Thread/Components and one component can be descripted by a SConscript file (then be compiled and linked into the system).
The Dynamic Module, formerly named as User Applicaion (UA) is a dynamic loaded module or library, it can be compiled standalone without Kernel. Each Dynamic Module has its own object list to manage thread/semaphore/kernel object which was created or initialized inside this UA. More information about UA, please visit another git repo.
Board Support Package
RT-Thread RTOS can support many architectures:

ARM Cortex-M0
ARM Cortex-M3/M4/7
ARM Cortex-R4
ARM Cortex-A8/A9
ARM920T/ARM926 etc
MIPS32
x86
Andes
C-Sky
RISC-V
PowerPC

License
RT-Thread is Open Source software under the Apache License 2.0 since RT-Thread v3.1.1. License and copyright information can be found within the code.
/*
 * Copyright (c) 2006-2018, RT-Thread Development Team
 *
 * SPDX-License-Identifier: Apache-2.0
 */

Since 9th of September 2018, PRs submitted by the community may be merged into the main line only after signing the Contributor License Agreement(CLA).
Usage
RT-Thread RTOS uses scons as building system. Therefore, please install scons and Python 2.7 firstly.
So far, the RT-Thread scons building system support the command line compile or generate some IDE's project. There are some option varaibles in the scons building script (rtconfig.py):

CROSS_TOOL the compiler which you want to use, gcc/keil/iar.
EXEC_PATH the path of compiler.

In SConstruct file:
RTT_ROOT This variable is the root directory of RT-Thread RTOS. If you build the porting in the bsp directory, you can use the default setting. Also, you can set the root directory in RTT_ROOT environment variable and not modify SConstruct files.
When you set these variables correctly, you can use command:
scons

under BSP directory to simplely compile RT-Thread RTOS.
If you want to generate the IDE's project file, you can use command:
scons --target=mdk/mdk4/mdk5/iar/cb -s

to generate the project file.
NOTE: RT-Thread scons building system will tailor the system according to your rtconfig.h configuration header file. For example, if you disable the lwIP in the rtconfig.h by commenting the #define RT_USING_LWIP, the generated project file should have no lwIP related files.
Contribution
Please refer the contributors in the github. Thank all of RT-Thread Developers.
",2553
Bistua/flutter_shop,Dart,"##1
flutter android ios google hybridæ¹æ¡
éè¦flutterææ°ç1.2
æèä½¿ç¨dev1.19çä¹è¡
##2
å¶å®çæ¬ä¸ç¡®å®æ¯å¦æ¯æhybrid
æ°å»ºç®å½â bristuaftshopâ

å¨â bristuaftshopâ ä¸­ cloneæ¬é¡¹ç®

æèï¼
ä¿®æ¹settings.gradle

å°'./bristuaftshop/flutter_lib/.android/include_flutter.groovy'ä¸­ç

bristuaftshopæ¹æä½ çç¶ç±»æä»¶å¤¹ç®å½

##3æ§è¡ä»¥ä¸å½ä»¤
cd flutter_lib
flutter build apk
google hybridæ¹æ¡ï¼https://github.com/flutter/flutter/wiki/Add-Flutter-to-existing-apps
ååå¾ï¼
https://fbw50t.axshare.com/#g=1
å¯ç ï¼201902
èå¾å°åï¼
https://lanhuapp.com/url/tzWeO
ç¾åº¦äºå°åï¼
https://pan.baidu.com/s/12gGDI8O5WicXhgkXaEdFMQ
å¯ç : nxms
ç¦é é¡¹ç®è·è¿ç³»ç»ï¼
pm.bristua.com
åå§å¯ç ï¼bristua123456
è´¦å·ï¼ä¸ªäººææºå·
",5
jidroid404/MLiterature,None,"Getting a taste of Research Papers-ð¯

Repo to track my progress on New Resolution of reading, understanding and tinkering with Machine Learning Research Papers.



Category




Computer Vision


Convolutional Neural Networks


Federated Learning


Generative Models


Geometric Deep Learning


Initialization And Optimization


Miscellaneous


Natural Language Processing


Reinforcement Learning



Computer Vision




Title
Tags




1.
Panoptic Feature Pyramid Networks



2.
Unsupervised Data Augmentation



3.
Fast AutoAugment



4.
DeViSE: A Deep Visual-Semantic Embedding Model



5.
S4L: Self-Supervised Semi-Supervised Learning



6.
Processing Megapixel Images with Deep Attention-Sampling Models



7.
LEDNet: A Lightweight Encoder-Decoder Network for Real-Time Semantic Segmentation




Convolutional Neural Networks




Title
Tags




1.
Bag of Tricks for Image Classification with Convolutional Neural Networks



2.
Drop an Octave: Reducing Spatial Redundancy in Convolutional Neural Networks with Octave Convolution



3.
Local Relation Networks for Image Recognition



4.
Invertible Residual Networks



5.
Kervolutional Neural Networks



6.
4D Spatio-Temporal ConvNets: Minkowski Convolutional Neural Networks



7.
Approximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet



8.
Making Convolutional Networks Shift-Invariant Again



9.
Attention Augmented Convolutional Networks



10.
Rethinking Atrous Convolution for Semantic Image Segmentation




Federated Learning




Title
Tags




1.
Towards Federated Learning at Scale



2.
Federated Learning for Mobile Keyboard Prediction



3.
Federated Reinforcement Learning



4.
Federated Learning: Strategies for Improving Communication Efficiency



5.
Gaussian Differential Privacy




Generative Models




Title
Tags




1.
A Style-Based Generator Architecture for Generative Adversarial Networks 



2.
Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks



3.
Controllable Artistic Text Style Transfer via Shape-Matching GAN



4.
SinGAN: Learning a Generative Model from a Single Natural Image



5.
Sketchforme: Composing Sketched Scenes from Text Descriptions for Interactive Applications



6.
Few-Shot Unsupervised Image-to-Image Translation



7.
Semantic Image Synthesis with Spatially-Adaptive Normalization



8.
Self-Attention Generative Adversarial Networks




Deep Learning on Graphs




Title
Tags




1.
Deep Learning on Graphs : A Survey



2.
Graph Neural Networks: A Review of Methods and Applications



3.
A Comprehensive Survey on Graph Neural Networks



4.
Graph Matching Networks for Learning the Similarity of Graph Structured Objects




Initialization And Optimization




Title
Tags




1.
Fixup Initialization: Residual Learning Without Normalization



2.
A disciplined approach to neural network hyper-parameters: Part 1 -- learning rate, batch size, momentum, and weight decay



3.
L4: Practical loss-based stepsize adaptation for deep learning



4.
A Mean Field Theory of Batch Normalization



5.
The Lottery Ticket Hypothesis:Finding Sparse,Trainable Neural Networks



6.
Deconstructing Lottery Tickets: Zeros, Signs, and the Supermask



7.
The Lottery Ticket Hypothesis at Scale



8.
REGAL: Transfer Learning For Fast Optimization of Computation Graphs




Miscellaneous




Title
Tags




1.
EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Task



2.
Attentive Neural Processes



3.
TensorLy: Tensor Learning in Python



4.
Meta-Sim: Learning to Generate Synthetic Datasets



5.
Low-Memory Neural Network Training: A Technical Report



6.
Using Deep Learning to Annotate the Protein Universe



7.
Initialized Equilibrium Propagation for Backprop-Free Training



8.
MixMatch: A Holistic Approach to Semi-Supervised Learning



9.
Adversarial Examples Are Not Bugs, They Are Features



10.
Style Transfer by Relaxed Optimal Transport and Self-Similarity




Natural Language Processing




Title
Tags




1.
BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding



2.
Parameter-Efficient Transfer Learning for NLP



3.
Attention Is All You Need



4.
Visualizing Attention in Transformer-Based Language Representation Models



5.
Language Models with Transformers



6.
Generating Long Sequences with Sparse Transformers



7.
Neural Networks for Modeling Source Code Edits



8.
Sample Efficient Adaptive Text-to-Speech



9.
Unified Language Model Pre-training for Natural Language Understanding and Generation



10.
Controllable Neural Story Plot Generation via Reward Shaping




Reinforcement Learning




Title
Tags




1.
Scalable agent alignment via reward modeling: a research direction



2.
Reinforcement Learning with Attention that Works: A Self-Supervised Approach



3.
Challenges of Real-World Reinforcement Learning



4.
An Introduction to Deep Reinforcement Learning




",31
IdleLands/IdleLands4,TypeScript,"IdleLands4
ð
Requirements

Git
MongoDB (not tested against other DBs)
Node 10.x

MongoDB Note
The game is only tested against MongoDB. TypeORM currently lacks support for joins, etc and these are done manually. Additionally, the seed process requires using MongoDB. This could be cleaned up in the future, but is not a priority right now.
Getting Started

Clone the repo
npm install
If you do not have an assets folder, run npm run postinstall
npm run seed
Create .env file (see Environment Variables)

Environment Variables
Create a .env file in the root of the cloned project and fill it with these values.
Required

TYPEORM_CONNECTION - the DB type (you probably want to use mongodb)
TYPEORM_URL - the URL to connect to the DB
TYPEORM_SYNCHRONIZE - set to true
TYPEORM_ENTITIES - set to src/shared/models/entity/**/*.ts

Optional

SCC_BROKER_REDIS_HOST - the URL to the Redis instance
SCC_BROKER_REDIS_PORT - the port of the Redis instance
GAME_DELAY - the game loop delay. Default: 5000ms.
GRACE_PERIOD_DISCONNECT - the delay between disconnect and character exiting game. Default: 30000ms.
FIREBASE_ADMIN_DATABASE - the admin database URL for firebase. Should be in the format https://<DATABASE_NAME>.firebaseio.com.
FIREBASE_ADMIN_JSON - the JSON blob (stringified) for a service account private key. You can read how to do that here.
DISCORD_SECRET - the Discord API secret for your created Discord bot
DISCORD_GUILD_ID - the Discord guild ID
DISCORD_CHANNEL_ID - the Discord channel ID

Useful Commands

npm run start:server - start the server
npm run start:client - start the client

",3
zpoint/CPython-Internals,None,"Cpython Internals

ç®ä½ä¸­æ
watching this repo so that you will be notified when there's update

This repository is my notes/blog for cpython source code
Trying to illustrate every detail of cpython implementation
# based on version 3.8.0a0
cd cpython
git reset --hard ab54b9a130c88f708077c2ef6c4963b632c132b3

Table of Contents

Objects
Modules
Lib
Interpreter
learning material

Objects

 dict
 long/int
 unicode/str
 set
 list
 tuple
 bytes
 bytearray
 float
 func(user-defined method)
 method(builtin method)
 iter
 gen
 class(bound method/classmethod/staticmethod)
 complex
 enum

Modules

 io

 fileio



Lib

 re
 asyncio

Interpreter

 frame
 code
 descr
 exception
 module
 namespace
 GIL
 gc
 memory management

learning material
I will only recommend what I've read

rushter
YET ANOTHER PYTHON INTERNALS BLOG
CPython internals - Interpreter and source code overview
< < Inside The Python Virtual Machine > >
< < Pythonæºç åæ > >

",236
scummvm/scummvm,C++,"ScummVM README Â·   
For more information, compatibility lists, details on donating, the
latest release, progress reports and more, please visit the ScummVM home
page at: https://www.scummvm.org/
Table of Contents:

1.0) Introduction

1.1) About ScummVM
1.2) Quick start
1.3) F.A.Q.


2.0) Contact

2.1) Reporting Bugs


3.0) Supported Games

3.1) Copy Protection
3.2) Datafiles
3.3) Multi-CD games notes
3.4) Known Problems
3.5) Extra Data Files
3.6) Broken Sword games notes

3.6.1) Broken Sword
3.6.2) Broken Sword II
3.6.3) Broken Sword games
cutscenes
3.6.4) Broken Sword games cutscenes, in
retrospect


3.7) Day of the Tentacle notes
3.8) Dragon History notes
3.9) Flight of the Amazon Queen
notes
3.10) Gobliiins notes
3.11) Inherit the Earth: Quest for the Orb
notes
3.12) Mickey's Space Adventure
notes
3.13) Might and Magic Xeen games
notes
3.14) Myst game notes
3.15) Quest for Glory notes
3.16) Riven game notes
3.17) Simon the Sorcerer games
notes
3.18) Starship Titanic game
notes
3.19) The Curse of Monkey Island
notes
3.20) The Feeble Files notes
3.21) The Legend of Kyrandia
notes
3.22) Troll's Tale notes
3.23) Winnie the Pooh notes
3.24) Sierra AGI games: Predictive Input
Dialog
3.25) Sierra SCI games: Simultaneous speech and
subtitles
3.26) Zork games notes

3.26.1) Zork Nemesis: The Forbidden
Lands
3.26.2) Zork: Grand
Inquisitor


3.27) Commodore64 games notes
3.28) Macintosh games notes


4.0) Supported Platforms
5.0) Running ScummVM

5.1) Command Line Options
5.2) Global Menu
5.3) Graphics filters
5.4) Hotkeys
5.5) Language options


6.0) Saved Games

6.1) Autosaves
6.2) Converting Saved Games
6.3) Viewing/Loading saved games from the command
line


7.0) Music and Sound

7.1) AdLib emulation
7.2) FluidSynth MIDI emulation
7.3) MT-32 emulation
7.4) MIDI emulation
7.5) Native MIDI support

7.5.1) Using MIDI options to customize Native MIDI
output


7.6) UNIX native, ALSA and dmedia sequencer
support

7.6.1) ALSA sequencer [UNIX
ONLY]
7.6.2) IRIX dmedia sequencer: [UNIX
ONLY]


7.7) TiMidity++ MIDI server
support
7.8) Using compressed audio
files

7.8.1) Using MP3 files for CD
audio
7.8.2) Using Ogg Vorbis files for CD
audio
7.8.3) Using Flac files for CD
audio
7.8.4) Compressing MONSTER.SOU with
MP3
7.8.5) Compressing MONSTER.SOU with Ogg
Vorbis
7.8.6) Compressing MONSTER.SOU with
Flac
7.8.7) Compressing music/sfx/speech in AGOS
games
7.8.8) Compressing speech/music in Broken
Sword
7.8.9) Compressing speech/music in Broken Sword
II


7.9) Output sample rate


8.0) Configuration file

8.1) Recognized configuration
keywords
8.2) Custom game options that can be toggled via the
GUI


9.0) Screenshots (SDL backend
only)
10.0) Compiling
11.0) Changelog
12.0) Credits

1.0) Introduction
1.1) About ScummVM
ScummVM is a program which allows you to run certain classic graphical
point-and-click adventure games, provided you already have their data
files. The clever part about this: ScummVM just replaces the executables
shipped with the game, allowing you to play them on systems for which
they were never designed!
Originally it was designed to run LucasArts' SCUMM games, such as Maniac
Mansion, Monkey Island, Day of the Tentacle or Sam and Max. SCUMM stands
for 'Script Creation Utility for Maniac Mansion', which was the first
game for which LucasArts designed this system. And much later it gave
its name to ScummVM ('VM' meaning Virtual Machine).
Over time support for a lot of non-SCUMM games has been added, and
ScummVM now also supports many of Sierra's AGI and SCI games (such as
King's Quest 1-6, Space Quest 1-5, ...), Discworld 1 and 2, Simon the
Sorcerer 1 and 2, Beneath A Steel Sky, Lure of the Temptress, Broken
Sword I and II, Flight of the Amazon Queen, Gobliiins 1-3, The Legend of
Kyrandia series, many of Humongous Entertainment's children's SCUMM
games (including Freddi Fish and Putt Putt games) and many more. You can
find a full list with details on which adventures are supported and how
well on the compatibility page. ScummVM is continually improving, so
check back often.
Among the systems on which you can play those games are regular desktop
computers (running Windows, Linux, Mac OS X, ...), game consoles
(Dreamcast, Nintendo DS & Wii, PS2, PSP, ...), smartphones (Android,
iPhone, PocketPC, Symbian ...) and more.
At this time ScummVM is still under heavy development. Be aware that
whilst we attempt to make sure that many games can be completed with few
major bugs, crashes can happen and we offer no warranty. That being
said, some of the games have been supported for a long time and should
work fine with any recent stable release. You can get a feeling of how
well each game is working in ScummVM by looking at the compatibility
page. Actually, if you browse a bit around you might discover that
ScummVM is even being used commercially to re-release some of the
supported games on modern platforms. This shows that several companies
are happy with the quality of the software and how well it can run some
of the games.
If you enjoy ScummVM feel free to donate using the PayPal button on the
ScummVM homepage. This will help us buy utilities needed to develop
ScummVM easier and quicker. If you cannot donate, help and contribute a
patch!
1.2) Quick start
For the impatient among you, here is how to get ScummVM running in five
simple steps.


Download ScummVM from https://www.scummvm.org/downloads/ and
install it.


Create a directory on your hard drive and copy the game datafiles
from the original media to this directory. Repeat this for every
game you want to play.


Start ScummVM, choose 'Add game', select the directory with the game
datafiles (do not try to select the datafiles themselves!) and
press Choose.


A dialog should pop up allowing you to configure various settings if
you wish to (it should be just fine to leave everything at its
default, though). Confirm the dialog.


Select the game you want to play in the list, and press Start.


In the future, you should be able to directly skip to step 5, unless you
want to add more games.
Hint: If you want to add multiple games in one go, try pressing and
holding the shift key before clicking 'Add game' -- its label will
change to 'Mass Add' and if you press it, you are again asked to select
a directory, only this time ScummVM will search through all
subdirectories for supported games.
1.3) F.A.Q.
We've compiled a list of F.A.Q. at:
https://www.scummvm.org/faq/
2.0) Contact
The easiest way to contact the ScummVM team is by submitting bug reports
(see section 2.1) or by using our forums at https://forums.scummvm.org.
You can also join and e-mail the scummvm-devel mailing list, or chat
with us on IRC (#scummvm on irc.freenode.net) Please do not ask us to
support an unsupported game -- read the FAQ on our web site first.
2.1) Reporting Bugs
To report a bug, please follow the ""Bug Tracker"" link from our homepage
and log in with your GitHub account. Please make sure the bug is
reproducible, and still occurs in the latest git/Daily build version.
Also check the known problems list (below) and the compatibility list on
our website for that game, to ensure the issue is not already known:
https://www.scummvm.org/compatibility/
Please do not report bugs for games that are not listed as being
completeable in the 'Supported Games' section, or compatibility list. We
know those games have bugs.
Please include the following information:

ScummVM version (PLEASE test the latest git/Daily build)
Bug details, including instructions on reproducing
Language of game (English, German, ...)
Version of game (talkie, floppy, ...)
Platform and Compiler (Win32, Linux, FreeBSD, ...)
Attach a saved game if possible - If this bug only occurred
recently, please note the last version without the bug, and the
first version including the bug. That way we can fix it quicker by
looking at the changes made.

Finally, please report each issue separately; do not file multiple
issues on the same ticket. (Otherwise, it gets difficult to track the
status of each individual bug).
3.0) Supported Games
At the moment the following games have been reported to work, and should
be playable to the end: A more detailed compatibility list of the
supported games can be found here:
https://www.scummvm.org/compatibility/



LucasArts (SCUMM) Games:





Maniac Mansion
[maniac]


Zak McKracken and the Alien Mindbenders
[zak]


Indiana Jones and the Last Crusade
[indy3]


Loom
[loom]


Passport to Adventure
[pass]


The Secret of Monkey Island
[monkey]


Monkey Island 2: LeChuck's Revenge
[monkey2]


Indiana Jones and the Fate of Atlantis
[atlantis]


Day of the Tentacle
[tentacle]


Sam & Max Hit the Road
[samnmax]


Full Throttle
[ft]


The Dig
[dig]


The Curse of Monkey Island
[comi]






Activision (MADE) Games:





Leather Goddesses of Phobos 2
[lgop2]


The Manhole
[manhole]


Return to Zork
[rtz]


Rodney's Funscreen
[rodney]






Adventuresoft/Horrorsoft (AGOS) Games:





Elvira - Mistress of the Dark
[elvira1]


Elvira II - The Jaws of Cerberus
[elvira2]


Personal Nightmare
[pn]


Simon the Sorcerer 1
[simon1]


Simon the Sorcerer 2
[simon2]


Simon the Sorcerer's Puzzle Pack - Demon In My Pocket
[dimp]


Simon the Sorcerer's Puzzle Pack - Jumble
[jumble]


Simon the Sorcerer's Puzzle Pack - NoPatience
[puzzle]


Simon the Sorcerer's Puzzle Pack - Swampy Adventures
[swampy]


The Feeble Files
[feeble]


Waxworks
[waxworks]






Coktel Vision (GOB) Games:





Bargon Attack
[bargon]


Fascination
[fascination]


Geisha
[geisha]


Gobliiins
[gob1]


Gobliins 2
[gob2]


Goblins 3
[gob3]


Lost in Time
[lostintime]


Once Upon A Time: Little Red Riding Hood
[littlered]


Playtoons: Bambou le sauveur de la jungle
[bambou]


The Bizarre Adventures of Woodruff and the Schnibble
[woodruff]


Urban Runner
[urban]


Ween: The Prophecy
[ween]






Revolution Software (Various) Games:





Beneath a Steel Sky
[sky]


Broken Sword: The Shadow of the Templars
[sword1]


Broken Sword II: The Smoking Mirror
[sword2]


Lure of the Temptress
[lure]






Sierra (AGI/preAGI) Games:





The Black Cauldron
[bc]


Gold Rush!
[goldrush]


King's Quest I
[kq1]


King's Quest II
[kq2]


King's Quest III
[kq3]


King's Quest IV
[kq4]


Leisure Suit Larry in the Land of the Lounge Lizards
[lsl1]


Mixed-Up Mother Goose
[mixedup]


Manhunter 1: New York
[mh1]


Manhunter 2: San Francisco
[mh2]


Police Quest I: In Pursuit of the Death Angel
[pq1]


Space Quest I: The Sarien Encounter
[sq1]


Space Quest II: Vohaul's Revenge
[sq2]


Fanmade Games
[agi-fanmade]


Mickey's Space Adventure
[mickey]


Troll's Tale
[troll]


Winnie the Pooh in the Hundred Acre Wood
[winnie]






Sierra (SCI) Games:





Castle of Dr. Brain
[castlebrain]


Codename: ICEMAN
[iceman]


Conquests of Camelot
[camelot]


Conquests of the Longbow
[longbow]


EcoQuest: The Search for Cetus
[ecoquest]


EcoQuest 2: Lost Secret of the Rainforest
[ecoquest2]


Freddy Pharkas: Frontier Pharmacist
[freddypharkas]


Gabriel Knight: Sins of the Fathers
[gk1]


Hoyle's Book of Games 1
[hoyle1]


Hoyle's Book of Games 2
[hoyle2]


Hoyle's Book of Games 3
[hoyle3]


Hoyle Classic Card Games
[hoyle4]


Jones in the Fast Lane
[jones]


King's Quest I
[kq1sci]


King's Quest IV
[kq4sci]


King's Quest V
[kq5]


King's Quest VI
[kq6]


King's Quest VII
[kq7]


King's Questions
[kquestions]


Laura Bow: The Colonel's Bequest
[laurabow]


Laura Bow 2: The Dagger of Amon Ra
[laurabow2]


Leisure Suit Larry 1
[lsl1sci]


Leisure Suit Larry 2
[lsl2]


Leisure Suit Larry 3
[lsl3]


Leisure Suit Larry 5
[lsl5]


Leisure Suit Larry 6
[lsl6]


Leisure Suit Larry 6 (hires)
[lsl6hires]


Leisure Suit Larry 7
[lsl7]


Lighthouse: The Dark Being
[lighthouse]


Mixed-up Fairy Tales
[fairytales]


Mixed-up Mother Goose
[mothergoose]


Mixed-up Mother Goose Deluxe
[mothergoosehires]


Pepper's Adventures in Time
[pepper]


Phantasmagoria
[phantasmagoria]


Phantasmagoria 2: A Puzzle of Flesh
[phantasmagoria2]


Police Quest 1
[pq1sci]


Police Quest 2
[pq2]


Police Quest 3
[pq3]


Police Quest 4
[pq4]


Quest for Glory 1/Hero's Quest
[qfg1]


Quest for Glory 1
[qfg1vga]


Quest for Glory 2
[qfg2]


Quest for Glory 3
[qfg3]


RAMA
[rama]


Slater & Charlie Go Camping
[slater]


Shivers
[shivers]


Space Quest I
[sq1sci]


Space Quest III
[sq3]


Space Quest IV
[sq4]


Space Quest V
[sq5]


Space Quest 6
[sq6]


The Island of Dr. Brain
[islandbrain]


The Beast Within: A Gabriel Knight Mystery
[gk2]


Torin's Passage
[torin]






Other Games:





3 Skulls of the Toltecs
[toltecs]


Amazon: Guardians of Eden
[access]


Beavis and Butt-head in Virtual Stupidity
[bbvs]


Blue Force
[blueforce]


Broken Sword: The Return of the Templars
[sword25]


Bud Tucker in Double Trouble
[tucker]


Chivalry is Not Dead
[chivalry]


Cruise for a Corpse
[cruise]


DreamWeb
[dreamweb]


Discworld
[dw]


Discworld 2: Missing Presumed ...!?
[dw2]


Dragon History
[draci]


Drascula: The Vampire Strikes Back
[drascula]


Eye of the Beholder
[eob]


Eye of the Beholder II: The Legend of Darkmoon
[eob2]


Flight of the Amazon Queen
[queen]


Future Wars
[fw]


Hopkins FBI
[hopkins]


Hugo's House of Horrors
[hugo1]


Hugo 2: Whodunit?
[hugo2]


Hugo 3: Jungle of Doom
[hugo3]


I Have No Mouth, and I Must Scream
[ihnm]


Inherit the Earth: Quest for the Orb
[ite]


Lands of Lore: The Throne of Chaos
[lol]


Mortville Manor
[mortevielle]


Myst / Myst: Masterpiece Edition
[myst]


Nippon Safes Inc.
[nippon]


Rex Nebular and the Cosmic Gender Bender
[nebular]


Ringworld: Revenge Of The Patriarch
[ringworld]


Riven: The Sequel to Myst
[riven]


Return to Ringworld
[ringworld2]


Sfinx
[sfinx]


Soltys
[soltys]


Starship Titanic
[titanic]


The Journeyman Project: Pegasus Prime
[pegasus]


The Labyrinth of Time
[lab]


The Legend of Kyrandia
[kyra1]


The Legend of Kyrandia: The Hand of Fate
[kyra2]


The Legend of Kyrandia: Malcolm's Revenge
[kyra3]


The Lost Files of Sherlock Holmes: The Case of the Serrated Scalpel
[scalpel]


The Lost Files of Sherlock Holmes: The Case of the Rose Tattoo
[rosetattoo]


The Neverhood
[neverhood]


The 7th Guest
[t7g]


TeenAgent
[teenagent]


Toonstruck
[toon]


Tony Tough and the Night of Roasted Moths
[tony]


Touche: The Adventures of the Fifth Musketeer
[touche]


U.F.O.s / Gnap: Der Schurke aus dem All
[gnap]


Voyeur
[voyeur]


Zork: Grand Inquisitor
[zgi]


Zork Nemesis: The Forbidden Lands
[znemesis]






Humongous Entertainment (SCUMM) Games:





Backyard Baseball
[baseball]


Backyard Baseball 2001
[baseball2001]


Backyard Baseball 2003
[baseball2003]


Backyard Football
[football]


Backyard Football 2002
[football2002]


Bear Stormin'
[brstorm]


Big Thinkers First Grade
[thinker1]


Big Thinkers Kindergarten
[thinkerk]


Blue's 123 Time Activities
[Blues123Time]


Blue's ABC Time Activities
[BluesABCTime]


Blue's Art Time Activities
[arttime]


Blue's Birthday Adventure
[BluesBirthday]


Blue's Reading Time Activities
[readtime]


Fatty Bear's Birthday Surprise
[fbear]


Fatty Bear's Fun Pack
[fbpack]


Freddi Fish 1: The Case of the Missing Kelp Seeds
[freddi]


Freddi Fish 2: The Case of the Haunted Schoolhouse
[freddi2]


Freddi Fish 3: The Case of the Stolen Conch Shell
[freddi3]


Freddi Fish 4: The Case of the Hogfish Rustlers of Briny Gulch
[freddi4]


Freddi Fish 5: The Case of the Creature of Coral Cove
[freddicove]


Freddi Fish and Luther's Maze Madness
[maze]


Freddi Fish and Luther's Water Worries
[water]


Let's Explore the Airport with Buzzy
[airport]


Let's Explore the Farm with Buzzy
[farm]


Let's Explore the Jungle with Buzzy
[jungle]


Pajama Sam: Games to Play on Any Day
[pjgames]


Pajama Sam 1: No Need to Hide When It's Dark Outside
[pajama]


Pajama Sam 2: Thunder and Lightning Aren't so Frightening
[pajama2]


Pajama Sam 3: You Are What You Eat From Your Head to Your Feet
[pajama3]


Pajama Sam's Lost & Found
[lost]


Pajama Sam's Sock Works
[socks]


Putt-Putt Enters the Race
[puttrace]


Putt-Putt Goes to the Moon
[puttmoon]


Putt-Putt Joins the Circus
[puttcircus]


Putt-Putt Joins the Parade
[puttputt]


Putt-Putt Saves the Zoo
[puttzoo]


Putt-Putt Travels Through Time
[putttime]


Putt-Putt and Pep's Balloon-O-Rama
[balloon]


Putt-Putt and Pep's Dog on a Stick
[dog]


Putt-Putt & Fatty Bear's Activity Pack
[activity]


Putt-Putt's Fun Pack
[funpack]


SPY Fox 1: Dry Cereal
[spyfox]


SPY Fox 2: Some Assembly Required
[spyfox2]


SPY Fox 3: Operation Ozone
[spyozon]


SPY Fox in Cheese Chase
[chase]


SPY Fox in Hold the Mustard
[mustard]




The following games should load but are not yet fully playable. Play
these at your own risk, and please do not file bug reports about them.
If you want the latest updates on game compatibility, visit our web
site and view the compatibility chart.










Backyard Soccer
[soccer]


Backyard Soccer MLS
[soccermls]


Backyard Soccer 2004
[soccer2004]


Blue's Treasure Hunt
[BluesTreasureHunt]






Animation Magic (Composer) Games:





Darby the Dragon
[darby]


Gregory and the Hot Air Balloon
[gregory]


Magic Tales: Liam Finds a Story
[liam]


The Princess and the Crab
[princess]


Sleeping Cub's Test of Courage
[sleepingcub]






Living Books Games:





Aesop's Fables: The Tortoise and the Hare
[tortoise]


Arthur's Birthday
[arthurbday]


Arthur's Teacher Trouble
[arthur]


Dr. Seuss's ABC
[seussabc]


Green Eggs and Ham
[greeneggs]


Harry and the Haunted House
[harryhh]


Just Grandma and Me
[grandma]


Little Monster at School
[lilmonster]


Ruff's Bone
[ruff]


Sheila Rae, the Brave
[sheila]


Stellaluna
[stellaluna]


The Berenstain Bears Get in a Fight
[bearfight]


The Berenstain Bears in the Dark
[beardark]


The New Kid on the Block
[newkid]



The following games are based on the SCUMM engine, but NOT supported by
ScummVM (yet):
Moonbase Commander

Please be aware that the engines may contain bugs and unimplemented
features that sometimes make it impossible to finish the game. Save
often, and please file a bug report (instructions on submitting bug
reports are above) if you encounter such a bug in a 'supported' game.
3.1) Copy Protection
The ScummVM team does not condone piracy. However, there are cases where
the game companies (such as LucasArts) themselves bundled 'cracked'
executables with their games -- in these cases the data files still
contain the copy protection scripts, but the interpreter bypasses them
(similar to what an illegally cracked version might do, only that here
the producer of the game did it). There is no way for us to tell the
difference between legitimate and pirated data files, so for the games
where we know that a cracked version of the original interpreter was
sold at some point, ScummVM will always have to bypass the copy
protection.
In some cases ScummVM will still show the copy protection screen. Try
entering any answer. Chances are that it will work.
ScummVM will skip copy protection in the following games:

Beneath a Steel Sky

bypassed with kind permission from Revolution Software.


Dreamweb

a list of available commands in the in-game terminals is now
shown when the player uses the help command


Inherit the Earth: Quest for the Orb (Floppy version)

bypassed with kind permission from Wyrmkeep Entertainment, since
it was bypassed in all CD releases of the game.


Loom (EGA DOS)
Lure of the Temptress
Maniac Mansion
Might and Magic: World of Xeen
Monkey Island 2: LeChuck's Revenge
Rex Nebular and The Cosmic Gender Bender
Simon the Sorcerer 1 (Floppy version)
Simon the Sorcerer 2 (Floppy version)

bypassed with kind permission from Adventure Soft, since it was
bypassed in all CD releases of the game.


The Secret of Monkey Island (VGA)
Voyeur
Waxworks
Zak McKracken and the Alien Mindbenders

3.2) Datafiles
For a comprehensive list of required Datafiles for supported games
visit:
https://wiki.scummvm.org/index.php/Datafiles
3.3) Multi-CD games notes
In general, ScummVM does not deal very well with Multi-CD games. This is
because ScummVM assumes everything about a game can be found in one
directory. Even if ScummVM does make some provisions for asking the user
to change CD, the original game executables usually installed a small
number of files to the hard disk. Unless these files can be found on all
the CDs, ScummVM will be in trouble.
Fortunately, ScummVM has no problems running the games entirely from
hard disk, if you create a directory with the correct combination of
files. Usually, when a file appears on more than one CD you can pick
either of them.
3.4) Known Problems
This release has the following known problems. There is no need to
report them, although patches to fix them are welcome. If you discover a
bug that is not listed here, nor in the compatibility list on the web
site, please see the section on reporting bugs.
CD Audio Games:

When playing games that use CD Audio (FM-TOWNS games, Loom CD, etc)
users of Microsoft Windows 2000/XP may experience random crashes.
This is due to a long-standing Windows bug, resulting in corrupt
game files being read from the CD. Please copy the game data to your
hard disk to avoid this.

FM-TOWNS versions:

The Kanji versions require the FM-TOWNS Font ROM.

Loom:

Turning off the subtitles via the config file does not work reliably
as the Loom scripts automatically turn them on again.
MIDI support in the EGA version requires the Roland update from
LucasArts.
The PC-Engine Kanji version requires the system card rom.

The Secret of Monkey Island:

MIDI support in the EGA version requires the Roland update from
LucasArts.

Beneath a Steel Sky:

Amiga versions aren't supported.
Floppy demos aren't supported.
Not a bug: CD version is missing speech for some dialogs, this is
normal.

Elvira - Mistress of the Dark:

No music in the Atari ST version.

Elvira II - The Jaws of Cerberus

No music in the Atari ST version.
No sound effects in the PC version.
Palette issues in the Atari ST version.

Inherit the Earth: Quest for the Orb:

Amiga versions aren't supported.

Lure of the Temptress:

No Roland MT-32 support.
Sound support is incomplete and doesn't sound like original.

Simon the Sorcerer 1:

Subtitles aren't available in the English and German CD versions as
they are missing the majority of subtitles.

Simon the Sorcerer 2:

Combined speech and subtitles will often cause speech to be cut off
early, this is a limitation of the original game.
Only default language (English) of data files is supported in Amiga
and Macintosh versions.

Simon the Sorcerer's Puzzle Pack:

No support for displaying, entering, loading or saving high scores.
No support for displaying names of items, when hovering over them in
Swampy Adventures.

The Feeble Files:

Subtitles are often incomplete, they were always disabled in the
original game.

The Legend of Kyrandia:

No music or sound effects in the Macintosh floppy versions.
Macintosh CD is using included DOS music and sound effects.

Humongous Entertainment games:

Only the original load and save interface can be used.
No support for multiplayer or printing images.

3.5) Extra Data Files
Some games require additional files that are not part of the original data. Those files can generally be found in our Downloads page.
Games that require additional data:

Beneath a Steel Sky (sky.cpt)
Flight of the Amazon Queen
Kyrandia Series (kyra.dat)
Lands of Lore Series (kyra.dat)
Lure of the Temptress (lure.dat)

The most up to date list of Engine data files can be found in our source code repository
3.6) Broken Sword games notes
The instructions for the Broken Sword games are for the Sold-Out
Software versions, with each game on two CDs, since these were the
versions most easily available at the time ScummVM gained support for
them. Hopefully they are general enough to be useful to other releases
as well.
3.6.1) Broken Sword
For this game, you will need all of the files from the clusters
directories on both CDs. For the Windows and Macintosh versions, you
will also need the speech.clu files from the speech directories, but
since they are not identical you will need to rename them speech1.clu
and speech2.clu for CD 1 and 2 respectively. The PlayStation version
requires the speech.tab, speech.dat, speech.lis, and speech.inf.
In addition, the Windows and Macintosh versions require a music
subdirectory with all of the files from the music subdirectories on both
CDs. Some of these files appear on both CDs, but in these cases they are
either identical or, in one case, so nearly identical that it makes
little difference. The PlayStation version requires tunes.dat and
tunes.tab.
3.6.2) Broken Sword II
For this game, you will need all of the files from the clusters
directories on both CDs. (Actually, a few of them may not be strictly
necessary, but the ones that I'm uncertain about are all fairly small.)
You will need to rename the speech.clu and music.clu files speech1.clu,
speech2.clu, music1.clu and music2.clu so that ScummVM can tell which
ones are from CD 1 and which ones are from CD 2. Any other files that
appear in both cluster directories are identical. Use whichever you
like.
In addition, you will need the cd.inf and, optionally, the startup.inf
files from the sword2 directory on CD 1.
3.6.3) Broken Sword games cutscenes
The cutscenes for the Broken Sword games have a bit of a history (see
the next section, if you are interested), but in general all you need to
do is to copy the .SMK files from the ""SMACKS"" or ""SMACKSHI"" directories
on the CDs to the same directory as the other game data files. (Broken
Sword has a ""SMACKSLO"" directory with the same cutscenes, but these are
of lower quality.) You can put them in a subdirectory called ""video"" if
you find that neater.
For the PlayStation versions, you can dump the original videos off the
disc. For each of the files ending in an ""STR"" extension, you should
dump them as raw sectors off the disc (all 2352 bytes per sector). You
may also use the re-encoded cutscenes mentioned below instead, but this
will not work for all videos in Broken Sword II. For more information,
see:
https://wiki.scummvm.org/index.php/HOWTO-PlayStation_Videos
Some re-releases of the games, as well as the PlayStation version, do
not have Smacker videos. Revolution Software has kindly allowed us to
provide re-encoded cutscenes for download on our website:
https://www.scummvm.org/downloads/
These cutscenes are provided in DXA format with FLAC audio. Their
quality is equal to the original games due to the use of lossless
compression. Viewing these cutscenes requires a version of ScummVM
compiled with both FLAC and zlib support.
For systems that are too slow to handle the decoding of FLAC audio, the
audio for these cutscenes is also provided separately as OGG Vorbis
audio. Viewing these cutscenes with OGG Vorbis audio requires a version
of ScummVM compiled with both libVorbis and zlib support.
For Broken Sword, we also provide a subtitles add-on. Simply unpack it
and follow the instructions in its readme.txt file. The subtitle pack
currently does not work when running PlayStation videos. (Broken Sword
II already has subtitles; no extra work is needed for them.)
3.6.4) Broken Sword games cutscenes, in retrospect
The original releases of the Broken Sword games used RAD Game Tools's
Smacker(tm) format. As RAD was unwilling to open the older legacy
versions of this format to us, and had requested we not reverse engineer
it, an alternative solution had to be found.
In Broken Sword II, it was possible to play back the voice-over without
playing the video itself. This remained a fallback until ScummVM 1.0.0,
but was never the only solution for any stable release.
In ScummVM 0.6.0 we used MPEG, which provided a reasonable trade-off
between size and quality. In ScummVM 0.10.0 this was superseded by DXA
(originally added for AdventureSoft's ""The Feeble Files""). This gave us
a way of providing the cutscenes in the exact same quality as the
originals, at the cost of being larger.
Finally, in early 2006, the Smacker format was reverse engineered for
the FFmpeg project. Thanks to their hard work, ScummVM 1.0.0 now
supports the original cutscenes. At the same time, MPEG support was
dropped. From a technical standpoint, this was a good thing since
decoding MPEG movies added a lot of complexity, and they didn't look as
good as the Smacker and DXA versions anyway.
3.7) Day of the Tentacle notes
At one point in the game, you come across a computer that allows you to
play the original Maniac Mansion as an easter egg. ScummVM supports
this, with a few caveats:
ScummVM will scan your configuration file for a game that's in a
Maniac sub-folder of your Day of the Tentacle folder. If you've copied
the data files from the CD version, this should already be the case but
you have to add the game to ScummVM as well.
To return to Day of the Tentacle, press F5 and select ""Return to
Launcher"".
This means that you could in theory use any game as the easter egg.
Indeed, there is a ""secret"" configuration setting, easter_egg, to
override the ID of the game to run. Be aware, though, that not all games
support returning to the launcher, and setting it up to use Day of the
Tentacle itself as the easter egg game is not recommended.
3.8) Dragon History notes
There are 4 language variants of the game: Czech, English, Polish and
German. Each of them is distributed in a separate archive. The only
official version is the Czech one, and the English, Polish and German
ports have always been work in progress and never officially released.
Although all texts are fully translated, it is known that some of them
contain typos.
There exists an optional Czech dubbing for the game. For bandwidth
reasons, you can download it separately and then unpack it to the
directory of the game. You can listen to the Czech dubbing with all
language variants of the game, while reading the subtitles.
All game files and the walkthrough can be downloaded from:
http://www.ucw.cz/draci-historie/index-en.html
3.9) Flight of the Amazon Queen notes
Only the original non-freeware version of Flight of the Amazon Queen
(from original CD), requires the queen.tbl datafile (available from the Downloads page on our website) in either the
directory containing the queen.1 game data file, in your extrapath, or
in the directory where your ScummVM executable resides.
Alternatively, you can use the compress_queen tool from the tools
package to 'rebuild' your FOTAQ data file to include the table for that
specific version, and thus removing the run-time dependency on the
queen.tbl file. This tool also allows you to compress the speech and
sound effects with MP3, OGG or FLAC.
3.10) Gobliiins notes
The CD versions of the Gobliiins series contain one big audio track
which you need to rip (see the section on using compressed audio files)
and copy into the game directory if you want to have in-game music
without the CD in the drive all the time. The speech is also in that
track and its volume is therefore changed with the music volume control
as well.
3.11) Inherit the Earth: Quest for the Orb notes
In order to run the Mac OS X Wyrmkeep re-release of the game you will
need to copy over data from the CD to your hard disk. If you're on a PC
then consult:
https://wiki.scummvm.org/index.php/HOWTO-Mac_Games
Although it primarily talks about SCUMM games, it mentions the
""HFSExplorer"" utility which you need to extract the files. Note that you
have to put the speech data ""Inherit the Earth Voices"" in the same
directory as the game data which is stored in:
Inherit the Earth.app/Contents/Resources
For the old Mac OS 9 release you need to copy the files in MacBinary
format, as they should include both resource and data forks. Copy all
'ITE *' files.
3.12) Mickey's Space Adventure notes
To run Mickey's Space Adventure under ScummVM, the original executable
of the game (mickey.exe) is needed together with the game's data files.
There is extensive mouse support for the game under ScummVM, even though
there wasn't any mouse support in the original game. Menu items can be
selected using the mouse, and it is possible to move to other locations
using the mouse as well. When the mouse cursor is hovered on the edges
of the screen, it changes color to red if it is possible to walk towards
that direction. The player can then simply click on the edges of the
game's screen to change location, similar to many adventure games, which
is simpler and more straightforward than moving around using the menu.
3.13) Might and Magic Xeen games notes
To properly play the World of Xeen CD Talkie using original discs, use
LAME or some other encoder to rip the cd audio tracks to files, either
mp3 or ogg. Whichever you choose, the tracks of the first CD should be
named from track02 to track31, whereas the second CD's audio tracks
should be encoded and renamed as track32 through to track60.
For the GOG Might and Magic 4-5 installation, install the game to your
computer, and do the following steps:

The game1.inst (CUE) and game1.gog (BIN) file from the game folder
is a CD image. Use software like Virtual CloneDrive to mount it as a
drive. Linux and MacOS users can use bchunk to convert it to an ISO.
Copy all the .cc files from the subfolder in the mounted drive to a
new empty game folder that you create for the game.
Copy all the music/*.ogg files from the GOG installation to your
game folder. You'll then need to rename all of them from xeen??.ogg
to track??.ogg
You should then be able to point ScummVM to this new game folder,
and the CD talkie version should be detected.

Savegames from either Clouds or Darkside of Xeen games can be
transferred across to World of Xeen (that combines both games) simply by
setting up and detecting World of Xeen (either by manually combining the
two games or using the GOG World of Xeen installer), and then renaming
the savegames to use the World of Xeen savegame format, by default
'worldofxeen.*'
The Xeen engine also offers two custom options in the Engine tab for the
games in the ScummVM launcher. They are:

To change the threshold armor breaks at for characters from -10HP to
-80HP
To show values for inventory items, even outside of the blacksmith,
allowing the relative strength/value of armor and weapons to be
compared.

3.14) Myst game notes
Left Click: Move/action
Space: Pause the game
Esc: Skip cutscene
F5: Menu
Myst will autosave to slot 0 if no save or an autosave is present in
slot 0.
3.15) Quest for Glory notes
It is possible to import characters, beginning with Quest for Glory II,
from past games to future games and continue from the stats earned from
those games.
For example, a character can be imported from Quest for Glory I directly
to Quest for Glory III without having to necessarily play Quest for
Glory II.
Characters cannot be imported from future games to past games, nor can a
character be imported to the same game that was just completed. In other
words, a character from Quest for Glory II cannot be imported into Quest
for Glory II.
If you want to use a saved character from the original Sierra
interpreter, you will need to rename the character file to
""qfg[game-number]-[character-filename].sav"" and place it in the
ScummVM save path (see section 6.0), otherwise the file won't get listed
on the import screen.
Example: qfg2-thief.sav
3.16) Riven game notes
Left Click: Move/action
Arrow Keys: Movement
Page Up: Look up
Page Down: Look down
Space: Pause the game
Esc: Skip cutscene
F5: Menu
Ctrl-o: Load game
Ctrl-s: Save game
Riven will autosave to slot 0 if no save or an autosave is present in
slot 0.
3.17) Simon the Sorcerer games notes
If you have the dual version of Simon the Sorcerer 1 or 2 on CD, you
will find the Windows version in the main directory of the CD and the
DOS version in the DOS directory of the CD.
3.18) Starship Titanic game notes
For the purposes of solving the starfield puzzle, only mouse clicks, L
and Tab are really needed, though the action glyph in the PET can be
used instead of Tab.
3.19) The Curse of Monkey Island notes
For this game, you will need the comi.la0, comi.la1 and comi.la2 files.
The comi.la0 file can be found on either CD, but since they are
identical it doesn't matter which one of them you use.
In addition, you will need to create a ""resource"" subdirectory
containing all of the files from -both- ""resource"" subdirectories on the
two CDs. Some of the files appear on both CDs, but again they're
identical.
3.20) The Feeble Files notes
Amiga/Macintosh: You need to install a small pack of cutscenes that are
missing in both of these versions of The Feeble Files. It's called ""The
Feeble Files - Omni TV and epilogue cutscenes for the Amiga and
Macintosh versions"" and you can get it here:
https://www.scummvm.org/games/#feeble
Windows: If you have the Windows version of The Feeble Files, there are
several things to note.
Many of the files necessary for the game are stored in an InstallShield
file called data1.cab, which ScummVM is unable to unpack. You will need
to use the original installer or i5comp to unpack the contents of this
file. The i5comp decompression tool, can be found via a search on the
internet.
To use the speech files with ScummVM, they need to be renamed as
follows:

Rename voices.wav on CD1 to voices1.wav
Rename voices.wav on CD2 to voices2.wav
Rename voices.wav on CD3 to voices3.wav
Rename voices.wav on CD4 to voices4.wav

3.21) The Legend of Kyrandia notes
To run The Legend of Kyrandia under ScummVM you need the kyra.dat
file. The file should already be included in official ScummVM packages.
In case ScummVM complains that the file is missing you can find it on
the Downloads page of the ScummVM website. Note that the current
Windows release of ScummVM should contain the file embedded into the
executable, thus you only need to grab it in case ScummVM complains
about the file being missing.
3.22) Troll's Tale notes
The original game came in a PC booter disk, therefore it is necessary to
dump the contents of that disk in an image file and name it ""troll.img""
to be able to play the game under ScummVM.
3.23) Winnie the Pooh notes
It is possible to import saved games from the original interpreter of
the game into ScummVM.
There is extensive mouse support for the game under ScummVM, even though
there wasn't any mouse support in the original game. Menu items can be
selected using the mouse, and it is possible to move to other locations
using the mouse as well. When the mouse cursor is hovered on the edges
of the screen, it changes color to red if it is possible to walk towards
that direction. The player can then simply click on the edges of the
game's screen to change location, similar to many adventure games, which
is simpler and more straightforward than moving around using the menu.
3.24) Sierra AGI games: Predictive Input Dialog
The Predictive Input Dialog is a ScummVM aid for running AGI engine
games (which notoriously require command line input) on devices with
limited keyboard support. In these situations, since typing with
emulated keyboards is quite tedious, commands can be entered quickly and
easily via the Predictive Input Dialog.
In order to enable predictive input in AGI games, you need to copy the
pred.dic file in the ScummVM extras directory or the directory of the
game you wish to play. This dictionary has been created by parsing
through all known AGI games and contains the maximum set of common
words.
If the dictionary is detected, the Predictive Input Dialog is displayed
either when you click on the command line area (wherever keyboard input
is required, even in dialog boxes), or in some ports by pressing a
designated hot key.
The predictive input dialog operates in three modes, switchable by the
(*)Pre/123/Abc button. The primary input method is the predictive mode
(Pre) which resembles the way ""fast typing"" is performed at phones. The
alphabet is divided into 9 sets which naturally map to the 9 number keys
of the numeric keypad (0 is space). To type in a word, you press once
the number of the set which contains the letter of the word you intend
to type, then move on to the next. For example, to type the command
look, you should press 5665. As you gradually type the intended word's
numeric code, the dictionary is accessed for known words matching your
input up to that point. As you press more keys, the prediction converges
to the correct word. This is why the printed word may change
dramatically between key presses. There exist situations though where
more than one words share the same numeric representation. For example
the words quit and suit map to the same number, namely 7848. In
these cases the (#)next button lights up. By pressing it, you can cycle
through the list of words sharing the same code and finally accept the
correct one by pressing (0)space or the Ok button.
The second input method (123) is the numeric input: Each key you press
is entered verbatim as a number.
The third input method (Abc) is the Multi-tap Alpha input mode. This
mode is intended for entering free text, without assistance from the
dictionary scheme of predictive (Pre) mode. The text is entered one
letter at the time. For each letter first press the number of the set
which contains the letter you want, then use the (#)next button to
cycle through the letters and repeat with another number. For example,
to enter the word look you must press the following:
5##6##6##5#
The dialog is fully usable with the mouse, but a few provisions have
been made in some ScummVM ports to make its use more comfortable by
naturally mapping the functionality to the numeric keypad. Also, the
dialog's buttons can be navigated with the arrow and the enter keys.
3.25) Sierra SCI games: Simultaneous speech and subtitles
Certain CD versions of Sierra SCI games had both speech and text
resources. Some have an option to toggle between the two, but there are
some cases where there wasn't any option to enable both simultaneously.
In ScummVM, it is possible to enjoy a combined mode, where both speech
and text are shown at the same time. This mode can be toggled in the
ScummVM audio options, but each game has different behavior in-game
regarding speech and text toggling.
The CD games where speech and subtitles can be shown simultaneously are:

EcoQuest 1 CD
Freddy Pharkas CD
Gabriel Knight CD
King's Quest 6 CD
King's Quest VII CD
Laura Bow 2 CD
Leisure Suit Larry 6 CD
Leisure Suit Larry 6 (hires) CD
Police Quest 4 CD
Shivers CD
Space Quest 4 CD
Space Quest 6 CD Torin's Passage CD

EcoQuest 1 CD: Speech and text can be toggled via the game's ""Mode""
option in the options dialog, or via ScummVM's audio options.
Freddy Pharkas CD: There is no in-game option to toggle speech and
text. Only ScummVM's audio options can be used to toggle this feature.
Note that some spoken dialog is missing from the game texts.
Gabriel Knight CD: Speech and text can be toggled via the ""Text"" and
""Voice"" buttons in the game's settings dialog, or via ScummVM's audio
options.
King's Quest 6 CD: Speech and text can be toggled via the ""Mode""
button in the options dialog (with an extra ""Dual"" setting added in
ScummVM), or via ScummVM's audio options.
King's Quest VII CD: There is no in-game option to toggle speech and
text. Only ScummVM's audio options can be used to toggle this feature.
Note that the subtitles were disabled in the official release of this
game, so some subtitles may be wrong or missing.
Laura Bow 2 CD: Speech and text can be toggled via the ""Mode"" button
in the options dialog (with an extra ""Dual"" setting added in ScummVM),
or via ScummVM's audio options.
Leisure Suit Larry 6 CD: Either speech only or speech and text can
be selected. There is no in-game option to toggle text only. Only
ScummVM's audio options can be used to enable the text only mode.
Leisure Suit Larry 6 (hires) CD: Text can be toggled by selecting
the ""Text On/Off"" option from the in-game ""Game"" menu, or via ScummVM's
audio options. Speech cannot be disabled.
Police Quest 4 CD: Either speech only or text only can be selected
from the game's settings dialog. Only ScummVM's audio options can be
used to enable text+speech mode.
Shivers CD: Text can be toggled by selecting the ""Text"" option from
the game's settings dialog, or via ScummVM's audio options. Note that
only videos have subtitles in this game.
Space Quest 4 CD: Speech and text can be toggled via the ""Display
Mode"" button in the options dialog, or via ScummVM's audio options.
Space Quest 6 CD: Speech and text can be toggled via the ""Speech""
and ""Text"" buttons in the game's settings dialog, or via ScummVM's audio
options.
Torin's Passage CD: Text can be toggled by selecting ""Closed
Captioning"" from the in-game ""Game"" menu. Speech can be disabled by
selecting ""Audio Mixer"" from the in-game ""Game"" menu and setting the
speech volume to zero.
3.26) Zork games notes
To run the supported Zork games (Zork Nemesis: The Forbidden Lands and
Zork: Grand Inquisitor) you need to copy some (extra) data to its
corresponding destination.
3.26.1) Zork Nemesis: The Forbidden Lands
Download the Liberation(tm) fonts package
https://releases.pagure.org/liberation-fonts/liberation-fonts-ttf-2.00.1.tar.gz
and unpack all the ttf files into your ScummVM extras directory.
Alternatively, download the GNU FreeFont TTF package
https://ftp.gnu.org/gnu/freefont/freefont-ttf.zip and unzip all the
ttf files from the sfd directory into your ScummVM extras directory,
though at the time of writing these fonts cause some text rendering
issues. Download the subtitles patch
https://www.thezorklibrary.com/installguides/znpatch.zip and unzip the
addon directory into the game root directory
3.26.2) Zork: Grand Inquisitor
Download the Liberation(tm) fonts package
https://releases.pagure.org/liberation-fonts/liberation-fonts-ttf-2.00.1.tar.gz
and unpack all the ttf files into your ScummVM extras directory.
Alternatively, download the GNU FreeFont TTF package
https://ftp.gnu.org/gnu/freefont/freefont-ttf.zip and unzip all the
ttf files from the sfd directory into your ScummVM extras directory,
though at the time of writing these fonts cause some text rendering
issues.
3.27) Commodore64 games notes
Both Maniac Mansion and Zak McKracken run but Maniac Mansion is not yet
playable. Simply name the D64 disks ""maniac1.d64"" and ""maniac2.d64""
respectively ""zak1.d64"" and ""zak2.d64"", then ScummVM should be able to
automatically detect the game if you point it at the right directory.
Alternatively, you can use extract_mm_c64 from the tools package to
extract the data files. But then the game will not be properly
autodetected by ScummVM, and you must make sure that the platform is set
to Commodore64. We recommend using the much simpler approach described
in the previous paragraph.
3.28) Macintosh games notes
All LucasArts SCUMM based adventures, except COMI, also exist in
versions for the Macintosh. ScummVM can use most (all?) of them,
however, in some cases some additional work is required. First off, if
you are not using a Macintosh for this, accessing the CD/floppy data
might be tricky. The reason for this is that the mac uses a special disk
format called HFS which other systems usually do not support. However,
there are various free tools which allow reading such HFS volumes. For
example HFSExplorer for Windows and hfsutils for Linux and other
Unix-like operating systems.
Most of the newer games on the Macintosh shipped with only a single data
file (note that in some cases this data file was made invisible, so you
may need extra tools in order to copy it). ScummVM is able to directly
use such a data file; simply point ScummVM at the directory containing
it, and it should work (just like with every other supported game).
We also provide a tool called extract_scumm_mac in the tools package
to extract the data from these data files, but this is neither required
nor recommended.
For further information on copying Macintosh game files to your hard
disk see:
https://wiki.scummvm.org/index.php/HOWTO-Mac_Games
4.0) Supported Platforms
ScummVM has been ported to run on many platforms and operating systems.
Links to these ports can be found either on the ScummVM web page or by a
Google search. Many thanks to our porters for their efforts. If you have
a port of ScummVM and wish to commit it into the master git, feel free
to contact us!
Supported platforms include (but are not limited to):

UNIX (Linux, Solaris, IRIX, *BSD, ...)
Windows
Windows CE
Windows Mobile (including Smartphones and PocketPCs)
Mac OS X
AmigaOS
Android
Atari/FreeMiNT
BeOS
Dreamcast
GP2x
Haiku
iPhone (also includes iPod Touch and iPad)
Maemo (Nokia Internet tablet N810)
Nintendo 64
Nintendo DS
Nintendo GameCube
Nintendo Wii
OpenPandora
OS/2
PlayStation 2
PlayStation 3
PlayStation Portable
PlayStation Vita
Raspberry Pi
RISC OS
Symbian
WebOS

The Dreamcast port does not support The Curse of Monkey Island, nor The
Dig. The Nintendo DS port does not support Full Throttle, The Dig, or
The Curse of Monkey Island. For more platform specific limitations,
please refer to our Wiki:
https://wiki.scummvm.org/index.php/Platforms
In the Macintosh port, the right mouse button is emulated via Cmd-Click
(that is, you click the mouse button while holding the
Command/Apple/Propeller key).
There are unofficial ports to a variety of platforms, including the
Xbox, and Xbox 360. Please note that these are not made
by us, so we neither endorse nor can we support them. Use at your own
risk!
5.0) Running ScummVM
Please note that by default, ScummVM will save games in the directory it
is executed from, so you should refrain from running it from more than
one location. Further information, including how to specify a specific
save directory to avoid this issue, are in section 6.0.
ScummVM can be launched directly by running the executable. In this
case, the built-in launcher will activate. From this, you can add games
(click 'Add Game'), or launch games which have already been configured.
Games can also be added in mass quantities. By pressing shift + 'Add
Game' (Note that the image turns to 'Mass Add'), you can then specify a
directory to start in, and ScummVM will attempt to detect games in all
subdirectories of that directory.
ScummVM can also be launched into a game directly using Command Line
arguments -- see the next section.
5.1) Command Line Options
Usage: scummvm [OPTIONS]... [GAME]

[GAME]                   Short name of game to load. For example, 'monkey'
                          for Monkey Island. This can be either a built-in
                          gameid, or a user configured target.

-v, --version            Display ScummVM version information and exit
-h, --help               Display a brief help text and exit
-z, --list-games         Display list of supported games and exit
-t, --list-targets       Display list of configured targets and exit
--list-saves             Display a list of saved games for the target specified
                          with --game=TARGET, or all targets if none is specified
-a, --add                Add all games from current or specified directory.
                          If --game=ID is passed only the game with id ID is
                          added. See also --detect.
                          Use --path=PATH to specify a directory.
--detect                 Display a list of games with their ID from current or
                          specified directory without adding it to the config.
                          Use --path=PATH to specify a directory.
--game=ID                In combination with --add or --detect only adds or attempts to
                          detect the game with id ID.
--auto-detect            Display a list of games from current or specified directory
                          and start the first one. Use --path=PATH to specify
                          a directory.
--recursive              In combination with --add or --detect recurse down all
                          subdirectories
--console                Enable the console window (default: enabled) (Windows only)

-c, --config=CONFIG      Use alternate configuration file
-p, --path=PATH          Path to where the game is installed
-x, --save-slot[=NUM]    Saved game slot to load (default: autosave)
-f, --fullscreen         Force full-screen mode
-F, --no-fullscreen      Force windowed mode
-g, --gfx-mode=MODE      Select graphics scaler (see also section 5.3)
--stretch-mode=MODE      Select stretch mode (center, integral, fit, stretch)
--filtering              Force filtered graphics mode
--no-filtering           Force unfiltered graphics mode


--gui-theme=THEME        Select GUI theme (default, modern, classic)
--themepath=PATH         Path to where GUI themes are stored
--list-themes            Display list of all usable GUI themes
-e, --music-driver=MODE  Select music driver (see also section 7.0)
--list-audio-devices     List all available audio devices
-q, --language=LANG      Select game's language (see also section 5.5)
-m, --music-volume=NUM   Set the music volume, 0-255 (default: 192)
-s, --sfx-volume=NUM     Set the sfx volume, 0-255 (default: 192)
-r, --speech-volume=NUM  Set the voice volume, 0-255 (default: 192)
--midi-gain=NUM          Set the gain for MIDI playback, 0-1000 (default: 100)
                          (only supported by some MIDI drivers)
-n, --subtitles          Enable subtitles (use with games that have voice)
-b, --boot-param=NUM     Pass number to the boot script (boot param)
-d, --debuglevel=NUM     Set debug verbosity level
--debugflags=FLAGS       Enable engine specific debug flags
                          (separated by commas)
-u, --dump-scripts       Enable script dumping if a directory called 'dumps'
                          exists in the current directory

--cdrom=NUM              CD drive to play CD audio from (default: 0 = first
                          drive)
--joystick[=NUM]         Enable joystick input (default: 0 = first joystick)
--platform=WORD          Specify platform of game (allowed values: 2gs, 3do,
                          acorn, amiga, atari, c64, fmtowns, mac, nes, pc,
                          pce, segacd, windows)
--savepath=PATH          Path to where saved games are stored
--extrapath=PATH         Extra path to additional game data
--soundfont=FILE         Select the SoundFont for MIDI playback (Only
                          supported by some MIDI drivers)
--multi-midi             Enable combination of AdLib and native MIDI
--native-mt32            True Roland MT-32 (disable GM emulation)
--enable-gs              Enable Roland GS mode for MIDI playback
--output-rate=RATE       Select output sample rate in Hz (e.g. 22050)
--opl-driver=DRIVER      Select AdLib (OPL) emulator (db, mame, nuked)
--aspect-ratio           Enable aspect ratio correction
--render-mode=MODE       Enable additional render modes (hercGreen, hercAmber,
                          cga, ega, vga, amiga, fmtowns, pc9821, pc9801, 2gs,
                          atari, macintosh)

--alt-intro              Use alternative intro for CD versions of Beneath a
                          Steel Sky and Flight of the Amazon Queen
--copy-protection        Enable copy protection in games, when
                          ScummVM disables it by default.
--talkspeed=NUM          Set talk delay for SCUMM games, or talk speed for
                          other games (default: 60)
--demo-mode              Start demo mode of Maniac Mansion (Classic version)
--tempo=NUM              Set music tempo (in percent, 50-200) for SCUMM games
                          (default: 100)

The meaning of most long options (that is, those options starting with a
double-dash) can be inverted by prefixing them with ""no-"". For example,
--no-aspect-ratio will turn aspect ratio correction off. This is
useful if you want to override a setting in the configuration file.
The short game name ('game target') you see at the end of the command
line specifies which game is started. It either corresponds to an
arbitrary user defined target (from the configuration file), or to a
built-in gameid. A brief list of the latter can be found in section 3.0.
Examples:


Win32:
Running Monkey Island, fullscreen, from a hard disk:
C:\Games\LucasArts\scummvm.exe -f -pC:\Games\LucasArts\monkey\ monkey
Running Full Throttle from CD, fullscreen and with subtitles
enabled:
C:\Games\LucasArts\scummvm.exe -f -n -pD:\resource\ ft


Unix:
Running Monkey Island, fullscreen, from a hard disk:
/path/to/scummvm -f -p/games/LucasArts/monkey/ monkey
Running Full Throttle from CD, fullscreen and with subtitles
enabled:
/path/to/scummvm -f -n -p/cdrom/resource/ ft


5.2) Global Menu
The Global Menu is a general menu which is available to all of the game
engines by pressing Ctrl-F5. From this menu there are the following
buttons: Resume, Options, About, Return to Launcher, and Quit. Selecting
Options will display a dialog where basic audio settings, such as
volume levels, can be adjusted. Selecting 'Return to Launcher' will
close the current game and return the user back to the ScummVM Launcher,
where another game may be selected to play.
Note: Returning to the Launcher is not supported by all of the engines,
and the button will be disabled in the Global Menu if it is not
supported.
Engines which currently support returning to the Launcher are:
AGI
AGOS
CINE
COMPOSER
CRUISE
DRACI
DRASCULA
GOB
GROOVIE
HUGO
KYRA
LURE
MADE
MOHAWK
PARALLACTION
QUEEN
SAGA
SCI
SCUMM
SKY
SWORD1
SWORD2
TEENAGENT
TITANIC
TOUCHE
TSAGE
TUCKER
ZVISION

5.3) Graphics filters
ScummVM offers several anti-aliasing filters to attempt to improve
visual quality. These are the same filters used in many other emulators,
such as MAME. These filters take the original game graphics, and scale
it by a certain fixed factor (usually 2x or 3x) before displaying them
to you. So for example, if the game originally run at a resolution of
320x200 (typical for most of the SCUMM games), then using a filter with
scale factor 2x will effectively yield 640x400 graphics. Likewise with a
3x filter you will get 960x600.
They are:
1x         - No filtering, no scaling. Fastest.
2x         - No filtering, factor 2x (default for non 640x480 games).
3x         - No filtering, factor 3x.
2xsai      - 2xSAI filter, factor 2x.
super2xsai - Enhanced 2xSAI filtering, factor 2x.
supereagle - Less blurry than 2xSAI, but slower. Factor 2x.
advmame2x  - Doesn't rely on blurring like 2xSAI, fast. Factor 2x.
advmame3x  - Doesn't rely on blurring like 2xSAI, fast. Factor 3x.
hq2x       - Very nice high quality filter but slow. Factor 2x.
hq3x       - Very nice high quality filter but slow. Factor 3x.
tv2x       - Interlace filter, tries to emulate a TV. Factor 2x.
dotmatrix  - Dot matrix effect. Factor 2x.

To select a graphics filter, select it in the Launcher, or pass its name
via the '-g' option to scummvm, for example:
scummvm -gadvmame2x monkey2

Note #1: Not all backends support all (or even any) of the filters
listed above; some may support additional ones. The filters listed above
are those supported by the default SDL backend.
Note #2: Filters can be very slow when ScummVM is compiled in a debug
configuration without optimizations. And there is always a speed impact
when using any form of anti-aliasing/linear filtering.
Note #3: The FM-TOWNS version of Zak McKracken uses an original
resolution of 320x240, hence for this game scalers will scale to 640x480
or 960x720. Likewise, games that originally were using 640x480 (such as
Curse of Monkey Island or Broken Sword) will be scaled to 1280x960 and
1920x1440.
5.4) Hotkeys
ScummVM supports various in-game hotkeys. They differ between SCUMM
games and other games.
  Common:
    Ctrl-F5                - Displays the Global Menu
    Cmd-q                  - Quit (Mac OS X)
    Ctrl-q                 - Quit (other unices including Linux)
    Alt-F4                 - Quit (Windows)
    Ctrl-z                 - Quit (other platforms)
    Ctrl-u                 - Mute all sounds
    Ctrl-m                 - Toggle mouse capture
    Ctrl-Alt 1-8           - Switch between graphics filters
    Ctrl-Alt + and -       - Increase/Decrease the scale factor
    Ctrl-Alt a             - Toggle aspect-ratio correction on/off
                             Most of the games use a 320x200 pixel
                             resolution, which may look squashed on
                             modern monitors. Aspect-ratio correction
                             stretches the image to use 320x240 pixels
                             instead, or a multiple thereof
    Ctrl-Alt f             - Enable/disable graphics filtering
    Ctrl-Alt s             - Cycle through scaling modes
    Alt-Enter              - Toggles full screen/windowed
    Alt-s                  - Make a screenshot (SDL backend only)
    Ctrl-F7                - Open virtual keyboard (if enabled)
                             This can also be triggered by a long press
                             of the middle mouse button or wheel.

  SCUMM:
    Alt-x                  - Quit
    Ctrl 0-9 and Alt 0-9   - Load and save game state
    Ctrl-d                 - Starts the debugger
    Ctrl-f                 - Toggle fast mode
    Ctrl-g                 - Runs in really REALLY fast mode
    Ctrl-t                 - Switch between 'Speech only',
                             'Speech and Subtitles' and 'Subtitles only'
    Tilde (~)              - Show/hide the debugging console
    [ and ]                - Music volume, down/up
    - and +                - Text speed, slower/faster
    F5                     - Displays a save/load box
    Alt-F5                 - Displays the original save/load box, if the
                             game has one. You can save and load games using
                             this, however it is not intended for this purpose,
                             and may even crash ScummVM in some games.
    i                      - Displays IQ points (Indiana Jones and the Last
                             Crusade, and Indiana Jones and the Fate of
                             Atlantis)
    Space                  - Pauses
    Period (.)             - Skips current line of text in some games
    Enter                  - Simulate left mouse button press
    Tab                    - Simulate right mouse button press

  Beneath a Steel Sky:
    Ctrl-d                 - Starts the debugger
    Ctrl-f                 - Toggle fast mode
    Ctrl-g                 - Runs in really REALLY fast mode
    F5                     - Displays a save/load box
    Escape                 - Skips the game intro
    Period (.)             - Skips current line of text

  Broken Sword:
    F5 or Escape           - Displays save/load box

  Broken Sword II:
    Ctrl-d                 - Starts the debugger
    Ctrl-f                 - Toggle fast mode
    p                      - Pauses

  Dragon History:
    F5                     - Displays the Global Menu
    left click             - Walk, explore
    right click            - Use, talk
    move mouse up, i       - Inventory
    move mouse down, m     - Map
    Escape                 - Skip the intro, exit map/inventory
    any click              - Skip the currently dubbed sentence
    q                      - Quick walking on/off

  Flight of the Amazon Queen:
    Ctrl-d                 - Starts the debugger
    Ctrl-f                 - Toggle fast mode
    F1                     - Use Journal (saving/loading)
    F11                    - Quicksave
    F12                    - Quickload
    Escape                 - Skips cutscenes
    Space                  - Skips current line of text

  Future Wars:
    F1                     - Examine
    F2                     - Take
    F3                     - Inventory
    F4                     - Use
    F5                     - Activate
    F6                     - Speak
    F9                     - ""Activate"" menu
    F10                    - ""Use"" menu
    Escape                 - Bring on command menu

  Nippon Safes:
    Ctrl-d                 - Starts the debugger
    l                      - Load game
    s                      - Save game

  Simon the Sorcerer 1 and 2:
    Ctrl 0-9 and Alt 0-9   - Load and save game state
    Ctrl-d                 - Starts the debugger
    Ctrl-f                 - Toggle fast mode
    F1 - F3                - Text speed, faster - slower
    F10                    - Shows all characters and objects you can
                             interact with
    Escape                 - Skip cutscenes
    - and +                - Music volume, down/up
    m                      - Music on/off
    s                      - Sound effects on/off
    b                      - Background sounds on/off
                             [Simon the Sorcerer 2 only]
    Pause                  - Pauses
    t                      - Switch between speech only and
                             combined speech and subtitles
                             [Simon the Sorcerer 1 CD (other than
                             English and German) and Simon the
                             Sorcerer 2 CD (all languages)]
    v                      - Switch between subtitles only and
                             combined speech and subtitles
                             [Simon the Sorcerer 2 CD only]

  Simon the Sorcerer's Puzzle Pack:
    Ctrl-d                 - Starts the debugger
    Ctrl-f                 - Toggle fast mode
    F12                    - High speed mode on/off in Swampy Adventures
    - and +                - Music volume, down/up
    m                      - Music on/off
    s                      - Sound effects on/off
    Pause                  - Pauses

  Starship Titanic:    
    Ctrl-c                 - Open up the developer's cheat room
    Ctrl-d                 - Open up the ScummVM Debugger
    Left click             - Move action
    Shift-Left click       - Edit room glyph chevrons and 
                              quick movement transitions
    Right click            - Edit room glyph chevrons 
                              and quick transitions
    Mouse wheel            - Scroll through items (inventory, etc) 
                              and conversation log
    Arrow keys             - Movement. Down arrow/back is only available if the
                              given view explicitly has a backwards movement 
                              available.        
    F1                     - Switch to Chat-O-Mat
    F2                     - Switch to Personal Baggage
    F3                     - Switch to Remote Thingummy
    F4                     - Switch to Designer Room Numbers (chevron list)
    F5                     - GMM save menu
    F6                     - Switch to Real Life
    F7                     - GMM restore menu

  Starship Titanic (Starfield Puzzle):
    Tab                    - Toggle between starmap and skyscape
    Mouse click:           - skyscape star selection and
                              starmap star fast travel
    Mouse movement         - starmap orientation
    SPACE                  - starmap stop movement
    z                      - starmap turn left
    x                      - starmap turn right
    Single quote (')       - starmap turn up
    Forward slash (/)      - starmap turn down
    Semicolon (;)          - starmap move forward
    Period (.)             - starmap move backward
    l                      - starmap lock coordinate
    d                      - starmap unlock coordinate
    
  The Feeble Files:
    Ctrl-d                 - Starts the debugger
    Ctrl-f                 - Toggle fast mode
    F7                     - Switch characters
    F9                     - Hitbox names on/off
    s                      - Sound effects on/off
    Pause                  - Pauses
    t                      - Switch between speech only and
                             combined speech and subtitles
    v                      - Switch between subtitles only and
                             combined speech and subtitles

  The Legend of Kyrandia:
    Ctrl 0-9 and Alt 0-9   - Load and save game state
    Ctrl-d                 - Starts the debugger

  TeenAgent
    F5                     - Displays the Global Menu

  Touche: The Adventures of the Fifth Musketeer:
    Ctrl-f                 - Toggle fast mode
    F5                     - Displays options
    F9                     - Turn fast walk mode on
    F10                    - Turn fast walk mode off
    Escape                 - Quit
    Space                  - Skips current line of text
    t                      - Switch between 'Voice only',
                             'Voice and Text' and 'Text only'

  Zork: Grand Inquisitor:
    Ctrl-s                 - Save
    Ctrl-r                 - Restore
    Ctrl-q                 - Quit
    Ctrl-p                 - Preferences
    F1                     - Help
    F5                     - Inventory
    F6                     - Spellbook
    F7                     - Score
    F8                     - Put away current object/forget spell
    F9                     - Extract coin (must have the coin bag)
    Space                  - Skips movies

  Zork Nemesis: The Forbidden Lands:
    Ctrl-s                 - Save
    Ctrl-r                 - Restore
    Ctrl-q                 - Quit
    Ctrl-p                 - Preferences
    Space                  - Skips movies

Note that using Ctrl-f or Ctrl-g is not recommended: games can crash
when being run faster than their normal speed, as scripts will lose
synchronisation.
Note for WinCE users: Due to the limited keyboard input in most devices,
a small subset of these hot keys are supported via key remapping and/or
panel actions. Please consult the README-WinCE.txt file.
5.5) Language options
ScummVM includes a language option for Maniac Mansion, Zak McKracken,
The Dig, The Curse of Monkey Island, Beneath a Steel Sky and Broken
Sword.
Note that with the exception of Beneath a Steel Sky, Broken Sword,
multilanguage versions of Goblins games and Nippon Safes Inc., using
this option does not change the language of the game (which usually is
hardcoded), but rather is only used to select the appropriate font (e.g.
for a German version of a game, one containing umlauts).
An exception are The Dig and The Curse of Monkey Island -- non-English
versions can be set to 'English.' This however only affects subtitles;
game speech will remain the same.
Maniac Mansion and Zak McKracken
    en  - English (default)
    de  - German
    fr  - French
    it  - Italian
    es  - Spanish

The Dig
    jp  - Japanese
    zh  - Chinese
    kr  - Korean

The Curse of Monkey Island
    en  - English (default)
    de  - German
    fr  - French
    it  - Italian
    pt  - Portuguese
    es  - Spanish
    jp  - Japanese
    zh  - Chinese
    kr  - Korean

Beneath a Steel Sky
    gb  - English (Great Britain) (default)
    en  - English (USA)
    de  - German
    fr  - French
    it  - Italian
    pt  - Portuguese
    es  - Spanish
    se  - Swedish

Broken Sword
    en  - English (default)
    de  - German
    fr  - French
    it  - Italian
    es  - Spanish
    pt  - Portuguese
    cz  - Czech

6.0) Saved Games
Saved games are by default put in the current directory on some
platforms and preset directories on others. You can specify the save in
the config file by setting the savepath parameter. See the example
config file later in this README.
The platforms that currently have a different default directory are:
Mac OS X:
$HOME/Documents/ScummVM Savegames/
Other unices:
We follow the XDG Base Directory Specification. This means by default
saved games can be found in: $XDG_DATA_HOME/scummvm/saves/
If XDG_DATA_HOME is not defined or empty, ~/.local/share will be
used as value of XDG_DATA_HOME in accordance with the specification.
If an earlier version of ScummVM was installed on your system, the
previous default location of ~/.scummvm will be kept. This is detected
based on the presence of the path ~/.scummvm.
Windows Vista/7:
\Users\username\AppData\Roaming\ScummVM\Saved games\
Windows 2000/XP:
\Documents and Settings\username\Application Data\ScummVM\Saved games\
Windows NT4:
<windir>\Profiles\username\Application Data\ScummVM\Saved games\
Saved games are stored under a hidden area in Windows
NT4/2000/XP/Vista/7, which can be accessed by running
%APPDATA%\ScummVM\Saved Games or by enabling hidden files in Windows
Explorer.
Note for Windows NT4/2000/XP/Vista/7 users: The default saved games
location changed in ScummVM 1.5.0. The migration batch file can be used
to copy saved games from the old default location, to the new default
location.
6.1) Autosaves
For some games ScummVM will by default automatically save the current
state every five minutes (adjustable via the autosave_period config
setting). The default autosave slot for many engines is slot 0.
The games/engines listed below have autosave support.

AGI games
Beneath a Steel Sky
Bud Tucker in Double Trouble
COMPOSER games
Flight of the Amazon Queen
Myst
Riven
SCUMM games
The Legend of Kyrandia I (slot 999)
ZVISION games

For the SCUMM engine, this saved game can then be loaded again via
Ctrl-0, or the F5 menu.
6.2) Converting Saved Games
Using saved games from original versions isn't supported by all game
engines. Only the following games can use saved games from their
original versions.


Elvira 1

Add 8 bytes (saved game name) to the start of the saved game
file
Rename the saved game to elvira1.xxx



Elvira 2

Add 8 bytes (saved game name) to the start of the saved game
file
Rename the saved game to elvira2-pc.xxx (DOS version) or
elvira2.xxx (Other versions)



Myst

Rename the saved game to myst-xxx.mys
Saves from the masterpiece edition and the regular edition are
interchangeable



Riven

Rename the saved game to riven-xxx.rvn
Saves from the CD and DVD edition are not interchangeable



Simon the Sorcerer 1

Rename the saved game to simon1.xxx



Simon the Sorcerer 2

Rename the saved game to simon2.xxx



Starship Titanic

Rename the saved game to titanic-win.xxx for saves from the
English version and titanic-win-de.xxx for saves from the
German version
Saved games between different languages are not interchangeable



The Feeble Files

Rename the saved game to feeble.xxx



Waxworks

Add 8 bytes (saved game name) to the start of the saved game
file
Rename the saved game to waxworks-pc.xxx (DOS version) or
waxworks.xxx (Other versions)



Where xxx is exact the saved game slot (i.e., 001) under ScummVM
6.3) Viewing/Loading saved games from the command line
--list-saves
This switch may be used to display a list of the current saved games of
the specified target game and their corresponding save slots. If no
target is specified, it lists saved games for all known target.
Usage: --list-saves --game=[TARGET], where [TARGET] is the target
game.
Engines which currently support --list-saves are:

AGI
AGOS
CGE
CINE
CRUISE
DRACI
GROOVIE
HUGO
KYRA
LURE
MOHAWK
PARALLACTION
QUEEN
SAGA
SCI
SCUMM
SKY
SWORD1
SWORD2
TEENAGENT
TINSEL
TITANIC
TOON
TOUCHE
TSAGE
TUCKER
ZVISION

--save-slot/-x
This switch may be used to load a saved game directly from the command
line.
Usage: --save-slot[SLOT] or -x[SLOT], where [SLOT] is the save
slot number.
Engines which currently support --save-slot / -x are:

AGI
CGE
CINE
CRUISE
DRACI
GROOVIE
HUGO
KYRA
LURE
MOHAWK
QUEEN
SAGA
SCI
SCUMM
SKY
SWORD1
SWORD2
TEENAGENT
TINSEL
TITANIC
TOON
TOUCHE
TSAGE
TUCKER
ZVISION

7.0) Music and Sound
On most operating systems and for most games, ScummVM will by default
use MT-32 or AdLib emulation for music playback. MIDI may not be
available on all operating systems or may need manual configuration. If
you want to use MIDI, you have several different choices of output,
depending on your operating system and configuration.
null       - Null output. Don't play any music.

adlib      - Internal AdLib emulation
fluidsynth - FluidSynth MIDI emulation
mt32       - Internal MT-32 emulation
pcjr       - Internal PCjr emulation (only usable in SCUMM games)
pcspk      - Internal PC Speaker emulation
towns      - Internal FM-TOWNS YM2612 emulation
             (only usable in SCUMM FM-TOWNS games)

alsa       - Output using ALSA sequencer device. See below.
core       - CoreAudio sound, for Mac OS X users.
coremidi   - CoreMIDI sound, for Mac OS X users. Use only if you have
             a hardware MIDI synthesizer.
seq        - Use /dev/sequencer for MIDI, *nix users. See below.
timidity   - Connect to TiMidity++ MIDI server. See below.
windows    - Windows MIDI. Uses built-in sequencer, for Windows users

To select a sound driver, select it in the Launcher, or pass its name
via the -e option to scummvm, for example:
scummvm -eadlib monkey2
7.1) AdLib emulation
By default an AdLib card will be emulated and ScummVM will output the
music as sampled waves. This is the default mode for several games, and
offers the best compatibility between machines and games.
7.2) FluidSynth MIDI emulation
If ScummVM was build with libfluidsynth support it will be able to play
MIDI music through the FluidSynth driver. You will have to specify a
SoundFont to use, however.
Since the default output volume from FluidSynth can be fairly low,
ScummVM will set the gain by default to get a stronger signal. This can
be further adjusted using the --midi-gain command-line option, or the
midi_gain config file setting.
The setting can take any value from 0 through 1000, with the default
being 100. (This corresponds to FluidSynth's gain settings of 0.0
through 10.0, which are presumably measured in decibel.)
NOTE: The processor requirements for FluidSynth can be fairly high in
some cases. A fast CPU is recommended.
7.3) MT-32 emulation
Some games which contain MIDI music data also have improved tracks
designed for the MT-32 sound module. ScummVM can now emulate this
device, however you must provide original MT-32 ROMs to make it work:
MT32_PCM.ROM - IC21 (512KB)
MT32_CONTROL.ROM - IC26 (32KB) and IC27 (32KB), interleaved byte-wise
Place these ROMs in the game directory, in your extrapath, or in the
directory where your ScummVM executable resides.
You don't need to specify --native-mt32 with this driver, as it
automatically gets turned on.
NOTE: The processor requirements for the emulator are quite high; a fast
CPU is strongly recommended.
7.4) MIDI emulation
Some games (such as Sam & Max) only contain MIDI music data. This once
prevented music for these games from working on platforms that do not
support MIDI, or soundcards that do not provide MIDI drivers (e.g. many
soundcards will not play MIDI under Linux). ScummVM can now emulate MIDI
mode using sampled waves and AdLib, FluidSynth MIDI emulation or MT-32
emulation using the -eadlib, -efluidsynth or -emt32 options
respectively. However, if you are capable of using native MIDI, we
recommend using one of the MIDI modes below for best sound.
7.5) Native MIDI support
Use the appropriate -e<mode> command line option from the list above
to select your preferred MIDI device. For example, if you wish to use
the Windows MIDI driver, use the -ewindows option.
7.5.1) Using MIDI options to customize Native MIDI output
ScummVM supports a variety of MIDI modes, depending on the capabilities
of your MIDI device.
If --native-mt32 is specified, ScummVM will treat your device as a
real MT-32. Because the instrument mappings and system exclusive
commands of the MT-32 vary from those of General MIDI devices, you
should only enable this option if you are using an actual Roland MT-32,
LAPC-I, CM-64, CM-32L, CM-500, or GS device with an MT-32 map.
If --enable-gs is specified, ScummVM will initialize your
GS-compatible device with settings that mimic the MT-32's reverb, (lack
of) chorus, pitch bend sensitivity, etc. If it is specified in
conjunction with --native-mt32, ScummVM will select the
MT-32-compatible map and drumset on your GS device. This setting works
better than default GM or GS emulation with games that do not have
custom instrument mappings (Loom and Monkey1). You should only specify
both settings if you are using a GS device that has an MT-32 map, such
as an SC-55, SC-88, SC-88 Pro, SC-8820, SC-8850, etc. Please note that
--enable-gs is automatically disabled in both DOTT and Samnmax, since
they use General MIDI natively.
If neither of the above settings is enabled, ScummVM will initialize
your device in General MIDI mode and use GM emulation in games with
MT-32 soundtracks.
Some games contain sound effects that are exclusive to the AdLib
soundtrack. For these games, you may wish to specify --multi-midi in
order to combine MIDI music with AdLib sound effects.
7.6) UNIX native, ALSA and dmedia sequencer support
If your soundcard driver supports a sequencer, you may set the
environment variable SCUMMVM_MIDI to your sequencer device -- for
example, to /dev/sequencer
If you have problems with not hearing audio in this configuration, you
may need to set the environment variable SCUMMVM_MIDIPORT to 1 or 2.
This selects the port on the selected sequencer to use. Then start
scummvm with the -eseq parameter. This should work on several cards,
and may offer better performance and quality than AdLib emulation.
However, for those systems where sequencer support does not work, you
can always fall back on AdLib emulation.
7.6.1) ALSA sequencer [UNIX ONLY]
If you have installed the ALSA driver with sequencer support, then you
may set the environment variable SCUMMVM_PORT or the config file
variable alsa_port to specify your sequencer port. If neither is set,
the default behavior is to try both ""65:0"" and ""17:0"".
Here is a brief guide on how to use the ALSA sequencer with your
soundcard. In all cases, to obtain a list of all the sequencer ports you
have, try the command aconnect -o -l. This should give output similar
to:
    client 14: 'Midi Through' [type=kernel]
        0 'Midi Through Port-0'
    client 16: 'SBLive! Value [CT4832]' [type=kernel]
        0 'EMU10K1 MPU-401 (UART)'
    client 17: 'Emu10k1 WaveTable' [type=kernel]
        0 'Emu10k1 Port 0  '
        1 'Emu10k1 Port 1  '
        2 'Emu10k1 Port 2  '
        3 'Emu10k1 Port 3  '
    client 128: 'TiMidity' [type=user]
        0 'TiMidity port 0 '
        1 'TiMidity port 1 '
        2 'TiMidity port 2 '
        3 'TiMidity port 3 '

The most important bit here is that there are four WaveTable MIDI
outputs located at 17:0, 17:1, 17:2 and 17:3, and four TiMidity ports
located at 128:0, 128:1, 128:2 and 128:3.
If you have a FM-chip on your card, like the SB16, then you have to load
the SoundFonts using the sbiload software. Example:
sbiload -p 17:0 /etc/std.o3 /etc/drums.o3

If you have a WaveTable capable sound card, you have to load a sbk or
sf2 SoundFont using the sfxload or asfxload software. Example:
sfxload /path/to/8mbgmsfx.sf2

If you don't have a MIDI capable soundcard, there are two options:
FluidSynth and TiMidity. We recommend FluidSynth, as on many systems
TiMidity will 'lag' behind music. This is very noticeable in
iMUSE-enabled games, which use fast and dynamic music transitions.
Running TiMidity as root will allow it to setup real time priority,
which may reduce music lag.
Asking TiMidity to become an ALSA sequencer:
timidity -iAqqq -B2,8 -Os1S -s 44100 &

(If you get distorted output with this setting, you can try dropping the
-B2,8 or changing the value.)
Asking FluidSynth to become an ALSA sequencer (using SoundFonts):
fluidsynth -m alsa_seq /path/to/8mbgmsfx.sf2

Once either TiMidity or FluidSynth are running, use the 'aconnect -o -l'
command as described earlier in this section.
7.6.2) IRIX dmedia sequencer: [UNIX ONLY]
If you are using IRIX and the dmedia driver with sequencer support, you
can set the environment variable SCUMMVM_MIDIPORT or the config file
variable dmedia_port to specify your sequencer port. The default is to
use the first port.
To get a list of configured midi interfaces on your system, run
""startmidi"" without parameters. Example output:
  2 MIDI interfaces configured:
          Serial Port 2
          Software Synth

In this example, you can configure ScummVM to use the ""Software Synth""
instead of the default ""Serial Port 2"" by adding a line
dmedia_port=Software Synth

to your configuration file in the section [scummvm], or setting
SCUMMVM_PORT=Software Synth in your environment.
7.7) TiMidity++ MIDI server support
If your system lacks any MIDI sequencer, but you still want better MIDI
quality than default AdLib emulation can offer, you can try the
TiMidity++ MIDI server. See http://timidity.sourceforge.net/ for
download and install instructions.
First, you need to start a daemon:
timidity -ir 7777

Now you can start ScummVM and try selection TiMidity music output. By
default, it will connect to localhost:7777, but you can change host/port
via the TIMIDITY_HOST environment variable. You can also specify a
""device number"" using the SCUMMVM_MIDIPORT environment variable.
7.8) Using compressed audio files
7.8.1) Using MP3 files for CD audio
Use LAME or some other MP3 encoder to rip the cd audio tracks to files.
Name the files track1.mp3 track2.mp3 etc. ScummVM must be compiled with
MAD support to use this option. You will need to rip the file from the
CD as a WAV file, then encode the MP3 files in constant bit rate. This
can be done with the following LAME command line:
lame -t -q 0 -b 96 track1.wav track1.mp3

7.8.2) Using Ogg Vorbis files for CD audio
Use oggenc or some other vorbis encoder to encode the audio tracks to
files. Name the files track1.ogg track2.ogg etc. ScummVM must be
compiled with vorbis support to use this option. You will need to rip
the files from the CD as a WAV file, then encode the vorbis files. This
can be done with the following oggenc command line with the value after
q specifying the desired quality from 0 to 10:
oggenc -q 5 track1.wav

7.8.3) Using Flac files for CD audio
Use flac or some other flac encoder to encode the audio tracks to files.
Name the files track1.flac track2.flac etc. If your filesystem only
allows three letter extensions, name the files track1.fla track2.fla
etc. ScummVM must be compiled with flac support to use this option. You
will need to rip the files from the CD as a WAV file, then encode the
flac files. This can be done with the following flac command line:
flac --best track1.wav

Remember that the quality is always the same, varying encoder options
will only affect the encoding time and resulting filesize.
7.8.4) Compressing MONSTER.SOU with MP3
You need LAME, and our compress_scumm_sou utility from the
scummvm-tools package to perform this task, and ScummVM must be compiled
with MAD support.
compress_scumm_sou monster.sou

Eventually you will have a much smaller monster.so3 file, copy this file
to your game directory. You can safely remove the monster.sou file.
7.8.5) Compressing MONSTER.SOU with Ogg Vorbis
As above, but ScummVM must be compiled with OGG support. Run:
compress_scumm_sou --vorbis monster.sou

This should produce a smaller monster.sog file, which you should copy to
your game directory. Ogg encoding may take a considerable longer amount
of time than MP3, so have a good book handy.
7.8.6) Compressing MONSTER.SOU with Flac
As above, but ScummVM must be compiled with Flac support. Run:
compress_scumm_sou --flac monster.sou

This should produce a smaller monster.sof file, which you should copy to
your game directory. Remember that the quality is always the same,
varying encoder options will only affect the encoding time and resulting
file size. Playing with the blocksize (-b <value>), has the biggest
impact on the resulting file size -- 1152 seems to be a good value for
those kind of soundfiles. Be sure to read the encoder documentation
before you use other values.
7.8.7) Compressing music/sfx/speech in AGOS games
Use our compress_agos utility from the scummvm-tools package to
perform this task. You can choose between multiple target formats, but
note that you can only use each if ScummVM was compiled with the
respective decoder support enabled.
  compress_agos effects     (For Acorn CD version of Simon 1)
  compress_agos simon       (For Acorn CD version of Simon 1)
  compress_agos effects.voc (For DOS CD version of Simon 1)
  compress_agos simon.voc   (For DOS CD version of Simon 1)
  compress_agos simon.wav   (For Windows CD version of Simon 1)
  compress_agos simon2.voc  (For DOS CD version of Simon 2)
  compress_agos simon2.wav  (For Windows CD version of Simon 2)
  compress_agos mac         (For Macintosh version of Simon 2)

  compress_agos voices1.wav (For Windows 2CD/4CD version of Feeble)
  compress_agos voices2.wav (For Windows 2CD/4CD version of Feeble)
  compress_agos voices3.wav (For Windows 4CD version of Feeble)
  compress_agos voices4.wav (For Windows 4CD version of Feeble)

  compress_agos Music       (For Windows version of Puzzle Pack)

For Ogg Vorbis add --vorbis to the options, i.e.
compress_agos --vorbis

For Flac add --flac and optional parameters, i.e.
compress_agos --flac

Eventually you will have a much smaller *.mp3, *.ogg or *.fla file,
copy this file to your game directory. You can safely remove the old
file.
7.8.8) Compressing speech/music in Broken Sword
The compress_sword1 tool from the scummvm-tools package can encode
music and speech to MP3, Ogg Vorbis as well as Flac. The easiest way to
encode the files is simply copying the executable into your BS1
directory (together with the lame encoder) and run it from there. This
way, it will automatically encode everything to MP3. Afterwards, you can
manually remove the SPEECH?.CLU files and the wave music files.
Running compress_sword1 --vorbis will compress the files using Ogg
Vorbis instead of MP3.
Running compress_sword1 --flac will compress the files using Flac
instead of MP3.
Use compress_sword1 --help to get a full list of the options.
7.8.9) Compressing speech/music in Broken Sword II
Use our compress_sword2 utility from the scummvm-tools package to
perform this task. You can choose between multiple target formats, but
note that you can only use each if ScummVM was compiled with the
respective decoder support enabled.
  compress_sword2 speech1.clu
  compress_sword2 music1.clu

For Ogg Vorbis add --vorbis to the options, i.e.
compress_sword2 --vorbis

Eventually you will have a much smaller *.cl3 or *.clg file, copy this
file to your game directory. You can safely remove the old file.
It is possible to use Flac compression by adding the --flac option.
However, the resulting *.clf file will actually be larger than the
original.
Please note that compress_sword2 will only work with the four
speech/music files in Broken Sword II. It will not work with any of the
other *.clu files, nor will it work with the speech files from Broken
Sword.
7.9) Output sample rate
The output sample rate tells ScummVM how many sound samples to play per
channel per second. There is much that could be said on this subject,
but most of it would be irrelevant here. The short version is that for
most games 22050 Hz is fine, but in some cases 44100 Hz is preferable.
On extremely low-end systems you may want to use 11025 Hz, but it is
unlikely that you have to worry about that.
To elaborate, most of the sounds ScummVM has to play were sampled at
either 22050 Hz or 11025 Hz. Using a higher sample rate will not
magically improve the quality of these sounds. Hence, 22050 Hz is fine.
Some games use CD audio. If you use compressed files for this, they are
probably sampled at 44100 Hz, so for these games that may be a better
choice of sample rate.
When using the AdLib, FM Towns, PC Speaker or IBM PCjr music drivers,
ScummVM is responsible for generating the samples. Usually 22050 Hz will
be plenty for these, but there is at least one piece of AdLib music in
Beneath a Steel Sky that will sound a lot better at 44100 Hz.
Using frequencies in between is not recommended. For one thing, your
sound card may not support it. In theory, ScummVM should fall back on a
sensible frequency in that case, but don't count on it. More
importantly, ScummVM has to resample all sounds to its output frequency.
This is much easier to do well if the output frequency is a multiple of
the original frequency.
8.0) Configuration file
By default, the configuration file is saved in, and loaded from:
Windows Vista/7:
\Users\username\AppData\Roaming\ScummVM\scummvm.ini
Windows 2000/XP:
\Documents and Settings\username\Application Data\ScummVM\scummvm.ini
Windows NT4:
<windir>\Profiles\username\Application Data\ScummVM\scummvm.ini
Windows 95/98/ME:
<windir>\scummvm.ini
If an earlier version of ScummVM was installed under Windows, the
previous default location of <windir>\scummvm.ini will be kept.
Unix:
We follow the XDG Base Directory Specification. This means our
configuration can be found in: $XDG_CONFIG_HOME/scummvm/scummvm.ini
If XDG_CONFIG_HOME is not defined or empty, ~/.config will be used
as value for XDG_CONFIG_HOME in accordance with the specification.
If an earlier version of ScummVM was installed on your system, the
previous default location of ~/.scummvmrc will be kept.
Mac OS X:
~/Library/Preferences/ScummVM Preferences (here, ~ refers to your
home directory)
Others:
scummvm.ini in the current directory
An example config file looks as follows:
    [scummvm]
    gfx_mode=supereagle
    fullscreen=true
    savepath=C:\saves\

    [sky]
    path=C:\games\SteelSky\

    [germansky]
    gameid=sky
    language=de
    path=C:\games\SteelSky\
    description=Beneath a Steel Sky w/ German subtitles

    [germandott]
    gameid=tentacle
    path=C:\german\tentacle\
    description=German version of DOTT

    [tentacle]
    path=C:\tentacle\
    subtitles=true
    music_volume=40
    sfx_volume=255

    [loomcd]
    cdrom=1
    path=C:\loom\
    talkspeed=5
    savepath=C:\loom\saves\

    [monkey2]
    path=C:\amiga_mi2\
    music_driver=windows

8.1) Recognized configuration keywords
The following keywords are recognized:
path               string   The path to where a game's data files are
autosave_period    number   The seconds between autosaving (default: 300)
save_slot          number   The saved game number to load on startup.
savepath           string   The path to where a game will store its
                            saved games.
screenshotpath     string   The path to where screenshots are saved.
iconpath           string   The path to where to look for icons to use as
                            overlay for the ScummVM icon in the Windows
                            taskbar or macOS X Dock when running a game.
                            The icon files should be named after the game
                            ids and be in ico format on Windows or png
                            format on macOS X.
versioninfo        string   The version of the ScummVM that created the
                            configuration file.

gameid             string   The real id of a game. Useful if you have
                            several versions of the same game, and want
                            different aliases for them. See the example.
description        string   The description of the game as it will appear
                            in the launcher.

language           string   Specify language (en, us, de, fr, it, pt, es,
                            jp, zh, kr, se, gb, hb, cz, ru)
speech_mute        bool     If true, speech is muted
subtitles          bool     Set to true to enable subtitles.
talkspeed          number   Text delay in SCUMM games, or text speed in
                            other games.

fullscreen         bool     Fullscreen mode
aspect_ratio       bool     Enable aspect ratio correction
gfx_mode           string   Graphics mode (normal, 2x, 3x, 2xsai,
                            super2xsai, supereagle, advmame2x, advmame3x,
                            hq2x, hq3x, tv2x, dotmatrix, opengl)
filtering          bool     Enable graphics filtering

confirm_exit       bool     Ask for confirmation by the user before
                            quitting (SDL backend only).
console            bool     Enable the console window (default: enabled)
                            (Windows only).
cdrom              number   Number of CD-ROM unit to use for audio. If
                            negative, don't even try to access the CD-ROM.
joystick_num       number   Number of joystick device to use for input
controller_map_db  string   A custom controller mapping file to load to
                            complete default database (SDL backend only).
                            Otherwise, file gamecontrollerdb.txt will be
                            loaded from extrapath.
music_driver       string   The music engine to use.
opl_driver         string   The AdLib (OPL) emulator to use.
output_rate        number   The output sample rate to use, in Hz. Sensible
                            values are 11025, 22050 and 44100.
audio_buffer_size  number   Overrides the size of the audio buffer. The
                            value must be one of: 256 512 1024 2048 4096
                            8192 16384 32768. The default value is
                            calculated based on the output_rate to keep
                            audio latency below 45ms.
alsa_port          string   Port to use for output when using the
                            ALSA music driver.
music_volume       number   The music volume setting (0-255)
multi_midi         bool     If true, enable combination AdLib and native
                            MIDI.
soundfont          string   The SoundFont to use for MIDI playback. (Only
                            supported by some MIDI drivers.)
native_mt32        bool     If true, disable GM emulation and assume that
                            there is a true Roland MT-32 available.
enable_gs          bool     If true, enable Roland GS-specific features to
                            enhance GM emulation. If native_mt32 is also
                            true, the GS device will select an MT-32 map
                            to play the correct instruments.
sfx_volume         number   The sfx volume setting (0-255)
tempo              number   The music tempo (50-200) (default: 100)
speech_volume      number   The speech volume setting (0-255)
midi_gain          number   The MIDI gain (0-1000) (default: 100) (Only
                            supported by some MIDI drivers.)

copy_protection    bool     Enable copy protection in certain games, in
                            those cases where ScummVM disables it by
                            default.
demo_mode          bool     Start demo in Maniac Mansion
alt_intro          bool     Use alternative intro for CD versions of
                            Beneath a Steel Sky and Flight of the Amazon
                            Queen

boot_param         number   Pass this number to the boot script

Sierra games using the AGI engine add the following non-standard keywords:
originalsaveload   bool     If true, the original save/load screens are
                            used instead of the enhanced ScummVM ones
altamigapalette    bool     Use an alternative palette, common for all
                            Amiga games. This was the old behavior
mousesupport       bool     Enables mouse support. Allows to use mouse
                            for movement and in game menus

Sierra games using the SCI engine add the following non-standard keywords:
disable_dithering  bool     Remove dithering artifacts from EGA games
prefer_digitalsfx  bool     If true, digital sound effects are preferred
                            instead of synthesized ones
originalsaveload   bool     If true, the original save/load screens are
                            used instead of the enhanced ScummVM ones
native_fb01        bool     If true, the music driver for an IBM Music
                            Feature card or a Yamaha FB-01 FM synth module
                            is used for MIDI output
use_cdaudio        bool     Use CD audio instead of in-game audio,
                            when available
windows_cursors    bool     Use the Windows cursors (smaller and monochrome)
                            instead of the DOS ones (King's Quest 6)
silver_cursors     bool     Use the alternate set of silver cursors,
                            instead of the normal golden ones (Space Quest 4)

Broken Sword II adds the following non-standard keywords:
gfx_details        number   Graphics details setting (0-3)
music_mute         bool     If true, music is muted
object_labels      bool     If true, object labels are enabled
reverse_stereo     bool     If true, stereo channels are reversed
sfx_mute           bool     If true, sound effects are muted

Flight of the Amazon Queen adds the following non-standard keywords:
music_mute         bool     If true, music is muted
sfx_mute           bool     If true, sound effects are muted

Hopkins FBI adds the following non-standard keyword:
enable_gore        bool     If true, enable some optional gore content in
                            the game

Jones in the Fast Lane adds the following non-standard keyword:
music_mute         bool     If true, CD audio is used, if available,
                            instead of in-game audio

King's Quest VI Windows adds the following non-standard keyword:
windows_cursors    bool     If true, the original unscaled black and white
                            Windows cursors are used instead of the DOS
                            ones. If false, the DOS cursors are used in the
                            Windows version, upscaled to match the rest of
                            the upscaled graphics

Lands of Lore: The Throne of Chaos adds the following non-standard keywords:
smooth_scrolling   bool     If true, scrolling is smoother when changing
                            from one screen to another
floating_cursors   bool     If true, the cursor changes when it floats to
                            the edge of the screen to a directional arrow.
                            The player can then click to walk towards that
                            direction.

Space Quest IV CD adds the following non-standard keyword:
silver_cursors     bool     If true, an alternate set of silver mouse
                            cursors is used instead of the original golden
                            ones

Simon the Sorcerer 1 and 2 add the following non-standard keywords:
music_mute         bool     If true, music is muted
sfx_mute           bool     If true, sound effects are muted

Soltys adds the following non-standard keyword:
enable_color_blind bool     If true, original colors are replaced by a set
                            of greys

The Legend of Kyrandia adds the following non-standard keyword:
walkspeed          number   The walk speed (0-4)

The Legend of Kyrandia: The Hand of Fate adds the following non-standard
keyword:
walkspeed          number   The walk speed (3 or 5, resp. fast or
                            slow)

The Legend of Kyrandia: Malcolm's Revenge adds the following non-standard
keywords:
walkspeed          number   The walk speed (3 or 5, resp. fast or
                            slow)
studio_audience    bool     If true, applause and cheering sounds are heard
                            whenever Malcolm makes a joke
skip_support       bool     If true, the player can skip text and cutscenes
helium_mode        bool     If true, people sound like they've inhaled
                            Helium

The Neverhood adds the following non-standard keywords:
originalsaveload   bool     If true, the original save/load screens are
                            used instead of the enhanced ScummVM ones
skiphallofrecordsscenes     bool
                            If true, allows the player to skip
                            past the Hall of Records storyboard scenes
scalemakingofvideos  bool   If true, the making of videos are scaled, so that
                            they use the whole screen

The 7th Guest adds the following non-standard keyword:
fast_movie_speed   bool     If true, movies are played at an increased
                            speed, matching the speed of the iOS version.
                            Movies without sound are still played at their
                            normal speed, to avoid music synchronization
                            issues

Zork Nemesis: The Forbidden Lands adds the following non-standard keywords:
originalsaveload   bool     If true, the original save/load screens are
                            used instead of the enhanced ScummVM ones
doublefps          bool     If true, game FPS are increased from 30 to 60
venusenabled       bool     If true, the in-game Venus help system is
                            enabled
noanimwhileturning bool     If true, animations are disabled while turning
                            in panoramic mode

Zork: Grand Inquisitor adds the following non-standard keywords:
originalsaveload   bool     If true, the original save/load screens are
                            used instead of the enhanced ScummVM ones
doublefps          bool     If true, game FPS are increased from 30 to 60
noanimwhileturning bool     If true, animations are disabled while turning
                            in panoramic mode
mpegmovies         bool     If true, the hires MPEG movies are used in the
                            DVD version of the game, instead of the lowres
                            AVI ones

8.2) Custom game options that can be toggled via the GUI
A lot of the custom game options in the previous section can be toggled
via the GUI. If a custom option is available for a specific game, a new
tab called ""Engine"" will appear when adding or editing the configuration
of that game. If the custom options are not shown, the games in question
will need to be run once or readded in the ScummVM launcher's game list.
This will update the configuration of each entry, allowing the custom
options to be shown.
9.0) Screenshots (SDL backend only)
On systems using the SDL backend (for example Windows, Mac or Linux) you
can use alt+s to take snapshots (see section 5.4 - Hotkeys).
You can specify the directory in which you want the screenshots to be
created in the config file. To do so add a screenshotpath value under
the [scummvm] section:
[scummvm]
screenshotpath=/path/to/screenshots/

The default location, when no screenshot path is defined in the config
file, depends on the OS:

Windows: In Users\username\My Pictures\ScummVM Screenshots.
macOS X: On the Desktop.
Other unices: In the XDG Pictures user directory,
e.g. ~/Pictures/ScummVM Screenshots
Any other OS: In the current directory.

10.0) Compiling
For an up-to-date overview on how to compile ScummVM for various
platforms, please consult our Wiki, in particular this page:
https://wiki.scummvm.org/index.php/Compiling_ScummVM
If you are compiling for Windows, Linux or Mac OS X, you need SDL-1.2.2
or newer (older versions may work, but are unsupported), and a supported
compiler. Several compilers, including GCC, mingw and recent versions of
Microsoft Visual C++ are supported. If you wish to use MP3-compressed CD
tracks or .SOU files, you will need to install the MAD library; likewise
you will need the appropriate libraries for Ogg Vorbis and FLAC
compressed sound. For compressed save states, zlib is required.
Some parts of ScummVM, particularly scalers, have highly optimized
versions written in assembler. If you wish to use this option, you will
need to install nasm assembler (see https://www.nasm.us/). Note that
we currently only have x86 MMX optimized versions, and they will not
compile on other processors.
On Windows, you can define USE_WINDBG and attach WinDbg to browse
debug messages (see
https://docs.microsoft.com/en-us/windows-hardware/drivers/debugger/index).


Windows:


MinGW:

Please refer to:
https://wiki.scummvm.org/index.php/Compiling_ScummVM/MinGW



Visual Studio (MSVC):

Please refer to:
https://wiki.scummvm.org/index.php/Compiling_ScummVM/Visual_Studio





Linux:


GCC:

Please refer to:
https://wiki.scummvm.org/index.php/Compiling_ScummVM/GCC





AmigaOS4:

Please refer to:
https://wiki.scummvm.org/index.php/Compiling_ScummVM/AmigaOS4



Apple iPhone:

Please refer to:
https://wiki.scummvm.org/index.php/Compiling_ScummVM/iPhone



Atari/FreeMiNT:

Please refer to:
https://wiki.scummvm.org/index.php/Compiling_ScummVM/Atari/FreeMiNT



Bada/Tizen:

Please refer to:
https://wiki.scummvm.org/index.php/Compiling_ScummVM/Bada/Tizen



BeOS/ZETA/Haiku:

Please refer to:
https://wiki.scummvm.org/index.php/Compiling_ScummVM/BeOS/ZETA/Haiku



Google Android:

Please refer to:
https://wiki.scummvm.org/index.php/Compiling_ScummVM/Android



HP webOS:

Please refer to:
https://wiki.scummvm.org/index.php/Compiling_ScummVM/WebOS



Mac OS:


Mac OS X:

Please refer to:
https://wiki.scummvm.org/index.php/Compiling_ScummVM/macOS



Mac OS X 10.2.8:

Please refer to:
https://wiki.scummvm.org/index.php/Compiling_ScummVM/Mac_OS_X_10.2.8



Mac OS X Crosscompiling:

Please refer to:
https://wiki.scummvm.org/index.php/Compiling_ScummVM/Mac_OS_X_Crosscompiling





Maemo:

Please refer to:
https://wiki.scummvm.org/index.php/Compiling_ScummVM/Maemo



Nintendo Wii and Gamecube:

Please refer to:
https://wiki.scummvm.org/index.php/Compiling_ScummVM/Wii



Raspberry Pi:

Please refer to:
https://wiki.scummvm.org/index.php/Compiling_ScummVM/RPI



Sega Dreamcast:

Please refer to:
https://wiki.scummvm.org/index.php/Compiling_ScummVM/Dreamcast



Sony Playstation:


Sony PlayStation 2:

Please refer to:
https://wiki.scummvm.org/index.php/Compiling_ScummVM/PlayStation_2



Sony PlayStation 3:

Please refer to:
https://wiki.scummvm.org/index.php/PlayStation_3#Building_from_source



Sony PlayStation Portable:

Please refer to:
https://wiki.scummvm.org/index.php/Compiling_ScummVM/PlayStation_Portable





Symbian:

Please refer to:
https://wiki.scummvm.org/index.php/Compiling_ScummVM/Symbian



11.0) Changelog
Please refer to our extensive Changelog here.
12.0) Credits
Please refer to our extensive Credits list here.


Good Luck and Happy Adventuring!
The ScummVM team.
https://www.scummvm.org/

",1065
TheCjw/scoop-retools,PowerShell,"scoop-retools
   
Scoop bucket for reverse engineering tools.
Usage


Install scoop


Add this bucket to scoop:


scoop bucket add retools https://github.com/TheCjw/scoop-retools.git

Install tools via scoop install:

scoop install smali baksmali apktool

Done.

Using DynamoRIO
Bulid WinAFL
scoop install dynamorio
git clone https://github.com/googleprojectzero/winafl
cd winafl
# Compile 32bit tool
mkdir build32
cd build32
cmake .. -DDynamoRIO_DIR=""$env:DYNAMORIO_DIR""
cmake --build . --config Release
# or 64bit
mkdir build64
cd build64
cmake .. -DDynamoRIO_DIR=""$env:DYNAMORIO_DIR""
cmake --build . --config Release
",21
geekhch/homework,Jupyter Notebook,"homework
",6
vromero/activemq-artemis-docker,XSLT,"     
1. What is ActiveMQ Artemis?
Apache ActiveMQ Artemis is an open source project to build a multi-protocol, embeddable, very high performance, clustered, asynchronous messaging system. Apache ActiveMQ Artemis is an example of Message Oriented Middleware (MoM).

2. Tags and Dockerfile links



Debian Based
Alpine Based




latest
latest-alpine


2.7.0
2.7.0-alpine


2.6.4
2.6.4-alpine


2.6.3
2.6.3-alpine


2.6.2
2.6.2-alpine


2.6.1
2.6.1-alpine


2.6.0
2.6.0-alpine


2.5.0
2.5.0-alpine


2.4.0
2.4.0-alpine


2.3.0
2.3.0-alpine


2.2.0
2.2.0-alpine


2.1.0
2.1.0-alpine


2.0.0
2.0.0-alpine


1.5.6
1.5.6-alpine


1.5.5
1.5.5-alpine


1.5.4
1.5.4-alpine


1.5.3
1.5.3-alpine


1.5.2
1.5.2-alpine


1.5.1
1.5.1-alpine


1.5.0
1.5.0-alpine


1.4.0
1.4.0-alpine


1.3.0
1.3.0-alpine


1.2.0
1.2.0-alpine


1.1.0
1.1.0-alpine


1.0.0
1.0.0-alpine



3. About this image
The ActiveMQ Artemis images come in two flavors, both equally supported :

Debian based: the default one.
Alpine based: much lighter.

All versions of ActiveMQ Artemis are provided for the time being but versions previous to 1.5.5 shall be considered deprecated and could be removed at any time.
This image shall not be considered production ready as is. If you plan to use this image in a production environment, fork the image in order to maintain stability as
the build is reproducible in a best effort basis. Then at each rebase, make sure you tests the changes you are importing.
4. How to use this image
You can find how to run this image in the section Running the image. Beware as the default
configuration is not recommended for production usage, at the very least you'll want to set your own
login and password. This is described with detail in section Setting the username and password.
In case you also want to set some customized memory limits, this is described in
Setting the memory values.
ActiveMQ Artemis typically persists the queue state to disk. In order to leverage the most of your
disk ActiveMQ artemis might require some fine-tuning. The good news is that this process is
fully automated and its described in Performing a performance journal test.
JMX uses RMI and therefore random ports. This is extremely bad for automatization in Docker and
in general. For that reason its not supported for most of the use cases. However, when using this
image in orchestrators like Kubernetes you might want to connect from a sidecar where it
does make sense. How to enable JMX is described in section Enabling JMX.
The Jolokia console CORS header won't be a problem by default as it set to *, however if you want to
narrow it down for improved security don't miss the section Settings the console's allow origin.
In rare ocassions you might find the need of running ActiveMQ Artemis without security. This
is described in section Disabling security.
Some of the configurations mentioned above are scripted automations that modify the
configuration files. You might have your own configuration that you want to provide as a whole.
In that case disregard the aforementioned sections and find how to pass your own
configuration in section Using external configuration files.
If instead you want to use the configuration parameters and make some non-mayor changes to the
configuration you could use the mechanisms to apply some small transformations using XSLT
as described in section Overriding parts of the configuration.
5. Running the image
There are different methods to run a Docker image, from interactive Docker to Kubernetes and Docker
Compose. This documentation will cover only Docker with an interactive terminal mode. You should
refer to the appropriate documentation for more information around other execution methods.
To run ActiveMQ with AMQP, JMS and the web console open (if your are running 2.3.0 or later),
run the following command:
docker run -it --rm \
  -p 8161:8161 \
  -p 61616:61616 \
  vromero/activemq-artemis
After a few seconds you'll see in the output a block similar to:
_        _               _
/ \  ____| |_  ___ __  __(_) _____
/ _ \|  _ \ __|/ _ \  \/  | |/  __/
/ ___ \ | \/ |_/  __/ |\/| | |\___ \
/_/   \_\|   \__\____|_|  |_|_|/___ /
Apache ActiveMQ Artemis x.x.x

HH:mm:ss,SSS INFO  [...] AMQ101000: Starting ActiveMQ Artemis Server

At this point you can open the web server port at 8161 and check the web console using
the default username and password of artemis / simetraehcapa.
5.1 Setting the username and password
If you wish to change the default username and password of artemis / simetraehcapa, you can do so with the ARTEMIS_USERNAME and ARTEMIS_PASSWORD environment variables:
docker run -it --rm \
  -e ARTEMIS_USERNAME=myuser \
  -e ARTEMIS_PASSWORD=otherpassword \
  vromero/activemq-artemis
5.2 Setting the memory values
By default this image does leverage the new features that came in Java 8u131 related to memory ergonomics in containerized environments, more information about it here.
It does use a -XX:MaxRAMFraction=2 meaning that half of the memory made avaiable to the container will be used by the Java heap, leaving the other half for other types of Java memory and other OS purposes. However, in some
circumstances it might be advisable to fine tune the memory to manual values, in that case you can set the memory that you application needs by using the parameters ARTEMIS_MIN_MEMORY and ARTEMIS_MAX_MEMORY:
docker run -it --rm \
  -e 'ARTEMIS_MIN_MEMORY=1512M' \
  -e 'ARTEMIS_MAX_MEMORY=3048M' \
  vromero/activemq-artemis
The previous example will launch Apache ActiveMQ Artemis in docker with 1512 MB of memory, with a maximum usage of 3048 MB of memory.
The format of the values passed is the same than the format used for the Java -Xms and -Xmx parameters and its documented here.
5.3 Performing a performance journal test
Different kinds of volumes need different values in fine tuning. In ActiveMQ Artemis the journal-buffer-timeout is oftentimes configured for this purpose.
Since 1.5.3 it is possible to calculate the optimal value automatically. This image supports this automation using the environment variable: ARTEMIS_PERF_JOURNAL with one of the following values:



Value
Description




AUTO (default)
Checks for the existence of a .perf-journal-completed file in the data volume, if it doesn't exist performs the calculation, applies the configuration and creates the file.


NEVER
Never do the performance journal configuration


ALWAYS
Always do the performance journal configuration



It is safe to leave it as AUTO even for the casual usage of this image given that the image already have
incorporated a .perf-journal-completed for its internal directory used when no volume is mounted.
One example of execution with the performance journal calibration set to be executed always can be found
in the next listing:
docker run -it --rm \
  -e ARTEMIS_PERF_JOURNAL=ALWAYS \
  vromero/activemq-artemis
5.4 Enabling JMX
Due to the JMX's nature, often with dynamics ports for RMI and the need having configure the public IP address to reach the RMI server.
It is discouraged to use JMX in Docker. Although in certain scenarios, it could be advisable, as when deploying in a
container orchestrator such as Kubernetes or Mesos, and deploying along side this container a side car. For such cases
the following environment variable could be used: ENABLE_JMX.
It is also possible to set the JMX port and the JMX RMI port with these two environment variables respectively: JMX_PORT (default: 1099) and JMX_RMI_PORT (default: 1098).
Given that JMX is intended for side cars, it is attached only to localhost and not protected with SSL. Likewise, its ports are not declared in the Dockerfile.
docker run -it --rm \
  -e ENABLE_JMX=true \
  -e JMX_PORT=1199 \
  -e JMX_RMI_PORT=1198 \
  vromero/activemq-artemis
5.5 Prometheus metrics
When using this image in a orchestrated environmnet like in Kubernetes. It is often useful to have metrics endpoints compatible
with prometheus to ease monitoring.
This image can export such metrics in port 9404 thanks to the integration with the Prometheus JMX exporter. In order to enable it the environmnet variable ENABLE_JMX_EXPORTER should
be present, it will also inderectly enable JMX as if ENABLE_JMX was set.
To see what is exported just:
docker run -it --rm \
  -p9404:9404 \
  -e ENABLE_JMX_EXPORTER=true \
  vromero/activemq-artemis
And then in a different terminal run:
curl http://127.0.0.1:9404
To obtain the following and more:
# HELP artemis_disk_scan_period How often to check for disk space usage, in milliseconds (org.apache.activemq.artemis<broker=""0.0.0.0""><>DiskScanPeriod)
# TYPE artemis_disk_scan_period counter
artemis_disk_scan_period 5000.0
# HELP artemis_durable_delivering_count number of durable messages that this queue is currently delivering to its consumers (org.apache.activemq.artemis<broker=""0.0.0.0"", component=addresses, address=""DLQ"", subcomponent=queues, routing-type=""anycast"", queue=""DLQ""><>DurableDeliveringCount)
# TYPE artemis_durable_delivering_count counter
artemis_durable_delivering_count{queue=""DLQ"",address=""DLQ"",} 0.0
artemis_durable_delivering_count{queue=""ExpiryQueue"",address=""ExpiryQueue"",} 0.0
# HELP artemis_journal_min_files Number of journal files to pre-create (org.apache.activemq.artemis<broker=""0.0.0.0""><>JournalMinFiles)
# TYPE artemis_journal_min_files counter
artemis_journal_min_files 2.0
# HELP artemis_message_expiry_thread_priority Priority of the thread used to scan message expiration (org.apache.activemq.artemis<broker=""0.0.0.0""><>MessageExpiryThreadPriority)
# TYPE artemis_message_expiry_thread_priority counter
artemis_message_expiry_thread_priority 3.0
# HELP artemis_messages_killed number of messages removed from this queue since it was created due to exceeding the max delivery attempts (org.apache.activemq.artemis<broker=""0.0.0.0"", component=addresses, address=""DLQ"", subcomponent=queues, routing-type=""anycast"", queue=""DLQ""><>MessagesKilled)
# TYPE artemis_messages_killed counter
artemis_messages_killed{queue=""DLQ"",address=""DLQ"",} 0.0
artemis_messages_killed{queue=""ExpiryQueue"",address=""ExpiryQueue"",} 0.0
# HELP artemis_address_memory_usage_percentage Memory used by all the addresses on broker as a percentage of global maximum limit (org.apache.activemq.artemis<broker=""0.0.0.0""><>AddressMemoryUsagePercentage)
# TYPE artemis_address_memory_usage_percentage counter
artemis_address_memory_usage_percentage 0.0
# HELP artemis_journal_sync_non_transactional Whether the journal is synchronized when receiving non-transactional datar (org.apache.activemq.artemis<broker=""0.0.0.0""><>JournalSyncNonTransactional)
# TYPE artemis_journal_sync_non_transactional counter
artemis_journal_sync_non_transactional 1.0
# HELP artemis_journal_buffer_size Size of the internal buffer on the journal (org.apache.activemq.artemis<broker=""0.0.0.0""><>JournalBufferSize)
# TYPE artemis_journal_buffer_size counter
artemis_journal_buffer_size 501760.0
# HELP artemis_journal_max_io Maximum number of write requests that can be in the AIO queue at any given time (org.apache.activemq.artemis<broker=""0.0.0.0""><>JournalMaxIO)
# TYPE artemis_journal_max_io counter
artemis_journal_max_io 4096.0

In case you need more control over the metrics that are exported, you can mount a jmx-exporter
configuration file in /opt/jmx-exporter/etc-override with the file name jmx-exporter-config.yaml.
5.6 Settings the console's allow origin
ActiveMQ Artemis console uses Jolokia. In the default vanilla non-docker installation Jolokia does set a CORS header to
allow only localhost. In the docker image this create problems as things are rarely accesed as localhost.
Therefore the docker image does set the CORS header to * by default. However there is a mechanism to narrow it
down to whatever value is best suited to you for improved security through the environmnet property: JOLOKIA_ALLOW_ORIGIN.
docker run -it --rm \
  -e JOLOKIA_ALLOW_ORIGIN=192.168.1.1 \
  vromero/activemq-artemis
5.7 Overriding parts of the configuration
ActiveMQ Artemis support disabling the security using the element <security-enabled>false</security-enabled>
as described in the official documentation.
This docker image makes it simple to set that element using the environment property: DISABLE_SECURITY:
docker run -it --rm \
  -e DISABLE_SECURITY=true \
  vromero/activemq-artemis
Please keep in mind no production system, possible no environment at all, should ever disable security.
Make sure you read the falacy number one of the falacies of the distributed computing before disabling the security.
5.8 Using external configuration files
It is possible to mount a whole artemis etc directory in this image in the volume /var/lib/artemis/etc.
Be careful as this might be an overkill for many situations where only small tweaks are necessary.
When using this technique be aware that the configuration files of Artemis might change from version to version.
Generally speaking, when in need to configure Artemis beyond what it is offered by this image using environment
variables, it is recommended to use the partial override mechanism described in the next section.
5.9 Overriding parts of the configuration
The default ActiveMQ Artemis configuration can be partially modified, instead of completely replaced as in the previous section, using three mechanisms. Merge snippets, XSLT tranformations and entrypoint overrides.
Merging snippets
Multiple files with snippets of configuration can be dropped in the /var/lib/artemis/etc-override volume. Those configuration files must be named following the name convention broker-{{num}}.xml where num is a numeric representation of the snippet.
The configuration files will be merged with the default configuration. An alphabetical precedence of the file names will be considered for the merge and in case of collision the latest change will be treated as final.
For instance lets say that you want to add a diverts section, you could have a local directory, lets say /var/artemis-data/etc-override
where you could place a broker-00.xml file that looks like the following listing:
<?xml version=""1.0"" encoding=""UTF-8"" standalone=""no""?>

<configuration xmlns=""urn:activemq"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""urn:activemq /schema/artemis-configuration.xsd"">
   <!-- from 1.0.0 to 1.5.5 the following line should be : <core xmlns=""urn:activemq:core""> -->
   <core xmlns=""urn:activemq:core"" xsi:schemaLocation=""urn:activemq:core "">
      <diverts>
         <divert name=""order-divert"">
            <routing-name>order-divert</routing-name>
            <address>orders</address>
            <forwarding-address>spyTopic</forwarding-address>
            <exclusive>false</exclusive>
         </divert>
      </diverts>
   </core>
</configuration>
Please notice the core element change along with the versions:

1.0.0 up to 1.5.5: <core xmlns=""urn:activemq:core"">
2.0.0 onwards: <core xmlns=""urn:activemq:core"" xsi:schemaLocation=""urn:activemq:core "">

Configuration transformations
For the use cases where instead of merging, the desired outcome is a deletion or some other kind of advanced transformation a file named broker-00.xslt
in /var/lib/artemis/etc-override is supported. For instance to delete the jms definitions that is present by default in the broker.xml file shown below:
<?xml version=""1.0"" encoding=""UTF-8"" standalone=""no""?>

<configuration xmlns=""urn:activemq"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""urn:activemq /schema/artemis-configuration.xsd"">
  ...
  <jms xmlns=""urn:activemq:jms"">
    <queue name=""myfancyqueue""/>
    <queue name=""myotherqueue""/>
  </jms>
  ...
</configuration>
A file name broker-00.xslt with content like the following listing, could be used:
<xsl:stylesheet version=""1.0"" xmlns:xsl=""http://www.w3.org/1999/XSL/Transform""
  xmlns:activemq=""urn:activemq"" xmlns:jms=""urn:activemq:jms"">

 <xsl:output omit-xml-declaration=""yes""/>

    <xsl:template match=""node()|@*"">
      <xsl:copy>
         <xsl:apply-templates select=""node()|@*""/>
      </xsl:copy>
    </xsl:template>

    <xsl:template match=""*[local-name()='jms']""/>
</xsl:stylesheet>
Entrypoint Overrides
Multiple shell scripts can be dropped in the /var/lib/artemis/etc-override volume. Those shell files must be named following the name convention entrypoint-{{num}}.sh where num is a numeric representation of the snippet.
The shell scripts will be executed in alphabetical precedence of the file names on startup of the docker container.
A typical use case for using entrypoint overrides would be if you want to make a minor modification to a file which cannot be overriden using the 2 methods above and you do not want to expose the etc volume.
If you would like to see the final result of your transformations, execute the following:
docker run -it --rm \
  -v /var/artemis-data/override:/var/lib/artemis/etc-override \
  vromero/activemq-artemis \
  cat ../etc/broker.xml

5.10 Broker Config
ActiveMQ allows you to override key configuration values using System properties.
This docker image has built in support to set these values by passing environment variables prefixed with BROKER_CONFIG to the docker image.
Below is an example which overrides the global-max-size and disk-scan-period values
docker run -it --rm   -p 8161:8161 \
    -e BROKER_CONFIG_GLOBAL_MAX_SIZE=50000 \
    -e BROKER_CONFIG_DISK_SCAN_PERIOD=6000 \
    vromero/activemq-artemis

5.11 Environment Variables
Additionally, the following environment variables are supported



Env Var
Default
Description




JAVA_OPTS

Will pass additional java options to the artemis runtime



5.12 Mount points



Mount point
Description




/var/lib/artemis/data
Holds the data files used for storing persistent messages


/var/lib/artemis/etc
Holds the instance configuration files


/var/lib/artemis/etc-override
Holds the instance configuration files


/var/lib/artemis/lock
Holds the command line locks (typically not useful to mount)


/opt/jmx-exporter/etc-override
Holds the configuration file for jmx-exporter jmx-exporter-config.yaml



5.13 Exposed ports



Port
Description




8161
Web Server


9404
JMX Exporter


61616
Core,MQTT,AMQP,HORNETQ,STOMP,Openwire


5445
HORNETQ,STOMP


5672
AMQP


1883
MQTT


61613
STOMP



6. Running in orchestrators
At the moment only docker is directly supported for this image. However there is an attempt to create
a helm chart for Kubernetes and some configuration tuning for OpenShift.
6.1 Running in Kubernetes
ActiveMQ Artemis can leverage JGroups to discover the members of the cluster. And JGroups
can be extended with a plugin called jgroups-kubernetes
that allows JGroups to discover using Kubernetes.
jgroups-kubernetes version 0.9.3 is included in the classpath of
this image, however everything about the configuration of jgroups and jgroups-kubernetes is left to the user.
If you rather prefer a easier solution to run a cluster of ActiveMQ Artemis nodes, there is an attempt to create a Helm chart
by the same author of this image. It can be found here. It
does leverage jgroups-kubernetes in a transparent way.
6.2 OpenShift
OpenShift has diverted a bit from Kubernetes (e.g: automounts empty volumes in all declared volumes without
the user asking for it at all) and Docker (e.g: runs on an random user).
The biggest problem to run this image is the automount of empty directories because it empties the etc directory.
In order to restore it the environment variable RESTORE_CONFIGURATION has been created. It can be used as follows:
oc new-app --name=artemis vromero/activemq-artemis -e RESTORE_CONFIGURATION=true
7. License
View license information for the software contained in this image.
8. User Feedback
8.1 Issues
If you have any problems with or questions about this image, please contact us through a GitHub issue.
8.2 Contributing
You are invited to contribute new features, fixes, or updates, large or small; we are always thrilled to receive pull requests, and do our best to process them as fast as we can.
Before you start to code, we recommend discussing your plans through a GitHub issue, especially for more ambitious contributions. This gives other contributors a chance to point you in the right direction, give you feedback on your design, and help you find out if someone else is working on the same thing.
",57
d-e-s-o/cell,Rust,"



cell

Documentation
Changelog

cell is a crate providing a revised RefCell implementation with
additional mapping capabilities. It can be used as a drop-in replacement
for std::cell::RefCell where this additional functionality is required.
The Problem
A borrowed RefCell is represented as a
Ref. Such a Ref contains a reference to the data
contained in the RefCell. To extend the borrow to a different member
in the original data, the map method can be used.
Using this method a new Ref object can be created that contains a
reference to a member in the borrowed data.
While having a direct reference to such a data member is appropriate in
many cases, there are some where this is insufficient, and an actual
object that contains such a reference is required.
Example
The most prominent example is an iterator. While an iterator internally
keeps a reference to the object being iterated over, it is more than
just a reference to it: it contains state about the progress of the
iteration.
If such an iterator is to be exposed for an object contained in a
RefCell that is currently borrowed, the Ref::map function is
insufficient:
struct RefStrings(RefCell<Vec<String>>);

impl RefStrings {
    fn iter(&self) -> Ref<Iter<String>> {
        Ref::map(self.0.borrow(), |x| x.iter())
    }
}
error[E0308]: mismatched types
 |  Ref::map(self.0.borrow(), |x| x.iter())
 |                                ^^^^^^^^ expected reference, found struct `std::slice::Iter`
 |
 = note: expected type `&_`
            found type `std::slice::Iter<'_, std::string::String>`

(Note that required lifetimes have been elided in the example for brevity)
A Solution
This crate provides alternative RefCell and Ref implementations that
solve this problem by introduction of another mapping method: map_val.
This method returns a RefVal object. RefVal is a new type that is
similar to Ref but, instead of embedding a reference to its T (a
type parameter), it embeds a value of it. T in turn would contain the
actual reference to the borrowed object.
In the above example the only changes that need to happen are the
replacement of std::cell::RefCell with cell::RefCell, that of
std::cell::Ref with cell::Ref, and the usage of Ref::map instead
of Ref::map_val.
--- test.rs
+++ test.rs
@@ -1,13 +1,14 @@
-use std::cell::Ref;
-use std::cell::RefCell;
+use cell::Ref;
+use cell::RefCell;
+use cell::RefVal;
 use std::slice::Iter;


 struct RefStrings(RefCell<Vec<String>>);

 impl RefStrings {
-    fn iter<'t, 's: 't>(&'s self) -> Ref<'t, Iter<String>> {
-        Ref::map(self.0.borrow(), |x| x.iter())
+    fn iter<'t, 's: 't>(&'s self) -> RefVal<'t, Iter<String>> {
+        Ref::map_val(self.0.borrow(), |x| x.iter())
     }
 }

Alternative Implementations
The possibility of providing this functionality by means of a trait has
been investigated but no viable solution has been identified. The main
problem stems from the fact that we require access to Ref internals in
order to provide this functionality. Such a trait would alleviate the
need for providing alternative RefCell and Ref implementations.
No other existing solutions for this problem have been found.
A discussion around the upstreaming of this functionality is tracked by
Rust issue #54776.
",3
vromero/activemq-artemis-docker,XSLT,"     
1. What is ActiveMQ Artemis?
Apache ActiveMQ Artemis is an open source project to build a multi-protocol, embeddable, very high performance, clustered, asynchronous messaging system. Apache ActiveMQ Artemis is an example of Message Oriented Middleware (MoM).

2. Tags and Dockerfile links



Debian Based
Alpine Based




latest
latest-alpine


2.7.0
2.7.0-alpine


2.6.4
2.6.4-alpine


2.6.3
2.6.3-alpine


2.6.2
2.6.2-alpine


2.6.1
2.6.1-alpine


2.6.0
2.6.0-alpine


2.5.0
2.5.0-alpine


2.4.0
2.4.0-alpine


2.3.0
2.3.0-alpine


2.2.0
2.2.0-alpine


2.1.0
2.1.0-alpine


2.0.0
2.0.0-alpine


1.5.6
1.5.6-alpine


1.5.5
1.5.5-alpine


1.5.4
1.5.4-alpine


1.5.3
1.5.3-alpine


1.5.2
1.5.2-alpine


1.5.1
1.5.1-alpine


1.5.0
1.5.0-alpine


1.4.0
1.4.0-alpine


1.3.0
1.3.0-alpine


1.2.0
1.2.0-alpine


1.1.0
1.1.0-alpine


1.0.0
1.0.0-alpine



3. About this image
The ActiveMQ Artemis images come in two flavors, both equally supported :

Debian based: the default one.
Alpine based: much lighter.

All versions of ActiveMQ Artemis are provided for the time being but versions previous to 1.5.5 shall be considered deprecated and could be removed at any time.
This image shall not be considered production ready as is. If you plan to use this image in a production environment, fork the image in order to maintain stability as
the build is reproducible in a best effort basis. Then at each rebase, make sure you tests the changes you are importing.
4. How to use this image
You can find how to run this image in the section Running the image. Beware as the default
configuration is not recommended for production usage, at the very least you'll want to set your own
login and password. This is described with detail in section Setting the username and password.
In case you also want to set some customized memory limits, this is described in
Setting the memory values.
ActiveMQ Artemis typically persists the queue state to disk. In order to leverage the most of your
disk ActiveMQ artemis might require some fine-tuning. The good news is that this process is
fully automated and its described in Performing a performance journal test.
JMX uses RMI and therefore random ports. This is extremely bad for automatization in Docker and
in general. For that reason its not supported for most of the use cases. However, when using this
image in orchestrators like Kubernetes you might want to connect from a sidecar where it
does make sense. How to enable JMX is described in section Enabling JMX.
The Jolokia console CORS header won't be a problem by default as it set to *, however if you want to
narrow it down for improved security don't miss the section Settings the console's allow origin.
In rare ocassions you might find the need of running ActiveMQ Artemis without security. This
is described in section Disabling security.
Some of the configurations mentioned above are scripted automations that modify the
configuration files. You might have your own configuration that you want to provide as a whole.
In that case disregard the aforementioned sections and find how to pass your own
configuration in section Using external configuration files.
If instead you want to use the configuration parameters and make some non-mayor changes to the
configuration you could use the mechanisms to apply some small transformations using XSLT
as described in section Overriding parts of the configuration.
5. Running the image
There are different methods to run a Docker image, from interactive Docker to Kubernetes and Docker
Compose. This documentation will cover only Docker with an interactive terminal mode. You should
refer to the appropriate documentation for more information around other execution methods.
To run ActiveMQ with AMQP, JMS and the web console open (if your are running 2.3.0 or later),
run the following command:
docker run -it --rm \
  -p 8161:8161 \
  -p 61616:61616 \
  vromero/activemq-artemis
After a few seconds you'll see in the output a block similar to:
_        _               _
/ \  ____| |_  ___ __  __(_) _____
/ _ \|  _ \ __|/ _ \  \/  | |/  __/
/ ___ \ | \/ |_/  __/ |\/| | |\___ \
/_/   \_\|   \__\____|_|  |_|_|/___ /
Apache ActiveMQ Artemis x.x.x

HH:mm:ss,SSS INFO  [...] AMQ101000: Starting ActiveMQ Artemis Server

At this point you can open the web server port at 8161 and check the web console using
the default username and password of artemis / simetraehcapa.
5.1 Setting the username and password
If you wish to change the default username and password of artemis / simetraehcapa, you can do so with the ARTEMIS_USERNAME and ARTEMIS_PASSWORD environment variables:
docker run -it --rm \
  -e ARTEMIS_USERNAME=myuser \
  -e ARTEMIS_PASSWORD=otherpassword \
  vromero/activemq-artemis
5.2 Setting the memory values
By default this image does leverage the new features that came in Java 8u131 related to memory ergonomics in containerized environments, more information about it here.
It does use a -XX:MaxRAMFraction=2 meaning that half of the memory made avaiable to the container will be used by the Java heap, leaving the other half for other types of Java memory and other OS purposes. However, in some
circumstances it might be advisable to fine tune the memory to manual values, in that case you can set the memory that you application needs by using the parameters ARTEMIS_MIN_MEMORY and ARTEMIS_MAX_MEMORY:
docker run -it --rm \
  -e 'ARTEMIS_MIN_MEMORY=1512M' \
  -e 'ARTEMIS_MAX_MEMORY=3048M' \
  vromero/activemq-artemis
The previous example will launch Apache ActiveMQ Artemis in docker with 1512 MB of memory, with a maximum usage of 3048 MB of memory.
The format of the values passed is the same than the format used for the Java -Xms and -Xmx parameters and its documented here.
5.3 Performing a performance journal test
Different kinds of volumes need different values in fine tuning. In ActiveMQ Artemis the journal-buffer-timeout is oftentimes configured for this purpose.
Since 1.5.3 it is possible to calculate the optimal value automatically. This image supports this automation using the environment variable: ARTEMIS_PERF_JOURNAL with one of the following values:



Value
Description




AUTO (default)
Checks for the existence of a .perf-journal-completed file in the data volume, if it doesn't exist performs the calculation, applies the configuration and creates the file.


NEVER
Never do the performance journal configuration


ALWAYS
Always do the performance journal configuration



It is safe to leave it as AUTO even for the casual usage of this image given that the image already have
incorporated a .perf-journal-completed for its internal directory used when no volume is mounted.
One example of execution with the performance journal calibration set to be executed always can be found
in the next listing:
docker run -it --rm \
  -e ARTEMIS_PERF_JOURNAL=ALWAYS \
  vromero/activemq-artemis
5.4 Enabling JMX
Due to the JMX's nature, often with dynamics ports for RMI and the need having configure the public IP address to reach the RMI server.
It is discouraged to use JMX in Docker. Although in certain scenarios, it could be advisable, as when deploying in a
container orchestrator such as Kubernetes or Mesos, and deploying along side this container a side car. For such cases
the following environment variable could be used: ENABLE_JMX.
It is also possible to set the JMX port and the JMX RMI port with these two environment variables respectively: JMX_PORT (default: 1099) and JMX_RMI_PORT (default: 1098).
Given that JMX is intended for side cars, it is attached only to localhost and not protected with SSL. Likewise, its ports are not declared in the Dockerfile.
docker run -it --rm \
  -e ENABLE_JMX=true \
  -e JMX_PORT=1199 \
  -e JMX_RMI_PORT=1198 \
  vromero/activemq-artemis
5.5 Prometheus metrics
When using this image in a orchestrated environmnet like in Kubernetes. It is often useful to have metrics endpoints compatible
with prometheus to ease monitoring.
This image can export such metrics in port 9404 thanks to the integration with the Prometheus JMX exporter. In order to enable it the environmnet variable ENABLE_JMX_EXPORTER should
be present, it will also inderectly enable JMX as if ENABLE_JMX was set.
To see what is exported just:
docker run -it --rm \
  -p9404:9404 \
  -e ENABLE_JMX_EXPORTER=true \
  vromero/activemq-artemis
And then in a different terminal run:
curl http://127.0.0.1:9404
To obtain the following and more:
# HELP artemis_disk_scan_period How often to check for disk space usage, in milliseconds (org.apache.activemq.artemis<broker=""0.0.0.0""><>DiskScanPeriod)
# TYPE artemis_disk_scan_period counter
artemis_disk_scan_period 5000.0
# HELP artemis_durable_delivering_count number of durable messages that this queue is currently delivering to its consumers (org.apache.activemq.artemis<broker=""0.0.0.0"", component=addresses, address=""DLQ"", subcomponent=queues, routing-type=""anycast"", queue=""DLQ""><>DurableDeliveringCount)
# TYPE artemis_durable_delivering_count counter
artemis_durable_delivering_count{queue=""DLQ"",address=""DLQ"",} 0.0
artemis_durable_delivering_count{queue=""ExpiryQueue"",address=""ExpiryQueue"",} 0.0
# HELP artemis_journal_min_files Number of journal files to pre-create (org.apache.activemq.artemis<broker=""0.0.0.0""><>JournalMinFiles)
# TYPE artemis_journal_min_files counter
artemis_journal_min_files 2.0
# HELP artemis_message_expiry_thread_priority Priority of the thread used to scan message expiration (org.apache.activemq.artemis<broker=""0.0.0.0""><>MessageExpiryThreadPriority)
# TYPE artemis_message_expiry_thread_priority counter
artemis_message_expiry_thread_priority 3.0
# HELP artemis_messages_killed number of messages removed from this queue since it was created due to exceeding the max delivery attempts (org.apache.activemq.artemis<broker=""0.0.0.0"", component=addresses, address=""DLQ"", subcomponent=queues, routing-type=""anycast"", queue=""DLQ""><>MessagesKilled)
# TYPE artemis_messages_killed counter
artemis_messages_killed{queue=""DLQ"",address=""DLQ"",} 0.0
artemis_messages_killed{queue=""ExpiryQueue"",address=""ExpiryQueue"",} 0.0
# HELP artemis_address_memory_usage_percentage Memory used by all the addresses on broker as a percentage of global maximum limit (org.apache.activemq.artemis<broker=""0.0.0.0""><>AddressMemoryUsagePercentage)
# TYPE artemis_address_memory_usage_percentage counter
artemis_address_memory_usage_percentage 0.0
# HELP artemis_journal_sync_non_transactional Whether the journal is synchronized when receiving non-transactional datar (org.apache.activemq.artemis<broker=""0.0.0.0""><>JournalSyncNonTransactional)
# TYPE artemis_journal_sync_non_transactional counter
artemis_journal_sync_non_transactional 1.0
# HELP artemis_journal_buffer_size Size of the internal buffer on the journal (org.apache.activemq.artemis<broker=""0.0.0.0""><>JournalBufferSize)
# TYPE artemis_journal_buffer_size counter
artemis_journal_buffer_size 501760.0
# HELP artemis_journal_max_io Maximum number of write requests that can be in the AIO queue at any given time (org.apache.activemq.artemis<broker=""0.0.0.0""><>JournalMaxIO)
# TYPE artemis_journal_max_io counter
artemis_journal_max_io 4096.0

In case you need more control over the metrics that are exported, you can mount a jmx-exporter
configuration file in /opt/jmx-exporter/etc-override with the file name jmx-exporter-config.yaml.
5.6 Settings the console's allow origin
ActiveMQ Artemis console uses Jolokia. In the default vanilla non-docker installation Jolokia does set a CORS header to
allow only localhost. In the docker image this create problems as things are rarely accesed as localhost.
Therefore the docker image does set the CORS header to * by default. However there is a mechanism to narrow it
down to whatever value is best suited to you for improved security through the environmnet property: JOLOKIA_ALLOW_ORIGIN.
docker run -it --rm \
  -e JOLOKIA_ALLOW_ORIGIN=192.168.1.1 \
  vromero/activemq-artemis
5.7 Overriding parts of the configuration
ActiveMQ Artemis support disabling the security using the element <security-enabled>false</security-enabled>
as described in the official documentation.
This docker image makes it simple to set that element using the environment property: DISABLE_SECURITY:
docker run -it --rm \
  -e DISABLE_SECURITY=true \
  vromero/activemq-artemis
Please keep in mind no production system, possible no environment at all, should ever disable security.
Make sure you read the falacy number one of the falacies of the distributed computing before disabling the security.
5.8 Using external configuration files
It is possible to mount a whole artemis etc directory in this image in the volume /var/lib/artemis/etc.
Be careful as this might be an overkill for many situations where only small tweaks are necessary.
When using this technique be aware that the configuration files of Artemis might change from version to version.
Generally speaking, when in need to configure Artemis beyond what it is offered by this image using environment
variables, it is recommended to use the partial override mechanism described in the next section.
5.9 Overriding parts of the configuration
The default ActiveMQ Artemis configuration can be partially modified, instead of completely replaced as in the previous section, using three mechanisms. Merge snippets, XSLT tranformations and entrypoint overrides.
Merging snippets
Multiple files with snippets of configuration can be dropped in the /var/lib/artemis/etc-override volume. Those configuration files must be named following the name convention broker-{{num}}.xml where num is a numeric representation of the snippet.
The configuration files will be merged with the default configuration. An alphabetical precedence of the file names will be considered for the merge and in case of collision the latest change will be treated as final.
For instance lets say that you want to add a diverts section, you could have a local directory, lets say /var/artemis-data/etc-override
where you could place a broker-00.xml file that looks like the following listing:
<?xml version=""1.0"" encoding=""UTF-8"" standalone=""no""?>

<configuration xmlns=""urn:activemq"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""urn:activemq /schema/artemis-configuration.xsd"">
   <!-- from 1.0.0 to 1.5.5 the following line should be : <core xmlns=""urn:activemq:core""> -->
   <core xmlns=""urn:activemq:core"" xsi:schemaLocation=""urn:activemq:core "">
      <diverts>
         <divert name=""order-divert"">
            <routing-name>order-divert</routing-name>
            <address>orders</address>
            <forwarding-address>spyTopic</forwarding-address>
            <exclusive>false</exclusive>
         </divert>
      </diverts>
   </core>
</configuration>
Please notice the core element change along with the versions:

1.0.0 up to 1.5.5: <core xmlns=""urn:activemq:core"">
2.0.0 onwards: <core xmlns=""urn:activemq:core"" xsi:schemaLocation=""urn:activemq:core "">

Configuration transformations
For the use cases where instead of merging, the desired outcome is a deletion or some other kind of advanced transformation a file named broker-00.xslt
in /var/lib/artemis/etc-override is supported. For instance to delete the jms definitions that is present by default in the broker.xml file shown below:
<?xml version=""1.0"" encoding=""UTF-8"" standalone=""no""?>

<configuration xmlns=""urn:activemq"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""urn:activemq /schema/artemis-configuration.xsd"">
  ...
  <jms xmlns=""urn:activemq:jms"">
    <queue name=""myfancyqueue""/>
    <queue name=""myotherqueue""/>
  </jms>
  ...
</configuration>
A file name broker-00.xslt with content like the following listing, could be used:
<xsl:stylesheet version=""1.0"" xmlns:xsl=""http://www.w3.org/1999/XSL/Transform""
  xmlns:activemq=""urn:activemq"" xmlns:jms=""urn:activemq:jms"">

 <xsl:output omit-xml-declaration=""yes""/>

    <xsl:template match=""node()|@*"">
      <xsl:copy>
         <xsl:apply-templates select=""node()|@*""/>
      </xsl:copy>
    </xsl:template>

    <xsl:template match=""*[local-name()='jms']""/>
</xsl:stylesheet>
Entrypoint Overrides
Multiple shell scripts can be dropped in the /var/lib/artemis/etc-override volume. Those shell files must be named following the name convention entrypoint-{{num}}.sh where num is a numeric representation of the snippet.
The shell scripts will be executed in alphabetical precedence of the file names on startup of the docker container.
A typical use case for using entrypoint overrides would be if you want to make a minor modification to a file which cannot be overriden using the 2 methods above and you do not want to expose the etc volume.
If you would like to see the final result of your transformations, execute the following:
docker run -it --rm \
  -v /var/artemis-data/override:/var/lib/artemis/etc-override \
  vromero/activemq-artemis \
  cat ../etc/broker.xml

5.10 Broker Config
ActiveMQ allows you to override key configuration values using System properties.
This docker image has built in support to set these values by passing environment variables prefixed with BROKER_CONFIG to the docker image.
Below is an example which overrides the global-max-size and disk-scan-period values
docker run -it --rm   -p 8161:8161 \
    -e BROKER_CONFIG_GLOBAL_MAX_SIZE=50000 \
    -e BROKER_CONFIG_DISK_SCAN_PERIOD=6000 \
    vromero/activemq-artemis

5.11 Environment Variables
Additionally, the following environment variables are supported



Env Var
Default
Description




JAVA_OPTS

Will pass additional java options to the artemis runtime



5.12 Mount points



Mount point
Description




/var/lib/artemis/data
Holds the data files used for storing persistent messages


/var/lib/artemis/etc
Holds the instance configuration files


/var/lib/artemis/etc-override
Holds the instance configuration files


/var/lib/artemis/lock
Holds the command line locks (typically not useful to mount)


/opt/jmx-exporter/etc-override
Holds the configuration file for jmx-exporter jmx-exporter-config.yaml



5.13 Exposed ports



Port
Description




8161
Web Server


9404
JMX Exporter


61616
Core,MQTT,AMQP,HORNETQ,STOMP,Openwire


5445
HORNETQ,STOMP


5672
AMQP


1883
MQTT


61613
STOMP



6. Running in orchestrators
At the moment only docker is directly supported for this image. However there is an attempt to create
a helm chart for Kubernetes and some configuration tuning for OpenShift.
6.1 Running in Kubernetes
ActiveMQ Artemis can leverage JGroups to discover the members of the cluster. And JGroups
can be extended with a plugin called jgroups-kubernetes
that allows JGroups to discover using Kubernetes.
jgroups-kubernetes version 0.9.3 is included in the classpath of
this image, however everything about the configuration of jgroups and jgroups-kubernetes is left to the user.
If you rather prefer a easier solution to run a cluster of ActiveMQ Artemis nodes, there is an attempt to create a Helm chart
by the same author of this image. It can be found here. It
does leverage jgroups-kubernetes in a transparent way.
6.2 OpenShift
OpenShift has diverted a bit from Kubernetes (e.g: automounts empty volumes in all declared volumes without
the user asking for it at all) and Docker (e.g: runs on an random user).
The biggest problem to run this image is the automount of empty directories because it empties the etc directory.
In order to restore it the environment variable RESTORE_CONFIGURATION has been created. It can be used as follows:
oc new-app --name=artemis vromero/activemq-artemis -e RESTORE_CONFIGURATION=true
7. License
View license information for the software contained in this image.
8. User Feedback
8.1 Issues
If you have any problems with or questions about this image, please contact us through a GitHub issue.
8.2 Contributing
You are invited to contribute new features, fixes, or updates, large or small; we are always thrilled to receive pull requests, and do our best to process them as fast as we can.
Before you start to code, we recommend discussing your plans through a GitHub issue, especially for more ambitious contributions. This gives other contributors a chance to point you in the right direction, give you feedback on your design, and help you find out if someone else is working on the same thing.
",57
d-e-s-o/cell,Rust,"



cell

Documentation
Changelog

cell is a crate providing a revised RefCell implementation with
additional mapping capabilities. It can be used as a drop-in replacement
for std::cell::RefCell where this additional functionality is required.
The Problem
A borrowed RefCell is represented as a
Ref. Such a Ref contains a reference to the data
contained in the RefCell. To extend the borrow to a different member
in the original data, the map method can be used.
Using this method a new Ref object can be created that contains a
reference to a member in the borrowed data.
While having a direct reference to such a data member is appropriate in
many cases, there are some where this is insufficient, and an actual
object that contains such a reference is required.
Example
The most prominent example is an iterator. While an iterator internally
keeps a reference to the object being iterated over, it is more than
just a reference to it: it contains state about the progress of the
iteration.
If such an iterator is to be exposed for an object contained in a
RefCell that is currently borrowed, the Ref::map function is
insufficient:
struct RefStrings(RefCell<Vec<String>>);

impl RefStrings {
    fn iter(&self) -> Ref<Iter<String>> {
        Ref::map(self.0.borrow(), |x| x.iter())
    }
}
error[E0308]: mismatched types
 |  Ref::map(self.0.borrow(), |x| x.iter())
 |                                ^^^^^^^^ expected reference, found struct `std::slice::Iter`
 |
 = note: expected type `&_`
            found type `std::slice::Iter<'_, std::string::String>`

(Note that required lifetimes have been elided in the example for brevity)
A Solution
This crate provides alternative RefCell and Ref implementations that
solve this problem by introduction of another mapping method: map_val.
This method returns a RefVal object. RefVal is a new type that is
similar to Ref but, instead of embedding a reference to its T (a
type parameter), it embeds a value of it. T in turn would contain the
actual reference to the borrowed object.
In the above example the only changes that need to happen are the
replacement of std::cell::RefCell with cell::RefCell, that of
std::cell::Ref with cell::Ref, and the usage of Ref::map instead
of Ref::map_val.
--- test.rs
+++ test.rs
@@ -1,13 +1,14 @@
-use std::cell::Ref;
-use std::cell::RefCell;
+use cell::Ref;
+use cell::RefCell;
+use cell::RefVal;
 use std::slice::Iter;


 struct RefStrings(RefCell<Vec<String>>);

 impl RefStrings {
-    fn iter<'t, 's: 't>(&'s self) -> Ref<'t, Iter<String>> {
-        Ref::map(self.0.borrow(), |x| x.iter())
+    fn iter<'t, 's: 't>(&'s self) -> RefVal<'t, Iter<String>> {
+        Ref::map_val(self.0.borrow(), |x| x.iter())
     }
 }

Alternative Implementations
The possibility of providing this functionality by means of a trait has
been investigated but no viable solution has been identified. The main
problem stems from the fact that we require access to Ref internals in
order to provide this functionality. Such a trait would alleviate the
need for providing alternative RefCell and Ref implementations.
No other existing solutions for this problem have been found.
A discussion around the upstreaming of this functionality is tracked by
Rust issue #54776.
",3
Erisa/gittag-testing-i-think,HTML,"gittag-testing-i-think
",3
pvaiko/course-generator,Lua,"Fieldwork Course Generator
This is an extended course generator for Courseplay. It can be used in standalone mode or from within the game.
Using from the Game

You can now select 'Vehicle location' in the HUD as
starting corner. If you do so, Starting Direction is set to
automatic too and one headland is selected (can't generate
without headland)
As usual you can set the number of headlands, clockwise/counterclockwise
and headland/center order.
If you select anything other than 'Vehicle location' for the
starting corner, the old generator is invoked.
Using the Standalone Version
Since this generator is now part of the Courseplay release, the only point of
having a standalone version is to provide an efficient development environment
for the course generator outside of the game engine. This allows shorter development
cycles and some automated tests as well.
Standalone mode requires that you embed the Courseplay repository under the
courseplay folder.
The rest of this guide is outdated and startCourseGenerator.lua is not maintained
anymore (it still may work).

In standalone mode it'll loada saved field or a fieldwork course previously
generated in Courseplay, then you can make some adjustments and save the
customized course.
Note that if you load fieldwork courses the course must have
a headland track as the tool uses the outermost headland track
to find the field boundary.
You can then load this customized course in the game just
as a Courseplay generated course.
What this preview does:

generates tracks in any direction
finds the optimum angle, that is the direction the parallel
tracks must run in order to have the minimum number of turns.
makes a best effort to find an angle for non-convex fields
which results in continuous tracks
start the headland tracks at any location.
link the headland tracks with the parallel track (remember,
the parallel tracks start location changes with the angle)
generate course starting in the center and finishing with
the headland for sowing and any fieldwork other than
harvesting
interleaved parallel tracks (sorry, don't know the exact term)
where you work every second (or 3rd, 4th...) track to prevent Y turns.
non-convex fields: can generate path for non-convex fields.
This is an experimental feature.
If there is no convex solution for a field or the non-convex
solution results in significantly less tracks it'll choose the
non-convex solution.
A non-convex solution will always have the middle of the field
divided in two or more blocks which will be worked one by one.
Once a block is finished, the course will lead to the next block
on the innermost headland path. This is not optimal but will
cover the entire field and the course will always remain within
the field.
In general, the algorithm will try to create the minimum amount
of blocks and avoids creating blocks with just a few tracks.

Upcoming features:

integration with Courseplay so courses can be generated
in game
optimized headland track generation to prevent skipping
fruit at corners.

Installation
The package is for Windows and contains everything needed
to run, including a lua interpreter and the LOVE graphical
framework.
This is the Windows version, I don't have access to Mac
computers. If you are willing to install lua and LOVE,
you can run the scripts on a Mac too.
Just unzip the latest release from https://github.com/pvajko/course-generator/releases
to any folder you like. The release has all the required
tools bundled.
Alternatively, if you have lua and LOVE (love2d.org) installed
and the executables in the PATH you can clone or unzip the
source from git.
Usage


Find your game folder. On Windows, this will most likely
be under My Documents\My Games\FarmingSimulator2017


Under that, there is a CoursePlay_Courses folder with
a subfolder for each installed map. This is where
the Courseplay courses are stored for each map.
Note the full path to these folders.


MAKE A BACKUP OF YOUR CoursePlay_Courses FOLDER! This is
a beta version, there may be bugs in there I don't want
you to lose your saved courses!


Now switch to the folder where you unzipped the course
generator and type:
lua.exe startCourseGenerator.lua 
for example, on my computer this would be:
lua53.exe startCourseGenerator.lua ""c:\Users\Peter\Documents\My Games\FarmingSimulator2017\CoursePlay_Courses\FS17_coldboroughParkFarm.SampleModMap""
for the Coldborough Farm map. Make sure there is no \ at the very
end of the folder name just before the "".


Alternatively, you can load a previously saved field with:
lua53.exe startCourseGenerator.lua 
(Courseplay saves the fields into the savegame folder)
for example, on Savegame 8 on my computer would be:
lua53.exe startCourseGenerator.lua ""c:\Users\Peter\Documents\My Games\FarmingSimulator2017\savegame8


You should now see a list which contains either the
the saved courses of the map (if you started it with a map folder)
or the saved fields of the savegame.
Has limited support for course folders: when a new course is created
from an existing one it'll be in the same folder as the original.
If created from a field, it'll be in the root folder.


Select a fieldwork course or a field by typing in the number of the course
and pressing enter. The course generator will use this course
or field to generate the course.
If you selected a course, the course generator will use the
outermost headland pass of the course without alterations and
build everything based on that.
Remember, the course must have a headland track!
Selecting non-fieldwork courses or fieldwork courses with no
headland tracks will result in errors.
If you selected a field, the course generator uses the field
boundary to generate the headland tracks.


Next, you have to select the course where you want to save
the generated course. Or, you can create a new course and
type in the name.


After you confirm the creation/overwrite of the course,
the course generator window appears showing the outline of the
field.


Set the width and number of passes using the w/W and p/P keys.


Next, you'll have to define where to start the headland track.
Use the right mouse button to place a marker where your want to
start it, just outside the field boundary.


The course is now generated. Green is the headland, blueish
are the tracks in the center of the field and the red line is
the path between the two.
The green dot is where the course starts, the red is where it ends.


By pressing 'c' you can toggle between clockwise or counterclockwise
headland tracks.


If you want you can reverse the course so it starts in the middle
and ends with the headland passes. This is great for sowing and
other, non harvesting fieldwork.


You can experiment with the various settings (you may need to
press g to regenerate the course).


If you like what you see, press s to save the course.


If you are in a game, you'll have to quit it and restart to be
able to see the new course, otherwise it won't show up.


Load the new course and test.


Thanks for giving it a try. If you have any problems, report it on
github https://github.com/pvajko/course-generator/issues or
at courseplay@vajko.name.
Peter
",13
christopher4lis/canvas-boilerplate,JavaScript,"Canvas Boilerplate is the go-to solution for quickly creating modern canvas pieces using ES6 and webpack.
Getting Started


Clone the repo:
git clone https://github.com/christopher4lis/canvas-boilerplate.git



Install dependencies:
yarn

or
npm install



Run webpack:
npm start



Your canvas piece should open up automatically at http://localhost:3000 and you should see 'HTML CANVAS BOILERPLATE' on hover.
",187
chenjian158978/chenjian.github.io,CSS,"ChenJian Blog
2017.04.01
åå®¢ä»æ¥å¼éï¼ChenJian Blog
ä»å¼å§æ­å»ºå°ä¸çº¿ï¼å¤§æ¦æåå¹´æä½ã
éè¦å


æ¾ä¸ä¸ªå¥½çæ¨¡çï¼ææç¨Huxpro/huxpro.github.ioï¼è®¤çéè¯»éé¢çå¸®å©è¯´æï¼


å­¦ä¹ ä¸äºåºæ¬ç¥è¯ï¼ä¾å¦markdown, photoshop, gitï¼jekyll, rubyç­ç­ãå¦æä½ ä¸æ¯ITçè¯ï¼è¿è¦äºè§£åºæ¬çhtmlï¼javascriptç­ï¼


é¡¹ç®cloneä¸æ¥åï¼ä¸ä¸ªå­ï¼æ¹ãå¾çæ³¨æå¤§å°ï¼å°ºå¯¸ï¼é¢è²ï¼è¿éå»ºè®®ä¼ç¨psçactionsï¼ææä½è®°å½ä¸æ¥ï¼æ¹åç§é¾æ¥ï¼ä¾å¦github,zhihuè´¦æ·ç­ç­ï¼


ç»åæmdæä»¶æ·»å åç¼ï¼è§èå½åï¼éå¾ç­ç­ãè¿æ­¥å¼å®åï¼åºæ¬åå®¢ä¸æ²¡å¥è¯å¼çäºï¼


è¯è®ºä½¿ç¨disqueæä»¶ï¼è¿ä¸ªè¦æ³¨ådisqueè´¦æ·ï¼åæ¶æ³¨åshortname;


è´­ä¹°ååãä¹°çé¿éäºçcomååï¼æ³¨æå¤ä¹°å å¹´çï¼åç»­ç»­è´¹å¾è´µãç»å®åå®¢ä¸ååè¿æ¹é¢åå®¹æ¥æ¥å°±ç¥æäºã


2017.04.05
å·²ç»å®æä»¥ä¸åå®¹


å®æhttpsãéç¨Cloudflareæ¹å¼


å¾çå¤§å°çä¿®æ¹ãè®©å è½½æ´å¿«


æ·»å æç´¢åè½


æ¹åmdæä»¶ä¸­ç""å¹´""çé®é¢


2017.04.06
å·²ç»å®æä»¥ä¸åå®¹


è¿ä¸æ­¥ä¿®æ¹åå®¢åå®¹error


å¢å ä¾§è¾¹çç®å½æ ï¼ä¸æç´¢ï¼å¹¶æ¯å¶å§ç»ä¿æå¨ä¸ä¸ªé¡µé¢jQuery-One-Page-Nav


æ·»å ææåææ·»å ä¾§è¾¹æ¡éé¡¹


æ·»å åºé¨ç""åå""ç¿»å¨é®


ä¿®æ¹FRIENDSä¸æ 


åæ¬¡ç¼©å°å¾çå¤§å°ï¼æ´æ°icon


2017.04.07
å·²ç»å®æä»¥ä¸åå®¹


æ´æ°icon


ä¿®æ¹aboutåå®¹


åºååé¨åæç« 


æ·»å RSSè®¢é,ååæ¶æäº


æ·»å ä¸æ åäº«åè½ï¼æä»¶share.js


åææ«å°¾æ·»å cc4åè®®


2017.04.08
å·²ç»å®æä»¥ä¸åå®¹


é¿æç« åºååå®æ


ä¿®æ¹cc4é¨åéè¯¯


æç®åç


è¿ä¸æ­¥ä¿®æ¹åå®¢çé®é¢


åå®¢çè¿ç»´


è³æ­¤ï¼æ´ä¸ªåå®¢åºæ¬å®æ
2017.04.13

ç»READMEæ·»å åèåæ

2017.04.20

æ·»å google search consoleæä»¶

2017.05.02


ä¿®æ¹404é¾æ¥éè¯¯


æ·»å æ°åæ


æé«å¯è¯»æ§å°é¢ç®æ¹ä¸ºä¸­æï¼å¯æ é¢æ¹ä¸ºè±æ


2017.05.03


æ·»å ç½ç«å°å¾


æ·»å baiduè®¤è¯æä»¶


2017.05.27


ä¿®æ¹åæä¸­ä»£ç çæ®µçé«äº®é®é¢ï¼ä½¿ç¨highlight.jsä¸­çstyles:solarized-dark.css


ä¿®æ¹é¨åcssæä»¶


2017.08.30


æ´æ°ç½ç«å°å¾


æ·»å ä»£ç ä¸è½½é¾æ¥


èç³»gmailæ´æ¢ç¹å»æ¨¡å¼


2018.06.06


æ·»å html5çé³ä¹æ­æ¾


æ´æ°é¨å""æ­è¯ç¿»è¯""åæ


2018.06.15


æ´æ¢ä¸ºaplayer+metingjså¨çº¿æ­æ¾é³ä¹


æ´æ¢åæå¤´æä»¶


2018.06.16

è§£å³yamlçå¤´ä¿¡æ¯ï¼front matterï¼é®é¢ï¼ä¸»è¦æ¯æ¢è¡æ ¼å¼é®é¢ï¼åºè¯¥ä¸ºLFæ ¼å¼ï¼

åè

ä½¿ç¨jekyllåhexoæ­å»ºåè´¹åå®¢
Hexoæ­å»ºåå®¢æç¨
Hexo themeå¶ä½ç¬è®°-é¿ææ´æ°
ä¸æ­¥æ­¥å¨GitHubä¸åå»ºåå®¢ä¸»é¡µ-1

",2
lrusso/3DObjectMaker,HTML,"3D Object Maker
3D Object Maker compatible with models in STL, OBJ and 3DS format. You can export your work ready to print in 3D (STL format) or to keep working on it later (SCENE format).

Web version
https://lrusso.github.io/3DObjectMaker/3DObjectMaker.htm
App version
https://play.google.com/store/apps/details?id=ar.com.lrusso.dobjectmaker
HOW TO USE THIS SOFTWARE
Add geometric shapes (from the right panel) to the plataform to create your own object. Also you can import STL, OBJ and 3DS models to the plataform. Later, export the object as STL file (for 3D printing) or as a SCENE file (to keep working on it later).
HOW TO CUT OBJECTS

Add object A to the plaform.
Add object B to the platform.
Select object B.
Select the material 'Hollow' (from the right panel).
Export the work as a STL file (the object B will erase every object, partially or entirely, that is within it's space). Depending of how complex are the objects, the device may take a few minutes to perform the task.


HOW TO FUSION OBJECTS

Add object A to the plaform.
Add object B to the platform.
Select object B.
Select any material (except 'Hollow') from the right panel.
Export the work as a STL file.


HOW TO MOVE AROUND THE PLATFORM


In the App: One finger to rotate, two fingers to zoom in and out and three fingers to move the camera.


In the Web: With your mouse, hold left-click and move the mouse to rotate, use the mouse wheel to zoom in and out and hold the right-click and move the mouse to move the camera.


",2
tkhamez/neucore,PHP,"

Neucore
An application for managing access for EVE Online players to external services
of an alliance.
Overview
Objectives:

Management of groups for players.
An API for applications to read these groups (and more).
Access to ESI data of all members.
Login via EVE SSO.

For more information, see the doc directory, including Documentation,
an API overview, and some screenshots.
This project consists of two applications, the Backend
and the Frontend.
A preview/demo installation is available at https://neucore.herokuapp.com.
Installation
EVE API Setup

Visit https://developers.eveonline.com or https://developers.testeveonline.com
Create a new application (e.g.: Neucore DEV)
Connection Type: ""Authentication & API Access"", add the required scopes. Scopes for the backend
are configured with the environment variable BRAVECORE_EVE_SCOPES.
Set the callback to https://your.domain/login-callback

App Setup
Server Requirements

PHP 7.1+ with Composer, see backend/composer.json for necessary extensions
Node.js 8 or 10, npm 6 (other versions may work, but are not tested)
MariaDB or MySQL Server
Apache or another HTTP Server

Set the document root to the web directory.
A sample Apache configuration is included in the Vagrantfile file and there
is a .htaccess file in the web directory.
A sample Nginx configuration can be found in the doc directory nginx.conf


Java 8+ runtime (only for openapi-generator)

Install/Update
Clone the repository or download the distribution
(the distribution does not require Composer, Node.js or Java).
Copy backend/.env.dist file to backend/.env and adjust values or
set the required environment variables accordingly.
Make sure that the web server can write in backend/var/logs and backend/var/cache.
Please note that both the web server and console user write the same files to backend/var/cache,
so make sure they can override each other's files, e. g. by putting them into each other's group
(the app uses umask 0002 when writing files and directories).
If available, the app uses the APCu cache in production mode. This must be cleared during an update
(depending on the configuration, restart the web server or php-fpm).
Archive file
If you downloaded the .tar.gz file, you only need to run the database migrations and seeds and,
depending on the update method, clear the cache:
cd backend
rm -rf var/cache/{di,http,proxies}
vendor/bin/doctrine-migrations migrations:migrate --no-interaction
bin/console doctrine-fixtures-load

Git
If you have cloned the repository, you must install the dependencies and build the backend and frontend:
./install.sh or
./install.sh prod
Cron Job
Set up necessary cron jobs, e. g. 3 times daily (adjust user and paths):
0 4,12,20 * * * neucore /var/app/backend/bin/run-jobs.sh

The output is logged to backend/var/logs.
First login and Customization
Read the backend documentation on how to make yourself an admin,
then you can navigate to ""Admin"" -> ""Settings"" and change texts, links and images that are specific to your
installation.
Using Vagrant
Only tested with Vagrant 2 + libvirt.

vagrant up creates and configures the virtual machine.
If the Vagrant file changes, run vagrant provision to update the VM.
vagrant destroy will completely remove the VM.

Please note that the rsync synchronization method used is a one-way synchronization from host to virtual
machine that is performed each time vagrant up or vagrant reload is executed.
The Vagrant setup will create the file backend/.env with correct values for the database connection.
The values for the EVE application must be adjusted.
Deploy on Heroku
You can deploy the application on a free Heroku account.

Create a new app
Add a compatible database, e. g. JawsDB Maria.
Add the necessary config vars (see backend/.env.dist file)
Add build packs in this order:

heroku buildpacks:add heroku/java
heroku buildpacks:add heroku/nodejs
heroku buildpacks:add heroku/php

Logs are streamed to stderr instead of being written to files.
Final notes
Origin
The software was originally developed for the Brave Collective,
when CCP shut down the old API and we had to replace our Core system.
This is also where the name ""Neucore"" comes from.
Related Software
Clients for the application API are available on the Brave Collective GitHub for PHP and Python:

neucore-api
neucore-api-python

Contact
If you have any questions or feedback, you can contact Tian Khamez on Tweetfleet Slack
(get invites here).
",2
alcros33/MHW-Costume-Armor,C++,"
MHW Costume Armor
MHW Costume Armor is a Monster Hunter World MOD which includes graphic user interface to customize the layered armor equipped.
It is a C++ implementaion of the original MHW Transmog MOD based on a decompilation of it.
Available also at Nexus Mods
Some Benchmarks
I tested out against original Transmog on My computer (i7 6700, GTX 970M, 8GB RAM) on what I considered ""Normal"" workload.
AKA: MHW open, Firefox playing a youtube video and Discord Running in the back.
I measured the time of the ""data retreival"" part and memory usage.

Original Transmog -> 23 seconds (Average) and 250MB RAM (Peak)
Costume Armor -> 4 seconds (Average) and 60MB RAM (Peak)

Release!
Checkout the compiled binaries on the latest Release !
State of Development

Memory reading (working properly).
Memory writing (working properly).
GUI Basic Functions (working properly).
GUI Design and vanity (A E S T H E T I C).
GUI Additional features :

Select ComboBox Instead of ID Input (working properly).
Save and Load ArmorSets by Name (working beta).
""Unsafe Mode"" (working beta).
Delete and Rename Saved Sets(pending...)



GUI Preview


Dependencies To Build

CMake # Download Link!
QT5 (Select MinGW 7.30)# Download Link!
MinGW 7.30 # When installing QT5 pick the actual MinGW compiler from the ""tools"" section
Python 3 and openpyxl (pip install openpyxl)

Add the following folders to Path C:\Qt\Tools\mingw730_64\bin and C:\Qt\5.12.0\mingw73_64\bin (Guide Info).
Extra Libraries that I include
Logging powered by EasyLogging++ Available here
Json powered by nholmannJson Available her
Sorry I'm to lazy to do the git submodule sutff.
Building Using MinGW
$ mkdir build
$ cd build
$ cmake .. -DCMAKE_BUILD_TYPE=[Debug | Release] -G ""MinGW Makefiles""
$ mingw32-make
Building Using Visual Studio

Visual Studio 2017
Have MSVC x64 in your Qt install

Build either with CMake directly, or use File > Open > CMake in Visual
Studio, then select Debug or Release, and press build.
Directly with CMake
mkdir build && cd build
cmake .. -DCMAKE_BUILD_TYPE=[Debug | Release] -G ""Visual Studio 15 2017 Win64""
cmake --build . --config [Debug | Release]
",13
Donaldliu94/DonaldLiu94.github.io,CSS,"Welcome to the GitHub page of Donald Liu's Personal Website!
Live Site
LinkedIn
Github
Introduction
I am a Software Engineer who is committed and driven about the future of autonomous technology, and wants to bridge the gap of technology and human experiences. With my detailed-oriented experience in web development using React/Redux, Ruby on Rails, JavaScript, PostgreSQL, HTML5, and CSS3, I am excited and capable of resolving challenges individually as well as collaboratively.
Projects


Pixel 800

Single-page 500px-clone web application, a photography platform with emphasis on improving user's experience on uploading photos, liking photos, and searching photo processes.
Stacks: React.js, Redux, Ruby on Rails, PostgreSQL, NPM
Live Site
GitHub



Floppy Duck

An interactive 2D-platform game where a player navigates a duck and dodges pipe and missle obstacles.
Technologies: JavaScript, HTML5, NPM
Live Site
GitHub



Visit the live site to find out more!
",3
known/Known,C#,"Known
Known is a .NET framework.
",2
iceiix/stevenarella,Rust,"Stevenarella

Multi-protocol Minecraft-compatible client written in Rust
Don't expect it to go anywhere, just doing this for fun.
Images


In action: http://gfycat.com/NeedyElaborateGypsymoth
Community chatroom
We have a chatroom on EsperNet: irc.esper.net server, #stevenarella channel.
Join with your favorite IRC client or Matrix.
Protocol support



Game version
Protocol version
Supported?




1.14
477
â


19w02a
452
â


18w50a
451
â


1.13.2
404
â


1.12.2
340
â


1.11.2
316
â


1.11
315
â


1.10.2
210
â


1.9.2
109
â


1.9
107
â


15w39c
74
â


1.8.9
47
â


1.7.10 + Forge
5
â



Stevenarella is designed to support multiple protocol versions, so that client
development is not in lock-step with the server version. The level of
support varies, but the goal is to support major versions from 1.7.10
up to the current latest major version. Occasionally, snapshots are also supported.
Support for older protocols will not be dropped as newer protocols are added.
Credits
Thanks to @thinkofname for
the original Steven (Rust),
which Stevenarella is an updated and enhanced version of.
Downloads
Windows users can download pre-compiled builds from here: https://ci.appveyor.com/project/iceiix/stevenarella
(Select your platform, Click the artifacts tab and download Steven.zip)
The Visual Studio 2017 Redistributable is required to run these builds.
Building
Requires Rust stable version 1.34.1 or newer to build.
Compile and run:
cargo run --release
Just compile:
cargo build --release
For progress on web support, see www/.
Running
Standalone
Just running Stevenarella via a double click (Windows) or ./stevenarella (everything else)
will bring up a login screen followed by a server list which you can select a server
from.
License
Dual-licensed MIT and ApacheV2
",92
microsoft/BuildXL,C#,"Microsoft Build Accelerator

Introduction
Build Accelerator, BuildXL for short, is a build engine originally developed for large internal teams at Microsoft, and owned by the Tools for Software Engineers team, part of the Microsoft One Engineering System internal engineering group. Internally at Microsoft, BuildXL runs 30,000+ builds per day on monorepo  codebases up to a half-terabyte in size with a half-million process executions per build, using distribution to thousands of datacenter machines and petabytes of source code, package, and build output caching. Thousands of developers use BuildXL on their desktops for faster builds even on mega-sized codebases.
BuildXL accelerates multiple build languages, including:

MSBuild (using new features under development in MSBuild 16 which will ship in future versions of Visual Studio 2019 and the .NET Core SDK)
CMake (under development)
Its own internal scripting language, DScript, an experimental TypeScript based format used as an intermediate language by a small number of teams inside Microsoft

BuildXL has a command-line interface. There are currently no plans to integrate it into Visual Studio. The project is open source in the spirit of transparency of our engineering system. You may find our technology useful if you face similar issues of scale. Note that BuildXL is not intended as a replacement for MSBuild or to indicate any future direction of build languages from Microsoft.
Documentation
The BuildXL documentation main page is here.
Examples and Demos
See the Examples/ folder for basic project examples. See the Demos page for information about various technical demos like using the process sandboxing code.
Building the Code
Build Status - Azure DevOps Pipelines

Command Line Build and Test
This repo uses DScript files for its own build. From the root of the enlistment run: bxl.cmd which will:

Download the latest self-host engine release.
Pull all needed packages from NuGet.org and other package sources.
Run a debug build as well as the unit tests locally.
Deploy a runnable bxl.exe to: out\bin\debug\net472.

Note you do not need administrator (elevated) privileges for your console window.
If you just want to do a 'compile' without running tests you can use: bxl.cmd -minimal after which you can find the binaries in out\bin\debug\net472.
Other build types can be performed as well:

bxl -deployConfig release : Retail build
bxl /vs : Converts DScript files into MSBuild .proj files and generates a .sln for the project at out\vs\BuildXL\BuildXL.sln

Windows
You should use Windows 10 with BuildXL. You do not need to install Visual Studio to get a working build, but see the section below on using VS with BuildXL for developing in the BuildXL codebase.
macOS
To run BuildXL on macOS you need to install:

Microsoft .NET Core SDK for macOS
The latest Mono runtime
If you want to run and load the sandbox to enable fully observed and cacheable builds, you also have to turn off System Integrity Protection (SIP) on macOS. SIP blocks the installation of the unsigned kernel extension (or Kext) produced by the build.

To start building, go to the root of the repository and run ./bxl.sh --minimal in your preferred terminal. Just like bxl.cmd, this bash script also supports several flags for your convenience.
Using BuildXL With Visual Studio
Because we don't have deep VS integration for BuildXL at this time, you can use bxl /vs which will convert the DScript files into MSBuild .proj files and generates a .sln for the project under out\vs\BuildXL\ with a base filename matching the top-level directory of your enlistment. So for example if your enlistment directory is c:\enlist\BuildXL, the generated solution file will be out\vs\BuildXL\BuildXL.sln.
Contributing
See CONTRIBUTING.
",463
johnynek/bosatsu,Scala,"The Bosatsu Programming Language

Bosatsu (è©è©) is the transliteration in Japanese of the sanskrit bodhisattva.
A bodhisattva is someone who can reach enlightenment but decides not to, to
help others achieve that goal.  -- Wikipedia
Bosatsu is a simple, non-turing complete language designed for configuration, queries and scripting. It
borrows from Python, Haskell,
Dhall and Rust.
An example of Bosatsu
Here is a working Bosatsu program to solve the first Project Euler problem:
package Euler/One

# see:
# https://projecteuler.net/problem=1
# Find the sum of all the multiples of 3 or 5 below 1000.

operator == = eq_Int
operator % = mod_Int

def operator ||(x, y):
  True if x else y

def keep(i):
  (i % 3 == 0) || (i % 5 == 0)

def sum(as): as.foldLeft(0, add)

# >>> sum(i for i in xrange(1000) if keep_fn(i))
# 233168
computed = [i for i in range(1000) if keep(i)].sum

test = Assertion(computed == 233168, ""expected 233168"")

For more details see the language guide in particular the section on syntax
Use cases
Currently we have only implemented type-checking, the package system, and an interpreter to evalute expressions. This could
already be useful if you want to give some programmability to configuration that can load, type-check and evaluate the configuration
before executing the rest of the scala or java code.
As a JSON templating engine
Along with Bazel Bosatsu can be used as a JSON generation
system, which could be useful for generating complex configurations in a way that has type-checking
and ability to compose. For a working example see this example.
cd test_workspace
bazel build ...
cat bazel-build/testjson.json

Future features
We would like to implement a number of features:

a REPL
a java backend and bazel rules which can call java and scala functions
a skylark backend to allow writing strongly typed bazel rules compiling to untyped skylark

",134
emacs-ess/ESS,Emacs Lisp,"


ESS
Git development branch of Emacs Speaks Statistics: ESS.
For more info, see our web page at https://ess.r-project.org/
",465
emacs-ess/ESS,Emacs Lisp,"


ESS
Git development branch of Emacs Speaks Statistics: ESS.
For more info, see our web page at https://ess.r-project.org/
",465
kids-first/kf-portal-etl,Scala,"


kf-portal-etl
The Kids-First ETL is built on Scala, Spark, Elasticsearch, HDFS, Postgresql, MySQL etc.
Dependencies
Before building this application, the following dependencies must be built and added to your local maven (.m2) directory.
Shaded json4s and jackson


Clone from repository
git clone git@github.com:kids-first/scalapb-json4s-shade.git



Publish Locally with sbt
cd scalapb-json4s-shade
sbt "";clean;assembly;publishLocal""



ES Model


Clone from repository
git clone git@github.com:kids-first/kf-es-model.git



Maven install
cd kf-es-model
mvn install



Build
To build the application, run the following from the command line in the root directory of the project
sbt "";clean;assembly""

Then get the application jar file from
${root of the project}/kf-portal-etl-pipeline/target/scala-2.11/kf-portal-etl.jar

Configuration
The Kids-First ETL uses lightbend/config as the configuration library. kf_etl.conf.sample defines all of the configuration objects used by ETL.
The top namespace of the configuration is io.kf.etl. To refer to any specific configuration object, please prefix the namespace string.

spark defines how the ETL connects to Spark environment
postgresql defines how the ETL connects to the PostgreSQL server, where the raw data to be transformed is stored
elasticsearch defines how the ETL connects to the Elasticsearch environment
hdfs defines how the ETL connects to the HDFS cluster. The HDFS cluster is used by the ETL for intermediate data writing

root: defines the root path of the entire ETL dataset under HDFS


processors defines all of the processors. Processors are the basic execution units of the ETL. Each processor has its own configurations, which means a processor could refer to the top level configuration objects or could also customize extra configuration objects to complete its specific job. At runtime, the ETL Context will pass the specific configlet to each processor.

download dumps clinical data from PostgreSQL and HPO data from MySQL to dump_path
file_centric transforms and generates the data for the file-centric index in Elasticsearch.

data_path defines where the processor stores both intermediate and output data
write_intermediate_data defines if the processor will write the intermediate data into data_path. It is optional; if not available in the file, false will be the default value


participant_entric transforms and generates the data for the participant-centric index in Elasticsearch
index stores the generated data from the above processors in Elasticsearch

release_tag defines how to generate a release tag as the suffix of the index name. It is format-free, which means one could define any necessary configuration objects needed for the current implementation

release_tag_class_name is a full class name of the release_tag implementation class and is required. At runtime, the ETL will pass the configlet to this class.







The ETL has a system environment variable called kf.etl.config which accept a URL string. The following are supported as values:

classpath:///.../${file_name}, URL scheme classpath:// is not defined in JDK, however theETL defines it. Remember to mixin ClasspathURLEnabler trait
file:///.../${file_name}
http://${http_server_ip}/.../${file_name}

If kf.etl.config is not provided when the application is submitted to Spark, the ETL will search the root of the class path for the default file with the name kf_etl.conf, otherwise the application will quit.
Running the Application
There are some dependencies to run Kids-First ETL, refer to submit.sh.example

PostgreSQL: primary storage for Kids-First data models
MySQL: contains HPO reference data. The reference DB dump file is found here
Spark 2.3.0
Configuration file: refer to Configuration for the format and contents of the file

To submit the application to Spark, run the following in the command line
${SPARK_HOME}/bin/spark-submit --master spark://${Spark master node name or IP}:7077 --deploy-mode cluster --class io.kf.etl.ETLMain --driver-java-options ""-Dkf.etl.config=${URL string for configuration file}"" --conf ""spark.executor.extraJavaOptions=-Dkf.etl.config=${URL string for configuration file}"" ${path to kf-portal-etl.jar} ${command-line arguments}
Command line arguments
Kids-First ETL supports command-line argument -study_id id1 id2. In this case, ETL will filter the dataset retrieved from data service through study_ids.
The second command-line argument is -study_id_file ${url of file}, for exmaple: -study_id_file file://${path} or -study_id_file s3://${bucket}/${key}, etc
The third command-line argument is -release_id rid
To submit the application with study_ids, run the following:
${SPARK_HOME}/bin/spark-submit --master spark://${Spark master node name or IP}:7077 --deploy-mode cluster --class io.kf.etl.ETLMain --driver-java-options ""-Dkf.etl.config=${URL string for configuration file}"" --conf ""spark.executor.extraJavaOptions=-Dkf.etl.config=${URL string for configuration file}"" ${path to kf-portal-etl.jar} -study_id id1 id2 -release_id rid

",5
Bystroushaak/tinySelf,Python,"
tinySelf is an experimental programming language inspired by the Self lang, with the emphasis on the word experimental.
I would like something like the glasswork rack you know from the chemistry pictures, but for computation.

The point of the experiment is not in the language itself, but in all kind of different stuff that can be done with it. tinySelf should be lightweight, compact, collapsible, interchangeable, universal computational apparatus for anything I can possibly hope to make.

Articles

Github Wiki
Articles about tinySelf


Planning
See

https://github.com/Bystroushaak/tinySelf/projects/1
https://github.com/Bystroushaak/tinySelf/projects/2

",9
facebook/facebook-android-sdk,Java,"Facebook SDK for Android


This open-source library allows you to integrate Facebook into your Android app.
Learn more about the provided samples, documentation, integrating the SDK into your app, accessing source code, and more at https://developers.facebook.com/docs/android
TRY IT OUT

Check-out the tutorials available online at https://developers.facebook.com/docs/android/getting-started
Start coding! Visit https://developers.facebook.com/docs/android/ for tutorials and reference documentation.

FEATURES

Login
Sharing
Places
Messenger
App Links
Analytics
Graph API
Marketing

STRUCTURE
The SDK is separated into modules with the following structure. Each box represents a module with an
estimated size when included into an app (when included using proguard and supporting a single language).
+--------------------------------------------------------------+
|                                                              |
|  Facebook-android-sdk : 367.95 kb                            |
|                                                              |
+--------------------------------------------------------------+
+----------+ +----------+ +----------+ +----------+ +----------+
|          | |          | |          | |          | |          |
|          | |          | |          | |          | |          |
| Facebook | | Facebook | | Facebook | | Facebook | | Facebook |
| -Login : | | -Share : | | -Places :| |-Messenger: |-Applinks:|
|          | |          | |          | |          | |          |
| 276.94 kb| | 282.46 kb| | 53.76 kb | | 91.63 kb | | 65.96 kb |
+----------+ +----------+ |          | |          | |          |
+-----------------------+ |          | |          | |          |
|                       | |          | |          | |          |
| Facebook-Common : N/A | |          | |          | |          |
|                       | |          | |          | |          |
+-----------------------+ +----------+ +----------+ +----------+
+--------------------------------------------------------------+
|                                                              |
| Facebook-Core : 52.61 kb                                     |
|                                                              |
+--------------------------------------------------------------+

Example: Including the Facebook-Login module (which depends on Facebook-Common and Facebook-Core) would
increase your app's size by an estimated 276.94 kb and including just Facebook-Core would only increase
your size by 52.61 kb.
USAGE
Facebook SDKs are broken up into separate modules as shown above. To ensure the most optimized use of
space only install the modules that you intend to use. To get started, see the Installation section below.
INSTALLATION
Facebook SDKs are published to Maven as independent modules. To utilize a feature listed above
include the appropriate dependency (or dependencies) listed below in your app/build.gradle file.
dependencies {
    // Facebook Core only (Analytics)
    implementation 'com.facebook.android:facebook-core:4.33.0'

    // Facebook Login only
    implementation 'com.facebook.android:facebook-login:4.33.0'

    // Facebook Share only
    implementation 'com.facebook.android:facebook-share:4.33.0'

    // Facebook Places only
    implementation 'com.facebook.android:facebook-places:4.33.0'

    // Facebook Messenger only
    implementation 'com.facebook.android:facebook-messenger:4.33.0'

    // Facebook App Links only
    implementation 'com.facebook.android:facebook-applinks:4.33.0'

    // Facebook Android SDK (everything)
    implementation 'com.facebook.android:facebook-android-sdk:4.33.0'
}

You may also need to add the following to your project/build.gradle file.
buildscript {
    repositories {
        mavenCentral()
    }
}

GIVE FEEDBACK
Please report bugs or issues to https://developers.facebook.com/bugs/
You can also join the Facebook Developers Group on Facebook (https://www.facebook.com/groups/fbdevelopers/) or ask questions on Stack Overflow (http://facebook.stackoverflow.com)
CONTRIBUTING
We are able to accept contributions to the Facebook SDK for Android. To contribute please do the following.

Follow the instructions in the CONTRIBUTING.mdown.
Submit your pull request to the master branch. This allows us to merge your change into our internal master and then push out the change in the next release.

LICENSE
Except as otherwise noted, the Facebook SDK for Android is licensed under the Facebook Platform License (https://github.com/facebook/facebook-android-sdk/blob/master/LICENSE.txt).
Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the License for the specific language governing permissions and limitations under the License.
DEVELOPER TERMS


By enabling Facebook integrations, including through this SDK, you can share information with Facebook, including information about peopleâs use of your app. Facebook will use information received in accordance with our Data Use Policy (https://www.facebook.com/about/privacy/), including to provide you with insights about the effectiveness of your ads and the use of your app.  These integrations also enable us and our partners to serve ads on and off Facebook.


You may limit your sharing of information with us by updating the Insights control in the developer tool (https://developers.facebook.com/apps/[app_id]/settings/advanced).


If you use a Facebook integration, including to share information with us, you agree and confirm that you have provided appropriate and sufficiently prominent notice to and obtained the appropriate consent from your users regarding such collection, use, and disclosure (including, at a minimum, through your privacy policy). You further agree that you will not share information with us about children under the age of 13.


You agree to comply with all applicable laws and regulations and also agree to our Terms (https://www.facebook.com/policies/), including our Platform Policies (https://developers.facebook.com/policy/) and Advertising Guidelines, as applicable (https://www.facebook.com/ad_guidelines.php).


By using the Facebook SDK for Android you agree to these terms.
",4811
AutoGentoo/AutoGentoo,C,"AutoGentoo
A gentoo portage binhost manager
Why use AutoGentoo
Overview
AutoGentoo is a socket server that can run on any Linux kernel. It will create a chroot enviroment to your specification (pretty much a make.conf and a profile).
Instead of downloading a stage3, autogentoo will emerge the basic profile packages into a new chroot folder. This will
give you binary packages with the compile flags (CFLAGS, CXXFLAGS etc.) you want from the start.
The advantage of a binhost
is that you can have one computer (build server) compiling packages for many different systems. This way all package building
will be kept separate from the client computer. This means if an update breaks your system (very common with Gentoo) it won't
affect your client computer, only the chroot environment on the build server.
How it works

Runtime dependencies

pcre2
curl
libarchive

",5
Hammermaps-DEV/SOHL-V1.9-Opposing-Force-Edition,C++,"Spirit of Half Life V1.9 - Opposing-Force Edition
Spirit of Half Life V1.9 with Opposing-Force Monsters, Weapons..
",2
yashha/wp-nuxt,JavaScript,"wp-nuxt







ð Release Notes
Features
The module adds WP-API to your nuxt application.
The size of the library is 49,8 kB minified (14 kB gzipped). 
Setup


Add wp-nuxt dependency using yarn or npm to your project


Add wp-nuxt to modules section of nuxt.config.js


{
  modules: [
    // Simple usage
    'wp-nuxt',

    // With options
    ['wp-nuxt', {
      endpoint: 'https://wp.kmr.io/wp-json'
      /* other options of WP-API */
    }],
 ]
}
Usage
You can use the API of WP-API using the injected 'app.$wp'. (s. example)
Example
<script>
export default {
  async asyncData ({ app, store, params }) {
    return { articles: await app.$wp.posts().perPage(10) }
  }
}
</script>
License
MIT License
Copyright (c) yashha

",69
darekf77/morphi,TypeScript,"

Morphi v2 (BETA)

    Isomorphic framework in TypeScript for NodeJS back-end and browser (web/mobile) front-end. 
    
 Do no repeat yourself anymore, never !!! 



-NO MORE SEPARATION BETWEEN BACKEND AND FRONTEND !
- Isomorphic classes as Angular/Ionic Services and ExpressJS controllers. 
One node_modules folder for browser, mobile and server.
- Write everything in TypeScript 
      all the time and  automaticly strip off server code for browser/ionic versions.
- Use power of  TypeORM
       framwork to write awesome, robust, clean NodeJS backend 
       connected to SQLite, Mysql, WebSQL, MongoDB and many others... 
- Keep amazing code consistency
        thanks to isomorphic entities classes, that you can use to
        create backend tables and also inside frontend-angular templates with type checking.        
      
- Change business logic in the fastest possible way!
- generate  formly objects from entites
        - have typescript typechecking from entity in db to html template!
        - set default values to entities
       
Support project to develop only amazing, creative things
      in the future... 
      
 Project is under development, but every 
        juicy features just works... try example.
      



        TODO: 
        - firebase like... realtime update of backend/frontend (in progress) 
        - extended authentication based on isomorphic decorators metadata and db roles (in progress) 
        - isomoprhic unit tests (with inheritance) in mocha/jasmine  
        - vscode extension to support @backend, @backendFunc #regions 




Instalation
Global CLI
First install global tool:
npm install -g morphi

Create new Isomorphic Workspace project ( mobile, web, server + sqlite db + basic rest authentication )
morphi new:workspace myAwesomeIsomrphicApp

OR create Isomorphic Single File  backend/frontend project
morphi new:simple myAwesomeIsomrphicApp

Visual Studio Code (recommended editor)
Open your project in VSCode to get the maximum of development experience.
code myAwesomeIsomrphicApp

Installation - Isomorphi Workspace
Link one version of node_modules
Once you have your app opened...

run:
npm install
npm run link

to install and link node_module folder for each subproject.
Build and run sub-projects with auto-reload

isomorphic-lib: npm run build:watch #or morphi:watch   + F5 to run server
angular-client: npm run build:watch + open browser http:\\localhost:4200
ionic-client: npm run build:watch + open browser http:\\localhost:8100

Instead of npm run build:watch you can also open each sub-project in separated vscode window code <sub-project-name>
and press: ctrl(cmd) + shift + b.
Installation - Isomorphi Single File
Install dependencies
Once you have your app opened... run:
npm install

Run isomorphic build
morphi build:watch

Run frontend client
npm run build:watch

Backend controllers, entities directly in the frontend
Isomorphic TypeScript Classes
The main reason why this framework has huge potential is that you can use your backend code
( usualy ExpressJS, REST controllers ) as Anguar 2+ (or any other js framework)
services, to access your RESTfull backend without dealing with backend patches and unessery source code.
This will allow you to change business login very quickly, without confusion and keep
no separation between your frontend/backend application.
Morphi CLI tool
Is responsible for magic behing stripping of backend code for browser version ( web app or ionic mobile app).
Regions @backend,@backendFunc
The difference between @backend and @backendFunc is that @backendFunc will replace code with 'return undefined' (it is needed for typescript compilation) and @backend
will precisely delete all lines between.
HOW IT WORKS:
+ Isomorphi initilization
Initialization for backend and frontend
import { Morphi } from 'morphi';


@Morphi.init({
  controllers: [ /* Your controllers clases here */ UserController  ],
  entites: [ /* Your entites clases here */  User ],
  host: 'http://localhost:4000' // host for backend and frontend,
  //#region @backend
  config: { /* Your db config clases here */  }
  //#endregion
})

To inject providers you can use
import { Morphi } from 'morphi';

...
  providers: [  ...Morphi.Providers  ]
...

+ Isomorphi backend
Typeorm isomorphic ENTITY in NodeJS backend:
import { Morphi } from 'morphi';

@Morphi.Entity()
export class User {

    //#region @backend
    @Morphi.Orm.Column.Primary()
    //#endregion
    id: number;

    //#region @backend
    @Morphi.Orm.Column.Custom()
    //#endregion
    name: string;

    //#region @backend
    @Morphi.Orm.Column.Custom()
    //#endregion
    surname: string;

    fullName() {
      return `${this.name} ${this.surname}`
    }
    
    //#region @backend 
    password: string
    //#endregion

}
Morphi isomorphic CONTROLLER in NodeJS backend:
import { Morphi } from 'morphi'

@Morphi.Controller() 
class UserController {
		
	@Morphi.Http.GET()
	getAllUser() {
		//#region @backendFunc 
		const  repository  =  this.connection.getRepository(User) as  any;
		return  async (req, res) => {
			return await  this.repository.findAll();
		}
		//#endregion
	}	
}

After isomorphic compilation by morphi;
morphi build

or (incremental watch build)
morphi build:watch

will be generated browser version.
+ Generated borwser version
The result for browser client will be like below:
Typeorm isomorphic ENTITY in browser version:
import { Morphi } from 'morphi/browser';

@Morphi.Entity()
export class User {

    id: number;

    name: string;

    surname: string;

    fullName() {
      return `${this.name} ${this.surname}`
    }
}
Morphi isomorphic CONTROLLER in browser version:
import { Morphi } from 'morphi/browser'

@Morphi.Controller()
class UserController {
	 // 'return undefined' is for purpose on the browser side
	 // The function body will be replaced through decorate
	 // to access REST endpoint
	@Morphi.Http.GET()
	getAllUser() { 
    return undefined; 
    }	
}
Angular 2+ services
Morphi.Controller(s) you can use as Angular 2+ services. If you
used Morphi.Entity your browser <-> backend REST communication will
keep entity type and automaticly reproduce it.
@Component({
	selector:  'app-test',
	templateUrl:'app-test.html'
})
class  AppTestComponent  implements  OnInit {

	// Inject isomorphic class as service into component
	constructor(public users: UserController) { } 
	
	async ngOnInit() {
          const data = await this.users.getAllUsers().received;
          const users = data.body.json;
          const firstUser = users[0]
          console.log( firstUser instanceOf User ) // true
	}
}
Directly in html template
To simplify object receiving from backend you can use async pipes (available with Angular4+)
and really make you MVVM amazing.
Morphi and Angular4+ lets you use backend functions in html frontend template.
app-test.html
Users:
<ul   *ngIf=""users.getAllUsers().received.observable | async; else loader; let users"" >

  <li  *ngFor=""let user of users""> 
  		{{user.id}} {{user.fullName()}} <!-- BACKEND FUNCTION IN FRONTEND TEMPLATE ! -->
		  <br>
		<input type=""name"" [(NgModel)]=""user.name"" >
  </li>

</ul>

<ng-template #loader> loading users...  </ng-template>

Of course Angular services can be used inside Angular web and Ionic mobile apps.
",7
instagrambot/instabotai,Python,"
Website | Read the Docs | Contribute | Buy Instagram Expert Marketing

InstabotAi ð¤
Instabotai is an instagram bot with face detection that uses the undocumented Web API. Instabotai can reupload photo to feed, reupload photo to stories, comment, like and DM users if a face is detected on image.
Unlike other bots, Instabotai does not require Selenium or a WebDriver. Instead, it interacts with the API over simple HTTP Requests. It runs on most systems.

Requirements

Python 3.6+
Min 20-30 Profiles to scrape or it will repost same image when no new image is posted in list.

Face detection at work on a live webcam

This script scrapes images from users and then repost, like and comment their images if face is detected with your own tags.
Demo:
https://www.instagram.com/siliconeheaven/
The script does not work with new accounts. If you know how to fix, send me a message.
To install script with Docker:
docker pull reliefs/instabotai

docker run [imageid] -u username -p password -l josephineskriver,wolfiecindy -t ""#like4like#follow4follow""

To install script on Windows:
Install Cmake
download link : https://github.com/Kitware/CMake/releases/download/v3.14.1/cmake-3.14.1.zip
Install Dblib
Download dlib â.wheelâ file as ur system requirnment (use link bellow)
download link : https://pypi.python.org/simple/dlib/
Open cmd navigate to dlib wheel file path and hit command
pip install dlib_file_name.wheel

Then run
git clone https://github.com/instagrambot/instabotai.git --recursive
cd instabotai/

pip install -r requirements.txt

python example.py -u yourusername -p password -l josephineskriver,wolfiecindy -t ""#like4like#follow4follow""


And press Enter.
To install script on Linux:
Ubuntu:
apt-get install python-dev python3-dev
sudo apt install g++
sudo apt install cmake
sudo apt install python3-pip

Arch Linux:
sudo pacman -S python3-dev
sudo pacman -S cmake
sudo pacman -S python3-pip

First, make sure you have dlib already installed with Python bindings:

How to install dlib from source on macOS or Ubuntu

Then do
git clone https://github.com/instagrambot/instabotai.git

cd instabotai

sudo pip install -r requirements.txt

python example.py -u yourusername -p password -l josephineskriver,wolfiecindy -t ""#like4like#follow4follow""


Troubleshoot
If you are getting Illegal Instruction with face_recognition follow this guide:
https://github.com/ageitgey/face_recognition/issues/11#issuecomment-475482716
AttributeError: 'module' object has no attribute 'face_recognition_model_v1'
Solution: The version of dlib you have installed is too old. You need version 19.7 or newer. Upgrade dlib.
For Dlib install error run
python3 setup.py install --no DLIB_USE_CUDA
DO WHAT THE FUCK YOU WANT TO PUBLIC LICENSE TERMS AND CONDITIONS FOR COPYING, DISTRIBIUTION AND MODIFICATION.

You just do WHAT THE FUCK YOU WANT TO.

Technology is destructive only in the hands of people who do not realize that they are one and the same process as the universe.
",62
LPGhatguy/rbx-dom,Rust,"rbx-dom

rbx-dom is a collection of crates to help represent, serialize, and deserialize Roblox DOMs. The goal of rbx-dom is to have a common format that projects like Rojo can use for handling Instances efficiently.
rbx_dom_weak


This crate was recently renamed from rbx_tree to rbx_dom_weak.
Weakly-typed Roblox DOM implementation. Defines types for representing instances and properties on them.
rbx_dom_lua
Roblox Lua implementation of DOM APIs, allowing Instance reflection from inside Roblox. Uses a data format that's compatible with rbx_dom_weak to facilitate communication with applications outside Roblox about instances.
rbx_xml


Serializer and deserializer for for Roblox's XML model and place formats, rbxmx and rbxlx.
rbx_binary


Serializer and deserializer for for Roblox's binary model and place formats, rbxm and rbxl.
rbx_reflection


Roblox reflection information for working with Instances in external tooling.
Property Type Coverage



Property Type
Example Property
rbx_dom_weak
rbx_dom_lua
rbx_xml
rbx_binary




Axes
ArcHandles.Axes
â
â
â
â


BinaryString
Terrain.MaterialColors
â
â
â
â


Bool
Part.Anchored
â
â
â
â


BrickColor
Part.BrickColor
â
â
â
â


CFrame
Camera.CFrame
â
â
â
â


Color3
Lighting.Ambient
â
â
â
â


Color3uint8
N/A
â
â
â
â


ColorSequence
Beam.Color
â
â
â
â


Content
Decal.Texture
â
â
â
â


Enum
Part.Shape
â
â
â
â


Faces
BasePart.ResizableFaces
â
â
â
â


Float32
Players.RespawnTime
â
â
â
â


Float64
Sound.PlaybackLoudness
â
â
â
â


Int32
Frame.ZIndex
â
â
â
â


Int64
Player.UserId
â
â
â
â


NumberRange
ParticleEmitter.Lifetime
â
â
â
â


NumberSequence
Beam.Transparency
â
â
â
â


PhysicalProperties
Part.CustomPhysicalProperties
â
â
â
â


ProtectedString
ModuleScript.Source
âÂ¹
â
âÂ¹
â


Ray
RayValue.Value
â
â
â
â


Rect
ImageButton.SliceCenter
â
â
â
â


Ref
Model.PrimaryPart
â
â
â
â


Region3
N/A
â
â
â
â


Region3int16
Terrain.MaxExtents
â
â
â
â


SharedString
N/A
â
â
â
â


String
Instance.Name
â
â
â
â


UDim
UIListLayout.Padding
â
â
â
â


UDim2
Frame.Size
â
â
â
â


Vector2
ImageLabel.ImageRectSize
â
â
â
â


Vector2int16
N/A
â
â
â
â


Vector3
Part.Size
â
â
â
â


Vector3int16
N/A
â
â
â
â


QDir
Studio.Auto-Save Path
â
â
â
â


QFont
Studio.Font
â
â
â
â



â Implemented | â Unimplemented | â Partially Implemented | â Never

ProtectedString is deserialized as String, which is technically lossy but does not change semantics in practice

Outcome
This project has unveiled a handful of interesting bugs and quirks in Roblox!

GuiMain.DisplayOrder is uninitialized, so its default value isn't stable
MaxPlayersInternal and PreferredPlayersInternal on Players are scriptable and accessible by the command bar
Instantiating a NetworkClient will turn your edit session into a game client and stop you from sending HTTP requests
ContentProvider.RequestQueueSize is mistakenly marked as serializable
Trying to invoke game:GetService(""Studio"") causes a unique error: singleton Studio already exists
Color3 properties not serialized as Color3uint8 would have their colors mistakenly clamped in the XML place format. This was bad for properties on Lighting.
ColorSequence's XML serialization contains an extra value per keypoint that was intended to be used as an envelope value, but was never implemented.

License
rbx-dom is available under the MIT license. See LICENSE.txt for details.
",9
LPGhatguy/rbx-dom,Rust,"rbx-dom

rbx-dom is a collection of crates to help represent, serialize, and deserialize Roblox DOMs. The goal of rbx-dom is to have a common format that projects like Rojo can use for handling Instances efficiently.
rbx_dom_weak


This crate was recently renamed from rbx_tree to rbx_dom_weak.
Weakly-typed Roblox DOM implementation. Defines types for representing instances and properties on them.
rbx_dom_lua
Roblox Lua implementation of DOM APIs, allowing Instance reflection from inside Roblox. Uses a data format that's compatible with rbx_dom_weak to facilitate communication with applications outside Roblox about instances.
rbx_xml


Serializer and deserializer for for Roblox's XML model and place formats, rbxmx and rbxlx.
rbx_binary


Serializer and deserializer for for Roblox's binary model and place formats, rbxm and rbxl.
rbx_reflection


Roblox reflection information for working with Instances in external tooling.
Property Type Coverage



Property Type
Example Property
rbx_dom_weak
rbx_dom_lua
rbx_xml
rbx_binary




Axes
ArcHandles.Axes
â
â
â
â


BinaryString
Terrain.MaterialColors
â
â
â
â


Bool
Part.Anchored
â
â
â
â


BrickColor
Part.BrickColor
â
â
â
â


CFrame
Camera.CFrame
â
â
â
â


Color3
Lighting.Ambient
â
â
â
â


Color3uint8
N/A
â
â
â
â


ColorSequence
Beam.Color
â
â
â
â


Content
Decal.Texture
â
â
â
â


Enum
Part.Shape
â
â
â
â


Faces
BasePart.ResizableFaces
â
â
â
â


Float32
Players.RespawnTime
â
â
â
â


Float64
Sound.PlaybackLoudness
â
â
â
â


Int32
Frame.ZIndex
â
â
â
â


Int64
Player.UserId
â
â
â
â


NumberRange
ParticleEmitter.Lifetime
â
â
â
â


NumberSequence
Beam.Transparency
â
â
â
â


PhysicalProperties
Part.CustomPhysicalProperties
â
â
â
â


ProtectedString
ModuleScript.Source
âÂ¹
â
âÂ¹
â


Ray
RayValue.Value
â
â
â
â


Rect
ImageButton.SliceCenter
â
â
â
â


Ref
Model.PrimaryPart
â
â
â
â


Region3
N/A
â
â
â
â


Region3int16
Terrain.MaxExtents
â
â
â
â


SharedString
N/A
â
â
â
â


String
Instance.Name
â
â
â
â


UDim
UIListLayout.Padding
â
â
â
â


UDim2
Frame.Size
â
â
â
â


Vector2
ImageLabel.ImageRectSize
â
â
â
â


Vector2int16
N/A
â
â
â
â


Vector3
Part.Size
â
â
â
â


Vector3int16
N/A
â
â
â
â


QDir
Studio.Auto-Save Path
â
â
â
â


QFont
Studio.Font
â
â
â
â



â Implemented | â Unimplemented | â Partially Implemented | â Never

ProtectedString is deserialized as String, which is technically lossy but does not change semantics in practice

Outcome
This project has unveiled a handful of interesting bugs and quirks in Roblox!

GuiMain.DisplayOrder is uninitialized, so its default value isn't stable
MaxPlayersInternal and PreferredPlayersInternal on Players are scriptable and accessible by the command bar
Instantiating a NetworkClient will turn your edit session into a game client and stop you from sending HTTP requests
ContentProvider.RequestQueueSize is mistakenly marked as serializable
Trying to invoke game:GetService(""Studio"") causes a unique error: singleton Studio already exists
Color3 properties not serialized as Color3uint8 would have their colors mistakenly clamped in the XML place format. This was bad for properties on Lighting.
ColorSequence's XML serialization contains an extra value per keypoint that was intended to be used as an envelope value, but was never implemented.

License
rbx-dom is available under the MIT license. See LICENSE.txt for details.
",9
dx7/ruby-bitly,Ruby,"
A simple bit.ly ruby client.
 
Configuration
You need to load the gem:

require 'ruby-bitly'

Set global configuration:

Bitly.config do |c|
  c.login   = 'login-here'
  c.api_key = 'api-key-here'
  c.use_ssl = false # read more below
  c.proxy   = 'http://localhost:8888' # read more below
end

Or set them individualy:

Bitly.login   = 'login-here'
Bitly.api_key = 'api-key-here'
Bitly.use_ssl = false # read more below
Bitly.proxy   = 'http://localhost:8888' # read more below

Or set them on methods if you prefer (see it below).
Shorten
bitly = Bitly.shorten(long_url: ""https://dx7.github.io/"")

# setting credentials
bitly = Bitly.shorten(long_url: ""https://dx7.github.io/"", domain: ""my.do"", login: ""login-here"", api_key: ""api-key-here"")

# result
bitly.short_url   #=> ""http://bit.ly/2dAjjfo""
bitly.long_url    #=> ""https://dx7.github.io/""
bitly.new_hash?   #=> true
bitly.global_hash #=> ""2dAkyet""
bitly.user_hash   #=> ""2dAjjfo""
bitly.success?    #=> true
Expand
bitly = Bitly.expand(short_url: ""http://bit.ly/2dAjjfo"")

# setting credentials
bitly = Bitly.expand(short_url: ""http://bit.ly/2dAjjfo"", login: ""login-here"", api_key: ""api-key-here"")

# result
bitly.short_url   #=> ""http://bit.ly/2dAjjfo""
bitly.long_url    #=> ""https://dx7.github.io/""
bitly.global_hash #=> ""2dAkyet""
bitly.user_hash   #=> ""2dAjjfo""
bitly.success?    #=> true
Get Clicks
bitly = Bitly.get_clicks(short_url: ""http://bit.ly/2dAjjfo"")

# setting credentials
bitly = Bitly.get_clicks(short_url: ""http://bit.ly/2dAjjfo"", login: ""login-here"", api_key: ""api-key-here"")

# result
bitly.short_url      #=> ""http://bit.ly/2dAjjfo""
bitly.user_hash      #=> ""2dAjjfo""
bitly.global_hash    #=> ""2dAkyet""
bitly.user_clicks    #=> 0
bitly.global_clicks  #=> 1
bitly.success?       #=> true
Error handling
# if something goes wrong you can check
bitly.success? #=> false
bitly.error    #=> 'INVALID_LOGIN'
Proxy
All calls will use the proxy specified by environment variable ""http_proxy"" by default.

You can set the proxy directly if you prefer:

Bitly.proxy = 'http://localhost:8888'
SSL
All calls will use SSL by default. You can disable it:

Bitly.use_ssl = false
Command Line
Usage: bitly [options] URL
  -l, --login LOGIN                You need a free Bitly login and api key. Sign up here: http://bit.ly/a/sign_up.
  -k, --api-key KEY                You can find your api key here: http://bit.ly/a/your_api_key.

  -d, --domain DOMAIN              The short domain to use: either bit.ly, j.mp, bitly.com or a custom short domain.
                                   This option will override the default short domain selected in your Bitly account settings.

  -s, --shorten                    Given a long URL, returns a Bitlink.
  -e, --expand                     Given a Bitlink, hash or custom path, returns the target (long) URL.
  -u, --user-clicks                The total count of clicks to this user's Bitlink.
  -g, --global-clicks              The total count of the corresponding Bitly aggregate hash.

  -h, --help                       Print this help.
  -v, --version                    Print version.

Basic examples:
  bitly -s http://dx7.github.io
  bitly -e http://bit.ly/2dAjjfo
  bitly --user-clicks http://bit.ly/2dAjjfo
  bitly --global-clicks http://bit.ly/2dAjjfo
Authentication
bit.ly API requires authentication credentials.

Using commmand line you can supply credentials as parameters. For example:
  bitly -l <login-here> -k <api-key-here> -s http://dx7.github.io

Or you can create the file ~/.bitly (YAML format) with that content:
  login: <login-here>
  api_key: <api-key-here>
Author
dx7 ~ dx7(a)protonmail.ch
Copyright
Copyright (c) 2010 dx7. Licensed under the MIT License:
http://www.opensource.org/licenses/mit-license.php
",14
romanblanco/KaktusBOT,Python,"Telegram bot notifying about news from mobile operator Kaktus

pip install -r requirements.txt --user
Give it a try!
",3
Qiskit/qiskit-terra,Python,"Qiskit Terra

Qiskit is an open-source framework for working with Noisy Intermediate-Scale Quantum (NISQ) computers at the level of pulses, circuits, and algorithms.
Qiskit is made up of elements that work together to enable quantum computing. This element is Terra and is the foundation on which the rest of Qiskit is built.
Installation
We encourage installing Qiskit via the pip tool (a python package manager), which installs all Qiskit elements, including Terra.
pip install qiskit
PIP will handle all dependencies automatically and you will always install the latest (and well-tested) version.
To install from source, follow the instructions in the contribution guidelines.
Creating Your First Quantum Program in Qiskit Terra
Now that Qiskit is installed, it's time to begin working with Terra.
We are ready to try out a quantum circuit example, which is simulated locally using
the Qiskit BasicAer element. This is a simple example that makes an entangled state.
$ python

>>> from qiskit import *
>>> q = QuantumRegister(2)
>>> c = ClassicalRegister(2)
>>> qc = QuantumCircuit(q, c)
>>> qc.h(q[0])
>>> qc.cx(q[0], q[1])
>>> qc.measure(q, c)
>>> backend_sim = BasicAer.get_backend('qasm_simulator')
>>> result = execute(qc, backend_sim).result()
>>> print(result.get_counts(qc))
In this case, the output will be:
{'00': 513, '11': 511}
A script is available here, where we also show how to
run the same program on a real quantum computer via IBMQ.
Executing your code on a real quantum chip
You can also use Qiskit to execute your code on a
real quantum chip.
In order to do so, you need to configure Qiskit for using the credentials in
your IBM Q account:
Configure your IBMQ credentials


Create an IBM Q > Account if you haven't already done so.


Get an API token from the IBM Q website under My Account > Advanced > API Token.


Take your token from step 2, here called MY_API_TOKEN, and run:
>>> from qiskit import IBMQ
>>> IBMQ.save_account('MY_API_TOKEN')


If you have access to the IBM Q Network features, you also need to pass the
URL listed on your IBM Q account page to save_account.


After calling IBMQ.save_account(), your credentials will be stored on disk.
Once they are stored, at any point in the future you can load and use them
in your program simply via:
>>> from qiskit import IBMQ
>>> IBMQ.load_accounts()
Those who do not want to save their credentials to disk should use instead:
>>> from qiskit import IBMQ
>>> IBMQ.enable_account('MY_API_TOKEN')
and the token will only be active for the session. For examples using Terra with real
devices we have provided a set of examples in examples/python and we suggest starting with using_qiskit_terra_level_0.py and working up in
the levels.
Contribution Guidelines
If you'd like to contribute to Qiskit Terra, please take a look at our
contribution guidelines. This project adheres to Qiskit's code of conduct. By participating, you are expected to uphold this code.
We use GitHub issues for tracking requests and bugs. Please
join the Qiskit Slack community
and use our Qiskit Slack channel for discussion and simple questions.
For questions that are more suited for a forum we use the Qiskit tag in the Stack Exchange.
Next Steps
Now you're set up and ready to check out some of the other examples from our
Qiskit Tutorials repository.
Authors and Citation
Qiskit Terra is the work of many people who contribute
to the project at different levels. If you use Qiskit, please cite as per the included BibTeX file.
License
Apache License 2.0
",2488
StevenUpForever/leetcode-java,Java,"leetcode-java
Introduction
The legacy_code implementations in Java sorted by solving method.
problem's title as the class name.
With as many possible solutions which from brute force to optimized solutions (by time complexity and real runtime).
Include explanations and time/space complexity analysis.
Coding style
Followed Google Java Coding style.
Source code
Under the root/src folder ./src/
Clone from this repo:
git clone https://github.com/StevenUpForever/LeetCode_Java.git
pull requests and Issues are welcome
ä¸­æ
è¿ä¸ªrepoæ¯ä»¥è§£é¢æ¹æ³ä¸ºåºçLeetCode Javaçè§£æ³ï¼ç±»åæ¯å½åé®é¢çæ é¢ã
æä¾ä»è®åæ³å°ä¼åè§£æ³çå°½å¯è½å¤ç§çå¾ªåºæ¸è¿çä¼åè§£æ³ ï¼æåºæ¹å¼æç§æ¶é´å¤æåº¦åå®éè¿è¡æ¶é´ï¼ã
åå«äºæ¶é´/ç©ºé´å¤æåº¦çåæã
ç¼ç é£æ ¼
éµå¾ª Google Java Coding styleã
æºä»£ç 
å¨å½åç®å½çsrcæä»¶å¤¹ä¸ ./src/
å¤å¶å½årepo:
git clone https://github.com/StevenUpForever/LeetCode_Java.git
æ¬¢è¿æåºpull requests and Issues
",2
JavaDominicano/conference,JavaScript,"conference
Contents behind the https://jconfdominicana.org web site
This site is baked with JBake, a static site generator.
The idea behind JBake is very simple: contents is written using a markup language and ""baked"" with template engines into actual HTML. Everything is generated statically and you can upload the generated site wherever you want.
How to contribute
There are a few guidelines that we need contributors to follow so that we can have a chance of keeping on
top of things.
Prerequisites

A Github account
Gradle

Getting Started

Fork the repository
Clone your fork repository

Example:
git clone https://github.com/ecabrerar/conference.git
cd conference
Exploring the project structure
The directory src/jbake contains the classic JBake folder contents:
src
 |-- jbake
       |-- assets    : static assets (images, css, ...)
       |-- content   : blog posts, ...
       |-- templates : HTML templates (by default, uses FreeMarker, but we are using Thymeleaf)

To do any change, you have to explore JBake and Thymeleaf a template engine for Java.
Generating the output
you can generate the site by running the following command:
./gradlew -i jbake
after the rendering step, you should now have a new directory:
build
  |-- jbake
into which you will find the generated HTML contents.
Running the site
./gradlew bakePreview
Browse to http://localhost:8080
Submitting Changes

Push your changes to your fork.
Submit a pull request.

Additional Resources

General GitHub documentation
GitHub pull request documentation

",2
andrewcooke/choochoo,Jupyter Notebook,"Choochoo (ch2)
An open, hackable and free training diary.
Please see the full
documentation.  This page
contains only some images and a Technical
Overview.
The following plots are generated automatically from the diary -
clicking a ""link"" starts Jupyter and pushes the page to the browser.
The pages can be edited and serve as an introduction to accessing the
data manually.


Technical Overview
The system includes:


An SQLite3 database containing time series data.


An interface to move data between the database and Pandas
DataFrames.


A FIT reader to import new data.


Algorithms to derive new statistics from the data (using Pandas for
efficiency).


Pipelines to apply the algorithms to new data on import (in parallel
processes for efficiency).


An embedded Jupyter server to explore the data.


Pre-written scripts to present graphical data views via Jupyter.


A ""diary"" to present textual data and allow data entry.


The database has an SQLAlchemy ORM interface.  The schema separates
""statistics"" (named time series data) from the source (which might be
direct entry, read from a FIT file, or calculated from pre-existing
values).  SQL tracks dependencies to avoid stale values.
The pipelines are Python classes whose class names are also configured
in the database.
The data are stored in an ""open"" format, directly accessible by third
party tools, and easily backed-up (eg by copying the database file).
When the database format changes scripts are provided to migrate
existing data (see package ch2.migraine).  Data extracted from FIT
files are not migrated - they must be re-imported.
Support libraries include: FIT file parsing; spatial R-Trees; reading
elevation data from SRTM files; estimating power from elevation and
speed; Fitness / Fatigue models; detection of pre-defined segments;
clustering of routes; climb detection.
The ""diary"" view, where the user enters data, is also configured via
the database.  So the fields displayed (and the statistics collected)
can be customized.  This configuration can include ""schedules"" which
control when information is displayed (eg: weekdays only; every other
day; second Sunday in the month).
The combination of customizable diary fields and scheduling allows
training plans to be entered and displayed.  This presents a steep
learning curve but is ultimately very flexible - ""any"" training plan
can be accommodated.  Python code for generating example plans is
included (see package ch2.config.plan).
Currently the program is single-user (ie the data in the database are
not grouped by user).  Multiple users can co-exist using separate
database files.
Choochoo collects and organizes time-series data using
athlete-appropriate interfaces.  It facilitates calculations of
derived statistics and extraction of data for further analysis using
Python's rich data science tools.  Both data and code are open and
extensible.
",29
KeyboardCowboy/iawriter-templates,CSS,"iawriter-templates
Custom templates for IA Writer
",3
KeyboardCowboy/iawriter-templates,CSS,"iawriter-templates
Custom templates for IA Writer
",3
krestaino/themer.js,JavaScript,"Themer.js
Spice up your app with themes. Themer.js features include:

Automatic night/day theme switching
System prefers-color-scheme support
Android meta theme-color support
Custom themes
Manual control over everything

Demo
https://themer.js.kmr.io
Quick Start
Install
# using yarn
$ yarn add themer.js

# using npm
$ npm install themer.js

Define the light and dark themes
To use the auto or system themes, you must define a light and dark Theme object.
import Themer from ""themer.js"";

const config = {
  ""light"": {
    ""styles"": {
      ""--app-background-color"": ""#f1f1f1"",
      ""--primary-text-color"": ""#555""
    }
  },
  ""dark"": {
    ""styles"": {
      ""--app-background-color"": ""#242835"",
      ""--primary-text-color"": ""#f1f1f1""
    }
  }
}

// instantiate Themer.js
const themer = new Themer(config);

Setting a theme
import Themer from ""themer.js"";
import { light, dark } from ""./themes/index.js"";

const themer = new Themer({ light, dark });

// set theme to dark
themer.setTheme(dark);

// set theme to auto
themer.setAuto();

// set theme to system
themer.setSystem();

Setting a custom theme
Pass a valid Theme object to setTheme().
import Themer from ""themer.js"";

const custom = {
  ""styles"": {
    ""--app-background-color"": ""#f1f1f1"",
    ""--primary-text-color"": ""#555""
  }
};

const themer = new Themer();

themer.setTheme(custom);

API
Themer(config)


Arguments:

{Object} config



Details: Instantiate Themer.js.


Usage:
import { light, dark } from ""./themes/index.js"";

const config = {
  light,
  dark,
  debug: true,
  onUpdate: (theme) => console.log(theme)
};

const themer = new Themer(config);



See also: Config object


Themer.setAuto()


Details: Sets the active theme to light during the day and dark during the night.


Restrictions:

light and dark themes must be defined.
Requires user geolocation consent.



Usage:
Themer.setAuto();



Themer.setSystem()


Details: Sets the active theme to system.


Restriction:

light and dark themes must be defined.
The browser must support prefers-color-scheme.



Usage:
Themer.setSystem();

See also: Themer.systemThemeSupport()


Themer.setTheme( theme )


Arguments:

{Object | string} theme



Details: Sets the active theme.


Usage:
const dark = {
  ""android"": ""#242835"",
  ""styles"": {
    ""--app-background-color"": ""#242835""
  }
};

Themer.setTheme(dark);



See also: Theme object


Themer.systemThemeSupport()


Details: Helper function to determine browser support for the system theme.


Returns: boolean


Usage:
// Chrome 76, Firefox 67, Safari 12.1
Themer.systemThemeSupport();
â³ true

// unsupported browsers
Themer.systemThemeSupport();
â³ false



See also: prefers-color-scheme


Config object



Key
Type
Description




debug
boolean
Log debug console statements.


onUpdate
function
A callback function that returns the set theme.


light
object
The dark theme.


dark
object
The light theme.



Example:
{
  debug: true,
  onUpdate: (theme) => console.log(theme),
  ""light"": {
    ""styles"": {
      ""--app-background-color"": ""#f1f1f1"",
      ""--primary-text-color"": ""#555""
    }
  },
  ""dark"": {
    ""styles"": {
      ""--app-background-color"": ""#242835"",
      ""--primary-text-color"": ""#f1f1f1""
    }
  }
}

Theme object



Key
Type
Description




android
string
Sets the meta theme-color.


styles
object
The theme CSS variables.



Example:
{
  ""android"": ""#f1f1f1"",
  ""styles"": {
    ""--app-background-color"": ""#f1f1f1"",
    ""--primary-text-color"": ""#555""
  }
}

Use the CSS variables anywhere in your CSS and it will update in real time to the active theme.
html {
  background-color: var(--app-background-color);
  color: var(--primary-text-color);
}

",16
zhedahht/leetcode,Go,"Leetcode Solutions In Go
I try to solve some LeetCode problems when I'm learning Go. All code here passes LeetCode tests. However, it might not be elegant Go code, because I'm still a Go amateur.
",11
facebook/redex,C++,"ReDex: An Android Bytecode Optimizer
ReDex is an Android bytecode (dex) optimizer originally developed at
Facebook. It provides a framework for reading, writing, and analyzing .dex
files, and a set of optimization passes that use this framework to improve the
bytecode.  An APK optimized by ReDex should be smaller and faster than its
source.
Go to https://fbredex.com for full documentation.
",4434
basinserver/jasm,Java,"JASM
Description
This project is a Java disassembler aimed at automatic analysis of JVM bytecode. It used to have rewriting functionality, and it may again in the future, but it does not at present.
Status
This project can accurately disassemble Minecraft, which is the primary test case.
Goals
The end goal is to write a Java decompiler and possibly deobfuscator.
Running
This project does not have a frontend, it is designed as a library with Classpath as the primary entrypoint. You can hack together a test as I have done, or write a simple CLI frontend.
API
Loading happens through the Classpath class. Klass represents a loaded and disassembled .class file, with all pointers to other classes, methods, constants, etc, resolved.
",3
zewenlee/RandomPicApi,PHP,"OASIS's Free API
My blog https://imoasis.cn ( I'm OASIS)
æ­£å¨éå
",5
sarojaba/awesome-devblog,None,"Awesome Devblog


ê°ì
êµ­ë´ ê°ë°ì ë¸ë¡ê·¸ ëª¨ì(ì¼ë¡ ììíì¼ë êµ­ë´ì¸ ê°ì¸/ë¨ì²´ ì¬ì´í¸ë¡ ë°ëì´ë²ë¦°, í¥í ê°ë°ì ì¬ì ì¼ë¡ ë°ì íê³  ì¶ì) Awesome Devblog ìëë¤.

ëª©ë¡ì ì¤ëªì¼ë¡ ë±ë¡ì ìì¹ì¼ë¡ í©ëë¤. (ê°ë°ìë¤ì´ì¬. ìì§ìì ìì§ë¡ ëì ì ëªí´ì§ìë¤.)
ëª©ë¡ì ê³µê°ë ë´ì©ì ê¸°ë°íì¬ ìì±í©ëë¤. ì´ ëª©ë¡ì ë¤ë¥¸ íë¡ì í¸ì ê¸°ë° ë°ì´í°ë¡ ì¬ì©íìë Great! ë¨, í´ë¹ íë¡ì í¸ì ì´ ëª©ë¡ì ì¬ì©(ëë ì°¸ê³ )íë¤ ì ëë¡ë§ ë¨ê²¨ì£¼ì¸ì.
ëª©ë¡ì ê¸°ë°ì¼ë¡ OPML ë° RSSë í¨ê» ì ê³µíê³  ììµëë¤. (ë¨, ìë°ì´í¸ë ì´ ëª©ë¡ë³´ë¤ ë¦ì ì ììµëë¤.)
ëª©ë¡ì ë°ì´í° ë¶ì ëë ë ëë§ì ì©ìíê² íê¸° ìí´ db.yml íì¼ì ìë°ì´í¸ í´ì£¼ì¸ì.

README.md ì ì¼ë¶ë¶ë db.yml íì¼ìì ìì±íê³  ììµëë¤. (íê·  ì 1í ìì±)
OPML íì¼ì db.yml íì¼ìì ìì±íê³  ììµëë¤. Feed Readerì êµ­ë´ ê°ì¸ ëª©ë¡ìì OPML í¬ë§·ì ë¤ì´ë¡ë ë°ì ì ììµëë¤.
ê°ì¢ ì°¨í¸ë db.yml íì¼ìì ìì±íê³  ììµëë¤. (Feed Readerì íµê³ íì´ì§ìì íì¸íì¤ ì ììµëë¤.)
db.yml íì¼ì ì´ì©í 2ì°¨ ì ì íìí©ëë¤.


ì¢ìì, í¬í¬, ì ë³´, íë¦¬í ëª¨ë íììëë¤.íë¡ì í¸ì ê´ì¬ìì¼ìë©´ gitter ë¤ì´ì¤ìì ë¬¸ìë°ëëë¤.

ìê°ê¸

awesome-devblog íê³  2017ë 2018ë
áá¢áá¡á¯áá¡áá³á¯ áá±áá¡á« (ë¸ë¡ê·¸) áá³á¯áá³ááµ intro
ê¸°ì ë¸ë¡ê·¸ êµ¬ëìë¹ì¤ ê°ë° íê¸° - 1ë¶
(tech-trend) êµ¬ë£¨ë¤ì´ ì°¾ëë¤ë íí¬ í¸ë ë - ì ëª ë¸ë¡ê·¸ì ìì ì ëªì¸
íêµ­ ì¤íìì¤ íë¡ì í¸ ë­í¹ Top 100 - 69ì

íì ìë§¤ íë¡ì í¸

AWESOME DEVBLOG(í¬í) Main
ì´ì¸ë¸ë¡ê·¸(ìëë¡ì´ë)
ì´ì¸ë¸ë¡ê·¸(iOS)
ì´ì¸ë¸ë¡ê·¸(íì´ì¤ë¶ íì´ì§)
Daily DevBlog(ë´ì¤ë í°)
DEVBLOG(ë©íë¸ë¡ê·¸)

ëª©ì°¨

êµ­ë´ ê°ì¸ ì¬ì´í¸

ã±
ã´
ã·
ã¹
ã
ã
ã
ã
ã
ã
ã
ã


êµ­ë´ í ì¬ì´í¸
êµ­ì¸ ê°ì¸ ì¬ì´í¸
êµ­ì¸ í ì¬ì´í¸

êµ­ë´ ê°ì¸ ì¬ì´í¸
á



Name
Blog
Description
Social




ê°ê·ì
http://www.ecogwiki.com/




ê°ê´ì°
https://brunch.co.kr/@kd4
Java



ê°ëëª
https://charsyam.wordpress.com/
ìë² ì¬ì´ë



ê°ëí
https://brunch.co.kr/@dongkang
ì¸ë ê°ë°



ê°ëí¬
https://medium.com/@kanglpmg
iOS, RxSwift



ê°ëªí
http://kangmyounghun.blogspot.kr/
ë³´ì



ê°ë¯¸ê²½
http://minieetea.com/
ê¸°í



ê°ë³ì
https://01010011.blog/
DevOps



ê°ë³ì±
https://medium.com/@brillante9111
ë¼ì´ì¸ë´



ê°ì±ì¼
https://b.luavis.kr/
Python



ê°ì±í
http://mearie.org/
ì¹´ì¼ë£¨ì



ê°ì±í
https://medium.com/@devholic
RxJava



ê°ì±í¬
https://medium.com/@shaynekang




ê°ì¤ì
https://blog.juneyoung.io/
Web Backend/Server



ê°ì§ì°
https://brunch.co.kr/@alden
Linux



ê°íì±
http://daddynkidsmakers.blogspot.kr/
IoT



ê°íë³
https://brunch.co.kr/@cloud09
ë°ì´í° ë¶ì



ê°íì
https://hskang9.github.io/
ë¨¸ì ë¬ë



ê°íêµ¬
https://wckhg89.github.io
Web



ê²½ì¤í¸
http://firejune.com/
Front-end



ê³ì£¼ì±
http://kyejusung.com/




ê¹ì² ë¯¼
http://blog.naver.com/kbs4674/
Ruby on Rails, AWS, Heroku



ê³ ëë
http://blog.naver.com/nackji80/
ë¤í¸ìí¬



ê³ ëªì§
https://rjs1197.github.io/
C++



ê³ ëªí
https://brunch.co.kr/@maru7091
ì¤íí¸ì



ê³ ì ì
https://medium.com/@yooyoungko
Javascript



ê³ ì¢ë²
https://brunch.co.kr/@jbgo
ì ìì¼



ê³ íí¸
http://hhko.tistory.com/
Functional Programming



ê³½ë¯¼ì
https://brunch.co.kr/@imagineer
ì±ê°í´ ë°ì´í° ìì§ëì´



êµ¬êµì¤
http://danielku.com/
AWS



êµ¬ìì² 
http://forest71.tistory.com/
Java



êµ¬ì¢ë§
http://theyearlyprophet.com/
ìê³ ë¦¬ì¦



ê¶ê¸°í¸
http://kwongyo.tistory.com/




ê¶ë¨
http://kwon37xi.egloos.com/
Java



ê¶ëì¤
https://mayajuni.github.io/
Web



ê¶ë¯¼ì¬
https://mingrammer.com/
Python



ê¶ì±ì¤
https://gwonsungjun.github.io/
Back-end



ê¶ìì¬
https://nesoy.github.io/




ê¶ì©ê·¼
https://kingbbode.github.io/
Spring



ê¶ì©ì§
https://brunch.co.kr/@nsung
íí¸



ê¶ì±ì 
http://wookje.dance/




ê¶ì¤í
http://web-front-end.tistory.com/
Web



ê¶ì¬ëª
http://dataninja.me/
Data Science



ê¶ì í
http://xguru.net/guru
ê°ë° í¸ë ë



ê¶ì§í¸
http://jinhokwon.tistory.com/
Full Stack



ê¶ì°½í
http://thoughts.chkwon.net/
ì°ìê³µí



ê¶íê´
https://taetaetae.github.io/
Back-end



ê¶íí
https://taebbong.github.io/
Node.js



ê¶íí
http://thdev.tech/
Android, Kotlin



ê¶íì°
https://medium.com/@khwsc1
React



ê¶í¬ì 
https://gmlwjd9405.github.io/




ê¹ê´í(ê´íë¦¬)
https://kwang82.blogspot.kr/
IT ìì



ê¹êµ­í
http://goodhyun.com/
IT ì¹¼ë¼



ê¹ê¸°í
http://kihoonkim.github.io/
Agile



ê¹ê¸¸í¸
http://kilhokim.github.io/




ê¹ëì
https://brunch.co.kr/@nassol
ê°ë°ì ìì´



ê¹ëì
https://brunch.co.kr/@appletreehill
EOS, HCI



ê¹ë¨ì¤
https://cheese10yun.github.io/
Node.JS, Spring



ê¹ë¨í
http://namhoon.kim/
Jekyll, Firebase Korea



ê¹ëë¶
https://nolboo.kim/
ë²ì­ ëª¨ì



ê¹ëê¶
http://nacyot.com/




ê¹ëê¸°
http://daegikim.github.io/
Web



ê¹ëí
http://hatemogi.com/
ë°±ìë



ê¹ëê¸°
http://martian36.tistory.com/
ìëíë ì¤



ê¹ëí
http://insanehong.kr/




ê¹ëê³¤
http://dokonk.blogspot.kr/
DB



ê¹ëê· 
http://www.dokyun.pe.kr/




ê¹ëí
http://loboprix.com/




ê¹ëí
https://dohoons.com/
Web



ê¹ëì°
https://dongwoo.blog/
Javascript



ê¹ë§ì
https://mansoo-sw.blogspot.kr/




ê¹ëªì 
http://himskim.egloos.com/
Microsoft



ê¹ëªì£¼
http://blog.naver.com/bansuk78
Lagom



ê¹ëªì¤
http://html5lab.kr/
íë¡ í¸ìë



ê¹ë¯¼ê·¼
http://mingeun.com/
Laravel



ê¹ë¯¼ì
http://blog.naver.com/mseokim011117
Swift



ê¹ë¯¼ì
https://brunch.co.kr/@brunchqvxt
Spring Boot



ê¹ë¯¼ì
http://www.kmshack.kr/
ìëë¡ì´ë



ê¹ë¯¼ì
http://alwayspr.tistory.com/




ê¹ë¯¼ì¥
http://minjang.github.io/
ì»´í¨í° ìí¤íì²



ê¹ë¯¼ì¤
https://velopert.com/
Front-end



ê¹ë²ì¤
http://bomjun.tistory.com/




ê¹ë²ì¤
http://nolsigan.github.io/




ê¹ë²ì§
https://medium.com/@beejei




ê¹ë³í
http://kimbyeonghwan.tumblr.com/
UX



ê¹ë³´ì
https://boribap.github.io/
Block Chain



ê¹ë´í
https://harfangk.github.io/
Elixir



ê¹ìí
https://interpiler.com/
IT ì¹¼ë¼



ê¹ìê¸°
https://brunch.co.kr/@neo3xdh
IT ì¹¼ë¼



ê¹ì ì
http://sunyzero.tistory.com/
Linux



ê¹ìì¤
https://seokjun.kim/
React



ê¹ì ì² 
http://blog.naver.com/PostList.nhn?blogId=sckim007




ê¹ì±ë¹
http://sungbine.github.io/
Web



ê¹ì±ì
http://sungsoo.github.io/




ê¹ì±ì
http://devopser.me/
DevOps



ê¹ì±ì¤
https://brunch.co.kr/@sungjoonkim
IT ì»¬ë¼



ê¹ì±ì¤
http://sungjk.github.io/




ê¹ì±í
http://greemate.tistory.com/
ìëì°ì¦ ì»¤ë



ê¹ì±í¸
http://shiren.github.io/
Front-end



ê¹ì±í
http://www.se.or.kr/
íêµ ìí



ê¹ì±í
http://elky84.github.io/
C++, C#, Ruby, Python



ê¹ìë¡
http://babysunmoon.tistory.com/




ê¹ìë¯¼
https://brunch.co.kr/@flatdesign
UX ëìì¸



ê¹ìë³´
https://subokim.wordpress.com/
IT ì¹¼ë¼



ê¹ìì
http://i-bada.blogspot.kr/




ê¹ì¹í¸
http://raccoonyy.github.io/
Python



ê¹ì¬ê¸°
http://blog.seulgi.kim/




ê¹ìì
https://brunch.co.kr/@springboot
Spring Boot



ê¹ìì°
http://datajournal.kr/
ë°ì´í° ë¶ì



ê¹ìì
http://keyassist.tistory.com/
Data Science



ê¹ìì¬
https://youngjaekim.wordpress.com/




ê¹ìì¬
http://haviyj.tistory.com/
Spring Boot



ê¹ìì 
https://qpfmtlcp.github.io




ê¹ìí
https://brunch.co.kr/@fermat39




ê¹ìí
https://blog.martinwork.co.kr/
AI, Javascript



ê¹ìì­
https://josephkim75.wordpress.com/




ê¹ì©ê· 
http://haruair.com/
Web



ê¹ì©ë¬µ
http://moogi.new21.org/
íê¸ ì¸ì´, C++



ê¹ì©ì¼
http://app-developer.tistory.com
iOS



ê¹ì©ì¤
https://kimkevin.net/
Android



ê¹ì©í
http://blog.naver.com/drvoss
C++



ê¹ì©í
http://knight76.tistory.com/




ê¹ì©í
https://ggoals.github.io/
Data Infrastructure



ê¹ì°ì­
https://brunch.co.kr/@linterpreteur




ê¹ì°ì¹
https://kimws.wordpress.com/
ë¹ë°ì´í°



ê¹ì°ì©
https://brunch.co.kr/@wedump
ê²ì ê°ë°



ê¹ìì¼
http://androidkr.blogspot.kr/
ìëë¡ì´ë



ê¹ìí¸
https://undefine.me/
Javascript



ê¹ì¸ê¶
https://blog.naver.com/gi_balja




ê¹ì¸ê¸°
http://ingeec.tistory.com/
Web



ê¹ì¸ì
http://webholic.net/
Web



ê¹ì¬êµ­
https://jaigouk.com/




ê¹ì¬ì
http://epiloum.net/
Front-end



ê¹ì¬í¸
http://www.benjaminlog.com/
C++



ê¹ì ì
https://swtpumpkin.github.io/
Javascript, Node



ê¹ì í
http://feelteller.com/
Android



ê¹ì í
http://blog.jeonghwan.net/
Javascript, Node



ê¹ì í
https://blog.naver.com/writer0713/
Javascript, Java, Web



ê¹ì í
https://wonderer80.github.io/
ìíí¸ì¨ì´ ê°ë°



ê¹ì¢ë¯¼
http://kimjmin.net/
Elastic Stack



ê¹ì¢ë¯¼
http://blog.cmiscm.com/
ì¸í°ë í°ë¸ ëë²¨ë¡í¼



ê¹ì¢ë¯¼
http://uroa.tistory.com/




ê¹ì¢ë¯¼
https://jongmin92.github.io/
Spring



ê¹ì¢ì±
http://catlog.kr/




ê¹ì¢ì¸
http://zzong.net
Java, Spring



ê¹ì¢ì² 
https://infoscis.github.io/
Front-end



ê¹ì¢í
https://dev.wisedog.net/
Python, Go, Javascript, Cloud



ê¹ì¢í
http://story.wisedog.net/
ì ì ë¶ì



ê¹ì¢í
http://shovelman.tistory.com/
.NET



ê¹ì¢í¬
https://kimpaper.github.io/
Back-end



ê¹ì¤ì±
https://brunch.co.kr/@codertimo




ê¹ì¤ì
https://junebuug.github.io/
Java / Python
 


ê¹ì¤ì² 
http://jetalog.net/
Solr



ê¹ì¤í
https://medium.com/@ghilbut




ê¹ì¤í
http://topnanis.tistory.com/




ê¹ì¤í¬
https://wnsgml972.github.io/




ê¹ì¤ê·¼
https://swtools.review/
IT Tour Guider, SW Tools, SW Internals, Android



ê¹ì§ì
https://brunch.co.kr/@pubjinson




ê¹ì§ì°
https://brunch.co.kr/@ken1224
ì¤íí¸ì, ììì°ì



ê¹ì§ì´
https://kishe89.github.io/
Javascript



ê¹ì§í
http://java.ihoney.pe.kr/
Java



ê¹ì§í
https://hyeon.me/




ê¹ì§í
https://brunch.co.kr/@jihere1001
íë¡í íì´í



ê¹ì§êµ­
http://forensic-proof.com/
í¬ë ì



ê¹ì§ì­
http://vmfhrmfoaj.gitlab.io/
Clojure



ê¹ì§ì±
http://jinseong0928.blogspot.kr/




ê¹ì§ì
https://item4.github.io/
Web



ê¹ì§ì
https://brunch.co.kr/@lifidea
ë°ì´í° ê³¼í



ê¹ì§ì±
http://rein.kr/blog/




ê¹ì§
https://medium.com/@jimkimau
Front-end



ê¹ì°¬ë¹
https://blog.kesuskim.com/
Front-end



ê¹ì°½ì
http://www.memoriesreloaded.net/
ì¤ë¦¬ì½ë°¸ë¦¬



ê¹ì°½ì¤
http://agile.egloos.com/
ì ìì¼



ê¹ì²­ì§
https://jinblog.kr
ITìì/ë¦¬ë·°, ê°ë°(ì¹, ëª¨ë°ì¼)
  


ê¹ì¶©ì­
http://subicura.com/




ê¹íê³¤
http://taegon.kim/
ì¹



ê¹íê· 
http://blog.gaerae.com/




ê¹íê¸°
https://beyondj2ee.wordpress.com/
Java



ê¹íì
https://tykimos.github.io/
ë¨¸ì ë¬ë



ê¹íì
http://taewan.kim/
Oracle



ê¹íí
http://javaexpert.tistory.com/
ë¸ë¡ì²´ì¸, ì¹, ëª¨ë°ì¼



ê¹íí¸
http://www.androidhuman.com/
ìëë¡ì´ë



ê¹íí¸
https://medium.com/@xissy
ì¤íí¸ì



ê¹íí
http://thefinestartist.com/
Java, Android



ê¹íí
https://brunch.co.kr/@myte
í´ì¸ ì·¨ì



ê¹íí
http://carpedm20.github.io/




ê¹í¬í
http://kblog.popekim.com/




ê¹íê²°
http://devkyeol.tistory.com/




ê¹íì
https://medium.com/@zvuc




ê¹íì§
http://flymogi.tistory.com/
Android



ê¹íë¨
http://booksummary.tistory.com/




ê¹íì
https://hanwong.github.io/
Front-end



ê¹íì (ë¯¸í¤ê¹)
http://www.mickeykim.com/
êµ¬ê¸



ê¹íì¤
http://www.gisdeveloper.co.kr/
GIS



ê¹íì¤
http://www.jaso.co.kr/
ë§ì´í¬ë¡ ìë¹ì¤



ê¹íì¤
http://www.smallake.kr/
í¸ë ì´ë©



ê¹íì² 
https://sites.google.com/site/hcgoon
Java, ê°ì¸ìí¤(ì£¼ë¡ ì¼ë³¸ì´)



ê¹íë¡
http://rokrokss.com
NLP



ê¹í¸ë
http://cogniti-works.blogspot.kr/
nimf



ê¹íì
http://flowerexcel.tistory.com/
C++



ê¹íí¬
http://greentec.egloos.com/
ê²ìê°ë°



ê¹íë¯¼(ê¹ì½ë©)
http://huns.me/
Web



ê¹í¬ì¤
https://heejune.me/





á



Name
Blog
Description
Social




ëì¤í
https://nayunhwan.github.io/
React



ë¨ê²½ì§
https://kanteloper.github.io/
Centos



ë¨ê¶ë¯¼
https://medium.com/@minnamgoong
ì¤íí¸ì



ë¨ìì±
https://nso502354.github.io/
Swift



ë¨ì¸í
https://medium.com/@Nam_se
ê²ì ê°ë°



ë¨ìí
http://www.whynam.com/
Java, Javascript, Clojure



ë¨ì í
http://www.rkttu.com/
í´ë¼ì°ë



ë¨íì°
https://byline.network/author/smilla/
IT ë´ì¤



ë¸ê²½ëª¨
https://brightparagon.wordpress.com/
JavaScript, React, Webpack, ì¤íí¸ì



ë¸ìë²
https://medium.com/@sbroh




ë¸ì°¬ì°
https://rajephon.github.io/blog/




ë¸ìë¡ 
https://blog.aaronroh.org/
íë ììí¬, ì¤íìì¤



ë¸ì©í
http://bugsfixed.blogspot.kr/
ìëì°ì¦ ì»¤ë



ë¸ì¬ë¯¼
http://korsnack.kr/




ë¸íì
http://pluu.github.io/
Android




á



Name
Blog
Description
Social




ëê²½í
http://keen.devpools.kr/




ëì°½ì±
https://medium.com/@cwdoh
Android




á



Name
Blog
Description
Social




ë¥ê´
http://occamsrazr.net/
ë²ì­



ë¥ì¬ì
http://longbe00.blogspot.kr/




ë¥ì¢í
http://ryulib.tistory.com/




ë¥íì¤
https://activity.horyu.me





á



Name
Blog
Description
Social




ë§ê²½ì±
https://brunch.co.kr/@kyeongwook-ma
ì¤íí¸ì



ë§¹ì¤í¸
http://maengdev.tistory.com/
Data Science



ëª¨ìì°
https://brunch.co.kr/@aidenswmo




ë¬¸ëì 
http://dsmoon.tistory.com/
ë¨¸ì ë¬ë



ë¬¸ëì±
https://evan-moon.github.io/
Graphics, Web



ë¬¸ì¤ì
https://brunch.co.kr/@moonjoonyoung




ë¬¸íí
http://blog.lael.be/




ë¯¼ê²½ì´
http://min-it.tistory.com/
Docker



ë¯¼íê¸°
http://pinkwink.kr/
Robot, Data Science




á



Name
Blog
Description
Social




ë°ê²½ì±
https://kyungw00k.github.io/




ë°ê²½ì¤
https://ryanpark.me/
Domain Driven Design



ë°ê²½í(HOONS)
http://hoonsbara.tistory.com/
ë·ë·



ë°ê´ì´
http://eastsocial.co.kr/
ìëíë ì¤



ë°ê¸°ì
https://medium.com/@kpak
ì¤ë¦¬ì½ë°¸ë¦¬



ë°ë¯¸ì 
https://medium.com/@mjspring
Java



ë°ë¯¼
https://isme2n.github.io/
Front-end



ë°ë¯¼ê·¼(ìì½ì½ë)
http://blog.naver.com/agebreak
ê²ì ê°ë°



ë°ë¯¼ì°
http://earlybird.kr/
Realm



ë°ìê¶
http://gun0912.tistory.com/
Android



ë°ìê·¼
http://parksk.tistory.com/




ë°ìê¸¸
http://likejazz.com/




ë°ìê¸¸
https://kidmam.github.io/




ë°ìë¯¼
https://sangminpark.blog/




ë°ìì¼
https://tkddlf59.github.io/
AWS



ë°ìí
https://brunch.co.kr/@sanghoonpak
ì¸ëë¤ìì IT ìì



ë°ì±ë²
https://parksb.github.io
ì»´í¨í°ê³µí, ëìì¸



ë°ì±ì² 
http://blog.fupfin.com/
Java



ë°ìì 
https://parkseokje.github.io/




ë°ì±í
https://helloworldpark.github.io/
Graphics



ë°ì¹í¸
https://devwaf.blogspot.kr/
Front-end



ë°ì°ì¤
https://bakyeono.net/
Python



ë°ìë¡
http://youngrok.com/
ìí¤ëë¬´



ë°ì©ê¶
https://brunch.co.kr/@arawn




ë°ì©ì
https://gs.saro.me




ë°ìí¸
http://mellonia-lab.tistory.com/
Web



ë°ìì 
https://www.lucypark.kr/
ë°ì´í° ê³¼í



ë°ì¸
https://brunch.co.kr/@lynnata
ëì§í¸ ë¸ë§ë



ë°ì¼
http://parkpd.egloos.com/
ê²ì ê°ë°



ë°ì¬ì±(ìë°ì§ê¸°)
http://javajigi.net/
Java



ë°ì¬ì±
https://medium.com/@jspark141515




ë°ì¬ì±
https://medium.com/@alberto.park
billboard.js



ë°ì¬ì
https://kujyp.github.io
ML DevOps, Python, Docker



ë°ì¬í
http://wisefree.tistory.com/
IT ì¹¼ë¼



ë°ì¬í¸
http://jhrogue.blogspot.kr/
ë¹ë°ì´í°, ì¸ê³µì§ë¥



ë°ì ê·
http://bagjunggyu.blogspot.kr/
ë¦¬ëì¤



ë°ì ì´
https://jungwoon.github.io/
Android



ë°ì í
https://pjt3591oo.github.io/, http://blog.naver.com/pjt3591oo
Back-end, ìë²



ë°ì¢ëª
http://m.mkexdev.net/
ê¸°ì ì¬



ë°ì¢ì
https://medium.com/@mocona
iOS



ë°ì¤ê·
https://brunch.co.kr/@kospoll-lab
ì¸ê³µì§ë¥



ë°ì¤ê·
https://brunch.co.kr/@nattybear




ë°ì¤ì
https://swalloow.github.io/
BigData, AI



ë°ì¤í¸
http://junojunho.com/
Front-end



ë°ì¤í¸
https://blessingdev.wordpress.com/
Python



ë°ì§ì
https://medium.com/@JisuPark




ë°ì§í
https://medium.com/@ggikko
RxJava



ë°ì§ì
http://jasonpark.me/
Algorithm



ë°ì§ì°
https://www.jinpark.net/




ë°ì°¬ë¯¼
https://walkinpcm.blogspot.kr/
AWS



ë°ì°¬ì±
https://medium.com/@parkchansung
TensorFlow



ë°ì°¬ì¤
http://blog.naver.com/bcj1210
NLP



ë°ì°¬ì½
https://mrchypark.github.io/
R



ë°ì°¬ì±
http://chanwookpark.github.io/
Back-end



ë°ì²
https://say8425.github.io/
Ruby



ë°í´ì 
https://tensorflow.blog/
TensorFlow



ë°í
http://1ambda.github.io/
í¨ìí ì¸ì´



ë°í¬ê·¼
http://sirini.net/grboard2/blog
GR BOARD



ë°í¬ì°¬
https://blog.chann.kr/




ë°ì§ì°
https://mathbarn.wordpress.com/
Ubuntu



ë°©ì¤ì
http://bangjunyoung.blogspot.kr/
Java



ë°°ê¸°í
http://www.thestartupbible.com/
IT ì¹¼ë¼



ë°°ìí
https://blog.naver.com/soohan530/
ê³ ë±íì ê°ë°



ë°°ì±í
http://debop.tumblr.com/
ì¤ì¹¼ë¼



ë°°ì§í¸
https://medium.com/@baejinho/
ì¤íí¸ì, ì¹í¨ëª¨ì



ë°±ì¬ì°
http://jybaek.tistory.com/
Cloud



ë°±ì¢ì°¬
https://brunch.co.kr/@jeffpaik
ë¸ë¡ì²´ì¸



ë°±ê¸°ì 
http://whiteship.me/
Java, Spring



ë°±ëªì
https://brunch.co.kr/@cleancode
Java, OOP



ë°±ìì§
http://koreaceladon.tistory.com/
Storage



ë²ì´
http://blog.daum.net/funfunction
FP



ë³ê·í
https://novemberde.github.io/
AWS



ë³ì±ì¤
https://zzsza.github.io/
Machine Learning, Deep Learning, Data Engineering, BigQuery



ë³ì í(Outsider)
http://blog.outsider.ne.kr/
Web



ë³ìë¯¼
http://blog.suminb.com/




ë¶ì¢ë¯¼
https://durtchrt.github.io/blog/
Java, Spring




á



Name
Blog
Description
Social




ìê°í
https://medium.com/@darkrasid
Docker



ìê´ì´
http://gamecodingschool.org/
ê²ì ê°ë°



ìë¯¼ì
http://blog.naver.com/seo0511
Arduino



ìë³´ë£¡
http://inter6.tistory.com/
OpenStack



ììì
https://blog.seotory.com/
Full-stack



ìì¤ì
https://brunch.co.kr/@elijah17
Java



ìì©ë§
https://brunch.co.kr/@bonfire
Workflowy



ìì¸ì
http://isseo90.tistory.com/
ëìì¸



ìì£¼ì(ì²ì¬íì§)
http://seoz.com/
EFL, íì´ì  



ìì°½ì±
http://scw0531.blog.me/
Web, Mobile, IoT



ìì¶©ì
http://snowdeer.github.io/
C++, Linux



ìíêµ
https://brunch.co.kr/@zalhanilll
ëìì¸



ì±ëê²½
http://healthydeveloper.tistory.com/
Algorithm



ì±ëì°¬
http://gywn.net/
Database



ìì©í
http://www.sauru.so/
Docker, Elastic



ìì¹í
http://sonseungha.tistory.com/
Linux



ììì(arload)
https://arload.wordpress.com/
ê°ë°ë°©ë²ë¡ , Android



ìì°¬ì±
https://sculove.github.io/blog/
Web



ì¡ê¸°ì
http://blog.naver.com/agilesoft
Front-end



ì¡ë¯¼ì¹
https://brunch.co.kr/@minseungsong
ì¤ë¦¬ì½ë°¸ë¦¬



ì¡ì±ê´
http://blog.saltfactory.net/
Ghost, AWS



ì¡ìê¸¸
https://youngsong.com/
ì°½ì



ì¡ìí
https://purluno.wordpress.com/
Akka



ì¡ìì¤
http://wonjun.kr/




ì¡ì¤ì­
https://songyunseop.github.io/
Python, Node.js



ì¡ìì°
https://rampart81.github.io/
Python



ì¡ì¬ì¤
https://blog.jaeyoon.io/
Front-end



ì¡ì£¼ì±(ë¹ê¿)
http://emptydream.tistory.com/
IT ì¹¼ë¼



ì¡ì¤í
https://medium.com/@it_sjh9973




ì¡í¸ì°
https://brunch.co.kr/@chris-song/




ì¡í¨ì§
https://lovetoken.github.io/
R



ì ê¸°ì©
https://goodgid.github.io/
BE



ì¡í¨ì§
https://lovetoken.github.io/
R



ì ê²½ì
http://multeng.tistory.com/
AI



ì ê´ì
http://springsource.tistory.com/
Spring



ì ëì±
https://brunch.co.kr/@adrenalinee31




ì ë¯¼ì±
https://minwook-shin.github.io/
Python



ì ì¹í
http://www.talk-with-hani.com/




ì ìì§
http://www.jiniya.net/
ë³´ì



ì ìì§
http://dev.bloodevil.com/
Python



ì ì©ì¤
http://uni2u.tistory.com/
ë¤í¸ìí¬



ì ìê´
https://gracefullight.github.io/




ì ì¬ëª
https://medium.com/@Jaemyung




ì ì¬ì¸
http://jaynewho.com/




ì ì² ë¯¼
https://kato75.blog.me/
ìí¸ë¦¬



ì íë¬µ
https://brunch.co.kr/@supims
IT ì¹¼ë¼



ì íì
http://hyeonseok.com/
Web



ì íì
https://medium.com/@Hyeon_SS
Android



ì¬íì§
https://simhyejin.github.io/




ì í¸ì² 
http://hochulshin.com/
Java



ì í©ê·
https://medium.com/@hubert.shin
ê°ë°ë°©ë²ë¡ 



ì¬ì¬ì
https://byline.network/author/jsshim0622/
IT ë´ì¤




K



Name
Blog
Description
Social




Kevin Lee
https://blog.kevinlee.io/
Java




á



Name
Blog
Description
Social




ìëí
https://adhrinae.github.io/
Javascript



ìëí
https://brunch.co.kr/@donghyeokahn
ë¶ì°ëª¨ì



ììì±
https://www.bloter.net/archives/author/nuribit
ê¸ìµ



ìì±í
http://ash84.net/
Python



ììë¹
http://nyeong.github.io/
Python



ìì¹ê·
http://ahnseungkyu.com/
OpenStack



ììì 
https://lovemewithoutall.github.io/
Android, Web



ììí (Tony Lee)
https://www.popit.kr/author/tony
ìí¤íì²



ìì¤ê· 
http://ohgyun.com/
iOS, Python



ìì¤í¸
http://toyfab.tistory.com/
ë§ì´í¬ë¡ íë¡ì¸ì



ìì¬ì´
http://doublem.org/
Java



ìì¬ì°
http://blog.naver.com/saltynut
í´ì¸ì·¨ì



ìì¬í
http://programmingsummaries.tistory.com/
Front-end



ìì ì°
https://medium.com/@jeongwooahn
Vue.js



ìì í¸
http://ahnjungho.org/
Web



ìì í
http://www.andrewahn.co/
ì¤ë¦¬ì½ë°¸ë¦¬



ìì¢í
http://qnibus.com/
iOS



ìì¤ì
http://postgame.tistory.com/
ê²ìê°ë°, ì¹í°



ìíì°
https://mytory.net/
PHP



ìí¨ê·¼
http://hyogeun.tistory.com/
Android



ìí¬ì¢
http://ahnheejong.name/
Front-end



ìê¶ì±
https://blog.perfectacle.com/
Front-end



ìë³ê·
http://blog.naver.com/delmadang
ì¹¼ë¼



ìë´ì
https://yangbongsoo.gitbooks.io/study/content/
Java, Spring



ìì±ìµ
http://unikys.tistory.com
ìë°ì¤í¬ë¦½í¸



ìì±ì§
http://blog.hazard.kr/




ìì©ì±
https://brunch.co.kr/@ysyang
SQLGate



ìì¤ì² 
https://brunch.co.kr/@promise4u
ì¤íí¸ì



ìì§ì
https://brunch.co.kr/@jisuyang
IT ì¹¼ë¼



ìíì
https://medium.com/@FourwingsY
Front-end



ìí¬ì°¬
https://heechan.me/
Docker



ìì¹í
http://blog.eomdev.com




ìíê·
https://lazygyu.net/
HTML5 ê²ì ê°ë°



ìíì
http://t-robotics.blogspot.kr/
AI



ìíí
https://brunch.co.kr/@taebari




ì¬ì¤í¸
http://nogadaworks.tistory.com/
Hacking, Algorithm



ì¼ì¬í
https://only2sea.wordpress.com/




ì¼ì§ì
https://medium.com/@jwyeom63




ì¤ê´ì 
http://kwangshin.pe.kr/
í¨ìí ì¸ì´



ì¤ê²½ì
https://sikeeoh.github.io/
Android



ì¤ê¸¸í¸
http://kilho.net/
ìëíë ì¤



ì¤ëªì´
http://homoefficio.github.io/
Spring



ì¤ë¯¼í¸
http://wergia.tistory.com/
ê²ì ê°ë°



ì¤ìì¤
http://www.namooz.com/
Spring Boot, Angular2



ì¤ì¸ë¹
http://osebin.tistory.com/




ì¤ì¼ì
http://ilseokoh.com/
Azure



ì¤ì ê·
http://ohjeonggyu.github.io/
Kotlin



ì¤ì¢ë¹
http://ohyecloudy.com/




ì¤ì¤ì
https://brunch.co.kr/@hopeless
Android



ì¤íì
http://www.enshahar.me/
ì¤ì¹¼ë¼, ì¤ìíí¸



ì©ìí
https://xenonix.com/
PHP



ì©ì°¬í¸
http://blog.naver.com/alice_k106
Docker, RTOS



ì°ìëª¬
https://brunch.co.kr/@wej6688
UX



ì°ìì¤
https://blog.hax0r.info
Serverside, security



ì°ì¤í
http://sarojaba.github.io/
Awesome-devblog



ìê°ë¯¼
https://blog.wonhada.com/
ì½ë¡ë



ìì¢ì
https://tedwon.com/




ì ê²½ì
http://www.simpleisbest.net/
.NET



ì ëê³¤
http://blog.naver.com/ehdrhs1004
C++



ì ëí
https://brunch.co.kr/@yudong




ì ë³í
https://libsora.so/
Unity



ì ìì½
https://medium.com/@Dev_Bono
Front-end



ì ì±ê·
https://skyoo2003.github.io/
Ansible



ì ìì¬
https://blog.asamaru.net/
Android



ì ì©ì°
http://luckyyowu.tistory.com/




ì ì©í¸
http://blog.eedler.com/
Swift



ì ì¬ì
https://brunch.co.kr/@yoojs8512
IT ì»¬ë¼



ì ì¬ì¤
http://jaejunyoo.blogspot.com
ë¨¸ì ë¬ë



ì ì£¼ì
http://hipercube.tistory.com/




ì ì¤ì
https://wnstkdyu.github.io/
iOS



ì ì§í¸
https://brunch.co.kr/@jinhoyooephf




ì ì°¨ì
https://yous.be/
CTF



ì íì
http://duriepark.tistory.com/




ì íì¤
http://programmeringermany.blogspot.kr/
í´ì¸ ì·¨ì



ì í¬ì² 
https://medium.com/@ryuheechul
DevOps



ì¡ì¹ì°¬
http://loup1788.blogspot.kr/




ì¤ìë°°
http://www.joinc.co.kr/
ìí¤



ì¤ìì°¬
http://channy.creation.net/
ì¤íì¹, Mozilla



ì¤ìì
http://mobicon.tistory.com/
Angular



ì¤ì°ì
http://suitee.me/
Node.js, Python, Backend



ì¤ì§
http://storycompiler.tistory.com/
Tizen



ì¤ì²­í
https://brunch.co.kr/@brunch4nrs
êµ¬ê¸ë¬



ì¤íì² 
http://metashower.egloos.com/
Data Analytics



ì´ê²½ì
http://blog.woniper.net/
Java



ì´ê²½ì¼
http://blog.leekyoungil.com/
Java, Spring



ì´ê²½ì°¬
http://leekchan.com/
Go



ì´ê´ì
http://www.kwangsiklee.com/




ì´ê´í
http://honeyperl.tistory.com/
Perl



ì´ê·ì
https://justhackem.wordpress.com/
OOP



ì´ê·í
http://kyuhyuk.kr/
Security



ì´ê¸°ì
https://brunch.co.kr/@kiyoungleefige




ì´ê¸°ì°½
https://ratsgo.github.io/
NLP, ML



ì´ë¤ì
https://brunch.co.kr/@designforhuman
ëìì¸



ì´ëí
http://genesis8.tistory.com/




ì´ëê±´
http://baked-corn.tistory.com
iOS



ì´ëê·
http://chandong83.blog.me/




ì´ëê·
https://medium.com/@guleum
Web



ì´ëë ¨
http://start.goodtime.co.kr/




ì´ëì±
https://blog.naver.com/edy5016
Spring Boot



ì´ëì±
https://jojoldu.tistory.com
Java, Spring, IntelliJ, Backend



ì´ëì¸
https://brunch.co.kr/@leedongins
ìë² ëª¨ëí°ë§



ì´ëì¤
http://javalab.org/
Java, Math



ì´ëì¤
https://dongjunlee.github.io/
ML



ì´ëí
https://medium.com/@moralmk
Front-end



ì´ëªì¢
https://jijong.github.io/
Front-end



ì´ëªí
https://brunch.co.kr/@brightlee
ì¤íí¸ì



ì´ë¬´ì´
https://mooyoul.github.io/




ì´ë¯¼êµ¬
https://medium.com/@premist
Docker



ì´ë¯¼ì
http://hl1itj.tistory.com/
ìíí¸ì¨ì´ ë¬¸í



ì´ë¯¼ì°
https://brunch.co.kr/@minwoo
ê¸°í



ì´ë¯¼ì² 
http://bab2min.tistory.com/
Python



ì´ë¯¼í¸
http://lumiamitie.github.io/
Data Science



ì´ë²ì¬
https://medium.com/@beomjae




ì´ë³ì¤
http://www.buggymind.com/
Agile



ì´ë´ê· 
https://medium.com/@deptno
Front-end



ì´ìê· 
https://blog.naver.com/iyooha
Game



ì´ìë³µ
https://medium.com/@sangboaklee
Front-end



ì´ìì
http://blog.sangyoung.me/




ì´ìì°
http://prostars.net/
C++



ì´ìì±
https://sangwook.github.io/
ìí¤íì² ë¶ì



ì´ìì´
https://highluck.github.io/
Back-end



ì´ìì£¼
http://surpreem.com/




ì´ìí
http://sanghaklee.tistory.com/
Back-end



ì´ì í
https://medium.com/@kciter
Back-end



ì´ì±ê·
http://www.shalomeir.com/




ì´ì±ê·
http://blog.ohmynews.com/dangun76/
ì ëë¦¬ì¦



ì´ì±ê·¼
http://crazrain.tistory.com/
Spring Boot



ì´ì±ëª½
http://blog.naver.com/santalsm
ê¸°ì ì¬



ì´ì±ì
http://blog.sungwonandseohyun.us/




ì´ì±í¸
http://blog.scaloid.org/
ì¤ì¹¼ë¼, ìëë¡ì´ë



ì´ì¸ì°
http://blog.xcoda.net/
Raspberry Pi



ì´ìì
https://medium.com/@soeunlee
Front-end



ì´ìí
https://brunch.co.kr/@sohyeonlee




ì´ìì§
http://sujinlee.me/




ì´ìí
https://brunch.co.kr/@sbcoba
Spring Boot, Security



ì´ì¬
https://lee-seul.github.io/
Python, Django



ì´ì¹ì°
https://blog.2dal.com/
Docker, Kubernetes, AWS



ì´ì¹ì¬
https://saystone.github.io/
Hexo



ì´ì¹í
http://hamait.tistory.com/
Python



ì´ì¹í
https://brunch.co.kr/@oemilk
Android



ì´ì¹í
https://brunch.co.kr/@seunghoon82
ì¤íí¸ì



ì´ìê²½
http://sori-nori.gitlab.io/
AWS



ì´ìë¯¼
https://brunch.co.kr/@mapthecity
ì¸ê³µì§ë¥



ì´ìí
http://resoliwan.blogspot.kr/




ì´ìê·¼
http://icednut.github.io/
Java, Spark



ì´ìí¬
http://woongheelee.com/




ì´ì¤ì°½
http://daddycat.blogspot.kr/
Back-end



ì´ìì¤
https://blog.npcode.com/
Web



ì´ìë³µ
https://brunch.co.kr/@eundang
IT í¸ë ë



ì´ì¬í
http://www.unity3dstudy.com/
Unity



ì´ì¬í
http://pyrasis.com/
Go



ì´ì ê·¼
http://blog.cjred.net/
OpenShift



ì´ì ì
https://blog.jyslash.com/@jungyounglee
UI ëìì¸



ì´ì ì´
https://medium.com/@jwlee98
GCP



ì´ì ì
https://brunch.co.kr/@madlymissyou
IT ì¹¼ë¼



ì´ì ë¯¼
http://goodtogreate.tistory.com/
Data Science



ì´ì¢ë¦½
https://johngrib.github.io/
Python



ì´ì¢ì
https://medium.com/@yomybaby




ì´ì¢í¸
http://jhleed.tistory.com/




ì´ì£¼ì
https://dev-juyoung.github.io/
Android



ì´ì¤ë²
https://beomi.github.io/
Python, Django



ì´ì¤ì©
https://brunch.co.kr/@junyong
í´ì¸ ì·¨ì



ì´ì¤í¸
http://www.vonzone.kr/
ê¸°í



ì´ì§ì
https://www.bloter.net/archives/author/izziene
íµì , ê¸ìµ



ì´ì§í
https://www.bloter.net/archives/author/jihyun
ì¤íìì¤



ì´ì§í
http://jihoonlee.io/
ë¡ë´ê³µí



ì´ì§ì
https://medium.com/@allieuslee
Python, Django



ì´ì°¬ì§
https://medium.com/@chanjin
IT ì¹¼ë¼



ì´ì°¬í
http://blog.naver.com/dlcksgod1
3D Graphics



ì´ì°¬í¬
https://iamchanii.github.io/
Go



ì´íí
http://platformengineer.tistory.com/
Linux



ì´íí¬
https://brunch.co.kr/@bradlee
ì¤íí¸ì



ì´íì 
http://realignist.me/
Java, Rust



ì´í
https://blog.hanlee.io/
Python, Front-end



ì´íë³
http://lhb0517.tistory.com/
Ubuntu, Java



ì´í´ì
http://www.haeyounglee.com/
ê°ë°ì ìì´



ì´í
https://hy00un.github.io/
ì ë³´ë³´í¸



ì´íê·
https://codefict.com/
Python, Go



ì´íì­
http://hyunseob.github.io/
Web



ì´íì°
https://blog.naver.com/PostList.nhn?blogId=hidejj79




ì´íì£¼
https://wayhome25.github.io/
Algorithm, Django



ì´í¸ì±
https://brunch.co.kr/@leehosung
8í¼ì¼í¸ CTO. ê°ë° ë¬¸í



ì´í¸ì² 
http://hochul.net/blog/
ë°ì´í° ë¶ì



ì´íê·
https://medium.com/@mldevhong
ë¨¸ì ë¬ë



ì´í¥ì­
http://subl.ee/
ê²ì



ì´íì
http://alex.devpools.kr/




ì´í¥í
https://medium.com/@maxzidell
tyle.io CTO. Web



ì´í¬ì¹
http://t.motd.kr/ko/
armedia



ì´í¬ì±
https://www.bloter.net/archives/author/asadal
í¬í¸



ìëë¬¸
http://dmlim.egloos.com/
Java



ìì±ì§
http://blog.bbom.org/
Linux



ìì±í
https://brunch.co.kr/@sunghyunlim




ìì í
http://medium.com/@heartsavior
Apache Storm



ìì¢ë
https://medium.com/@jongdae.lim
Java, AI



ìì§í
http://www.jimmyrim.com/
ì¤íí¸ì í¬ì



ìíì
http://hsol.tistory.com/
Web



ìí¬ì§
http://epicdevs.com/
Back-end




á



Name
Blog
Description
Social




ì¥ê¸°í¨(ê¸°í¨ ì¡°ìì ì¥)
https://joshua1988.github.io/




ì¥ëë¯¼
https://medium.com/@Dongmin_Jang
Front-end



ì¥ëì
http://blog.iolo.kr/
Web



ì¥ë©í
https://matthew.kr/
Spring



ì¥ë¬¸ìµ
http://mooneegee.blogspot.kr/
3D



ì¥ì±ì§
https://brunch.co.kr/@99-life
ì¹ëìì¸, CSS Animation



ì¥ì±ë§
http://frontjang.info/




ì¥ì±ë¯¼
http://www.jangkunblog.com/
ì¹ì ê·¼ì±



ì ë¯¸ì 
https://mijeongjeon.github.io/
iOS, Keras



ì ì¹í
https://fuzer.github.io/




ì¥ìì² 
http://dkdlel072.tistory.com/
Unity



ì¥ìí
https://brunch.co.kr/@younghakjang
ì¡°ì§ë¬¸í



ì¥ìì
http://blog.lastmind.io/




ì¥ì©ì
http://devyongsik.tistory.com/
Java, Lucene



ì¥ì¬ì
http://superjang.com/
Front-end



ì¥ì¬í´
https://jaehue.github.io/
Go



ì¥ì¤í
https://medium.com/@hyuk
Interaction Design



ì¥íë¹
http://dork94.tistory.com/
Linux



ì¥íì
https://devjang.github.io/




ì¥íì¹
http://www.xeronichs.com/
ë¦¬ë²ì±



ì¥íì 
http://naleejang.tistory.com/
OpenStack



ì¥íì
http://openlook.org/wp/
ë¹ë°ì´í°



ì ê·í
http://www.allofsoftware.net/
ê¸°ìë¬¸í



ì ëê·
http://www.php5.me/blog/
PHP



ì ë¬´ìµ
https://medium.com/@muik




ì ë¯¼ì
https://brunch.co.kr/@ebprux
UX



ì ìí
http://sanghyukchun.github.io/
Machine Learning



ì ì¢í
http://mobile2.tistory.com/
ê¸°ì  ëí¥



ì ì°½ì
http://wani.kr/
PHP, Backend



ì íì¤
http://guswnsxodlf.github.io/
Web



ì íí
http://hjun.me/
UI



ì í¸ì
http://guruble.com/
ìë²ì¬ì´ë



ì í¬ì(ê³ ê°ì)
http://freesearch.pe.kr/
ë¹ë°ì´í°



ì ê²¨ì¸
https://winterj.me/
Python



ì ê´ì­
https://www.lesstif.com/
Linux, ë³´ì, Laravel, JIRA



ì ëì
http://blog.iamartin.com/
Cloud



ì ëí
http://www.moreagile.net/
ê°ë°ë°©ë²ë¡ 



ì ëë¯¼
http://jdm.kr/blog/
Java



ì ë¯¼í
https://www.holaxprogramming.com/
JavaScript, DevOps



ì ë²í¬
http://blog.sonim1.com/
Front-end



ì ë³ê¸°
https://byeongkijeong.github.io/
ì¸ê³µì§ë¥



ì ìí
http://blog.benelog.net/
Java



ì ìí
https://medium.com/@soonhyungjung
ë¸ë¡ì²´ì¸



ì ì¹ì±
https://medium.com/@jsuch2362
Android



ì ìì±
https://yangeok.github.io
Back-end



ì ìí¬
https://brunch.co.kr/@hee072794
React, Next.js



ì ì ì§
http://dudmy.net/
Android



ì ì í
https://takeuu.tistory.com
Front-end



ì ì¤ì±
http://yoonsung.github.io/
Rust



ì ì¤ì
http://youknowone.github.io/
IOS



ì ì¤ì§
http://kerberosj.tistory.com/
Cloud



ì ì¬ê´
https://jae-kwang.github.io/blog/
Front-end



ì ì¬ë¨
http://gomugom.github.io/
Front-end



ì ì¬í
http://uzys.net/
Rankedin



ì ì¢ì¤
https://wormwlrm.github.io/
Front-end



ì ì£¼í
https://brunch.co.kr/@toughrogrammer




ì ì°¬ëª
http://naradesign.net/
Front-end



ì ì°¬ì
https://korchris.github.io/




ì ì°½ì
http://downman.tistory.com/
C



ì ì°½í
https://code.iamseapy.com/
iOS



ì ì² 
https://wedul.site
Full-Stack



ì íí
http://chomman.github.io/blog/
Back-end



ì íì¼
http://blog.nuti.pe.kr/
Java, Spring



ì í¬ì°
https://yeun.github.io/
ì¹ëìì¸



ì ê°ë¯¼
http://jekalmin.tistory.com/
Spring



ì¡°ëí
https://hudi.kr/
Front-end



ì¡°ë§ì
http://manseok.blogspot.kr




ì¡°ë§ì
https://medium.com/@manyoung
Web



ì¡°ë³ì±(ì¡°ëí)
http://bcho.tistory.com/
Java



ì¡°ìí
https://brunch.co.kr/@aaa




ì¡°ì±ë¬¸
http://sungmooncho.com/
ì¤ë¦¬ì½ë°¸ë¦¬



ì¡°ì±ì
https://printf.kr/
Linux, Openstack



ì¡°ì¹ì°
http://blog.kivol.net/
ì¹¼ë¼



ì¡°ì¹ì§
http://www.tacogrammer.com/
IT ì¹¼ë¼



ì¡°ìêµ­
https://brunch.co.kr/@ziyocode
DevOps



ì¡°ìê·
http://dev.youngkyu.kr/
Android



ì¡°ìì¸
http://codersbrunch.blogspot.kr/
Algorithm



ì¡°ìí¸
http://aeternum.egloos.com/
DDD



ì¡°ì°ì§
http://www.notforme.kr/
Angular



ì¡°ì
https://brunch.co.kr/@techhtml
Front-end



ì¡°ìì
http://itnp.kr/blog/
Spring



ì¡°ìì°
http://jonnung.github.io/




ì¡°ì¸ì
https://brunch.co.kr/@insuk
SW ì¹¼ë¼



ì¡°ì¬ì°
http://flowkater.github.io/
Java



ì¡°ì¤í
http://blog.naver.com/chowin21
ë§ì¼í



ì¡°ì°½ë¯¼
http://incredible.ai/
AI



ì¡°íì(ZeroCho)
https://www.zerocho.com/
Javascript



ì¡°íì
https://dev.zzoman.com/
Front-end



ì¡°íì¢
http://hangumkj.blogspot.kr/
Eclipse



ì¡°íì§
http://resistan.com/
ì¹ì ê·¼ì±



ì¡°íì² 
https://cchcc.github.io/
Kotlin



ì¡°í
https://medium.com/@hooncho
UX/UI Design



ì£¼ê¸¸ì¬
http://www.giljae.com/
Cloud



ì£¼ë¯¼í
https://alegruz.imweb.me/
Python, ê²ì ê°ë°, C



ì£¼ììµ
http://haah.kr/
Web, PHP



ì£¼ì°ì
http://blog.coderifleman.com/
React.js



ì£¼ì¬ë²
http://joojaebum.com/
í½ì ìí¸



ì§êµ­í
http://wlhermit.blog.me/
ê²ì ê°ë°



ì§ìì¤
https://brunch.co.kr/@wjchee
IT ì¹¼ë¼



ì§ë¯¼ê·
https://medium.com/@justin_jin
ë§ì¼í



ì§ë¯¼ì
https://minwan1.github.io/
Spring



ì§ì±ì£¼
http://softwaregeeks.org/
ì¤íìì¤



ì§ìë¯¼
http://blog.naver.com/pistolcaffe
Android



ì§ìí
https://medium.com/@timotolkie
Javascript



ì§ì©ì§
https://brunch.co.kr/@yongjinjinipln
IT ì¹¼ë¼



ì§ì ë¦¼
https://milooy.wordpress.com/
Front-end



ì ë¯¼ì
https://medium.com/@HarrisonJung
ê¿ë§ìì²­ëë¤




á



Name
Blog
Description
Social




ì°¨ê²½ë¬µ
http://blog.hannal.com/
Django



ì°¨ì¤ë²
http://khanrc.tistory.com/
Data Science



ì±ë°ì
https://www.bloter.net/archives/author/chaibs




ì±ìì
http://blog.doortts.com/
Node.js



ì±ìí
https://proinlab.com/
Web, Data Mining



ì±ì¤ì°½
http://mcchae.egloos.com/
Python



ìµê´ë¯¼
http://dl-ai.blogspot.kr/
AI



ìµê·ì°
https://medium.com/@kyuwoo.choi
Front-end



ìµê·¼ì°
https://keunwoochoi.wordpress.com/
ì¸ê³µì§ë¥



ìµëì 
http://decisive.egloos.com/
ì ë³´ë³´í¸



ìµë§
http://manchoikorea.blogspot.kr/
êµì¡



ìµë°±ì¤
http://www.baekjoon.com/
ìê³ ë¦¬ì¦



ìµë²ê· 
http://javacan.tistory.com/
Java



ìµìê· 
http://syaku.tistory.com/
Full-stack



ìµì±ì¬
http://yumere.tistory.com/
Paper Review



ìµìì
http://cionman.tistory.com/
Linux



ìµì¹í
https://brunch.co.kr/@pilsogood
í¸ë¦½ê·¸ë¦¬ë¤



ìµì©ì
https://blog.naver.com/cys_star




ìµì ì
http://whitechoi.tistory.com/
Cloud



ìµì¤ì­
http://www.yoonsupchoi.com/
í¬ì¤ì¼ì´



ìµìì 
https://im-mota.github.io/
UX



ìµì¬ê¸¸
http://blog.devjoshua.me/




ìµì¬í
http://andromedarabbit.net/
Cloud



ìµì ë
http://blog.woosum.net/
ì¤íì¤í



ìµì ë ¬
http://bestalign.github.io/
Javascript



ìµì ì°
http://blog.naver.com/cenodim
Kotlin



ìµì¢ì±
https://wook.kr/




ìµì¢ì
https://brunch.co.kr/@voiz
íí¬ ì¹¼ë¼



ìµì¢ì°¬
http://blog.0xabcdef.com/




ìµì¤ê±´
http://junegunn.kr/
fzf



ìµì¤ì
https://jicjjang.github.io/blog
Front-end



ìµì¤ì
https://rokt33r.github.io/
React, Electron, Boostnote



ìµì¤í¸
http://blog.saturnsoft.net/




ìµì§ì
https://wpu.kr/
ìëíë ì¤



ìµì§í¸
http://calmglow.egloos.com/
Web



ìµì°½ê·
https://brunch.co.kr/@cg4jins
ì¹´ì¹´ì¤í¤ì´ìµ ìë² ê°ë° íê¸°



ìµì°½ì
https://qwefgh90.github.io/sphinx
ì»´í¨í° ê³µí ë¶ì¼ ìí¤



ìµì°½ì
https://medium.com/@qwefgh90
ì¹/ë²ì­, ì»´í¨í° ê³µí ë¶ì¼



ìµì°½í
https://alklid.github.io/dlog/
Spark



ìµì² í¸
https://brunch.co.kr/@chulhochoiucj0
UI/UX ëìì¸



ìµì¶©ì½
https://medium.com/@albertseewhy




ìµíì¬
https://brunch.co.kr/@mirr5510
ì¤íí¸ì



ìµíë¯¼
https://medium.com/@hyunmin.choi
Scala



ìµíì
https://diveintodata.org/
Apache Tajo



ìµí¸ì­
https://byline.network/author/hs-choi/
IT ë´ì¤



ìµí¥ë°°
https://jacking75.github.io/
C++




á



Name
Blog
Description
Social




í¸í´ê±¸
https://medium.com/@la.place
Front-end




á



Name
Blog
Description
Social




íëì°
https://medium.com/@cookatrice
Angular



íìí¸(Las)
https://medium.com/@haho6629
ì¸ê³µì§ë¥, Devops



íí¸ì§(Mimul)
http://www.mimul.com/
ì¹¼ë¼



íê³  (10ëì½ë)
https://10yearscoder.tistory.com/
íë¦¬ëì



íë¯¼ì
http://creativeprm.tistory.com/
R



íìê³¤
http://www.sangkon.com/
Django



íìí
https://brunch.co.kr/@skykamja24




íì±ë¯¼
https://blog.pigno.se/




íìì°
https://www.bloter.net/archives/author/again
ë¸ë¡ì²´ì¸, ë¹ë°ì´í°



íì¹í(kkamagui)
http://kkamagui.tistory.com/
OS



íìë¹
https://blog.youngbin.xyz/
Ubuntu



íìì 
https://nicewoong.github.io/
Linux



íì¥í
http://han41858.tistory.com/
Angular



íì¬ì½
https://jaeyeophan.github.io/
Front-end



íì ì¼
https://brunch.co.kr/@lonnie
Android



íì í
http://blog.kazikai.net/
Front-end



íì£¼ì
https://medium.com/@jooyunghan
Functional Programming



íì°½ì
https://free-strings.blogspot.kr/
Rust



íê´ë¨
http://okjsp.tistory.com/
OKKY



íì¹
https://seanlion.github.io/
ì¤ëµë´ì¤



íìì² 
http://heowc.tistory.com/
Java



íì¬ì
https://kirade.github.io/
ì±



íì¬ì
http://blog.import.re/
Kotlin



íì¤í(ì£¼ë¤)
http://joone.net/
ë§í



íì§í¸
https://medium.com/@hur
ì¤íí¸ì í¬ì



íìëª
http://soomong.net/
ì±



íì¤í¸
https://jhyun.wordpress.com/
ì¹ì ê·¼ì±



íê¸¸í
http://blog.naver.com/hgh73
ìëíë ì¤



íë¯¼í¬(dahlia)
https://blog.hongminhee.org/




íì±ì² 
https://medium.com/@sungcheulhong




íìí
http://hackerwins.github.io/
summernote



íì©ë¨
https://brunch.co.kr/@doberman
ì¤íí¸ì



íì ëª¨
http://blog.naver.com/atelierjpro
AI



íì² ì£¼
https://medium.com/@angdev
Ruby, Javascript



í©êµë¹
http://archive.htrucci.com
Java, Back-End



í©ê·í
http://lespinside.com
Reactive Programming



í©ì±ì°
https://king10tech.github.io/
Java



í©ì¸ì
https://medium.com/@chequer
Spring



í©ì¥í¸
http://xrath.com/




í©ìì² 
http://pragmaticstory.com/
ì ìì¼



í©ìì£¼
http://dolppi.egloos.com/
ê¸ìµê³µí



í©ì±ì¬
https://brunch.co.kr/@uxinventor
ì°½ì



í©ì¤ì
http://jsideas.net/
Data Science



í©ì¤ì
http://nuxlear.tistory.com/
Keras



í©ì§í
http://jhhwang4195.tistory.com/
NFV, 5G, Devops



í©ì¹ê·
https://brunch.co.kr/@delight412
IT ì¹¼ë¼



í©íì
https://yahwang.github.io
ë°ì´í° ë¶ì, ìì§ëì´ë§



íì¸
http://recipes.egloos.com/
Embedded Recipes




S



Name
Blog
Description
Social




Steve Park
https://brunch.co.kr/@stevepark
ë¯¸êµ­ ì·¨ì ì±ê³µê¸°




",1376
susalib/susa,C++,"Susa Open Source Project  
Susa is a mathematics and signal processing C++ framework based on KISS
principle. It is stand-alone with a modern architecture. It is designed not to have any dependencies to none standard third
party libraries. Indeed, a C++11 compiler along with STL is necessary and sufficient in order to compile it. Therefore,
portability is the key feature of Susa. For example it can be exploited in mobile platforms such as Android NDK (Native
Development Toolkit) without any restriction. This brings the power and speed of the C++ native code to the user friendly
Java based mobile applications. Susa is also a simulation framework for the researchers and engineers who design
computational systems. It has linear algebra, signal processing and common communications blocks.
The matrix and array template classes i.e. types are at the heart of Susa. A vector is simply a single column (or a single row) matrix. It is bundled with a constellation of classes and functions.
Highlights

Algebraic types (template classes): matrix and multi-dimensional array.
Linear algebraic operations and analysis (e.g. Determinant and SVD).
Signal processing operations (e.g. FFT, Filter (FIR/IIR), Convolution and Random Number Generators).
Convolutional Forward Error Correction (FEC) blocks: encoder, MLSE (Viterbi) and MAP (BCJR) decoders.
Channel equalisers: MLSE (Viterbi) and MAP (BCJR).
Automatic memory management i.e. allocation, deallocation, move and copy.

Build, Test and Install
Build
To build Susa you need to have a C++ compiler, Make and CMake installed.
mkdir build
cd build
cmake ..
make

Test
It is highly recommended to run the tests after the build.
make test

Should you verify which test(s) has/have been failed, run the following for a more detailed report.
ctest -V

Install
Once it has been built and tested you are ready to code. Assuming your current path is build directory, run
make install

to be able to build against Susa system-wide. However, you may continue using the local build without installation.
Examples
In the examples directory
a number of simulation and tutorial source codes have been provided.
Contribution
This is a non-profit project and it belongs to its users. You can contribute to your project by reporting bugs and extending it by following the provided guidelines. This paves the way for further improvements and protects the authors' rights.
History
Susa was born in April 2008 out of a university project course in digital communications.
At the time the libraries that could be used for digital communications simulation had
many dependencies (e.g. LAPACK, BLAS and ATLAS).
Once it took about six hours on a decent PC to compile one of them. On the other hand those
weighty codes had nested bugs that sometimes stemmed from their third party dependencies.
The answer to these problems was Susa that was released
in November 2008.
Later in early 2009, Susa was used for a bandwidth efficient coding scheme, namely,
Faster Than Nyquist (FTN).
It required preferment equalizers to decode up to some twenty taps (compared to the fading channels with few taps).
The simulation of such systems took a long time between an hour to a few days. This library could simulate
a FTN system with thirteen taps using a modified BCJR algorithm (a sub-optimal variant that could outperform
the original algorithm) in about an hour whereas a similar script in a commercial computing software took
at least twelve hours.
Unearthed tablets from Susa (2000 BC) revealed a rather precise calculation of Pi = 3.125 with the fractional part
whereas the other earlier efforts calculated the integer part.
Since the very first line of code was simply the definition of constant Pi, it has been named Susa.
License
Susa has been released under GNU Lesser General Public License (LGPL).
",19
susalib/susa,C++,"Susa Open Source Project  
Susa is a mathematics and signal processing C++ framework based on KISS
principle. It is stand-alone with a modern architecture. It is designed not to have any dependencies to none standard third
party libraries. Indeed, a C++11 compiler along with STL is necessary and sufficient in order to compile it. Therefore,
portability is the key feature of Susa. For example it can be exploited in mobile platforms such as Android NDK (Native
Development Toolkit) without any restriction. This brings the power and speed of the C++ native code to the user friendly
Java based mobile applications. Susa is also a simulation framework for the researchers and engineers who design
computational systems. It has linear algebra, signal processing and common communications blocks.
The matrix and array template classes i.e. types are at the heart of Susa. A vector is simply a single column (or a single row) matrix. It is bundled with a constellation of classes and functions.
Highlights

Algebraic types (template classes): matrix and multi-dimensional array.
Linear algebraic operations and analysis (e.g. Determinant and SVD).
Signal processing operations (e.g. FFT, Filter (FIR/IIR), Convolution and Random Number Generators).
Convolutional Forward Error Correction (FEC) blocks: encoder, MLSE (Viterbi) and MAP (BCJR) decoders.
Channel equalisers: MLSE (Viterbi) and MAP (BCJR).
Automatic memory management i.e. allocation, deallocation, move and copy.

Build, Test and Install
Build
To build Susa you need to have a C++ compiler, Make and CMake installed.
mkdir build
cd build
cmake ..
make

Test
It is highly recommended to run the tests after the build.
make test

Should you verify which test(s) has/have been failed, run the following for a more detailed report.
ctest -V

Install
Once it has been built and tested you are ready to code. Assuming your current path is build directory, run
make install

to be able to build against Susa system-wide. However, you may continue using the local build without installation.
Examples
In the examples directory
a number of simulation and tutorial source codes have been provided.
Contribution
This is a non-profit project and it belongs to its users. You can contribute to your project by reporting bugs and extending it by following the provided guidelines. This paves the way for further improvements and protects the authors' rights.
History
Susa was born in April 2008 out of a university project course in digital communications.
At the time the libraries that could be used for digital communications simulation had
many dependencies (e.g. LAPACK, BLAS and ATLAS).
Once it took about six hours on a decent PC to compile one of them. On the other hand those
weighty codes had nested bugs that sometimes stemmed from their third party dependencies.
The answer to these problems was Susa that was released
in November 2008.
Later in early 2009, Susa was used for a bandwidth efficient coding scheme, namely,
Faster Than Nyquist (FTN).
It required preferment equalizers to decode up to some twenty taps (compared to the fading channels with few taps).
The simulation of such systems took a long time between an hour to a few days. This library could simulate
a FTN system with thirteen taps using a modified BCJR algorithm (a sub-optimal variant that could outperform
the original algorithm) in about an hour whereas a similar script in a commercial computing software took
at least twelve hours.
Unearthed tablets from Susa (2000 BC) revealed a rather precise calculation of Pi = 3.125 with the fractional part
whereas the other earlier efforts calculated the integer part.
Since the very first line of code was simply the definition of constant Pi, it has been named Susa.
License
Susa has been released under GNU Lesser General Public License (LGPL).
",19
ernestochero/volskaya,Scala,"GraphQL - Volskaya
GraphQL server written with akka-http, circe and sangria.
",2
CHEF-KOCH/nVidia-modded-Inf,JavaScript,"



nVidia modded Inf project was created 2017 by CHEF-KOCH and is under GNU GENERAL PUBLIC LICENSE v3.
The project is unofficial and not in any relationship or supported by nVidia Cooperation.
This project only support x64 Windows 10 versions, if you like to see x86 ask nVidia to extend the support.




What is a modded INF?
All drivers come with an ""Installation INF(ormation) file"". This tells the Windows internal installer how to install the driver. The INF has the instructions to what files to copy and where. It will also setup settings to install with. The INF-file itself contains a list of supported products (hardware/software/OS) that it will check and install for.
nVidia provides UDA (Unified Driver Architecture) where the driver should work for all their released GPUs. So the driver itself will support ALL GPUs, but the INF the driver comes with will only support a selected set of GPU
nVidia by default don't support laptop GPUs with beta and WHQL driver updates on their server. This is left up to the OEM to organize. I assume nVidia must charge to have an OEM driver made or be included, as they are very rear for OEM to actually update a video driver. So an OEM driver has specific instructions for that laptop (ie model specific) and will only work with a select few laptops.
For example a Toshiba OEM driver with a Toshiba INF (nvts.inf) will only work with the models included in that INF.
Modded drivers will NEVER transform your GPU to another one and will NEVER add features that you do not already have.
Reasons for modding

New driver features tests.
You like to test newer driver(s) which are no longer supported.
It could be used to force installation of newer drivers on OEM locked GPUs.
You need an older driver that is not officially supported for your GPU because you have a specific application that is broken in newer ones and you cannot wait for a fix.
Security reasons, you should ALWAYS use the latest driver (if possible) due to possible driver flaws

Keep in mind:

Fermi GPUs (400 and 500 series) as from 396 driver are official no longer supported! Same goes for 700M and 800M GPU's.

DCH or Standard drivers?
Short answer:

""Standard"" packages are those that do not require the DCH driver components. DCH represents UWD which you can install via the Windows Store or manually.
Standard is the ""old"" way which you (for now) should prefer since UWD drivers aren't tweakable (in terms of mods) compared to the standard (legacy) drivers.
""DCH"" (Declarative, Componentized, Hardware Support Apps) refers to new packages pre-installed by OEMs implementing the Microsoft Universal Driver paradigm.
DCH drivers cannot be installed over a standard system, and Standard drivers cannot be installed over a DCH system.
To confirm the type of system you have, locate Driver Type under the System Information menu in the nVidia Control Panel.

Detailed Answer:
DCH is a collaboration platform supporting the process of commercial forecasting Demand Collaboration Hub (DCH) is a collaboration platform that enables all members of your Sales organization, at the various hierarchical levels, to submit, consolidate and validate their periodic commercial forecast. DCH is fully configurable, allowing you to model the workflow and segment the data between users, in relation to their level of responsibility, to configure your editing form, by selecting and publishing the information that are relevant for your sales organization, to enter commercial forecast at various level of aggregation, with automatic splitting of edited quantities to the level of maximum detail. DCH is part of the SO99+ (Service Optimizer 99+) product suite and more specifically it is complementary to its statistical forecasting functionality, since the statistical forecast may be used as a guidance to support the Sales organization to provide more reliable figures. To support mobility, DCH is available on the web or from any mobile device that your Sales organization may adopt.
Remove old nVidia drivers

Extract Display Driver Uninstaller (DDU) and start the program, boot into ""safe mode"" (you can do this manually or within the given DDU option) and let DDU auto-clean and restart the OS automatically for you. You do not need to uninstall the driver or any package via Windows own uninstaller program first (that's the whole point using DDU). Keep in mind that DDU should only be used in case you get troubles while uninstalling/installing the driver with nVidia's own Setup, it's not recommend and needed to use DDU as 'normal' driver removal procedure. nVidia's own setup routine usually does the job just fine, however in some cases in can help to remove leftovers which might cause trouble.
After you rebooted you install the (modded/repack) nVidia driver, if the driver isn't digital signed you need to do it yourself or disable Windows driver signature enforcement.

An official DDU guide can be found here.
Modded Inf Driver installation

Download and extract the Driver (download from official source) - wait until the installer has unzipped the files e.g. to C:\nVidia.
Search for e.g. ""nv_disp.cat"" (or corresponding inf-file) in the 'Display.Driver Folder'.
Follow the Video or the written instruction to install the certificate manually (optional).
Now you can install all my modded drivers, without disabling 'driver signature enforcement'.

How to show current driver branch?!

Download nVidia Inspector
Check the Overview Window under ""Driver version"" you see the installed driver branch.

Troubleshoot - Disable Driver Signatures
Check the current secure boot status (optional), which gives you true or false (enabled/disabled) back:

Powershell confirm-SecureBootUEFI


Before you install unsigned drivers, you have to manually set those parameters via administrative command prompt to turn secure boot off:
bcdedit -set loadoptions DISABLE_INTEGRITY_CHECKS

bcdedit -set testsigning ON

shutdown.exe /r /o

After you're finished installing the unsigned driver:
bcdedit -set loadoptions ENABLE_INTEGRITY_CHECKS

bcdedit -set {globalsettings} advancedoptions true

bcdedit -set TESTSIGNING OFF

After executing the mentioned commands you need to reboot Windows 10 in order to apply the changes. Some (if not all) new laptops have no options to turn secure boot off.
How to sign your modded driver?
Download and install (or use the portable) SelfCert.
Select the following after starting the app:
x.500 distinguished name: cn=name_here,o=org_here,e=email@example.com

Key size: 2048

Valid from: today

Valid to: Your choice like 5 up to 10 years

Now put in a password in and save as PFX
CN = Microsoft Windows Hardware Compatibility PCA
O = Microsoft Corporation
L = Redmond
S = Washington
C = US
E = Your Email

OK, now that you have your PFX, you can generate a CAT for your modded driver and sing it (you will need the latest Windows Driver Kit)
Re-generate a new CAT with Inf2Cat with:
Inf2Cat /driver:<path_to_folder_with_INF_&_Files> /os:Vista_X86,Vista_X64,Server2008_X86,Server2008_X64,7_X86,7_X64,Server8_X64,8_X86,8_X64,Server6_3_X64,6_3_X86,6_3_X64


Sign the new CAT with your PFX
signtool sign /f <filename>.pfx /p <password> ""<path_to_folder>\nv_disp.cat""
Timesamp your CAT file
signtool timestamp /t http://timestamp.verisign.com/scripts/timstamp.dll ""<path_to_folder>\nv_disp.cat""
Now what you need to do, is get the cert from your PFX, install it in the Trusted Root Cert. Auth. and get the reg from this to give to users to apply

What the ""inf mod"" can't provide

 Adding support for legacy GPU's  (see EOL) because nVidia removed (within the source code) support for it and there is no patch which can undo or manipulate it.
 I'm not permitted to upload modified .dll files so please do not ask for ""patch xyz"". I consider to provide bunch of offset patches I use, without any tool or information how you add these patches because it violates nVidia TOS (it's not my fault).

Telemetry
All information regarding driver bundled telemetry can be found under the /Telemetry folder.
It's not necessary to block telemetry with your firewall, since you can manually opt-out or install a 'crap free' version and you also can remove the unneeded folders/services manually.
The Guru3d user uKER programmed a little utility called NVSlimmer which allows you (via GUI) to remove the unneeded folders/features - it's basically the same as doing it via a batch/cmd but with an simple interface to allow you to manually select all folders based on your own 'removal needs', the program includes also an integrated required list in order to warn user what is really necessary to keep in order to use the driver.
Another program (rip-off from NVSlimmer) called ""NVCleanstall"" can be found in the TechPowerUP forums.
Release








Latest nVidia PhysX System Software: 9.19.0218


Latest nVidia GeForce Experience: 3.18.0.102 Stable & Beta 3.18.0.102


Acknowledgement & References

DDU Source Code (github.com/Wagnard)
GeForce Driver Installation Guide A guide to ensure your drivers are installed properly (forums.geforce.com)
Install nVidia drivers on macOS the easy way (github.com)
LaptopVideo2Go (laptopvideo2go.com)
Official nVidia Display Driver Feedback Page (surveys.nvidia.com)
PC Gaming Wiki (pcgamingwiki.com)
PCI ID Project (pci-ids.ucw.cz)
Windows 10 FAQ and Driver installation tips (forums.geforce.com)
nVidia INF driver modding (forums.guru3d.com)

Debugging

How to enable nVidia Graphics Driver and GeForce Experience installer logging (nvidia.custhelp.com)

Unofficial patches

Driver patch for enabling unlimited NVENC sessions (old) (github.com)
NvencSessionLimitBump (github.com
WhateverGreen (github.com)
Wine patches (github.com)
nVidia kvm patcher (github.com)
nVidia patch to remove restriction on maximum number of simultaneous NVENC video encoding session (github.com)
purge-wrangler (github.com)

Unofficial updater

nVidia Update PowerShell Script (github.com)

Bios

Maxwell Bios Tweaker for edit nVidia GTX 9XX bios (github.com)
VGA and BIOS rom font extraction (github.com)
nVidia-PascalBiosEditor (github.com)
nVidia-vBIOS-VFIO-Patcher (github.com)

EOL

End of Driver Support for Quadro Kepler-series Notebook Products (April 30, 2020)
Support Plan for 3DVision Products (nvidia.custhelp.com)
Support Plan for Kepler-series GeForce GPUs for notebooks (nvidia.custhelp.com)

",68
lopsided98/nixos-config,Nix,"NixOS Configuration
Packages, modules and configurations for my NixOS machines
The files in this repository are used to build all my NixOS machines, across
4 different architectures (armv6l, armv7l, aarch64, and x86_64). Everything
is built with my private Hydra instance, and each device has its own channel
(see machines/default.nix).
My fork of nixpkgs
is required to build my machine configurations. Machines can be deployed
manually to test changes using the deploy.sh script.
Some interesting bits:

Machine specific channels
A pragmatic way of handling secrets in the Nix store
Selectively cross compile packages (search for crossPackages)

",2
jjos2372/blocktalk,Java,"BlockTalk: easy to use smart contracts for Burstcoin


Burstcoin was the world's first HDD-mined
cryptocurrency using an energy efficient
and fair Proof-of-Capacity (PoC) consensus algorithm.
It was also the first to implement a turing-complete smart contract
system in the form of Automated Transactions (AT), as specified by CIYAM.
However, before BlockTalk, the creation and deployment of smart contracts required writing
(assembler-like) bytecode and testing on-chain, making the development of contracts cumbersome.
This project allows the user to write, debug, and deploy Burst smart contracts relying only on Java.
You can use a simple text editor or your preferred IDE.
BlockTalk consists of the following key components:

Contract.java: a Java abstract class defining the basic API available for contracts
Emulator: an emulated blockchain and respective UI
Compiler: a system to convert Java bytecode into Burst AT bytecode that can run on the Burst blockchain


This project is in pre-alpha. Most contracts still cannot be compiled into CIYAM bytecode.
Please carefully inspect your compiled AT contracts and
test it exhaustively on the testnet before production.
Sample Contracts
Take a look on the samples source folder.
Using (write your own contract)
Sample application
The easiest way to start with BlockTalk is to clone the blocktalk-sample.
This sample application is actually a VSCode Java Application.
Just clone or download the sample application and open its folder with VSCode.
Manually add BlockTalk to your gradle project
Add the following to your gradle.build file:
repositories {
	maven { url 'https://jitpack.io' }
}
dependencies {
	implementation 'com.github.jjos2372:blocktalk:-SNAPSHOT'
}

Manually add BlockTalk to your maven project
Add the repository to your configuration:
<repositories>
	<repository>
	    <id>jitpack.io</id>
	    <url>https://jitpack.io</url>
	</repository>
</repositories>
<dependency>
	<groupId>com.github.jjos2372</groupId>
	<artifactId>blocktalk</artifactId>
	<version>-SNAPSHOT</version>
</dependency>

License
This code is licensed under GPLv3.
Author
jjos
Donation address: BURST-JJQS-MMA4-GHB4-4ZNZU
",9
cbuijs/ipasn,None,"ipasn
IP to ASN list
Note: Updated at least once every 24 hours.
",2
starsite/SwiftFM,Swift,"Originally posted Sep 18, 2018. I'll update it soon for SDK 18, Swift 5, and Xcode 10.2
SwiftFM
SwiftFM is a service class for working with the FileMaker Data API. Swift 4.2+ and Xcode 9.4+ required.

Overview
This README.md is aimed at FileMaker devs who want to integrate the v17 Data API into their iOS projects. Each function is paired with an example. Everything shown below is part of the DataAPI.swift file, in this repo.

Class Vars and Lets
A let is a constant, in Swift.
During testing it may be easier to hardcode baseURL and auth values, but best practice is to fetch that information from elsewhere and (optionally) park it in UserDefaults. Do not deploy apps with tokens or credentials visible in code.
I like to fetch my environment settings from CloudKit, in didFinishLaunching or didEnterForeground. Doing it this way also provides a remote kill-switch, if necessary.
import UIKit
 
class ViewController: UIViewController {
 
//  let baseURL = ""https://<hostName>/fmi/data/v1/databases/<databaseName>""
//  let auth    = ""xxxxxxxabcdefg1234567""  // base64 ""user:pass""

    let baseURL = UserDefaults.standard.string(forKey: ""fm-db-path"")  // better
    let auth    = UserDefaults.standard.string(forKey: ""fm-auth"")     //
  
    var token   = UserDefaults.standard.string(forKey: ""fm-token"")
    var expiry  = UserDefaults.standard.object(forKey: ""fm-token-expiry"") as? Date ?? Date(timeIntervalSince1970: 0)
    // ...
}

Active Token (function)
A simple bool check to see if there's an existing token and whether or not it's expired. The _ means we aren't using (don't care about) the token value right now, we only care that there /is/ one.
// swift bools return either 'true' or 'false'
func isActiveToken() -> Bool {
        
    if let _ = self.token, self.expiry > Date() {
        return true
    } else {
        return false
    }
}
Example
// active token?
switch isActiveToken() {  

case true:
    print(""token \(self.token) - expiry \(self.expiry)"")  
    // do stuff with self.token
 
case false:
    refreshToken(for: self.auth, completion: { newToken, newExpiry, error in
    
        guard error == ""0"" else {
            print(""refresh token sad."")  // optionally handle non-zero errors
            return
        }
        
        print(""token \(newToken) - expiry \(newExpiry)"")  
        // do stuff with newToken
    })
}    

Refresh Token (function)
Refresh an expired token. The @escaping marker allows the token, expiry, and error code types to be used later (they're permitted to ""escape"" or outlive the function). That's typical for async calls in Swift.
// returns -> (token, expiry, error code)
func refreshToken(for auth: String, completion: @escaping (String, Date, String) -> Void) {
    
    guard   let path = UserDefaults.standard.string(forKey: ""fm-db-path""),
            let baseURL = URL(string: path) else { return }
    
    let url = baseURL.appendingPathComponent(""/sessions"")
    let expiry = Date(timeIntervalSinceNow: 900)   // 15 minutes
    
    var request = URLRequest(url: url)
    request.httpMethod = ""POST""
    request.setValue(""Basic \(auth)"", forHTTPHeaderField: ""Authorization"")
    request.setValue(""application/json"", forHTTPHeaderField: ""Content-Type"")
    
    URLSession.shared.dataTask(with: request) { data, _, error in
        
        guard   let data      = data, error == nil,
                let json      = try? JSONSerialization.jsonObject(with: data) as! [String: Any],
                let response  = json[""response""] as? [String: Any],
                let messages  = json[""messages""] as? [[String: Any]],
                let code      = messages[0][""code""] as? String,
                let message   = messages[0][""message""] as? String else { return }
        
        guard let token = response[""token""] as? String else {
            print(message)  // optionally pass message to UIAlertController
            return
        }
        
        UserDefaults.standard.set(token, forKey: ""fm-token"")
        UserDefaults.standard.set(expiry, forKey: ""fm-token-expiry"")
        
        completion(token, expiry, code)
        
    }.resume()
}
Example
// refresh token
refreshToken(for: self.auth, completion: { newToken, newExpiry, error in

    guard error == ""0"" else { 
        print(""refresh token sad."")  // optionally handle non-zero errors
        return 
    }

    print(""token \(newToken) - expiry \(newExpiry)"")
    // do stuff with newToken
})

Get Records (function)
Returns an array of records with an offset of 1. This could be refactored to include an offset parameter if you'll be doing a lot of recursive calls/paginating records.
// returns -> ([records], error code)
func getRecords(token: String, layout: String, limit: Int, completion: @escaping ([[String: Any]], String) -> Void) {
    
    guard   let path = UserDefaults.standard.string(forKey: ""fm-db-path""),
            let baseURL = URL(string: path) else { return }
    
    let url = baseURL.appendingPathComponent(""/layouts/\(layout)/records?_offset=1&_limit=\(limit)"")
    
    var request = URLRequest(url: url)
    request.httpMethod = ""GET""
    request.addValue(""Bearer \(token)"", forHTTPHeaderField: ""Authorization"")
    request.addValue(""application/json"", forHTTPHeaderField: ""Content-Type"")
    
    URLSession.shared.dataTask(with: request) { data, _, error in
        
        guard   let data      = data, error == nil,
                let json      = try? JSONSerialization.jsonObject(with: data) as! [String: Any],
                let response  = json[""response""] as? [String: Any],
                let messages  = json[""messages""] as? [[String: Any]],
                let code      = messages[0][""code""] as? String,
                let message   = messages[0][""message""] as? String else { return }
        
        guard let records = response[""data""] as? [[String: Any]] else {
            print(message)  // optionally pass message to UIAlertController
            return
        }
        
        completion(records, code)
        
    }.resume()
}
Example
// get first 20 records
getRecords(token: self.token, layout: myLayout, limit: 20, completion: { records, error in

    guard error == ""0"" else { 
        print(""get records sad."")  // optionally handle non-zero errors
        return 
    }
    
    // array!
    for record in records {
        // deserialize with Codable, append object array, refresh UI
    }
}

Find Request (function)
Note the difference in payload between an ""or"" request vs. an ""and"" request. You can set your payload from the UI, or hardcode a query (like this). Then pass your payload as a parameter.
// returns -> ([records], error code)
func findRequest(token: String, layout: String, payload: [String: Any], completion: @escaping ([[String: Any]], String) -> Void) {
    
    //  myPayload = [""query"": [           myPayload = [""query"": [
    //      [""firstName"": ""Brian""],           [""firstName"": ""Brian"",
    //      [""firstName"": ""Geoff""]            ""lastName"": ""Hamm""]
    //  ]]                                ]]
    
    guard   let path = UserDefaults.standard.string(forKey: ""fm-db-path""),
            let baseURL = URL(string: path),
            let body = try? JSONSerialization.data(withJSONObject: myPayload) else { return }
    
    let url = baseURL.appendingPathComponent(""/layouts/\(layout)/_find"")
    
    var request = URLRequest(url: url)
    request.httpMethod = ""POST""
    request.addValue(""Bearer \(token)"", forHTTPHeaderField: ""Authorization"")
    request.addValue(""application/json"", forHTTPHeaderField: ""Content-Type"")
    request.httpBody = body
    
    URLSession.shared.dataTask(with: request) { data, _, error in
        
        guard   let data      = data, error == nil,
                let json      = try? JSONSerialization.jsonObject(with: data) as! [String: Any],
                let response  = json[""response""] as? [String: Any],
                let messages  = json[""messages""] as? [[String: Any]],
                let code      = messages[0][""code""] as? String,
                let message   = messages[0][""message""] as? String else { return }
        
        guard let records = response[""data""] as? [[String: Any]] else {
            print(message)  // optionally pass message to UIAlertController
            return
        }
        
        completion(records, code)
        
    }.resume()
}
Example
// find request
findRequest(token: self.token, layout: myLayout, payload: myPayload, completion: { records, error in

    guard error == ""0"" else { 
        print(""find request sad."")  // optionally handle non-zero errors
        return 
    }
    
    // array!
    for record in records {
        // deserialize with Codable, append object array, refresh UI
    }
}

Get Record (function)
Fetch a record with recID.
// returns -> (record, error code)
func getRecordWith(id: Int, token: String, layout: String, completion: @escaping ([String: Any], String) -> Void) {
    
    guard   let path = UserDefaults.standard.string(forKey: ""fm-db-path""),
            let baseURL = URL(string: path) else { return }
    
    let url = baseURL.appendingPathComponent(""/layouts/\(layout)/records/\(id)"")
    
    var request = URLRequest(url: url)
    request.httpMethod = ""GET""
    request.addValue(""Bearer \(token)"", forHTTPHeaderField: ""Authorization"")
    request.addValue(""application/json"", forHTTPHeaderField: ""Content-Type"")
    
    URLSession.shared.dataTask(with: request) { data, _, error in
        
        guard   let data      = data, error == nil,
                let json      = try? JSONSerialization.jsonObject(with: data) as! [String: Any],
                let response  = json[""response""] as? [String: Any],
                let messages  = json[""messages""] as? [[String: Any]],
                let code      = messages[0][""code""] as? String,
                let message   = messages[0][""message""] as? String else { return }
        
        guard let records = response[""data""] as? [[String: Any]] else {
            print(message)  // optionally pass message to UIAlertController
            return
        }
        
        completion(records[0], code)
        
    }.resume()
}
Example
// get record
getRecordWith(id: recID, token: self.token, layout: myLayout, completion: { record, error in

    guard error == ""0"" else { 
        print(""get record sad."")  // optionally handle non-zero errors
        return 
    }
    
    // record!
    // deserialize with Codable, refresh UI
}

Delete Record (function)
Delete record with recID. Only an error code is returned with this function.
// returns -> (error code)
func deleteRecordWith(id: Int, token: String, layout: String, completion: @escaping (String) -> Void) {
    
    guard   let path = UserDefaults.standard.string(forKey: ""fm-db-path""),
            let baseURL = URL(string: path) else { return }
    
    let url = baseURL.appendingPathComponent(""/layouts/\(layout)/records/\(id)"")
    
    var request = URLRequest(url: url)
    request.httpMethod = ""DELETE""
    request.addValue(""Bearer \(token)"", forHTTPHeaderField: ""Authorization"")
    request.addValue(""application/json"", forHTTPHeaderField: ""Content-Type"")
    
    URLSession.shared.dataTask(with: request) { data, _, error in
        
        guard   let data      = data, error == nil,
                let json      = try? JSONSerialization.jsonObject(with: data) as! [String: Any],
                let messages  = json[""messages""] as? [[String: Any]],
                let code      = messages[0][""code""] as? String else { return }
                        
        completion(code)
        
    }.resume()
}
Example
// delete record
deleteRecordWith(id: recID, token: self.token, layout: myLayout, completion: { error in
    
    guard error == ""0"" else { 
        print(""delete record sad."")  // optionally handle non-zero errors
        return 
    }
    
    // deleted!
    // remove object from local array, refresh UI
}

Edit Record (function)
Edit record with recID. Only pass values for the fields you want to modify. Optionally, you may include the modID from your last fetch, to ensure the server record isn't newer than the one you're editing. Passing an outdated modID will cause an edit request to fail. /Not/ including a modID will post the request.
Only an error code is returned with this function. The v17 Data API does not currently pass back a modified record object for you to use. Because of this, you may wish to refetch the record and update the view.
// returns -> (error code)
func editRecordWith(id: Int, token: String, layout: String, payload: [String: Any], modID: Int?, completion: @escaping (String) -> Void) {
    
    //  myPayload = [""fieldData"": [
    //      ""firstName"": ""newValue"",
    //      ""lastName"": ""newValue""
    //  ]]
    
    guard   let path = UserDefaults.standard.string(forKey: ""fm-db-path""),
            let baseURL = URL(string: path),
            let body = try? JSONSerialization.data(withJSONObject: myPayload) else { return }
    
    let url = baseURL.appendingPathComponent(""/layouts/\(layout)/records/\(id)"")
    
    var request = URLRequest(url: url)
    request.httpMethod = ""PATCH""
    request.addValue(""Bearer \(token)"", forHTTPHeaderField: ""Authorization"")
    request.addValue(""application/json"", forHTTPHeaderField: ""Content-Type"")
    request.httpBody = body
    
    URLSession.shared.dataTask(with: request) { data, _, error in
        
        guard   let data      = data, error == nil,
                let json      = try? JSONSerialization.jsonObject(with: data) as! [String: Any],
                let messages  = json[""messages""] as? [[String: Any]],
                let code      = messages[0][""code""] as? String else { return }
                                
        completion(code)
        
    }.resume()
}
Example
// edit record
editRecordWith(id: recID, token: self.token, layout: myLayout, playload: myPayload, completion: { error in

    guard error == ""0"" else {
        print(""edit record sad."")  // optionally handle non-zero errors
        return
    }
    
    // edited!
    // refetch record using recID, referesh UI
}

",14
Twinklebear/rtobj,C++,"rtobj
An example of OBJ rendering with OSPRay, Embree and OptiX.
Uses tinyobjloader to load OBJ files.
Ray Tracing Backends
The currently implemented backends are: OSPRay, Embree and OptiX.
When running the program, you can pick which backend you want from
those you compiled with by specifying it as the first argument on
the command line:
./rtobj <backend> <mesh.obj>

All three ray tracing backends use SDL2 for window management
and GLM for math.
If CMake doesn't find your SDL2 install you can point it to the root
of your SDL2 directory by passing -DSDL2=<path>.
Similarly for GLM, you can point it to the glmConfig.cmake file
in your GLM distribution by passing -Dglm_DIR=<path>.
OSPRay
Dependencies: OSPRay.
To build the OSPRay backend run CMake with:
cmake .. -DENABLE_OSPRAY=ON -Dospray_DIR=<path to osprayConfig.cmake>

You can then pass -ospray to use the OSPRay backend.
Embree
Dependencies: Embree,
TBB and ISPC.
To build the Embree backend run CMake with:
cmake .. -DENABLE_EMBREE=ON -Dembree_DIR=<path to embree-config.cmake> \
    -DTBB_DIR=<path TBBConfig.cmake>

You can then pass -embree to use the Embree backend. The TBBConfig.cmake will
be under <tbb root>/cmake, while embree-config.cmake is in the root of the
Embree directory.
OptiX
Dependencies: OptiX 6, CUDA 10.
To build the OptiX backend run CMake with:
cmake .. -DENABLE_OPTIX=ON

You can then pass -optix to use the OptiX backend.
If CMake doesn't find your install of OptiX you can tell it where
it's installed with -DOptiX_INSTALL_DIR.
DirectX Ray Tracing
If you're on Windows 10 1809, have the 10.0.17763 SDK and a DXR capable GPU you can also run
the DirectX Ray Tracing backend.
To build the DXR backend run CMake with:
cmake .. -DENABLE_DXR=ON

You can then pass -dxr to use the DXR backend.
",4
mamedev/mame,C++,"MAME

Build status for tiny build only, containing just core parts of project:



OS/Compiler
Status




Linux GCC / OSX Clang



Windows MinGW



Windows MSVC




Static analysis status for entire build (except for third-party parts of project):

What is MAME?
MAME is a multi-purpose emulation framework.
MAME's purpose is to preserve decades of software history. As electronic technology continues to rush forward, MAME prevents this important ""vintage"" software from being lost and forgotten. This is achieved by documenting the hardware and how it functions. The source code to MAME serves as this documentation. The fact that the software is usable serves primarily to validate the accuracy of the documentation (how else can you prove that you have recreated the hardware faithfully?). Over time, MAME (originally stood for Multiple Arcade Machine Emulator) absorbed the sister-project MESS (Multi Emulator Super System), so MAME now documents a wide variety of (mostly vintage) computers, video game consoles and calculators, in addition to the arcade video games that were its initial focus.
How to compile?
If you're on a *NIX or OSX system, it could be as easy as typing
make

for a MAME build,
make SUBTARGET=arcade

for an arcade-only build, or
make SUBTARGET=mess

for MESS build.
See the Compiling MAME page on our documentation site for more information, including prerequisites for Mac OS X and popular Linux distributions.
For recent versions of OSX you need to install Xcode including command-line tools and SDL 2.0.
For Windows users, we provide a ready-made build environment based on MinGW-w64.
Visual Studio builds are also possible, but you still need build environment based on MinGW-w64.
In order to generate solution and project files just run:
make vs2017

or use this command to build it directly using msbuild
make vs2017 MSBUILD=1

Where can I find out more?

Official MAME Development Team Site (includes binary downloads for MAME and MESS, wiki, forums, and more)
Official MESS Wiki
MAME Testers (official bug tracker for MAME and MESS)

Contributing
Coding standard
MAME source code should be viewed and edited with your editor set to use four spaces per tab. Tabs are used for initial indentation of lines, with one tab used per indentation level. Spaces are used for other alignment within a line.
Some parts of the code follow Allman style; some parts of the code follow K&R style -- mostly depending on who wrote the original version. Above all else, be consistent with what you modify, and keep whitespace changes to a minimum when modifying existing source. For new code, the majority tends to prefer Allman style, so if you don't care much, use that.
All contributors need to either add a standard header for license info (on new files) or inform us of their wishes regarding which of the following licenses they would like their code to be made available under: the BSD-3-Clause license, the LGPL-2.1, or the GPL-2.0.
License
The MAME project as a whole is distributed under the terms of the GNU General Public License, version 2 or later (GPL-2.0+), since it contains code made available under multiple GPL-compatible licenses. A great majority of files (over 90% including core files) are under the BSD-3-Clause License and we would encourage new contributors to distribute files under this license.
Please note that MAME is a registered trademark of Gregory Ember, and permission is required to use the ""MAME"" name, logo, or wordmark.



Copyright (C) 1997-2019  MAMEDev and contributors

This program is free software; you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation; either version 2 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License along
with this program; if not, write to the Free Software Foundation, Inc.,
51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.

Please see LICENSE.md for further details.
",3724
inductor/hugo-firebase-tools,Dockerfile,"hugo-firebase-tools
",3
stephengold/Minie,Java,"
The Minie Project is about improving the integration of
Bullet Real-Time Physics into the
jMonkeyEngine Game Engine.
It contains 3 sub-projects:

MinieLibrary: the Minie runtime library (in Java)
MinieExamples: demos, examples, and test software (in Java)
DacWizard: a GUI application to configure a ragdoll (in Java)

Java source code is provided under
a FreeBSD license.
Contents of this document

Why use Minie?
Downloads
Conventions
History
How to install the SDK and the Minie Project
How to add Minie to an existing project
Choosing a collision shape
An introduction to DynamicAnimControl
External links
Acknowledgments


Why use Minie?
jMonkeyEngine comes with 2 Bullet integration libraries.
Why use Minie instead of jme3-bullet or jme3-jbullet?

Minie has many more features. (See the feature list below.)
Minie fixes many bugs found in the jMonkeyEngine libraries.
(See the fix list below.)
Due to its shorter release cycle, future features and bug fixes
will probably appear first in Minie.
Minie has automated tests that reduce the risk of regressions and new bugs.
Minie's classes are better encapsulated, with fewer public/protected fields
and less aliasing of small objects like vectors.  This reduces the risk
of accidentally corrupting its internal data structures.
Minie validates method arguments.  This helps detect usage errors that
can lead to subtle bugs.
Minie's source code is more readable and better documented.

Summary of added features:

DynamicAnimControl for ragdoll simulation:

set dynamic/kinematic mode per bone
understands attachments
highly configurable, with many options for bone mass, center, and shape
apply inverse-kinematic controllers and joints


MultiSphere collision shapes based on btMultiSphereShape
EmptyShape collision shapes based on btEmptyShape
debugging aids:

dump the contents of a BulletAppState or PhysicsSpace
customize debug material per collision object
visualize the local axes, bounding box, and/or CCD swept sphere
of collision objects
visualize physics in multiple viewports
optional high-resolution debug meshes for convex shapes
options to generate debug meshes that include normals (for shading)


all joints, shapes, and collision objects implement the JmeCloneable
and Comparable interfaces
enable/disable a joint
single-ended joints
settable global default for collision margin
access more parameters of rigid bodies:

anisotropic friction
contact damping
contact stiffness
contact-processing threshold
deactivation time
linear factor
rolling friction
spinning friction


option to apply scaling with a RigidBodyControl

Some JME bugs that have been fixed in Minie:

772 scale of a physics shape is applied 2x
877 physics joints don't work unless both bodies are dynamic
883 extra physicsTick() callbacks
887 debug mesh ignores scaling of CollisionShape
889 disabled physics control gets added to a physics space
894 setRestitutionOrthoLin() sets wrong joint parameter
901 collision margin initialized to 0
911 sleeping-threshold setters have unexpected side effects
913 missing implementation of PhysicsJoint.finalizeNative()
917 HingeJoint.read() fails
918 getImpulseClamp() returns the wrong value
919 UnsatisfiedLinkError in getLimitSoftness()
928 crash caused by too many parallel threads
969 linear factors not cloned
1029 sphere-sphere collisions not reported
1037 performance issue with HullCollisionShape
1058 crash while removing body from BroadphaseType.SIMPLE PhysicsSpace
1060 doesn't implement bt32BitAxisSweep3

Some jme3-bullet/jme3-jbullet classes that Minie omits:

CharacterControl: use MinieCharacterControl or BetterCharacterControl
instead, or else use PhysicsCharacter directly
KinematicRagdollControl, HumanoidRagdollPreset, and RagdollPreset:
use DynamicAnimControl instead
RagdollUtils: not needed

Other important differences:

The default collision margin increased from 0 to 0.04 .
RagdollCollisionListener interface changed and moved
from the com.jme3.bullet.collision package
to the com.jme3.bullet.animation package.


Downloads
Newer releases (since v0.5.0) can be downloaded from
GitHub.
Older releases (v0.1.1 through v0.4.5) can be downloaded from
the Jme3-utilities Project.
Maven artifacts are available from
JFrog Bintray.

Conventions
Package names begin with
jme3utilities.minie. (if Stephen Gold holds the copyright) or
com.jme3. (if the jMonkeyEngine Project holds the copyright).
The source code is compatible with JDK 7.

History
Most of Minie was originally forked from jme3-bullet,
a library in the jMonkeyEngine Game Engine.
From January 2018 to November 2018, Minie was a sub-project of
the Jme3-utilities Project.
Since November 2018, the Minie Project has been an independent project at
GitHub.
The evolution of Minie is chronicled in
its release notes.

How to install the SDK and the Minie Project
jMonkeyEngine3 (jME3) Software Development Kit (SDK)
Minie currently targets Version 3.2.3 of jMonkeyEngine.
You are welcome to use the Engine without also using the SDK, but I use the SDK,
and the following installation instructions assume you will too.
The hardware and software requirements of the SDK are documented on
the JME wiki.

Download a jMonkeyEngine 3.2 SDK from
GitHub.
Install the SDK, which includes:

the engine itself,
an integrated development environment (IDE) based on NetBeans,
various plugins, and
the Blender 3D application.


To open the Minie project in the IDE (or NetBeans), you will need the
Gradle Support plugin.  Download and install it before proceeding.
If this plugin isn't shown in the IDE's ""Plugins"" tool,
you can download it from
GitHub.
You don't need this plugin if you merely want to use a pre-built Minie
release in an Ant project.

Source files
Clone the Minie repository using Git:

Open the ""Clone Repository"" wizard in the IDE:

Menu bar -> ""Team"" -> ""Git"" -> ""Clone..."" or
Menu bar -> ""Team"" -> ""Remote"" -> ""Clone...""


For ""Repository URL:"" specify
https://github.com/stephengold/Minie.git
Clear the ""User:"" and ""Password:"" text boxes.
For ""Clone into:"" specify a writable folder (on a local filesystem)
that doesn't already contain ""Minie"".
Click on the ""Next >"" button.
Make sure the ""master"" remote branch is checked.
Click on the ""Next >"" button again.
Make sure the Checkout Branch is set to ""master"".
Make sure the ""Scan for NetBeans Projects after Clone"" box is checked.
Click on the ""Finish"" button.
When the ""Clone Completed"" dialog appears, click on the ""Open Project...""
button.
Expand the root project node to reveal the sub-projects.
Select both sub-projects using control-click, then click on the
""Open"" button.

Build the project

In the ""Projects"" window of the IDE,
right-click on the ""MinieExamples"" sub-project to select it.
Select ""Build"".


How to add Minie to an existing project
Adding Minie to an existing JME3 project should be a simple 6-step process:

Remove any existing physics libraries which might interfere with Minie.
Add libraries to the classpath.
Create, configure, and attach a BulletAppState,
if the application doesn't already do so.
Configure the PhysicsSpace,
if the application doesn't already do so.
Create physics controls, collision objects, and joints
and add them to the PhysicsSpace,
if the application doesn't already do so.
Test and tune as necessary.

Remove any existing physics libraries
Minie replaces (and is therefore incompatible with) the following
jMonkeyEngine libraries:

jme3-bullet
jme3-bullet-native
jme3-jbullet

Before adding Minie, you should remove these libraries from your project so
they won't interfere with Minie.
For Gradle projects
Look for artifacts with these names in the dependencies section
of your project's gradle.build file and remove them.
For Ant projects
Open the project's properties in the IDE (JME 3.2 SDK or NetBeans 8.2):

Right-click on the project (not its assets) in the ""Projects"" window.
Select ""Properties to open the ""Project Properties"" dialog.
Under ""Categories:"" select ""Libraries"".
Click on the ""Compile"" tab.
Look for libraries with these names in the ""Compile-time Libraries""
listbox.  Select them and click on the ""Remove"" button.
Click on the ""OK"" button to exit the ""Project Properties"" dialog.

Add libraries to the classpath
Minie comes pre-built as a single library that includes both Java classes
and native libraries.  The Minie library depends on the
jme3-utilities-heart library, which in turn depends on
the standard jme3-core library from jMonkeyEngine.
For Gradle projects
For projects built using Maven or Gradle, it is sufficient to specify the
dependency on the Minie library.  The build tools should automatically
resolve the remaining dependencies automatically.
Because Minie is not on JCenter yet, you must explicitly specify the
repository location:
repositories {
    maven { url 'https://dl.bintray.com/stephengold/jme3utilities' }
    jcenter()
}
dependencies {
    compile 'jme3utilities:Minie:0.8.1'
}

For Ant projects
For projects built using Ant, download the 2 non-standard
libraries from GitHub:

https://github.com/stephengold/Minie/releases/tag/0.8.1
https://github.com/stephengold/jme3-utilities/releases/tag/heart-2.26.0

You'll want both class JARs
and probably the -sources and -javadoc JARs as well.
Open the project's properties in the IDE (JME 3.2 SDK or NetBeans 8.2):

Right-click on the project (not its assets) in the ""Projects"" window.
Select ""Properties to open the ""Project Properties"" dialog.
Under ""Categories:"" select ""Libraries"".
Click on the ""Compile"" tab.
Add the jme3-utilities-heart class JAR:

Click on the ""Add JAR/Folder"" button.
Navigate to the ""jme3-utilities"" project folder.
Open the ""heart"" sub-project folder.
Navigate to the ""build/libs"" folder.
Select the ""jme3-utilities-heart-2.26.0.jar"" file.
Click on the ""Open"" button.


(optional) Add JARs for javadoc and sources:

Click on the ""Edit"" button.
Click on the ""Browse..."" button to the right of ""Javadoc:""
Select the ""jme3-utilities-heart-2.26.0-javadoc.jar"" file.
Click on the ""Open"" button.
Click on the ""Browse..."" button to the right of ""Sources:""
Select the ""jme3-utilities-heart-2.26.0-sources.jar"" file.
Click on the ""Open"" button again.
Click on the ""OK"" button to close the ""Edit Jar Reference"" dialog.


Similarly, add the Minie JAR(s).
Click on the ""OK"" button to exit the ""Project Properties"" dialog.

Create, configure, and attach a BulletAppState
Strictly speaking, a BulletAppState isn't required for Minie, but
it does provide a convenient interface for configuring, accessing, and
debugging a PhysicsSpace.
If your application already has a BulletAppState, the code will probably
work fine with Minie.  If not, here is a snippet to guide you:
    BulletAppState bulletAppState = new BulletAppState();
    bulletAppState.setDebugEnabled(true); // default=false
    stateManager.attach(bulletAppState);

Configure the PhysicsSpace
Section to be written.
Create physics controls, collision objects, and joints
Section to be written.
Test and tune
Section to be written.

Choosing a collision shape
Minie provides more than a dozen CollisionShape subclasses.
Because jMonkeyEngine models are composed of triangular meshes,
beginners are often tempted to use mesh-based shapes
(such as GImpactCollisionShape) for everything.
However, since mesh-based collision detection is CPU-intensive, primitive
convex shapes (such as boxes and spheres) are usually a better choice, even
if they don't match the model's shape exactly.
In particular, CapsuleCollisionShape is often used with humanoid models.
if (the object isn't involved in collisions) {
    use an EmptyShape
} else if (its shape can be approximated by an infinite plane) {
    use a PlaneCollisionShape
} else if (its shape can be approximated by a triangle or a tetrahedron) {
    use a SimplexCollisionShape
} else if (its shape can be approximated by a centered sphere) {
    use a SphereCollisionShape
} else if (its shape can be approximated by a centered rectangular solid) {
    use a BoxCollisionShape
} else if (its shape can be approximated by a centered capsule) {
    use a CapsuleCollisionShape
} else if (its shape can be approximated by a centered cylinder) {
    use a CylinderCollisionShape
} else if (its shape can be approximated by a centered cone) {
    use a ConeCollisionShape
} else if (its shape can be approximated by an ellipsoid
            or an eccentric sphere
            or an eccentric capsule
            or the convex hull of multiple spheres) {
    use a MultiSphere
} else if (its shape can be approximated by an eccentric rectangular solid
            or an eccentric cylinder
            or an eccentric cone
            or a combination of convex primitives) {
        use a CompoundCollisionShape
} else if (the object does not move) {
    if (it is a 2-D heightfield) {
        use a HeightfieldCollisionShape
    } else {
        use a MeshCollisionShape
    }
} else { // if the object moves
    if (its shape can be approximated by the convex hull of a mesh) {
        use a HullCollisionShape
    } else {
        use a GImpactCollisionShape
    }
}

(Pseudocode adapted from the flowchart on page 13 of the Bullet User Manual.)

An Introduction to DynamicAnimControl
The centerpiece of Minie is DynamicAnimControl, a new PhysicsControl.
Adding a DynamicAnimControl to an animated model provides ragdoll physics and
inverse kinematics.
Configuration of DynamicAnimControl mostly takes place before the Control
is added to a model Spatial.  Adding the Control to a Spatial
automatically creates the ragdoll, including rigid bodies and joints.
No ragdoll exists before the Control is added to a Spatial,
and removing a Control from its controlled Spatial destroys the ragdoll.
The controlled Spatial must include the model's SkeletonControl.
Usually this is the model's root Spatial, but not always.
For a very simple example, see
HelloDac.java.
A model's ragdoll is composed of rigid bodies joined by 6-DOF joints.
Within the Control, each PhysicsRigidBody is represented by
a PhysicsLink, and the links are organized into a tree hierarchy.
PhysicsLink has 3 subclasses:

BoneLink: manages one or more bones in the modelâs Skeleton.
Each BoneLink has a parent link, to which it is jointed.
Its parent may be another BoneLink or it may be a TorsoLink.
TorsoLink: is always the root of a link hierarchy,
so it has no parent link.
It manages all root bones in the model's Skeleton.  It also manages any
Skeleton bones that aren't managed by a BoneLink.
AttachmentLink: manages a non-animated model that's
attached to the main model by means of an attachment Node.
An AttachmentLink cannot be the parent of a link.

The default constructor for DynamicAnimControl is configured to create a
ragdoll with no bone links, only a TorsoLink.
Before adding the Control to a Spatial, specify which Skeleton bones
should be linked, by invoking the link() method for each of those bones.
I recommend starting with a default LinkConfig and a generous range of motion
for each linked bone:
dynamicAnimControl.link(boneName, new LinkConfig(), new RangeOfMotion(1f, 1f, 1f));

For a simple example, see
HelloBoneLink.java.
Alternatively, you can generate configuration code for a specific model using
the DacWizard application, which uses animation data to estimate
the range of motion for each linked bone.
You probably don't want to link every Bone in the model's Skeleton.
For instance, if the model has articulated fingers, you probably want to link
the hand bones but not the individual finger bones.
Unlinked bones will be managed by the nearest linked ancestor Bone.
The TorsoLink will manage any bones for which no ancestor Bone is linked.
If you link too many bones, the ragdoll may become inflexible or jittery
due to collisions between rigid bodies that don't share a PhysicsJoint.

External links

The Bullet Physics SDK Manual
The Physics section of the JME Wiki

YouTube videos about Minie:

April 2019 walkthru of the DacWizard application
watch (8:12)
source code
March 2019 short demo (IK for head/eye directions)
watch (1:25)
source code
March 2019 teaser (simulating buoyancy)
watch (0:10)
source code
February 2019 demo (simulating rope)
watch (4:47)
source code
December 2018 demo (inverse kinematics)
watch (6:27)
source code
December 2018 teaser (inverse kinematics)
watch (0:51)
November 2018 demo (single-ended joints):
watch (5:50)
source code
November 2018 demo (MultiSphere shape):
watch (0:13)
source code
October 2018 demo (DynamicAnimControl ragdolls):
watch (2:49)
source code


Acknowledgments
Like most projects, the Minie Project builds on the work of many who
have gone before.  I therefore acknowledge the following
artists and software developers:

Normen Hansen (aka ""normen"") for creating most of the jme3-bullet library
(on which Minie is based) and also for helpful insights
RÃ©my Bouquet (aka ""nehon"") for co-creating
KinematicRagdollControl (on which DynamicAnimControl is based)
and also for many helpful insights
Jules (aka ""dokthar"") for creating the soft-body fork of jMonkeyEngine
from which Minie's soft-body support is derived
Paul Speed, for helpful insights
""oxplay2"", for reporting a PhysicsRigidBody bug and helping me pin it down.
Nathan Vegdahl, for creating the Puppet model (used in
the TestDac walkthru video)
plus the creators of (and contributors to) the following software:

the Blender 3-D animation suite
the Bullet real-time physics library
the FindBugs source-code analyzer
the Git revision-control system and GitK commit viewer
the Google Chrome web browser
the Gradle build tool
the Java compiler, standard doclet, and runtime environment
jMonkeyEngine and the jME3 Software Development Kit
the Linux Mint operating system
LWJGL, the Lightweight Java Game Library
the MakeHuman Community
the Markdown document conversion tool
Microsoft Windows
the NetBeans integrated development environment
the Nifty graphical user interface library
Open Broadcaster Software Studio
the PMD source-code analyzer
the WinMerge differencing and merging tool



I am grateful to JFrog and Github for providing free hosting for the
Minie Project and many other open-source projects.
I'm also grateful to my dear Holly, for keeping me sane.
If I've misattributed anything or left anyone out, please let me know so I can
correct the situation: sgold@sonic.net
",12
fzxiao233/Auto_Record_Matsuri,Python,"Auto_Record_Matsuri 
æ­¤ç¨åºè½å¤èªå¨çæ§å¤å¦¹ç´æ­å¹¶ä¸è½½å½åçç´æ­è§é¢ï¼å¶å®ä½ ä¹å¯ä»¥ä¿®æ¹å¶ä¸­çé¢éç¼å·æ¥çæ§å¶ä»VTB[è­DD]
ç®åæå·²ç»å¨VPSä¸é¨ç½²äºï¼ä½ å¯ä»¥éè¿è®¿é®http://matsuri.fzxiao.tw è·åå½æ­
ç¹æ§

ä½¿ç¨å¤è¿ç¨æ¨¡åï¼åæ¶çæ§å¤ä¸ªVtuberå ç¨è¾ä½ï¼DDï¼

åè½

èªå¨çæ§Youtube|Openrec|Mirrativ|Twitcastingå¹³å°çç´æ­
èªå¨çæ§Bilibiliçèæ´æ°
èªå¨åéç´æ­éç¥è³QQç¾¤ï¼å»¶è¿æä½ï¼å¨æ£æµæ¶é´è®¾ç½®ä¸º15sæ¶ï¼
èªå¨å³æ¶ææµä¸è½½ç´æ­è§é¢ï¼ä»æ­¤æç»è¦è¦åæ±å½æ­manï¼
èªå¨å°ä¸è½½çè§é¢ä¸ä¼ å¹¶è®¾ç½®åäº«å°ç¾åº¦äº
é¡ºå¸¦ç»´æ¤äºä¸ä¸ªç½é¡µç¨æ¥åå¸ç´æ­å­æ¡£

ä½¿ç¨


è¯·å¡å¿å¨å¯å¨åç¼è¾config.pyæä»¶


é¦æ¬¡å¯å¨ææ´æ°æ¶
  $ pip3 install -r requirements.txt



æ§è¡ç¨åº
  $ python run.py



ä½¿ç¨æºå¨äººéè¦ä¸è½½é·Q Air å¹¶å®è£ HTTP API


ä½¿ç¨èªå¨ä¸ä¼ åäº«éè¦æå¨å¨BaiduPCS-Goæä»¶å¤¹ä¸­æ¾å¥æä»¶ï¼å¹¶ç»å½


æ¯æ

æé®é¢æèæ°åè½è¯·æ±è¯·åIssues

",11
hongjw1991/Java-DataStructure-Algorithm-DesignPattern,Java,"Java Data Structure

í´ë¹ Repositoryë ìë£êµ¬ì¡° ë° ìê³ ë¦¬ì¦ Study ë° ë¬¸ì  íì´ë¥¼ ì¢í©íì¬ ì ë¦¬í Repository ìëë¤.
DataStructure

Java ê¸°ë° Data Structure ê³µë¶ ë´ì©ì ì ë¦¬í Directory ìëë¤.


Algorithm

ê¸°ë³¸ Algorithm ê³µë¶í ë´ì©ì ì ë¦¬í Directory ìëë¤.


DesignPattern

ê¸°ë³¸ DesignPattern ê³µë¶í ë´ì©ì ì ë¦¬í Directory ìëë¤.


JDK 1.8 ì¤ì¹

Linux(Ubuntu)

ì°¸ì¡°


Ubuntu update ë° íìì íì í¨í¤ì§ ì¤ì¹

sudo apt-get update && sudo apt-get upgrate
sudo apt-get install software-properties-common


Java repository ì¶ê°

sudo add-apt-repository ppa:webupd8team/java
sudo apt-get update


Java ì¤ì¹

sudo apt-get install oracle-java8-installer




Windows

ì¬ê¸°ì ì¤ì¹




IDE ì¤ì¹

ì¬ê¸°ì ì¤ì¹
IntelliJë¥¼ ë¤ì´ë¡ë ë°ê³  ì¤ì¹.
Community versionì ë¬´ë£, Ultimateë 30ì¼ ë¬´ë£ trial ê°ë¥
ì¤ì¹ ì, Windowsë¼ë©´, 32/64 ì í í, extensionì ëª¨ë checkíë ê²ì ê¶ì¥
ì´ì  versionìì ì¤ì¹í ì´ë ¥ì´ ìë ê²½ì° importíê³  ìë ê²½ì° ë¹ ìíë¡ ìì
Templateì ê³ ë¥´ê³ , Default setting ë° pluginì íì ì ì¤ì¹ í next
JDK ê²½ë¡ ì¤ì 









",3
rrwick/Long-read-assembler-comparison,HTML,"Benchmarking of long-read assembly tools for bacterial whole genomes
Ryan R. Wick1 and Kathryn E. Holt1,2

1. Department of Infectious Diseases, Central Clinical School, Monash University, Melbourne, Victoria 3004, Australia2. London School of Hygiene & Tropical Medicine, London WC1E 7HT, UK

This repo contains early results for our benchmarking of long-read assemblers for bacterial genomes. It is still a work in progress, and we'll be putting together a manuscript in the future. But until then, we decided to show our results here on GitHub for the eager and/or curious!
Still interested? Read on! Or if you're feeling impatient, skip to the results or conclusions.
Table of contents

Introduction
Methods

Assemblers and commands
Simulated read sets
Real read sets
Assessing chromosome contiguity
Assessing plasmid assembly


Results and discussion

Robustness
Reliability
Sequence identity
Speed performance
Plasmids


Conclusions
References
License

Introduction
We had two primary aims for this study:

To explore how different features of a read set affect assemblers. I.e. what does and does not matter about your reads for the purposes of assembly?
To compare the performance of long-read assemblers for bacterial genomes and make recommendations for users.

We investigated aim 1 using simulated read sets from Badread, which gives a lot of control over many read parameters. For aim 2, we used both simulated read sets (again from Badread) and real read sets (both ONT and PacBio).
We approached this study with the following attitude: long read assembly of a bacterial genome should be a solved problem, at least from a large-scale structural perspective. A successful long-read assembly is complete (one contig per replicon) and without any structural errors â anything else counts as a failure. However, small-scale errors (substitutions and indels) are currently inevitable in long-read assemblies, i.e. consensus sequence accuracy is less than 100%. While consensus accuracy is interesting and does briefly feature in our results, it wasn't a major focus for this study. That's because long-read assemblies should probably be polished with a platform-specific tool like Arrow or Nanopolish anyway. Since sequence identity is something that can (and should) be fixed up in a separate post-assembly step, an assembler's consensus error rate doesn't matter too much.
Finally, I should also point out some things that this study does not do:

It doesn't address where Illumina reads fit into the picture. E.g. is it better to do a hybrid assembly with a tool like Unicycler or to do a long-read-only assembly and then polish with a tool like Pilon? This is a great question which deserves attention, but here we studied assembly of long reads only.
It doesn't investigate how assemblers perform on viruses, eukaryotes, metagenomes or anything else that isn't a bacterial genome.

Methods
Assemblers and commands
We tested the current version (as of the time of writing) of five different assemblers: Canu, Flye, Ra, Unicycler and Wtdbg2.
Assemblers that only work on PacBio reads (i.e. not on Oxford Nanopore reads) were excluded, such as HGAP, FALCON and HINGE. We also excluded SMARTdenovo as it seems to have been superseded by Wtdbg2 (same author).
We ran each assembler with its default options or by following the recommended usage in its documentation. I.e. we didn't explore the effect of assembler options/parameters on assemblies (with the exception of a couple options for Flye, see below).
Canu
Canu v1.8 is run with a single command which needs a genome size estimate. We also used some options to set threads/memory and turn off parallel grid computing, and we used stopOnLowCoverage=0 to ensure that Canu continued in cases where read depth is low. It produces an output directory where the final assembly is named *.contigs.fasta.
canu -p canu -d out_dir genomeSize=3.565m stopOnLowCoverage=0 useGrid=false minThreads=4 maxThreads=4 maxMemory=31 -nanopore-raw reads.fastq.gz

For PacBio read sets we used -pacbio-raw instead of -nanopore-raw. While the Canu documentation makes a setting recommendation for plasmid recovery, this is no longer needed since Canu v1.7, so we did not change the command for the plasmid tests.
Flye
Flye v2.4.2 is run with a single command which needs a genome size estimate. It produces an output directory where the final assembly is named scaffolds.fasta.
flye --nano-raw reads.fastq.gz -g 3.565m -o out_dir -t 4

For PacBio read sets we used --pacbio-raw instead of --nano-raw. For the plasmid tests, we additionally tried Flye with its --plasmids and --meta options.
Ra
Ra 07364a1 (it doesn't have releases, so we used the latest commit) is run with a single command that does not require genome size. It delivers its assembly to stdout.
ra -x ont -t 4 reads.fastq.gz > assembly.fasta

For PacBio read sets we used -x pb instead of -x ont.
Unicycler
While Unicycler is most commonly used as a hybrid assembler, it can do long-read-only assemblies as well. It uses miniasm to conduct the assembly and multiple rounds of Racon to polish the result. Its miniasm has been slightly altered to better handle circularisation of bacterial replicons.
Unicycler v0.4.7 is run with a single command that does not require genome size. It produces an output directory where the final assembly is assembly.fasta.
unicycler -l reads.fastq.gz -o out_dir -t 4

Unicycler doesn't make a distinction between ONT and PacBio reads, so we did not change the command for PacBio read sets. And a disclosure: I am the developer of Unicycler, so may hold some biases here. But I did my best to be fair!
Wtdbg2
Wtdbg2 v2.4 separates its functionality into assembly, consensus and polishing steps, so it requires multiple commands to run, the first of which requires genome size.
wtdbg2 -x nanopore -g 3.565m -i reads.fastq.gz -t 4 -fo out
wtpoa-cns -t 4 -i out.ctg.lay.gz -fo out.ctg.fa
minimap2 -t 4 -x map-ont -a out.ctg.fa reads.fastq.gz | samtools sort > out.ctg.bam
samtools view out.ctg.bam | wtpoa-cns -t 4 -d out.ctg.fa -i - -fo assembly.fasta

For PacBio read sets we used -x rsII instead of -x nanopore in the wtdbg2 command and -x map-pb instead of -x map-ont in the minimap2 command.
Simulated read sets
To make all of our simulated read sets we used Badread (which was developed largely for this assembler comparison) and a Comamonas kerstersii genome as the reference. This genome was chosen because it is of medium size (3.56 Mbp), has no plasmids and is of moderate complexity. It is not particularly repeat-rich, but it does have four tandem copies of its rRNA operon, which creates a 20 kbp repeat region in the genome.
Problem sets
For seven different Badread parameters, we conducted a parameter sweep, generating a range of read sets which varied from very good (often better than a real read set) to very bad (much worse than a real read set). For each of the seven parameter sweeps, the other parameters were kept in a good state. E.g. when varying the amount of junk reads in a set, the chimeric reads were kept at 0%. These read sets served to assess the robustness of each assembler: how tolerant it is of read set problems. They are referred to as the 'problem sets'.
Adapter lengths were varied from 0 to 1000 bp. Real read sets probably have adapters lengths measured in 10s of bp, assuming they haven't been trimmed off.
for x in {0..149}; do
    adapter_len=$(printf ""%04d"" $(python3 -c ""print(int(round(""$x"" ** 1.38046)))""))
    badread simulate --reference ref.fasta --quantity 60x --junk_reads 0 --random_reads 0 --chimeras 0 --glitches 0,0,0 --start_adapter_seq ""$adapter_len"" --end_adapter_seq ""$adapter_len"" --start_adapter 100, 50 --end_adapter 100, 50 | gzip > ""$adapter_len"".fastq.gz
done

Chimera reads were varied from 0% to 25%. I expect a real read set to have less than 2% chimeric reads.
for chimeras in $(seq -f ""%06.3f"" 0.0 0.125 25.0); do
    badread simulate --reference ref.fasta --quantity 60x --junk_reads 0 --random_reads 0 --chimeras ""$chimeras"" --glitches 0,0,0 --start_adapter_seq """" --end_adapter_seq """" | gzip > ""$chimeras"".fastq.gz
done

Read glitches are controlled by three parameters. This parameter sweep varies all three together, with size and skip ranging from 0 to 100 and rate ranging from 100000 to 100.
for size_skip in $(seq -f ""%05.1f"" 0.0 0.5 100.0); do
    rate=$(printf ""%06d"" $(python3 -c ""print(int(round(100000 / (1.995276 ** (""$size_skip""/10)))))""))
    glitches=""$rate"",""$size_skip"",""$size_skip""
    badread simulate --reference ref.fasta --quantity 60x --junk_reads 0 --random_reads 0 --chimeras 0 --glitches ""$glitches"" --start_adapter_seq """" --end_adapter_seq """" | gzip > ""$glitches"".fastq.gz
done

Random read rates and junk read rates were varied together from 0% to 25%. E.g. when set to 15%, that means 15% of the reads are random reads and 15% are junk reads, so a total of 30% of reads are either random or junk. A real read set probably has no more than a few percent of random/junk reads, and possibly much less if the reads have been demultiplexed out of a barcoded run which serves to clean them up.
for random_junk in $(seq -f ""%06.3f"" 0.0 0.125 25.0); do
    badread simulate --reference ref.fasta --quantity 60x --junk_reads ""$random_junk"" --random_reads ""$random_junk"" --chimeras 0 --glitches 0,0,0 --start_adapter_seq """" --end_adapter_seq """" | gzip > ""$random_junk"".fastq.gz
done

Read depth was varied from 0.5Ã to 100Ã. Canu documentation states '30Ã and 60Ã coverage is the recommended minimum.' Flye's documentation states 'Typically, 30Ã coverage is enough to produce good draft contigs.'
for read_depth in $(seq -f ""%05.1f"" 0.0 0.5 100.0); do
    badread simulate --reference ref.fasta --quantity ""$read_depth""x --junk_reads 0 --random_reads 0 --chimeras 0 --glitches 0,0,0 --start_adapter_seq """" --end_adapter_seq """" | gzip > ""$read_depth"".fastq.gz
done

Read identity was varied from a mean of 60% (so low as to be nearly indistinguishable from junk) to 99.75%, always using a small standard deviation of 0.25%. Real long read sets typically have a mean identity in the mid-80s to low-90s and with a larger standard deviation.
for identity in $(seq -f ""%.2f"" 60 0.25 99.75); do
    badread simulate --reference ref.fasta --quantity 60x --identity ""$identity"",100,1 --junk_reads 0 --random_reads 0 --chimeras 0 --glitches 0,0,0 --start_adapter_seq """" --end_adapter_seq """" | gzip > ""$identity"".fastq.gz
done

Read length was varied from a mean of 250 bp to 50 kbp, always using a standard deviation of 1/10th the mean. The read length in real read sets depends on the DNA extraction and library preparation but would usually have a much larger standard deviation than I used here.
for length in $(seq -f ""%05g"" 250 250 50000); do
    badread simulate --reference ref.fasta --quantity 60x --length $length"",""$(echo $length"" / 10"" | bc) --junk_reads 0 --random_reads 0 --chimeras 0 --glitches 0,0,0 --start_adapter_seq """" --end_adapter_seq """" 2> ""varying_read_length/""$1"".log"" | gzip > ""varying_read_length/""$1"".fastq.gz""
done

Good sets
Unlike for the problem sets, these read sets all stay within the realm of assemble-ability. The Badread parameters were randomly generated for each set, so there should be a decent amount of variation between them.
We refer to these as the 'good sets' to distinguish them from the problem sets. These doesn't mean that they are all exceptionally good, but they are good enough to assemble, i.e. there's nothing terribly wrong with any of them,
I made 500 such sets using these commands:
for x in {000..499}; do

    # Randomly generate parameters:
    quantity=$(python3 -c ""import random; print(random.randint(142608240, 356520600))"")  # 40x to 100x
    length=$(python3 -c ""import random; print(random.randint(10000, 25000))"")"",""$(python3 -c ""import random; print(random.randint(5000, 20000))"")
    identity=$(python3 -c ""import random; print(random.randint(85, 90))"")"",""$(python3 -c ""import random; print(random.randint(95, 100))"")"",""$(python3 -c ""import random; print(random.randint(1, 8))"")
    chimeras=$(python3 -c ""import random; print('{:.3f}'.format(random.uniform(0.0, 2.0)))"")
    junk_reads=$(python3 -c ""import random; print('{:.3f}'.format(random.uniform(0.0, 2.0)))"")
    random_reads=$(python3 -c ""import random; print('{:.3f}'.format(random.uniform(0.0, 2.0)))"")
    glitches=$(python3 -c ""import random; print(random.randint(1000, 10000))"")"",""$(python3 -c ""import random; print(random.randint(0, 20))"")"",""$(python3 -c ""import random; print(random.randint(0, 20))"")
    start_adapter=$(python3 -c ""import random; print(random.randint(0, 30))"")
    end_adapter=$(python3 -c ""import random; print(random.randint(0, 30))"")

    # Create the read set:
    badread simulate --reference ref.fasta --quantity ""$quantity"" --length ""$length"" --identity ""$identity"" --junk_reads ""$junk_reads"" --random_reads ""$random_reads"" --chimeras ""$chimeras"" --glitches ""$glitches"" --start_adapter_seq ""$start_adapter"" --end_adapter_seq ""$end_adapter"" | gzip > ""$x"".fastq.gz
    gzip ""$x"".fastq
done

Plasmid sets
The plasmid sets are also simulated with Badread, but we used reference genomes with plasmids added in addition to the Comamonas kerstersii chromosome used in the previous tests. I took the plasmids from the curated dataset presented in Orlek 2017, which can be downloaded here.
The make_plasmid_test_references.py script created the references, adding between 1 and 9 plasmids per genome, at various depths:
for x in {000..214}; do
    make_plasmid_test_references.py chromosome.fasta nucleotideseq.fa plasmid_references
done

There's nothing special about the number of reference genomes: 215. This was just the amount which gave us 1000 total usable plasmids (a nice round number) for our assembly tests.
We then simulated the read sets with Badread, keeping the problem parameters at zero and the base (chromosomal) depth at 100x:
for x in {000..214}; do
    badread simulate --reference plasmid_references/""$x"".fasta --quantity 100x --junk_reads 0 --random_reads 0 --chimeras 0 --glitches 0,0,0 --start_adapter_seq 0 --end_adapter_seq 0 | gzip > ""$x"".fastq
done

Real read sets
For real read sets, we used data from PRJNA422511 (produced for Nicola De Maio's paper on long-read sequencing platforms) which contains Illumina, ONT and PacBio reads for 20 bacterial samples. In order to test our assemblers, we need a nice completed assembly for each sample to use as a reference, but to avoid biasing the results we didn't want to use any of the tested long-read assemblers to get that assembly.
We therefore conducted Unicycler hybrid assemblies using its --no_miniasm option (this turns off the part of the hybrid Unicycler pipeline which it has in common with long-read-only Unicycler, ensuring an independent assembly) using both Illumina-ONT and Illumina-PacBio combinations. We looked for samples where: a) both hybrid assemblies successfully completed the genome, and b) the two hybrid assemblies were in near-perfect agreement with each other. This was only the case for five of the 20 samples: SAMN10819801, SAMN10819805, SAMN10819807, SAMN10819813 and SAMN10819815. Those five samples were therefore the ones we used for our real read tests (ONT and PacBio read sets for each) using our hybrid assemblies as reference genomes.
The ONT and PacBio read sets were pretty large, so we made 10 random samplings of each with seqtk to produce read sets between 40Ã and 100Ã depth:
genome_size=5390818
reads=SAMN10819801/nanopore_SRR8494941.fastq.gz
total_bases=$(fast_count $reads | cut -f3)
for x in {00..09}; do
    target_bases=$(python3 -c ""import random; print(int(random.uniform(40.0, 100.0) * ""$genome_size""))"")
    fraction=$(python3 -c ""print('{:.4f}'.format(""$target_bases"" / ""$total_bases""))"")
    seqtk sample $reads $fraction | gzip > SAMN10819801_nanopore_""$x"".fastq.gz
done

Making 10 such subsampled sets for both Nanopore and PacBio reads of the five samples produced 10 Ã 2 Ã 5 = 100 real read sets.
Assessing chromosome contiguity
Both problem set assemblies and good set assemblies were analysed in the same manner. In an attempt to distil assembly quality down to a single metric, we defined a measure that we call assembly contiguity. This is the longest single alignment between the assembly and the reference, in terms of the reference length:

Contiguity is 100% if the assembly went perfectly.
Contiguity slightly less than 100% (e.g. 99.99%) indicates that the assembly was complete, but some bases were lost at the start/end of the circular chromosome.
Contiguity more than 100% (e.g. 102%) indicates that the assembly contains duplicated sequence via a start-end overlap.
Much lower contiguity (e.g. 70%) indicate that the assembly was not complete, either due to fragmentation or misassembly.

The first step in determining contiguity is to align the assembly to the reference chromosome. However, since the chromosome is circular, an assembled version of this chromosome might start at any point (and on either strand). This means that a single assembly-to-reference alignment is unlikely, even if the assembly went perfectly, as the assembled contig probably starts in a different location from the reference. Instead, we would get two alignments: one alignment from the start of the contig to the end of the reference and a second alignment from the start of the reference to the end of the contig:

By doubling the reference (two copies of the chromosome back-to-back), we can avoid this problem and get a single alignment covering the whole assembly:

However, if the assembly contains extra sequence from a start-end overlap then even a doubled reference may not be enough:

We therefore used a tripled reference to ensure that any assembled version of the genome (even with a big start-end overlap) could fully align to the reference:

Having made this tripled reference, we used minimap2 to align the assembly:
minimap2 -c -t 4 -r 10000 -g 10000 -x asm20 --eqx ref_tripled.fasta assembly.fasta > assembly.paf

The -x asm20 preset allows minimap2 to align sequences even when they are somewhat divergent. To encourage minimap2 to align through lower identity regions in the assembly (as opposed to stopping one alignment and starting another), we also used the -r 10000 -g 10000 options.
We then gave the assembly, the read set, the minimap2 alignment and the reference genome length to the assembly_stats.py script:
assembly_stats.py assembly.fasta reads.fastq.gz assembly.paf 3565206 >> results

It produces a single line of output with many columns which describe both the read set and the assembly, including the contiguity value.
Assessing plasmid assembly
Unlike the problem sets and good sets, the plasmid sets have multiple replicons. We therefore devised a different analysis which produces a binary pass/fail metric for each replicon in the reference.
The completed_contigs.py script takes three inputs: the assembly, the read set and the reference genome.
completed_contigs.py assembly.fasta reads.fastq.gz reference.fasta >> results

It carries out the following steps:

Aligns the reads to the reference to find the read depth of each replicon.
Aligns the assembly to a tripled reference.
For each replicon in the reference, look for a single contig in the assembly that is a clean match: the contig covers aligns to at least 95% of the reference and vice versa. If such a contig is found, that replicon's assembly succeeded. If no such contig is found, that replicon's assembly failed.

Results and discussion
You can find the raw results in the results directory, along with the R script used to make the plots.
Robustness
This plot shows the results for each assembler's attempt at assembling our problem sets. The reference genome for these tests only contains one chromosome, so a single contig (solid dot) at 100% indicates success. An open dot indicates more than one contig and falling below 100% indicates incomplete assembly or misassembly.

Adapter length (lower is better)
I was surprised to see that adding adapters to reads made little difference to the assembly, even when the adapters were unrealistically large (up to 1 kbp). The lesson seems to be that adapters really don't matter for any of the tested assemblers!
Chimeras (lower is better)
Canu was most affected by chimeric reads, starting to suffer at rates of ~6% or more. Unicycler was affected by chimeras at higher rates of ~15% or more.
The other assemblers were robust against all chimera rates. Considering that real read sets typically have 2% chimeras or less, they are probably not a serious concern for assembly, regardless of the assembler used.
Glitches (lower is better)
Read glitchiness is defined by three parameters: rate, size and skip (see Badread docs for more explanation). Here we've condensed those down to a single parameter: glitch level. Higher levels mean glitches are larger and occur more frequently. The glitchiness of reads matters for all assemblers, but Wtdbg2 was the most sensitive to glitchy reads and Unicycler the most robust. This suggests that repairing read glitches (e.g. with a tool like DASCRUBBER) is probably not of great concern, though might be of benefit if using Wtdbg2.
Random/junk reads (lower is better)
Canu was most sensitive to the inclusion of random/junk reads in the read set. Rates of over 10% caused Canu to not finish (mainly due to timing out at four days of assembly time). Unicycler handles random/junk reads well up to a rate of ~17%, beyond which its assemblies often fail. Flye and Wtdbg2 successfully assemble the chromosome at all random/junk rates but usually produce spurious contigs in addition to the chromosome. Also, Flye's assembly time suffered greatly with increasing random/junk rates. Ra tolerated random/junk the best, with essentially no effect at any rate.
Read depth (higher is better)
All assemblers did well with ~25Ã depth or more. Unicycler was worst in this regard and needed greater read depth, while Flye did best and successfully assembled the chromosome at ~13Ã depth.
Read identity (higher is better)
Ra was able to tolerate the lowest identity reads, down to ~80% identity. Canu required ~86% identity, and the other assemblers fell in between. Assuming your long-reads are relatively modern, read identity probably won't be an issue for completing your assemblies. It is more likely to play a role in consensus sequence accuracy: higher accuracy reads probably give a better consensus sequence. We didn't explore that relationship in this study, but it is touched upon in our paper on basecalling performance.
Read length (higher is better)
Canu was pickiest with read length, not achieving consistent success until the mean length was ~15 kbp. The other assemblers were able to complete the chromosome with somewhat shorter reads. A subtle feature of the Canu plot is also worth pointing out: the contiguity climbs increasingly over 100% with greater read lengths. I.e. the longer the reads, the more start-end overlap in a Canu assembly.
Reliability
By 'reliability' we mean how likely an assembler is to create a complete chromosome assembly (i.e. a contiguity of ~100%) from a decent set of reads. These plots show the results from the simulated good sets and the real read sets:

The simulated and real read sets are in nice agreement here. Canu, Flye, Ra and Unicycler are all decently reliable, usually producing assemblies with a contiguity near 100%. Of these, Ra was the best, only failing to achieve >95% contiguity for 5/500 simulated read sets and 3/100 real read sets.
Wtdbg2 was the only assembler which often failed to produce a complete assembly. Sometimes the low contiguity of Wtdbg2's assemblies could be explained by fragmentation (the chromosome assembled into more than one piece), but there were also plenty of one-contig Wtdbg2 assemblies which got a low contiguity â why? I used the re-DOT-able tool to manually investigate and found that Wtdbg2 assemblies often contain junky regions hundreds of base pairs in size. Our contiguity metric is based on minimap2 alignments, and these junky regions can break the contig-to-reference alignment into pieces.
These plots also reveal how well the assemblers circularise the chromosome. Canu typically produces a large amount of start-end overlap. As the problem set tests showed, the size of this overlap depends on the read length, shown here with a larger contiguity on ONT assemblies than PacBio assemblies (the ONT read sets contained longer reads). Unicycler was the only assembler able to circularise the chromosome exactly, i.e. a contiguity of exactly 100% with no extra or deleted bases. Flye typically deleted a small amount of sequence at the start/end, on the order of tens of bases. Ra was worse in this respect and tended to delete hundreds of bases.
Sequence identity
This plot shows the consensus sequence identity for the real read sets:

For each assembler, the top part of the distribution is for PacBio read sets and the bottom for ONT read sets. This demonstrates a common issue with ONT reads: systematic read errors which make their way into the consensus sequence. I should also point out that neither the PacBio or ONT reads we used are state-of-the-art, so don't take take the particular accuracy values too seriously â modern data may well have fewer errors.
Ra and Unicycler (both of which use Racon to polish) do well on ONT reads but are underwhelming for PacBio reads. Conversely, Flye does best for PacBio reads and worst for ONT reads. I found this lack of correlation between PacBio and ONT accuracy to be surprising.
While this is interesting, as I stated in the introduction, I don't think consensus sequence identity is the most important metric in this comparison. If you're using a platform-specific polishing tool on your assembly (and you probably should be), then the assembly's structural correctness (measured by our contiguity metric) is much more important than its sequence identity.
Speed performance
This plot shows the time taken to assemble (using four CPU threads) for the real read sets:

Wtdbg2 and Ra were the fastest, both performing especially well on PacBio reads. Flye was slightly slower but always completed in less than 30 minutes. Unicycler was slower, sometimes taking up to 90 minutes to complete. Canu was by far the slowest, taking an hour or two for most PacBio read sets and many hours for Nanopore read sets.
Plasmids
These plots show plasmid assembly for both simulated and real reads. Each of the eight plots contains the same points â one for each plasmid. Filled points indicate successful assembly, and the plot titles indicate the percentage of success:

All assemblers did well with large plasmids of moderate depth. While you might expect that very high depth plasmids would also assemble well, this was curiously not the case for Unicycler and Wtdbg2. Small plasmids were often a problem, especially for Wtdbg2, but Canu did well there.
These were the only tests where I strayed into playing with assembler parameters. This is because Flye has an option specifically for plasmid recovery: --plasmids. It also has an option for metagenomes (--meta) which I tried on the basis that a plasmid-rich bacterial genome is a bit like a metagenome. Running Flye with --plasmids made a noticeable improvement for small plasmids and using --meta boosted its performance on low-depth plasmids. Both options can be used together, which gave the best overall performance on plasmid assembly.
This raises the question: are there any downsides to using Flye's --plasmids and/or --meta options? In particular, do these options negatively affect the assembly of the chromosome? Of the 215 simulated plasmid sets and the 100 real read sets, here are the number of successfully assembled chromosomes (>95% contiguity) for each combination of options:



Flye options
Complete chromosome (simulated)
Complete chromosome (real)




defaults
211 / 215
83 / 100


--plasmids
211 / 215
81 / 100


--meta
208 / 215
84 / 100


--plasmids --meta
209 / 215
84 / 100



No strong trend is apparent, so I'll tentatively conclude that the options do not have a downside â when in doubt, use them.
Conclusions
What about a read set does and does not matter for assembly? Read length and read depth seem to be the most important factors â no surprises there. Higher identity reads are obviously better, but they are probably more important for consensus sequence identity than they are for assembly contiguity. Don't worry about adapter sequences, and chimeras aren't a problem either as long as there aren't too many. Finally, it's probably a good idea to filter junky and glitchy reads out of your set before assembly, so some read QC is warranted.
Here are my final thoughts on each of the assemblers tested:

Canu was the slowest assembler and not the most reliable or robust. Its strength is in its configurability (something we didn't explore in this study) â just take a look at the parameter reference page of Canu's documentation to get an idea of how many knobs it has to adjust. I suspect that power users who are willing to learn Canu's nuances may find that they can tune it to fit their needs. But if you have a bacterial read set and just want to get it assembled without knowing how the sausage is made, then Canu is probably not the best choice.
Flye was definitely one of my favourites. It was reliable, robust and reasonably fast. It also did best on plasmids when we used its --plasmid and --meta options which enhanced assembly of small and low-depth plasmids, respectively. I would probably call it a clear winner if it wasn't for one small wart: Flye tends to delete some bases when assembling a circular chromosome.
Ra was another of my favourites. It was the most reliable assembler we tested, completing the chromosome in more cases than any other, and it was very fast. But it suffered from worse circularisation problems than Flye (deleted hundreds of bases) and wasn't good with small plasmids. If those two issues don't bother you, then Ra may be the best choice. I also liked that Ra doesn't require a genome size parameter â this makes it easier to use when you don't know what you are assembling.
Unicycler performed moderately well in most of our tests, not bad but not exceptional either. However, it was the only assembler that usually achieved perfect circularisation of the chromosome, i.e. the last base of a circular contig was followed by the first base â nothing duplicated and nothing missing. If this feature is crucial to you, then Unicycler is the best choice. Also, Unicycler does not require a genome size parameter to run, which is nice.
Wtdbg2 was the least reliable assembler we tested due to glitches in its assembled sequences that break contiguity, making it a hard one to recommend. But it was very fast, even though we ran it with a round of polishing. Excluding that step (i.e. deriving the consensus but not polishing it) would make it even faster. Since its main appeal is speed performance, I feel as though Wtdbg2 is better suited to assembly of larger eukaryote genomes where resources can be a limiting factor.

If I had to condense my recommendations into a tweet-sized snippet, I would say:

The overall best long-read assembler for bacterial genomes is Flye. However, you might prefer Canu for its configurability, Ra for its reliability, Unicycler for its clean circularisation or Wtdbg2 for its speed.

As always, there is still room for improvement in this space. A perfect long-read bacterial genome assembler would complete assemblies whenever possible, circularise contigs cleanly, handle plasmids of any size, tolerate bad reads, not require a genome size parameter and polish consensus sequences to the highest degree allowed by the read errors. The assemblers we tested were not too far from this platonic ideal, so I hope its realisation isn't far away!
References
Kolmogorov M, Yuan J, Lin Y, Pevzner PA. 2019. Assembly of long, error-prone reads using repeat graphs. Nature Biotechnology. doi:10.1038/s41587-019-0072-8.
Koren S, Walenz BP, Berlin K, Miller JR, Phillippy AM. 2017. Canu: scalable and accurate long-read assembly via adaptive k-mer weighting and repeat separation. Genome Research 27:722â736. doi:10.1101/gr.215087.116.
Li H. 2018. Minimap2: Pairwise alignment for nucleotide sequences. Bioinformatics 34:3094â3100. doi:10.1093/bioinformatics/bty191.
Maio N De, Shaw LP, Hubbard A, et al. 2019. Comparison of long-read sequencing technologies in the hybrid assembly of complex bacterial genomes. bioRxiv:530824. doi:10.1101/530824.
Orlek A, Phan H, Sheppard AE, et al. 2017. A curated dataset of complete Enterobacteriaceae plasmids compiled from the NCBI nucleotide database. Data in Brief 12:423â426. doi:10.1016/j.dib.2017.04.024.
Ruan J, Li H. 2019. Fast and accurate long-read assembly with wtdbg2. bioRxiv:530972. doi:10.1101/530972.
Vaser R, SoviÄ I, Nagarajan N, Å ikiÄ M. 2017. Fast and accurate de novo genome assembly from long uncorrected reads. Genome Research 27:737â746. doi:10.1101/gr.214270.116.
Wick RR, Judd LM, Gorrie CL, Holt KE. 2017. Unicycler: resolving bacterial genome assemblies from short and long sequencing reads. PLOS Computational Biology 13:e1005595. doi:10.1371/journal.pcbi.1005595.
License
GNU General Public License, version 3
",11
holdenk/clothes-from-code,Python,"clothes-from-code
Auto generate cool code based clothing.
Requires
This depends on jpglitch and pygments.
Samples
So far we've made samples for the gen.py generating its self and kubicorn's reconciler. I may post more in the glitch code cowcow store.
Development
Much of the development was live-streamed because ""why not?"" and you can look watch it at https://www.youtube.com/watch?v=nUbgxMqp27U
How to use
Run gen.py and provide an input file then take the output to cowcow and upload the individual image components.
",2
jensimmons/jensimmons.com,HTML,"Jen Simmons dot com
What is it?
The personal website of Jen Simmons.
Built on top of Dan Urbanowiczâ Eleventy Netlify Boilerplate, for making a static website using the Eleventy static site generator, with Netlify CMS baked-in, deployed to Netlify.
Notes on Making This Thing Go
Navigate to /admin, and start editing content.
Locally, run Eleventy to build the site
npx eleventy

Or build automatically when a template changes:
npx eleventy --watch

Or in debug mode:
DEBUG=* npx eleventy

",3
CoolerVoid/HiddenWall,C,"HiddenWall
HiddenWall is a Linux kernel module generator for custom rules with netfilter. (block ports, Hidden mode, rootkit functions etc).

The motivation: on bad situation, attacker can put your iptables/ufw to fall... but if you have HiddenWall,
the attacker will not find the hidden kernel module that block external access, because have a hook to netfilter on
kernel land(think like a second layer for firewall).
My beginning purpose at this project is protect my personal server, now is protect the machines of my friends.
When i talk ""friends"", i say peoples that don't know how to write low level code. Using the HiddenWall you can
generate your custom kernel module for your firewall configuration.
The low level programmer can write new templates for modules etc...
First step, understand before run
Verify if the kernel version is 3.x, 4.x or 5.x:
uname -r

Clone the repository
git clone https://github.com/CoolerVoid/HiddenWall

Enter the folder
cd HiddenWall/module_generator

Edit your firewall rules in directory  rules/server.yaml, the python scripts use that file to generate a new firewall module.
$ cat rules/server.yaml
module_name: SandWall
public_ports: 80,443,53
unhide_key: AbraKadabra
hide_key: Shazam
fake_device_name: usb14
liberate_in_2_out: True
whitelist: 
- machine: 
   ip: 192.168.100.181
   open_ports: 22,21
- machine:
   ip: 192.168.100.22
   open_ports: 22


If you want study the static code to generate, look the content at directory ""templates"".
Second step, generate your module
If you want generate a kernel module following your YAML file of rules, follow that command:
$ python3 WallGen.py --template template/hiddenwall.c -r rules/server.yaml

This generate a generic module with rules of server.yaml, if you want to use another template you can use ""wall.c"", so template module ""hiddenwall"" have option to run on hidden mode(is not visible to ""# lsmod"" for example).
Third step, install your module
To test module:
# cd output; make clean; make
# insmod SandWall.ko

The rule of YAML to generate module is simple, drop all out to in packets, accept ports 80,443 and 53. The machine 192*.181 can connect at ports 22 and 21...
if you use nmap at localhost/127.0.0.1 you can view the ports open... because rule liberate_in_2_out is true.
Password to turn Firewall visible is ""AbraKadabra"".
Password to turn Firewall invisible is ""Shazam"".
You need to send password for your fake device ""usb14"".
To exit module, you need turn visible at ""lsmod"" command ...
# echo ""AbraKadabra"" > /dev/usb14
# lsmod | grep SandWall
# rmmod SandWall

Random notes
Tested on ubuntu 16 and fedora 29 at kernels ""3.x"",""4.x"" and ""5.x"".
TODO
Suport to IPV6.
Macro to select the interface(to use multiple modes for each interface).
Option to remove last logs when turn hide mode.
Option to search and remove others toolkits...
Code generator to BFP...
References
Wikipedia Netfilter
https://en.wikipedia.org/wiki/Netfilter
Linux Device Drivers
http://lwn.net/Kernel/LDD3/
M0nad's Diamorphine
https://github.com/m0nad/Diamorphine/
",5
anishkny/integrify,JavaScript,"ððððððððð¢






ð¤ Enforce referential and data integrity in Cloud Firestore using triggers
Introductory blog post
Usage
// index.js

const { integrify } = require('integrify');

const functions = require('firebase-functions');
const admin = require('firebase-admin');
admin.initializeApp();
const db = admin.firestore();

integrify({ config: { functions, db } });

// Automatically replicate attributes from source to target
module.exports.replicateMasterToDetail = integrify({
  rule: 'REPLICATE_ATTRIBUTES',
  source: {
    collection: 'master',
  },
  targets: [
    {
      collection: 'detail1',
      foreignKey: 'masterId',
      attributeMapping: {
        masterField1: 'detail1Field1',
        masterField2: 'detail1Field2',
      },
    },
    {
      collection: 'detail2',
      foreignKey: 'masterId',
      attributeMapping: {
        masterField1: 'detail2Field1',
        masterField3: 'detail2Field3',
      },
    },
  ],

  // Optional:
  hooks: {
    pre: (change, context) => {
      // Code to execute before replicating attributes
      // See: https://firebase.google.com/docs/functions/firestore-events
    },
  },
});

// Automatically delete stale references
module.exports.deleteReferencesToMaster = integrify({
  rule: 'DELETE_REFERENCES',
  source: {
    collection: 'master',
  },
  targets: [
    {
      collection: 'detail1',
      foreignKey: 'masterId',
    },
  ],

  // Optional:
  hooks: {
    pre: (snap, context) => {
      // Code to execute before deleting references
      // See: https://firebase.google.com/docs/functions/firestore-events
    },
  },
});

// Automatically maintain count
[
  module.exports.incrementFavoritesCount,
  module.exports.decrementFavoritesCount,
] = integrify({
  rule: 'MAINTAIN_COUNT',
  source: {
    collection: 'favorites',
    foreignKey: 'articleId',
  },
  target: {
    collection: 'articles',
    attribute: 'favoritesCount',
  },
});
Deploy to Firebase by executing:
$ firebase deploy --only functions
Rules File
Alternately, rules can be specified in a file named integrify.rules.js.
// index.js

const { integrify } = require('integrify');

const functions = require('firebase-functions');
const admin = require('firebase-admin');
admin.initializeApp();
const db = admin.firestore();

integrify({ config: { functions, db } });

// Rules will be loaded from ""integrify.rules.js""
module.exports = integrify();
// integrify.rules.js

module.exports = [
  {
    rule: 'REPLICATE_ATTRIBUTES',
    name: 'replicateMasterToDetail',
    // ...
  },
  // ...
];
",17
ledgersmb/LedgerSMB,PLpgSQL,"LedgerSMB
Small and Medium business accounting and ERP






SYNOPSIS
LedgerSMB is a free integrated web application accounting system, featuring
double entry accounting, budgetting, invoicing, quotations, projects, timecards,
inventory management, shipping and more ...
The UI allows world-wide accessibility; with its data stored in the
enterprise-strength PostgreSQL open source database system, the system is known
to operate smoothly for businesses with thousands of transactions per week.
Screens and customer visible output are defined in templates, allowing easy and
fast customization. Supported output formats are PDF, CSV, HTML, ODF and more.
Directly send orders and invoices from the built-in e-mail function to your
customers or RFQs (request for quotation) to your vendors with PDF attachments.
System requirements
Note that these are the system requirements for LedgerSMB 1.7; the planned next
minor release. Please check the system requirements for the 1.5 old stable
version
and current 1.6 version.
Server

Perl 5.18+
PostgreSQL 9.4+
Web server (e.g. nginx, Apache, lighttpd)

The web external server is only required for production installs;
for evaluation purposes a simpler setup can be used, as detailed
below.
Client
A Dojo 1.14 compatible web browser
is all that's required on the client (except IE8 and 9); it includes Chrome as
of version 13, FireFox as of 3.6 and MS Internet Explorer as of version 10 and
a wide range of mobile browsers.
Quick start (Docker compose)
The quickest way to get the Docker image up and running is by using the
docker-compose file available through the GitHub repository at:
https://github.com/ledgersmb/ledgersmb-docker/blob/1.6/docker-compose.yml
which sets up both the LedgerSMB image and a supporting database image for
production purposes (i.e. with persistent (database) data, with the
exception of one thing: setting up an Nginx or Apache reverse proxy
with TLS 1.2 support -- a requirement if you want to access your
installation over any type of network.
See the documentation on Docker Hub.
Quick start (from source)
The instructions below are for getting started quickly; the project's site
provides in-depth installation instructions
for production installs.
System (library) dependencies
The following non-Perl (system) dependencies need to be in place for the
cpanm command mentioned below to work, in addition to what's documented
on the How to install CPAN modules
page on CPAN.

cpanminus  This can be manually installed, or installed as a system package.
It may not be necessary to install cpanminus if you are only going to install from debian packages.
PostgreSQL client libraries
PostgreSQL server
DBD::Pg 3.4.2+ (so cpanm recognises that it won't need to compile it)
This package is called libdbd-pg-perl in Debian and perl-DBD-Pg
in RedHat/Fedora
make       This is used by cpan dependencies during thier build process

Then, some of the features listed below have system requirements as well:

latex-pdf-ps depends on these binaries or libraries:

latex (usually provided through a texlive package)
pdflatex
dvitopdf
dvitops
pdftops



Perl module dependencies
This section depends on a working local::lib installation
as well as an installed cpanm executable. Both should be available from
your distribution's package repository (Debian calls them liblocal-lib-perl
and cpanminus respectively). cpanm depends on the make and gcc commands being available.
NOTE: gcc can be removed after all cpan dependencies are installed.
However, it may be necessary to reinstall it if additional modules are required during an upgrade
To install the Perl module dependencies, run:
 $ cpanm --quiet --notest --with-feature=starman [other features] --installdeps .

NOTE: Don't miss the ""."" at the end of the cpanm command!
Don't forget to make sure the environment variable PERL5LIB=/home/ledgersmb/perl5/lib/perl5 points at the running user's perl5 dir
Also, NEVER run cpanm as root, it's best to run it as the user you intend to run ledgersmb as when possible.
This installs the cpan modules in ~/perl5
If you can't run it as the final user, don't worry, just run it as any user (eg: johnny),
and make sure the environment variable PERL5LIB=/home/johhny/perl5/lib/perl5 points at jonny's perl5 dir
Setting the PERL5 environment variable is normally done by editing the initscript, or systemd service file.
If you are running manually, then you will need to set and export PERL5 before running starman/plack
The following features may be selected by
specifying --with-feature=<feature>:



Feature
Description




latex-pdf-ps
Enable PDF and PostScript output


starman
Starman Perl/PSGI webserver


openoffice
OpenOffice.org document output


edi
(EXPERIMENTAL) X12 EDI support


xls
Excel output filters (xls+xlsx)



Note: The example command contains --with-feature=starman for the
purpose of the quick start.
When not installing as root or through sudo, cpanm will install unfulfilled
library dependencies into a location which can be used with local::lib.
The in-depth installation instructions
contain a list of distribution provided packages to reduce the
number of dependencies installed from CPAN.
NOTES

For the pdf-ps target, LaTeX is required.

PostgreSQL configuration
While it's possible to use LedgerSMB with the standard postgres user,
it's good practice to create a separate 'LedgerSMB database administrator':
$ sudo -u postgres createuser --no-superuser --createdb --login \
          --createrole --pwprompt lsmb_dbadmin
Enter password for new role: ****
Enter it again: ****

The pg_hba.conf file should have at least these lines in it (order of the entries matters):
local   all                            postgres                         peer
local   all                            all                              peer
host    all                            postgres        127.0.0.1/32     reject
host    all                            postgres        ::1/128          reject
host    postgres,template0,template1   lsmb_dbadmin    127.0.0.1/32     md5
host    postgres,template0,template1   lsmb_dbadmin    ::1/128          md5
host    postgres,template0,template1   all             127.0.0.1/32     reject
host    postgres,template0,template1   all             ::1/128          reject
host    all                            all             127.0.0.1/32     md5
host    all                            all             ::1/128          md5


Note: pg_hba.conf can be found in /etc/postgresql/<version>/main/ on Debian
and in /var/lib/pgsql/data/ on RedHat/Fedora

After editing the pg_hba.conf file, reload the PostgreSQL server
(or without 'sudo' by running the commands as root user):
 $ sudo service postgresql reload
 # -or-
 $ sudo /etc/init.d/postgresql reload
Configure LedgerSMB
(Installation from tarball is highly preferred over installation from GitHub for production installs.)
 $ cp doc/conf/ledgersmb.conf.default ledgersmb.conf
Running Starman
With the above steps completed, the system is ready to run the web server:

NOTE: DO NOT run starman (or any web service) as root, this is considered
a serious security issue, and as such LedgerSMB doesn't support it.
Instead, if you need to start LedgerSMB from a root process, drop
privileges to a user that doesn't have write access to the LedgerSMB Directories first.
Most daemonising mechanisms (eg: systemd) provide a mechanism to do this.
Do not use the starman --user= mechanism, it currently drops privileges too late.

 $ starman -I lib -I old/lib --listen localhost:5762 bin/ledgersmb-server.psgi
2016/05/12-02:14:57 Starman::Server (type Net::Server::PreFork) starting! pid(xxxx)
Resolved [*]:5762 to [::]:5762, IPv6
Not including resolved host [0.0.0.0] IPv4 because it will be handled by [::] IPv6
Binding to TCP port 5762 on host :: with IPv6
Setting gid to ""1000 1000 24 25 27 29 30 44 46 108 111 121 1000""
Environment Variables
All regular Perl environment variables can be used. In particular, it's important to make sure
PERL5LIB is set correctly when setting up local::lib for the first time.
We support the following Environment Variables within our code

LSMB_WORKINGDIR : Optional

Causes a chdir to the specified directory as the first thing done in starman.psgi
If not set the current dir is used.
An example would be

LSMB_WORKINGDIR='/usr/local/ledgersmb/'



We support the following Environment Variables for our dependencies

PGHOST : Optional

Specifies the Postgres server Domain Name or IP address


PGPORT : Optional

Sepcifies the Postgres server Port


PGSSLMODE : Optional

Enables SSL for the Postgres connection



All Environment Variables supported by our dependencies should be passed through to them,
that includes the standard Postgres Variables and others
Next steps
The system is installed and should be available for evaluation through

http://localhost:5762/setup.pl    # creation and privileged management of company databases
http://localhost:5762/login.pl    # Normal login for the application

The system is ready for preparation for first
use.
Project information
Web site: http://ledgersmb.org/
Live chat:

IRC: irc://irc.freenode.net/#ledgersmb
Matrix: https://vector.im/#/room/#ledgersmb:matrix.org (bridged IRC channel)

Forums: http://forums.ledgersmb.org/
Mailing list archives: http://archive.ledgersmb.org
Mailing lists:

https://lists.ledgersmb.org/mailman/listinfo/announce
https://lists.ledgersmb.org/mailman/listinfo/users
https://lists.ledgersmb.org/mailman/listinfo/devel

Repository: https://github.com/ledgersmb/LedgerSMB
Project contributors
Source code contributors can be found in the project's Git commit history
as well as in the CONTRIBUTORS file in the repository root.
Translation contributions can be found in the project's Git commit history
as well as in the Transifex project Timeline.
Copyright
Copyright (c) 2006 - 2018 The LedgerSMB Project contributors
Copyright (c) 1999 - 2006 DWS Systems Inc (under the name SQL Ledger)

License
GPLv2
",122
ultrasilicon/parsly,C++,"Parsely

Describe & deploy net protocol with simply a JSON file.


Parsely is a library which helps developer serialize runtime application data into network packets, according to the network protocol defined by the user in a JSON file.

Get Started:


Step 1: Design and define your protocol in a  json file

How proto.json is defined (example):

{
	""version"" : [0, 0, 0],
	""protocol"" : {
		""header"" : 4,
		""flags"" : [""HeartBeat"", ""ConnectionInfo"", ""TextMessage"", ""ImageMessage""]
	},

	""fields"" : {
		""HeartBeat"" : [
			[""string"", ""uuid""],
			[""string"", ""usrName""],
			[""string"", ""publicKey""],
			[""uint32"", ""timestamp""]
		],
	
		""ConnectionInfo"" : [
			[""string"", ""uuid""],
			[""string"", ""peers""]
		],
		
		""TextMessage"" : [
			[""string"", ""uuid""],
			[""string"", ""msgId""],
			[""string"", ""msg""]
		],
		
		""ImageMessage"" : [
			[""string"", ""uuid""],
			[""string"", ""msgId""],
			[""string"", ""msg""]
		]
	}
}

version : POP version.
protocol : An overview of the protocol.
header : The size of header, which packetize the TCP stream. It is the size of the whole packet except the size of it self.
flags : Flags are used for application to determine what type of message the packet is transmitting. Different type of message has different fields, defined in fields.
fields : The message fields of flags. Consisted of an order sensitive array of sub fields. So that the binary will be serialized and deserialized sequencially described here. The first element of a subfield, like in [""string"", ""uuid""], is the type of the subfield data. And the second is the same of the data, which is just a label for your and the pre-processor's reference when debugging.



STEP 2: Compile your protocol to ParseEngine:

It translates the given protocol description JSON file to C++ code, which is a part of what we called the Parse Engine

$ python3 pop.py ./my_proto_v1.json ./my_proj/src/
Pre-processor of Parsely v1.0.1 stable 
pop: Parsing /home/han/my_proto_v1.json ...
pop: Generating decoder in C++ ...
pop: Injecting compiled code to ./my_proj/src/parse_engine_decode_pop.cpp
Sucessful!
$ make -j8


STEP 3: Encapsulate your own network stack:

The user first need to inherit his/her network class from our interface called the NetStack.
Note: you need to implement virtual int NetStack::write(char* data, string &ip) so that ParseEngine can automatically call NetStack to send out  message

#include ""parsely/net_stack.h""
using namespace std;

class ChatServer : public NetStack
{
public:
	ChatServer(string &ip, const int &port);
	
	virtual int NetStack::write(char* data, string &ip);
}


STEP 4: Send message with ParseEngine:

How ParseEngine is used (example):

#include ""chat_server.h""
#include ""parse_engine.h""

enum ProtoMsgType {
    HeartBeat,
    Text,
    Image,
}

void readMessage(Packet* p){
    // Do something...
}

int main(int argc, char **argv  ){
    // User code...
    
    ChatServer  *s = new ChatServer();
    ParseEngine *e = new ParseEngine(s);
    //bind read message callback
    e->onMessage = &readMessage;
    
    // construct packet according to the protocol
    Packet *p = new Packet{ 
        {
            ""{cfceb206-290e-4b60-b596-1a08a2c8d36a}"", // UUID
            ""731948"", 								  // Message ID
            ""Hello?""								  // Message Text
        },
        Text
    };
    e->message(p, Text}, ""155.246.104.55"");
    
    // User code...
}


What's next for Parsely

We will further simplify the usage
Add packet oriented protocol support, like UDP
Merge into opensource project libParsley - Asynchronous cross-platform C++ library with delicate OOP callback system as a module.

",2
discord-csharp/CSDiscord,C#,"
",6
arsns-iscteiul/SID_2018_32,Java,"SID_2018_32
",3
taka-sho/taka-sho.github.io,Vue,"This page's status

Who is taka-sho?

Shotaro Takahara (Nickname: Takasho)
ãã³ãã³ãªå¤§å­¦ã«éãæ®éã®å¤§å­¦ç

What award did I win?

Robot Presentation Award at First Lego League in 2014
Progate Award at Kaumo Hackathon in 2016

This page were made by ...

Languages : Typescript & Pug(Jade)
Framework : Vue.js
Bundler : Webpack
Lint : Tslint

",2
TheAlgorithms/C,C,"C
Computer Oriented Statistical Methods
- Gauss_Elimination
- Lagrange_Theorem
- Mean
- Median
- Seidal
- Simpson's_1-3rd_rule.c
- Variance
- statistic (C Lib)

Conversions
- binary_to_decimal
- decimal _to_binary
- decimal_to_hexa
- decimal_to_octal
- to_decimal

Data Structures
- stack
- queue
- dictionary
linked_list
	- singly_link_list_deletion
	- stack_using_linkedlists
binary_trees
	- create_node
	- recursive_traversals
trie
	- trie

Searching
- Binary_Search
- Other_Binary_Search
- Jump_Search

Sorting
- BinaryInsertionSort
- BubbleSort
- BogoSort
- InsertionSort
- MergeSort
- OtherBubbleSort
- QuickSort
- SelectionSort
- ShakerSort
- HeapSort

Hashing
- sdbm
- djb2
- xor8 (8 bit)
- adler_32 (32 bit)

Misc
- Binning
- Factorial
- Fibonacci
- isArmstrong
- LongestSubSequence
- palindrome
- QUARTILE
- rselect
- strongNumber
- TowerOfHanoi
- Greatest Common Divisor
- Sudoku Solver
- prime factorization

exercism
In this directory you will find (in the right order):

hello-world
isogram
acronym
word-count
rna-transcription

Simple Client Server Implementation
This directory contains

client.c
server.c

First execute server.c in a terminal and then client.c in a different terminal. Enables communication between two terminals.
",1763
TheAlgorithms/C,C,"C
Computer Oriented Statistical Methods
- Gauss_Elimination
- Lagrange_Theorem
- Mean
- Median
- Seidal
- Simpson's_1-3rd_rule.c
- Variance
- statistic (C Lib)

Conversions
- binary_to_decimal
- decimal _to_binary
- decimal_to_hexa
- decimal_to_octal
- to_decimal

Data Structures
- stack
- queue
- dictionary
linked_list
	- singly_link_list_deletion
	- stack_using_linkedlists
binary_trees
	- create_node
	- recursive_traversals
trie
	- trie

Searching
- Binary_Search
- Other_Binary_Search
- Jump_Search

Sorting
- BinaryInsertionSort
- BubbleSort
- BogoSort
- InsertionSort
- MergeSort
- OtherBubbleSort
- QuickSort
- SelectionSort
- ShakerSort
- HeapSort

Hashing
- sdbm
- djb2
- xor8 (8 bit)
- adler_32 (32 bit)

Misc
- Binning
- Factorial
- Fibonacci
- isArmstrong
- LongestSubSequence
- palindrome
- QUARTILE
- rselect
- strongNumber
- TowerOfHanoi
- Greatest Common Divisor
- Sudoku Solver
- prime factorization

exercism
In this directory you will find (in the right order):

hello-world
isogram
acronym
word-count
rna-transcription

Simple Client Server Implementation
This directory contains

client.c
server.c

First execute server.c in a terminal and then client.c in a different terminal. Enables communication between two terminals.
",1763
docker-library/repo-info,Perl,"Official Images ""Extended Information""
This repository includes a set of scripts for generating reports of extended information about published official image repositories.
It's still a firm Work In Progress, and concrete suggestions for improvement in gathering or presentation are welcome!


Automated update-remote.sh:

Automated scan-local.sh (one job per repo)

",169
liqiongfan/xserver,C,"Tiny & Effective Server: Xserver
Xserveræ¯ä»ä¹ï¼
Xserveræ¯ä¸ä¸ªå®å¨éç¨Cè¯­è¨ç¼åçå¤çº¿ç¨ãå¹¶ååãæ¨¡ååçæå¡å¨ç¨åºï¼æ¯æLinuxç³»ç»ç¯å¢ï¼ä¼åéç¨epollå¤è·¯å¤ç¨æºå¶ï¼å·ä½çè®¾è®¡ä½ç³»æ¶æå¦ä¸å¾æç¤ºï¼

Xserverçä½ç³»æ¶æç®åãæ§è½ææ§åº¦100%ï¼å ä¸ºéç¨Cè¯­è¨å¼åå æ­¤è½å¤å°æºå¨çæ§è½åæ¦¨å°æè´ï¼æ¯è¾éåæ¨éæå¡ãæ¶æ¯IMç³»ç»ç­å¹¶ååºæ¯æ¯è¾é«çç³»ç»ä½¿ç¨ã
æ©å±å¼åæå
æ©å±å¼åå¯ä»¥ä½¿ç¨Cè¯­è¨æèC++è¯­è¨å¼åï¼çæsoæä»¶å³å¯ï¼ææªå¤çBSDç³»ç»çkqueueæºå¶ï¼åç»­å¢å åæ¯ædylibæ©å±ï¼å·ä½çå¼åæ¹æ³å¦ä¸ï¼
Xserveré»è®¤æåµä¸èªå¨è§£æhttpè¯·æ±åè®®ï¼æç§æ åæ ¼å¼è¿è¡è§£æï¼è§£æçç»æä¼éè¿åæ°è¿åç»æ©å±åºçåè°å½æ°çåæ°ä¸­ï¼æ©å±æ¹æ³çååå¦ä¸ï¼
void (HTTP_FUNC)(list *request_headers, list *query_string_list);

éå Xserver èªå¸¦ç list ç»æå¯ä»¥ä½¿ç¨ Xserverå® éåå³å¯ï¼
å¶ä¸­ request_headers åè¡¨ä¸­å«æå ä¸ªåºå®çé®å¼ï¼



å­æ®µ
å«ä¹
åå¼




request_method
è¯·æ±æ¹æ³åç§°
GET|PUT|POST|DELETE ç­ç­


request_uri
è¯·æ±URL
é¤å»hostä¹åçè·¯å¾åå¼


http_version
HTTPåè®®çæ¬
HTTP/1.1


http_body
è¯·æ±çåä¸»ä½
GETè¯·æ±æ åä½



list *_temp = EMPTY_PTR;
LIST_FOREACH_VAL(request_headers, _temp) {
    
    /* list_dataç»æä½åå«ä¸ä¸ªnameå­æ®µï¼é®å
     * value:é®å¼ */
    list_data *_kv = (list_data *)_temp->node.data_ptr;
    
    printf(""%s:%s\t"", _kv->name, _kv->value);
    
} LIST_FOREACH_END();

ä¸è¦æå¿åå­æ³æ¼é®é¢ï¼Xserverä¼èªå¨å¨è°ç¨åºæ¹æ³è¿ååèªå¨éæ¾åå­ã
ååæµè¯çç®æ æºå¨éç½®ï¼
16GBåå­ï¼4æ ¸i5-4460 3.2GHzçIntel CPU

ååæµè¯å½ä»¤ä¸æµè¯ç»æï¼
ab -n100000 -c1000 -r -k http://localhost:8181/

josin@josin-PC:~$ ab -n100000 -c1000 -r -k http://localhost:8181/
This is ApacheBench, Version 2.3 <$Revision: 1826891 $>
Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/
Licensed to The Apache Software Foundation, http://www.apache.org/

Benchmarking localhost (be patient)
Completed 10000 requests
Completed 20000 requests
Completed 30000 requests
Completed 40000 requests
Completed 50000 requests
Completed 60000 requests
Completed 70000 requests
Completed 80000 requests
Completed 90000 requests
Completed 100000 requests
Finished 100000 requests


Server Software:
Server Hostname:        localhost
Server Port:            8181

Document Path:          /
Document Length:        26 bytes

Concurrency Level:      1000
Time taken for tests:   4.206 seconds
Complete requests:      100000
Failed requests:        0
Keep-Alive requests:    0
Total transferred:      12800000 bytes
HTML transferred:       2600000 bytes
Requests per second:    23777.23 [#/sec] (mean)
Time per request:       42.057 [ms] (mean)
Time per request:       0.042 [ms] (mean, across all concurrent requests)
Transfer rate:          2972.15 [Kbytes/sec] received

Connection Times (ms)
              min  mean[+/-sd] median   max
Connect:        0   20  92.4     11    1040
Processing:     5   22   8.4     20      68
Waiting:        0   17   7.8     16      67
Total:          7   42  93.3     33    1084

Percentage of the requests served within a certain time (ms)
  50%     33
  66%     39
  75%     42
  80%     44
  90%     47
  95%     50
  98%     55
  99%     73
 100%   1084 (longest request)

",6
RyanLinrm/CSC473Project,JavaScript,"CSC473 Project
Strategy Arena Game


Team members: Nabhan Maswood, Hongjie Huang, Adam McKoy, Michael Richards, Runmin Lin


Scrum master nameï¼ Runmin Lin


Product owner nameï¼Hongjie Huang


Documentation

https://ryanlinrm.github.io/CSC473Project/

Copyright Disclaimer

We do NOT own the sprite sheets/assets,sound/music files nor the images we used throughout the development of the project.
This project and the website that we deployed are only for study purposes for CSC473 class in The City College of New York.
All rights belong to it's rightful owner/owners.
No copyright infringement intended. Any files that violated the rights of the owner/owners wll be removed if needed.

",3
spec-journalism/everything,None,"Everything
A list of all our data analysis and interactives.
Table of Contents

Data Stories
Interactive Feautres
Data Analysis
Tool Ideas


Data Stories



Article
Repo
Description
Developer(s)




ð
graduate-diversity
Code for the Graduate Student Sex Diversity lead.
Jason


ð
net-price-inequity
Code for the Net Price Inequity article.
Jason



Interactive Features



Article
Repo
Description
Developer(s)




ð
uptown-arts
Code for the Uptown Arts feature.
Jason and Raeedah


ð
genealogy
Code for the Eastern Genealogical Records feature.
Jason



Data Analysis



Article
Repo
Description
Contact





visits-who
Data and analysis of Columbia Undergraduate Admissions events scraping project.
Jason



staff-diversity
Measuring diversity within the Columbia Daily Spectator and comparing staff diversity against other sections and top college newspapers.
Raeedah


ð
gss-diversity
Data and analysis of Columbia graduate student diversity.
Jason


ð
homeless-center
Data and analysis contextualizing homeless services at  Columbia.
Raeedah


ð
turkey
Data, analysis, and code for Turkey's panel cancellation article.
Jason


ð
international-students
Data analysis and graphics supporting the International Students lead.
Jason


ð
financial-aid
Data analysis underlying the original analysis reported in the net price inequity article.
Jason


ð
foreign-gifts
Analyzing monetary gifts from foreign entities to Columbia University.
Jason



Tool Ideas

Easy conversion of Google Docs text to code

Retains AML format but converts paragraphs, styles, and links to HTML
CLI to easily convert a Google Doc with an AML section into a scrollytelling piece (with different templates??!!)


Starter CLI to easily access all templaltes (see POLITICO, The Pudding)
Standard style template for interactive projects (like The Pudding starter for web pages)

",3
streamich/md-mdast,TypeScript,"md-mdast


Markdown to MDAST converter.
Small and fast.
No dependencies.

Installation
npm install md-mdast
Usage
const {create} = require('md-mdast');

const parser = create();

console.log(parser.tokenizeBlock('*hello* __world__'));
Result:
{ type: 'root',
  children:
   [ { type: 'paragraph',
       children:
        [ { type: 'emphasis',
            children: [ { type: 'text', value: 'hello' } ] },
          { type: 'text', value: ' ' },
          { type: 'strong',
            children: [ { type: 'text', value: 'world' } ] } ] } ],
}

License
Unlicense â public domain.
",5
gltd/gltd-td,Python,"gltd-td
touchdesigner files
",2
ermiry/Blackrock,C,"
About
Current Features
Upcoming Features
Installing
Contributing
About
Blackrock is currently a dungeon exploration rouguelike heavily inspired by the great Nethack, nut it is intended to become a much complex game featuring multiplayer and some bigger maps to explore with your friends.
Blackrock first started as a hobby program just to test my skills working with C, but as time went one, it became one of my biggest projects and I have to say that I have had a lot of fun working on it and also I have learned a lot.
This game is also intended to serve as a much more complex tutorial for anyone that would like to sharpen his or her skills in C. It includes many topics that I have had a hard time finding out how to implement them in C such as a database using Sqlite or some object pooling and an ECS. In the future it will feature a full wiki for any topic related to the game and its development. For now the code is heavily commented and I will try to keep that way trough its development. If you have any question please contact me.
Current Features

ECS  (Entity Component System)
Object Pooling
Simple dungeon generation
Ascii characters
Simple random enemy spawner
Loot and currency
Weapons and armor
Some items
Shops
Simple inventory system
Simple UI
Only one class -> warrior
Only one race -> human
Leaderboards
Support for Linux

Instalation
Linux
Build it yourself -> You need to install the following dependencies first:

Sdl 2.0 - libsdl2-dev
Sqlite3 - libsqlite3-dev
Pthread - libpthread-stubs0-dev

If you are using Ubuntu, you can run the following commands:
sudo apt-get install libsdl2-dev
sudo apt-get install sqlite3 libsqlite3-dev
sudo apt-get install libpthread-stubs0-dev
Note: You also need to have installed:

Make

Compiling -> Just use 'make' in the project folder.
Running ->  Use 'make run'.
Contributing
Anyone can make a pull request and I will try to check it, and if it seems fine with the flow of the game, I will include it on the project.
",3
nytimes/encoding-wrapper,Go,"encoding-wrapper



Collection of Go wrappers for Video encoding providers.
Supported providers

Elemental Conductor
Encoding.com

",91
NanoAdblocker/NanoCore2,JavaScript,"Nano Core 2
Restarting fresh
A patch driven fork of uBlock Origin.
Upstream commit pin: 07cbae66a475a8b0cf0a93cfbff0ac63c3bfa8b1 or 1.19.2
Please submit issues to the
Nano Core issues tracker.
Localization
Nano Core 2 has some extra locale strings, most of them are for Nano Linter.
You can contribute to localization here:
https://crowdin.com/project/nano-adblocker
Your language is not listed? Submit an issue to let me know.
Setup

Install latest version of Git and Node.js.
In an appropriate directory, run:

git clone --depth 1 https://github.com/NanoAdblocker/NanoCore2.git
git clone --depth 1 https://github.com/NanoAdblocker/NanoFilters.git
git clone --depth 1 https://github.com/jspenguin2017/Edgyfy.git
git clone --depth 1 https://github.com/jspenguin2017/uBlockProtector


Run git clone --depth 1 https://github.com/gorhill/uBlock.git in an
appropriate directory to get upstream. Check out a tag or commit as
appropriate.
In Nano Core 2 repository:

Navigate to /term directory and run npm install.
Update /config.json as appropriate.
Run node ./term to open Nano Core 2 Terminal.



Note: The private repository Prototype is required for publishing.
Development
You should not modify the upstream repository, instead, use Nano Core 2
Terminal to create and manage development environment.
reset    Nuke development environment and create a fresh one without any
         patches applied
sync     Resynchronize all existing patches, in order
apply    Apply all existing patches, in order
mark     Create a patch based on the difference between tip of applied patches
         and current code in development environment

make     Build extension from development environment
pack     Build, test, then package the extension
publish  Build, test, package, then publish the extension
         Optionally pass browser name to publish for only one browser
clean    Remove all build files

lmake    Build English locale file from locale definition
lsync    Synchronize (non-English) locale files with the latest build of the
         Crowdin project
         This will not rebuild the Crowdin project even if there are changes

config   Print active configuration data
reload   Reload configuration data
exit     Exit the terminal

Version Update Checklist

Pull filters updates
If needed, pull upstream updates then update about string and commit pin
If needed, pull upstream updates to build scripts
If needed, pull upstream updates to assets.json and manifest.json
If needed, pull upstream updates to 1p-filters.js and asset-viewer.js
If needed, build and pull locale updates
Bump version number
Test to make sure everything is working
Add tags to repositories, and upload packages
Upload packages to extension stores

Version Update Watchlist
These are the potential problems to look out for:

Font Awesome related CSS changes

Subresource Integrity Incidence Response Protocol
When there is a severe issue with the content of a subresource, an intervention
can be easily placed with the help of
UltimateMirror and
MirrorEngine:

Lock the subresource in UltimateMirror
Remove problematic content from UltimateMirror, if needed
Update assets.json so the sanitized subresource will be loaded from
UltimateMirror

Later, the intervention can be lifted as follows:

Update assets.json as appropriate, the subresource should no longer be
loaded from UltimateMirror
Wait a bit for cache to expire (takes about 10 minutes), then restart
MirrorEngine
Unlock the subresource in UltimateMirror

Tips
Do not forget to copy and commit generated patches from mark to make them
permanent. Also adjust the configuration file as appropriate.
To update a patch, simply paste further changes to the bottom of that patch and
sync them in. If something breaks, try disabling patches after that patch
temporarily.
To fix conflict, either edit the broken patch file manually or disable it
along with patches after it then recreate the changes.
",73
ninthDevilHAUNSTER/ArknightsAutoHelper,Python,"shaobao_adb

ææ¥æ¹èè¾å©èæ¬ï¼å½ç¶åªæ¯å¼åé¶æ®µï¼åªæ¯ååä¸çº¿æå°±å¾æ°ï¼

ADBShell
åºäºå¤ç¥æ¨¡æå¨éæäºå¤ç§å®åæ¨¡æå¨æä½æ¹æ³ï¼å¯ä»¥è¿è¡å®åè¾å©å¼åãå½ç¶ä½ è¦å¨çµèç«¯è·
è¿è¡é¡»ç¥
config.py
ADB_ROOT = r""D:\Program Files\Nox\bin""
ADB_HOST = ""127.0.0.1:62001""
SCREEN_SHOOT_SAVE_PATH = ""D:\\python_box\\shaobao_adb\\screen_shoot\\""
STORAGE_PATH = ""D:\\python_box\\shaobao_adb\\storage\\""

# arknights INFO
ArkNights_PACKAGE_NAME = ""com.hypergryph.arknights""
ArkNights_ACTIVITY_NAME = ""com.u8.sdk.U8UnityContext""
å¦æ³è¦äºæ¬¡å¼åï¼è¯·ä¿®æ¹config.pyä¸çç¸å³åæ°ãä»¥ç»å¯¹è·¯å¾ä¸ºä½³
ä¾èµå
# python çæ¬ 3.6 + 
Package    Version
---------- --------
certifi    2019.3.9
chardet    3.0.4
idna       2.8
Pillow     6.0.0
pip        10.0.1
requests   2.21.0
setuptools 39.1.0
soupsieve  1.9.1
tesserocr  2.4.0
urllib3    1.24.2
ç®åæ¯æçåè½

ADB æä»¤
ç¹å»å¨ä½
æå¨å¨ä½
æªå¾å¨ä½
è·åå­å¾
å­å¾ä¸ç®æ å­å¾æ¯è¾

",2
Harlekuin/SimQLe,Python,"SimQLe

The simple way to SQL



Perfect for no fuss SQL in your Python projects. Execute SQL and return simple
Recordsets. Manage several connections, and be certain that your production
databases aren't touched in your Integration Tests. Also, named parameters
across the board.
Installation
Repository
https://github.com/Harlekuin/SimQLe
Or choose your poison:

$ pip install simqle
$ poetry add simqle
$ pipenv install simqle

Once installed, requires a .connections.yaml file in the root of the project
that defines the connection strings the project should use. See the Connection
String section for syntax.
Usage
In Production
Get a result from the name of your connection, the SQL statement, and a dict
of parameters:
from simqle import recordset, load_connections

load_connections()

sql = ""SELECT name, age FROM people WHERE category = :category""
params = {""category"": 5}
result = recordset(con_name=""my-database"", sql=sql, params=params)
recordset() returns a tuple of (Data, Headings). ""Data"" is a list of row tuples.
Headings is a list of field names from the query.
In Integration Tests
Before running integration tests, set the SIMQLE_TEST environment variable
to True. This will cause the load_connections function to load the
test-connections (which should mirror the connections in terms of name and
type of database), and will cause the code in your project to run exactly the
same, but instead connect to your defined test connections instead.
The .connections.yaml File
Define the connection strings for production and test servers. The names of the test-connections should mirror the connections names. The file .connections.yaml should be in the root of your project. Each connection will be referred to by its name.
Example file:
connections:
    # The name of the connection - this is what will be used in your project
    # to reference this connection.
  - name: my-sql-server-database
    driver: mssql+pyodbc:///?odbc_connect=
    connection: DRIVER={SQL Server};UID=<username>;PWD=<password>;SERVER=<my-server>
    # some odbc connections require urls to be escaped, this is managed by
    # setting url_escaped = true:
    url_escape: true

    # File based databases like sqlite are slightly different - the driver
    # is very simple.
  - name: my-sqlite-database
    driver: sqlite:///
    # put a leading '/' before the connection for an absolute path, or omit
    # if it's relative to the project path
    connection: databases/my-database.db


test-connections:
    # the names of the test-connections should mirror the connections above.
  - name: my-sql-server-database
    driver: mssql+pyodbc:///?odbc_connect=
    # connecting to a different server here
    connection: DRIVER={SQL Server};UID=<username>;PWD=<password>;SERVER=<my-test-server>
    url_escape: true    

  - name: my-sqlite-database
    driver: sqlite:///
    connection: /tmp/my-test-database.db  # note the absolute path syntax
Author
Tom Malkin - tommalkin28@gmail.com
Release History

0.1.0

Add the basic skeleton of the project


0.1.1

Unit tests
Integration tests for sqlite added.
100% coverage


0.2.0

Added url_escape option in connections.yaml file
Integration tests added for mysql and postgresql



Road Map

all available relational databases tested.
scripts for easy project setup.
pypi upload.
default location connection file

",22
scottwillson/racing_on_rails,Ruby,"Racing on Rails is a bike racing association schedule, results, competitions, and membership database and website.
Open source (MIT license)
Ruby on Rails
http://rubyonrails.org/
Documentation, quick start
http://racingonrails.rocketsurgeryllc.com/
Google Group
http://groups.google.com/group/racing-on-rails
Source Code
https://github.com/scottwillson/racing_on_rails
RDoc
http://racingonrails.rocketsurgeryllc.com/rdoc
Issues
https://github.com/scottwillson/racing_on_rails/issues
Parallel tests
RECORD_RUNTIME=true DISABLE_SPRING=1 rake parallel:test[^test/{controllers,helpers,integration,lib,mailers,models,views}]
Requirements
Ruby 2.4
MySQL 5.6



",37
FyuriStudios/SFG,JavaScript,"Struggle for Gera
This is an original digital card game, currently in the very early pre-alpha development stages.
The SFG team consists of a group of friends who love to argue about what makes Hearthstone a bad game, or why Gwent sucks. When we realized that we could do something productive with our arguments like make our own game, we blew our own minds. So here we are. Here is the link to the official rules document. If the rules don't make any sense, sorry: We wrote them, so maybe it only makes sense to us.
The code
The frontend code is located here. The backend code is located here. Tests are located here.
The backend code is meant to be run using NodeJS on a server. It serves up a webpage (which is mostly just an embedded JS script, lol.) /static contains everything regarding the webpage.
",2
open-learning-exchange/open-learning-exchange.github.io,HTML,"What is this?
See what this is all about: http://open-learning-exchange.github.io/.
How to Contribute
First things first
Learn Markdown! Then check out MDwiki's quick start.
Whenever you feel stuck, go to MDwiki's own site for further information.
One Wiki Only? Fork It.
First off fork this repo and call it something like <MyProject>-wiki.
Multiple Wikis? Clone It.
In case would you like to create more than one wiki for the same GitHub user or organization, then forking won't cut it. At the moment of this writing GitHub won't allow you to fork a single repository multiple times for the same account.
There's a workaround to this, however on GitHub's web interface you won't see the sign that says ""forked from"" in your cloned repository.
Below instructions how to clone this repository using the CLI:
First off, create a new (empty) repository on GitHub, then;
git clone https://github.com/exalted/mdwiki-seed.git
cd mdwiki-seed
git remote add foobar <HTTPS/SSH Clone URL of the New Repository>
git push foobar gh-pages
Create a New Wiki
It all begins by creating an initial file structure for any language that you would like to support. For example, if you're interested having a wiki in English, then you will duplicate ll_CC folder and rename your copy to en. (For a complete list of languages [ll] and country codes [CC] see here.)
ll_CC is a starter template folder which you shouldn't ever edit directly, since you may loose your changes when MDwiki gets updated later.

If you want to have your wiki in more than one language, then you duplicate ll_CC as many times as necessary and rename each copy with the appropriate language and country code. (Country code is optional and it is only useful if you want to distinguish, for instance, American English from British English, such as: en_US and en_GB.)

Getting Started
You should have a language wiki folder by now, if not, go back and read above to create one.
Suppose your first wiki is going to be in English, hence you must have a folder called en, as previously described.

Open index.html file with your favorite plain text editor (the one that is at the same level where ll_CC and your language folder is located, NOT the one inside your language folder).
Find where it says ""Override ll_CC below with your default language and country code.""
Change refresh meta tag from url=ll_CC/ to url=en/ (trailing / is very important).

Structure
All file references here are relative to their respective language folder.



Name
Type
Description




index.md
File
Starting point (a.k.a. ""home page"") for your wiki. Note this is not the index.html, but index.md!


navigation.md
File
Various settings of your wiki (e.g., name of your wiki, items in the navigation bar at the top, etc.)


config.json
File
If you don't know what this is for, donât touch it.


pages
Folder
Ideally, inside this folder, you create one *.md file for every page inside your wiki (e.g., foo.md, much-longer-names-are-also-okay.md, etc.) You can also create as many subfolders as you need, just remember to link them accordingly.


uploads
Folder
An example folder structure where you could put other files. Although it is best to host your files somewhere else, like Dropbox, or a CDN, etc.



Best Practices
Relative URLs
Instead of using absolute URLs when linking one wiki page to another, use relative URLs.
For instance if en/pages/foo.md page had to link to en/pages/bar.md, it is enough to just add [Click here](bar.md) in your markdown.
Don't Host Your Uploads in Git(Hub)
Instead of hosting your uploads inside the uploads folder, consider using Dropbox, Google Drive, or a CDN.
Add References to Uploads
Whenever you can, avoid hosting your uploads using Git(Hub).
If you must add references to files hosted inside the uploads folder here's how to do it, for instance: ![Image Title](uploads/images/foo.png). Add that in your markdown and you're good to go.
How to Preview
In order to preview your changes locally, prior to publishing online, you may need to take some actions. Below some starting points for each operating system, also check out MDwiki's frequently asked questions section for some ideas.
Mac OS
The easiest way to serve up static sites on a Mac is to use Anvil. Go ahead and download it from their website, install and add a site using the status bar icon: simply select the folder where your wiki is located on your Mac.
If you don't want to download any apps, you can use the Terminal on your Mac and Python. To do this, go to your site folder in the Terminal app and type python -m SimpleHTTPServer 8000. This will start running a local server which you can navigate to by typing the URL localhost:8000 in any web browser.
Windows
Text editors like Brackets, and VS Code and Atom (with extensions) can be used to preview your files locally. However, it is recommended that you use the online GitHub editor and RawGit to make and view your changes in your own branch of your fork of this repository because this is the only sure way to preview your changes for live accuracy.
Linux
You can use Prax. Prax is a pure ruby alternative to Pow!! that runs on GNU/Linux.
For Developers
You don't need to read below here or do anything at all if you're only interested creating your own wiki. This section is for developers or maintainers of this repository.
Make changes to MDwiki

If you haven't already, install Node.
Open a command prompt/shell/git bash and navigate to your repo's directory.
Run npm install to install mdwiki dependencies.
For development, you can run ./node_modules/.bin/grunt devel or grunt devel if you have grunt installed globally.  This will start grunt watching the index.tmpl and *.js files for changes, which you can view at localhost:35729. The index.html file that it builds is the debug version of the html with the full js files.
As a note, the index.tmpl is where our custom CSS can be found.  Please only add CSS within the comment denoted section.
Once you have completed your changes, run ./node_modules/.bin/grunt release to build an index.html with minified js.

",28
apache/flink,Java,"Apache Flink
Apache Flink is an open source stream processing framework with powerful stream- and batch-processing capabilities.
Learn more about Flink at http://flink.apache.org/
Features


A streaming-first runtime that supports both batch processing and data streaming programs


Elegant and fluent APIs in Java and Scala


A runtime that supports very high throughput and low event latency at the same time


Support for event time and out-of-order processing in the DataStream API, based on the Dataflow Model


Flexible windowing (time, count, sessions, custom triggers) across different time semantics (event time, processing time)


Fault-tolerance with exactly-once processing guarantees


Natural back-pressure in streaming programs


Libraries for Graph processing (batch), Machine Learning (batch), and Complex Event Processing (streaming)


Built-in support for iterative programs (BSP) in the DataSet (batch) API


Custom memory management for efficient and robust switching between in-memory and out-of-core data processing algorithms


Compatibility layers for Apache Hadoop MapReduce


Integration with YARN, HDFS, HBase, and other components of the Apache Hadoop ecosystem


Streaming Example
case class WordWithCount(word: String, count: Long)

val text = env.socketTextStream(host, port, '\n')

val windowCounts = text.flatMap { w => w.split(""\\s"") }
  .map { w => WordWithCount(w, 1) }
  .keyBy(""word"")
  .timeWindow(Time.seconds(5))
  .sum(""count"")

windowCounts.print()
Batch Example
case class WordWithCount(word: String, count: Long)

val text = env.readTextFile(path)

val counts = text.flatMap { w => w.split(""\\s"") }
  .map { w => WordWithCount(w, 1) }
  .groupBy(""word"")
  .sum(""count"")

counts.writeAsCsv(outputPath)
Building Apache Flink from Source
Prerequisites for building Flink:

Unix-like environment (we use Linux, Mac OS X, Cygwin)
git
Maven (we recommend version 3.2.5)
Java 8 (Java 9 and 10 are not yet supported)

git clone https://github.com/apache/flink.git
cd flink
mvn clean package -DskipTests # this will take up to 10 minutes

Flink is now installed in build-target
NOTE: Maven 3.3.x can build Flink, but will not properly shade away certain dependencies. Maven 3.0.3 creates the libraries properly.
To build unit tests with Java 8, use Java 8u51 or above to prevent failures in unit tests that use the PowerMock runner.
Developing Flink
The Flink committers use IntelliJ IDEA to develop the Flink codebase.
We recommend IntelliJ IDEA for developing projects that involve Scala code.
Minimal requirements for an IDE are:

Support for Java and Scala (also mixed projects)
Support for Maven with Java and Scala

IntelliJ IDEA
The IntelliJ IDE supports Maven out of the box and offers a plugin for Scala development.

IntelliJ download: https://www.jetbrains.com/idea/
IntelliJ Scala Plugin: http://plugins.jetbrains.com/plugin/?id=1347

Check out our Setting up IntelliJ guide for details.
Eclipse Scala IDE
NOTE: From our experience, this setup does not work with Flink
due to deficiencies of the old Eclipse version bundled with Scala IDE 3.0.3 or
due to version incompatibilities with the bundled Scala version in Scala IDE 4.4.1.
We recommend to use IntelliJ instead (see above)
Support
Donât hesitate to ask!
Contact the developers and community on the mailing lists if you need any help.
Open an issue if you found a bug in Flink.
Documentation
The documentation of Apache Flink is located on the website: http://flink.apache.org
or in the docs/ directory of the source code.
Fork and Contribute
This is an active open-source project. We are always open to people who want to use the system or contribute to it.
Contact us if you are looking for implementation tasks that fit your skills.
This article describes how to contribute to Apache Flink.
About
Apache Flink is an open source project of The Apache Software Foundation (ASF).
The Apache Flink project originated from the Stratosphere research project.
",8628
swdotcom/swdc-vscode,TypeScript,"  
Code Time for Visual Studio Code

Programming metrics right in VS Code.




Power up your development
In-editor dashboard
Get daily and weekly reports of your programming activity right in your code editor.
Status bar metrics
After installing our plugin, your status bar will show real-time metrics about time coded per day.
Weekly email reports
Get a weekly report delivered right to your email inbox.
Data visualizations
Go to our web app to get simple data visualizations, such as a rolling heatmap of your best programming times by hour of the day.
Calendar integration
Integrate with Google Calendar to automatically set calendar events to protect your best programming times from meetings and interrupts.
More stats
See your best music for coding and the speed, frequency, and top files across your commits.
Why you should try it out

Automatic time reports by project
See what time you code your bestâfind your âflowâ
Defend your best code times against meetings and interrupts
Find out what you can learn from your data

Itâs safe, secure, and free
We never access your code
We do not process, send, or store your proprietary code. We only provide metrics about programming, and we make it easy to see the data we collect.
Your data is private
We will never share your individually identifiable data with your boss. In the future, we will roll up data into groups and teams but we will keep your data anonymized.
Free for you, forever
We provide 90 days of data history for free, forever. In the future, we will provide premium plans for advanced features and historical data access.
Getting started


Install the Code Time plugin from the Visual Studio Code Marketplace.


After installing Code Time, an alert will appear prompting you to login (you can also click on ""Code Time"" in the status bar of Visual Studio Code.


",51
LFDLFoundation/lfdl-landscape,None," 
Linux Foundation Deep Learning (LFDL) Landscape


LFDL Landscape

Current Version
Interactive Version
New Entries
Logos
Proper SVGs
Corrections
External Data
Best Practices Badge
Non-Updated Items
License
Formats
Installation
Vulnerability reporting
Adjusting the Landscape View



This landscape is intended as a map to explore open source artificial intelligence (AI), machine learning (ML), and deep learning (DL) projects, and also shows the member companies of the LF Deep Learning Foundation. It is modelled after the Cloud Native Computing Foundation (CNCF) landscape and based on the same open source code.
Current Version

Interactive Version
Please see landscape.lfdl.io.
New Entries

Projects must be open source and hosted on or mirrored to GitHub.
AI, ML, and DL projects with at least 300 GitHub stars that clearly fit in an existing category are generally included. Put the project in the single category where it best fits.
We are unlikely to create a new category for projects as we'd rather find the best home with the current options.
Your project or company needs a logo and the logo needs to include the name.
Crunchbase organization should be the company or organization that controls the software. That is normally the owner of the trademark, whether or not a trademark has been formally filed.

If you think your project should be included, please open a pull request to add it to landscape.yml. For the logo, you can either upload an SVG to the hosted_logos directory or put a URL as the value, and it will be fetched.
Netlify will generate a staging server for you to preview your updates. Please check that the logo and information appear correctly and then add LGTM to the pull request confirming your review and requesting a merge.
Logos
The following rules will produce the most readable and attractive logos:

We require SVGs, as they are smaller, display correctly at any scale, and work on all modern browsers. If you only have the logo in another vector format (like AI or EPS), please open an issue and we'll convert it to an SVG for you, or you can often do it yourself at https://cloudconvert.com/. Note that you may need to zip your file to attach it to a GitHub issue. Please note that we require pure SVGs and will reject SVGs that contain embedded PNGs since they have the same problems of being bigger and not scaling seamlessly. We also require that SVGs convert fonts to outlines so that they will render correctly whether or not a font is installed. See Proper SVGs below.
When multiple variants exist, use stacked (not horizontal) logos. For example, we use the second column (stacked), not the first (horizontal), of CNCF project logos.
Don't use reversed logos (i.e., with a non-white, non-transparent background color). If you only have a reversed logo, create an issue with it attached and we'll produce a non-reversed version for you.
Logos must include the company, product or project name in English. It's fine to also include words from another language. If you don't have a version of your logo with the name in it, please open an issue and we'll create one for you (and please specify the font).
Match the item name to the English words in the logos. So an Acme Rocket logo that shows ""Rocket"" should have product name ""Rocket"", while if the logo shows ""Acme Rocket"", the product name should be ""Acme Rocket"". Otherwise, logos looks out of place when you sort alphabetically.
Google images is often the best way to find a good version of the logo (but ensure it's the up-to-date version). Search for grpc logo filetype:svg but substitute your project or product name for grpc.
You can either upload an SVG to the hosted_logos directory or put a URL as the value, and it will be fetched.

Proper SVGs
SVGs need to not rely on external fonts so that they will render correctly in any web browser, whether or not the correct fonts are installed. If you have the original AI file, here are the steps in Illustrator to create a proper SVG:

Open file in Illustrator
Select all text
With the text selected, go to Object > Expand in the top menu
Export file by going to File > Export > Export As in top menu
Select SVG from the format drop down and make sure that ""Use Artboards"" is checked
This will open a SVG options box, make sure to set Decimal to 5 (that is the highest possible, so to ensure that sufficient detail is preserved)
Click Okay to export

Corrections
Please open a pull request with edits to landscape.yml. The file processed_landscape.yml is generated and so should never be edited directly.
If the error is with data from Crunchbase you should open an account there and edit the data. If you don't like a project description, edit it in GitHub. If your project isn't showing the license correctly, you may need to paste the unmodified text of the license into a LICENSE file at the root of your project in GitHub, in order for GitHub to serve the license information correctly.
External Data
The canonical source for all data is landscape.yml. Once a day, we download data for projects and companies from the following sources:

Project info from GitHub
Funding info from Crunchbase
Market cap data from Yahoo Finance
CII Best Practices Badge data

The update server enhances the source data with the fetched data and saves the result in processed_landscape.yml. The app loads a JSON representation of processed_landscape.yml to display data.
Best Practices Badge
As explained at https://bestpractices.coreinfrastructure.org/:

The Linux Foundation (LF) Core Infrastructure Initiative (CII) Best Practices badge is a way for Free/Libre and Open Source Software (FLOSS) projects to show that they follow best practices. Projects can voluntarily self-certify, at no cost, by using this web application to explain how they follow each best practice. The CII Best Practices Badge is inspired by the many badges available to projects on GitHub. Consumers of the badge can quickly assess which FLOSS projects are following best practices and as a result are more likely to produce higher-quality secure software.

The interactive landscape displays the status (or non-existence) of a badge for each open-source project. There's also a feature not available through the filter bar to see all items with and without badges. Note that a passing badge is a requirement for projects to graduate in the CNCF.
Non-Updated Items
We generally remove open source projects that have not had a commit in over 3 months. Note that for projects not hosted on GitHub, we need them to mirror to GitHub to fetch updates, and we try to work with projects when their mirrors are broken. Here is view of projects sorted by last update: https://landscape.lfdl.io/grouping=no&license=open-source&sort=latest-commit
We generally remove closed source products when they have not tweeted in over 3 months. This doesn't apply to Chinese companies without Twitter accounts, since Twitter is blocked there. Here is a view of products sorted by last tweet: https://landscape.lfdl.io/grouping=no&license=not-open-source&sort=latest-tweet
Items that have been removed can apply to be re-added using the regular New Entries criteria above.
License
This repository contains data received from Crunchbase. This data is not licensed pursuant to the Apache License. It is subject to Crunchbaseâs Data Access Terms, available at https://data.crunchbase.com/v3.1/docs/terms, and is only permitted to be used with this Landscape Project which is hosted by the Linux Foundation.
Everything else is under the Apache License, Version 2.0, except for project and product logos, which are generally copyrighted by the company that created them, and are simply cached here for reliability. The trail map, static landscape, serverless landscape, and landscape.yml file are alternatively available under the Creative Commons Attribution 4.0 license.
Formats
The LFDL Landscape is available in these formats:

PNG
PDF

Installation
You can install and run locally with the install directions. It's not necessary to install locally if you just want to edit landscape.yml. You can do so via the GitHub web interface.
Vulnerability reporting
Please open an issue or, for sensitive information, email info@cncf.io.
Adjusting the Landscape View
The file src/components/MainContent2.js describes the key elements of a
landscape big picture. It specifies where to put these sections: App Definition
and Development, Orchesteration & Management, Runtime,  Provisioning, Cloud,
Platform, Observability and Analyzis, Special. Also it specifies where to
locate the link to the serverless preview and an info with a QR code.
All these elements should have top, left, width and height properties to
position them. rows and cols specify how much columns or rows we expect in a
given horizontal or vertical section.
When we see that those elements can not fit the sections, we need to either increase
the width of all the horizontal sections, or increase height and amount of rows
in a single horitzontal section and adjust the position of sections below.
Beside that, we have to adjust the width of a parent div (1620), the width in a
src/components/BigPicture/FullscreenLandscape.js (1640) and the width in a
tools/renderLandscape.js (6560, because of x4 zoom and margins)
Sometimes the total height is changed too, then we need to adjust the height the
same way as we adjust the width.
We have an experimental fitWidth property, it is good when you want to get rid of
an extra space on the right of a section.
The best way to test that layout is ok, is to visit /landscape, and if it looks ok, run PORT=3000 babel-node tools/renderLandscape and see the rendered png files, they are in src/images folder.
",40
libretro/RetroArch,C,"

RetroArch
RetroArch is the reference frontend for the libretro API.
Popular examples of implementations for this API includes video game system emulators and game engines as well as
more generalized 3D programs.
These programs are instantiated as dynamic libraries. We refer to these as ""libretro cores"".



libretro
libretro is an API that exposes generic audio/video/input callbacks.
A frontend for libretro (such as RetroArch) handles video output, audio output, input and application lifecycle.
A libretro core written in portable C or C++ can run seamlessly on many platforms with very little to no porting effort.
While RetroArch is the reference frontend for libretro, several other projects have used the libretro
interface to include support for emulators and/or game engines. libretro is completely open and free for anyone to use.
libretro API header
Binaries
Latest binaries are currently hosted on the buildbot.
Support
To reach developers, either make an issue here on GitHub, make a thread on the forum, chat on discord, or visit our IRC channel: #retroarch @ irc.freenode.org.
Documentation
See our Documentation Center. On Unix, man-pages are provided.
More developer-centric stuff is found here.
Related projects

Cg/HLSL shaders: common-shaders
slang shaders: slang-shaders
GLSL shaders: glsl-shaders
Helper scripts to build libretro implementations: libretro-super
GitHub mirrors of projects, useful for generating diff files: libretro-mirrors

Philosophy
RetroArch attempts to be small and lean
while still having all the useful core features expected from an emulator.
It is designed to be very portable and features a gamepad-centric and touchscreen UI.
It also has a full-featured command-line interface.
In some areas, RetroArch goes beyond and emphasizes on not-so-common technical features such as multi-pass shader support,
real-time rewind (Braid-style), video recording (using FFmpeg), run-ahead input latency removal, etc.
RetroArch also emphasizes being easy to integrate into various launcher frontends.
Platforms
RetroArch has been ported to the following platforms:

DOS
Windows
Linux
Emscripten (WebAssembly and JavaScript)
FreeBSD
NetBSD
OpenBSD
Haiku
Solaris
macOS (PPC, x86-32 and x86-64)
PlayStation 3
PlayStation Portable
PlayStation Vita
Original Microsoft Xbox
Microsoft Xbox 360 (Libxenon/XeXDK)
Nintendo GameCube
Nintendo Wii
Nintendo Wii U
Nintendo 3DS
Nintendo Switch
Nintendo NES/SNES Classic Edition
Raspberry Pi
Android
iOS
Blackberry

Dependencies (PC)
There are no true hard dependencies per se.
On Windows, RetroArch can run with only Win32 as dependency.
On Linux, there are no true dependencies. For optimal usage, the
following dependencies come as recommended:

GL headers / Vulkan headers
X11 headers and libs, or EGL/KMS/GBM

OSX port of RetroArch requires latest versions of XCode to build.
RetroArch can utilize these libraries if enabled:

nvidia-cg-toolkit
libfreetype2 (TTF font rendering on screen)

RetroArch needs at least one of these audio driver libraries:

ALSA
OSS
RoarAudio
RSound
OpenAL
JACK
SDL
PulseAudio
XAudio2 (Win32, Xbox 360)
DirectSound (Win32, Xbox 1)
CoreAudio (OSX, iOS)

To run properly, RetroArch requires a libretro implementation present; however, as it's typically loaded
dynamically, it's not required at build time.
Dependencies (Console ports, mobile)
Console ports have their own dependencies, but generally do not require
anything other than what the respective SDKs provide.
Configuring
The default configuration is defined in config.def.h.
It is not recommended to change this unless you know what you're doing.
These can later be tweaked by using a config file.
A sample configuration file is installed to /etc/retroarch.cfg. This is the system-wide config file.
RetroArch will on startup create a config file in $XDG\_CONFIG\_HOME/retroarch/retroarch.cfg if it does not exist.
Users only need to configure a certain option if the desired value deviates from the value defined in config.def.h.
To configure joypads, use the built-in menu or the retroarch-joyconfig command-line tool.
Compiling and installing
Instructions for compiling and installing RetroArch can be found in the Libretro/RetroArch Documentation Center.
CRT 15Khz Resolution Switching
CRT SwitchRes will turn on, on the fly. However, you will need to restart RetroArch to disable it. With CRT SwitchRes enable RetroArch will start in 2560 x 480 @ 60.
If you are running Windows, before enabling the CRT SwitchRes options please make sure you have installed CRTEmudriver and installed some modelines. The minimum modelines for all games to switch correctly are:

2560 x 192 @ 60.000000
2560 x 200 @ 60.000000
2560 x 240 @ 60.000000
2560 x 224 @ 60.000000
2560 x 237 @ 60.000000
2560 x 256 @ 50.000000
2560 x 254 @ 55.000000
2560 x 448 @ 60.000000
2560 x 480 @ 60.000000

Install these modelines replacing 2560 with your desired super resolution. The above resolutions are NTSC only so if you would be playing any PAL content please add PAL modelines:

2560 x 192 @ 50.000000
2560 x 200 @ 50.000000
2560 x 240 @ 50.000000
2560 x 224 @ 50.000000
2560 x 288 @ 50.000000
2560 x 237 @ 50.000000
2560 x 254 @ 55.000000
2560 x 448 @ 50.000000
2560 x 480 @ 50.000000

Some games will require higher PAL resolutions which should also be installed:

2560 x 512 @ 50.000000
2560 x 576 @ 50.000000

Ideally install all these modelines and everything will work great.
Super Resolutions
The default super resolution is 2560. It is displayed just under the CRT switch option, which can be found in video settings. This can be changed within the retroarch.cfg. The only compatible resolutions are 1920, 2560 and 3840. Any other resolutions will be ignored and native switching will be activated.
Native Resolutions
If native resolutions are activated you will need a whole new set of modelines:


256 x 240 @ 50.006977 SNESpal


256 x 448 @ 50.006977 SNESpal


512 x 224 @ 50.006977 SNESpal


512 x 240 @ 50.006977 SNESpal


512 x 448 @ 50.006977 SNESpal


256 x 240 @ 60.098812 SNESntsc


256 x 448 @ 60.098812 SNESntsc


512 x 240 @ 60.098812 SNESntsc


512 x 224 @ 60.098812 SNESntsc


512 x 448 @ 60.098812 SNESntsc


256 x 192 @ 59.922745 MDntsc


256 x 224 @ 59.922745 MDntsc


320 x 224 @ 59.922745 MDntsc


320 x 240 @ 59.922745 MDntsc


320 x 448 @ 59.922745 MDntsc


320 x 480 @ 59.922745 MDntsc


256 x 192 @ 49.701458 MDpal


256 x 224 @ 49.701458 MDpal


320 x 224 @ 49.701458 MDpal


320 x 240 @ 49.701458 MDpal


320 x 288 @ 49.701458 MDpal


320 x 448 @ 49.701458 MDpal


320 x 480 @ 49.701458 MDpal


320 x 576 @ 49.701458 MDpal


256 x 288 @ 49.701458 MSYSpal


256 x 240 @ 60.098812 NESntsc


256 x 240 @ 50.006977 NESpal


640 x 237 @ 60.130001 N64ntsc


640 x 240 @ 60.130001 N64ntsc


640 x 480 @ 60.130001 N64ntsc


640 x 288 @ 50.000000 N64pal


640 x 480 @ 50.000000 N64pal


640 x 576 @ 50.000000 N64pal


256 x 252 @ 49.759998 PSXpal


320 x 252 @ 49.759998 PSXpal


384 x 252 @ 49.759998 PSXpal


640 x 252 @ 49.759998 PSXpal


640 x 540 @ 49.759998 PSXpal


384 x 240 @ 59.941002 PSXntsc


256 x 480 @ 59.941002 PSXntsc


352 x 240 @ 59.820000 Saturn/SGFX_NTSCp


704 x 240 @ 59.820000 SaturnNTSCp


352 x 480 @ 59.820000 SaturnNTSCi


704 x 480 @ 59.820000 SaturnNTSCi


352 x 288 @ 49.701458 SaturnPALp


704 x 288 @ 49.701458 SaturnPALp


352 x 576 @ 49.701458 SaturnPALi


704 x 576 @ 49.701458 SaturnPALi


240 x 160 @ 59.730000 GBA


320 x 200 @ 60.000000 Doom


// Arcade

400 x 254 @ 54.706841 MK
384 x 224 @ 59.637405 CPS1

These modelines are more accurate giving exact hz. However, some games may have unwanted results. This is due to mid-scanline resolution changes on the original hardware. For the best results super resolutions are the way to go.
CRT resolution switching & MAME
Some arcade resolutions can be very different from consumer CRTs. There is resolution detection to ensure MAME games will be displayed in the closest available resolution but drawn at their native resolution within this resolution. Meaning that the MAME game will look just like the original hardware.
MAME ROMs that run in a vertical aspect like DoDonPachi need to be rotated within MAME before resolution switching and aspect correction will work. Do this before enabling CRT SwitchRes so that RetroArch will run in your desktop resolution. Once you have rotated any games that may need it turn CRT SwitchRes on.
",3212
ConceptJunkie/rpn,Python,"rpn
rpn is a command-line Reverse-Polish Notation calculator.
rpn supports arithmetic with arbitrary precision, powers and roots, logarithms, algebraic functions (including polynomials arithmetic and solving), trigonometric functions, complex numbers, computer science related functions (bitwise math, base conversion), number theory functions, astronomical functions, prime number calculations and lookup, can operate with single operands or lists of operands and supports a wide variety of flexible unit conversions comparable to the GNU units program.
Updates
Update - April 26, 2019
Version 8 is released.   This version includes a small number of new features, but the primary focus was a significant refactor of the unit conversion code.  The 'convert' operator is more powerful and easier to use.
Update - March 8, 2019
rpnChilada 7.2.3 fixes the unit conversion bug.  Please upgrade.
Update - March 7, 2019
This is embarrassing.  I just discovered a long-standing bug with the unit conversion code where for some reason it thinks there are 59021.97 seconds in a day.  I've narrowed the bug down to between the 7.0.0 and 7.1.0 releases.  This is weird because
every other unit conversion I checked, including other conversions with days and seconds work correctly.  The makeUnits code has been in place for about 3 or 4 years and always seemed to be rock-solid.  I'll try to push a 7.2.2 in the next few days, or
possibly even 7.3.0 depending on what else gets included.
Update - February 26, 2019
OK, stick a fork in 7.2.0.  It's done.  I'd intended to get back to releasing often, but 10 months is not ""often"".
Aside from the usual ton of bug fixes and minor improvements, this version offers several operators having to do with the physics of black holes.  See ""rpn help physics"" for details.
The 7.2.0 release will show up on PyPI in the next day or two as soon as I have some time to test the wheel.
Update - February 22, 2019
Not much has happened with rpn lately, but I do have some good plans.  I haven't released 7.2 mostly due to laziness, but I've also got some solid ideas for improvements with the unit conversion functionality.  For one thing, I want to fold the constants into the units database, and I have an idea for adding some implicit unit conversion.
I've also wanted to migrate from pyephem, which is no longer being developed, to Skyfield, which is recommended by the people who used to make pyephem.  Skyfield is also a pure Python library, which makes my life easier.  However, Skyfield is a more low-level library, so there's not a one-to-one correspondence for most of the pyephem functionality I've been using.
Update - February 21, 2018
rpn is available on pypi.org.  Since there always was a project called ""rpn"", I had to come up with a new name, so I'm happy to introduce ""rpnChilada"".
Windows users will want to use Christophe Gohlke's Windows installers for gmpy2 and pyephem at https://www.lfd.uci.edu/~gohlke/pythonlibs/.
Update - August 15, 2016
I am very excited that people have started noticing rpn!
Please continue with comments, suggestions and bug reports. rpn has lots of little bugs and possibly some big ones, too, and although I have unit tests, most of the time, I find bugs from using it.
I especially want to thank the folks at The Nineteenth Byte on Stack Exchange for their nice comments. I also love solving puzzles with rpn, so if there's something you'd like to see it be able to do, drop me a line at rickg@his.com.
I'll try to focus on improving the help in the near future.
Update - July 19, 2016
I don't know if anyone has ever looked at this project... not even my Mom. But anyhow, I wanted to leave an update anyway. The ""imminent"" release of version 7 is anything but. I have been too lazy to tackle trying to make the wheel work correctly. I've been making small additions here and there, including bug fixes whenever I find problems.
Currently, my short list is topped with switching to SQLite for caching function results to disk. I was experimenting with the sigma function and found that once the cache of values got past a million, loading it had become unreasonably slow. I think it would also be a very good idea to convert the prime number data files to SQLite tables as well.
There are a few Python 2 compatibility problems that remain, and those should be easy to fix, but I've been too busy with a combiniation of real life and general laziness. The conversion to using generators mentioned in the last update is complete and has greatly improved performance for a lot of operators.
RPN continues to proceed slowly and it works just fine right now, so it can be used just fine despite being a ""pre-release"".
Update - November 16, 2015
The scope of changes for version 7 keeps growing. The transition to lazy list evaluation (using generators) is going to be a very big change and currently a lot of operators are broken.
It is recommended that anyone using RPN from Git stick with the 7.0.alpha1 tag for the time being.
Update - October 15, 2015
I've decided the upcoming release will be version 7 since so much has been added, a lot has been reorganized and I've gotten serious about unit tests.
An official release of version 7 probably won't be for a while, because I really want to be able to release it on PyPI. There's a lot of work I want to do before cutting another release, and it's going to take some time, but the current git master contains all the latest features and is working fine.
rpn should still work on Android, but there are problems with the ephem library. I think it has to do with building the AstroLib code, and haven't had a chance to try to diagnose the problem.
Update - August 5, 2015
I am working on creating a wheel for rpn, and I'm hoping I can also make it Python 2 compatible before cutting another release. The biggest roadblock is just getting some round tuits instead of adding in new operators, which is much more fun.
Another cool update: rpn can now be run on Android with the Termux app
(http://termux.com/)! Right now, it fails a unit test having to do with date formatting, which I haven't gotten around to investigating, but otherwise it works great. Where else can you factor a 50-digit number on your Android device?

The current release is 8.0.0.
See ""rpn help settings"" for more information.
Running RPN using the source:
rpn is written in Python 3, and requires several libraries for the hard math stuff (gmpy2 is optional, but recommended for improved performance).
You will need to install the following prerequisites:
arrow>=0.13.1
convertdate>=2.1.3
ephem>=3.7.6.0
geopy>=1.19.0
gmpy2>=2.0.8
importlib_resources>=1.0.2
mpmath>=1.1.0
numpy>=1.16.2
pyreadline>=2.1
pytz>=2018.9
rpnChiladaData>=1.0.0
skyfield>=1.10
timezonefinder>=4.0.2
tzlocal>=1.5.1

Windows users will want to use Christophe Gohlke's Windows installers for gmpy2 and pyephem at https://www.lfd.uci.edu/~gohlke/pythonlibs/.
Using rpnChilada:
rpnChilada is very easy to use.  It's just like any RPN calculator: Operands go first, then the operators. All examples assume rpn is an alias for python /<path-to-rpn>/rpn.py.  In interactive mode, you leave off the rpn.
I always create an alias for ""python rpn.py"" called ""rpn"".  If you are using the package installed with pip, there are commands in the scripts directories called ""rpn"" and ""rpnChilada"" to launch rpnChilada.
Unit tests can be run with the testRPN command (when installed from the wheel) or by running testRPN.py from the rpn/ directory.
For instance:
rpn 2 2 +

will calculate 2 + 2.
rpn supports more than 900 operators. (rpn _dump_operators will list them all.)
The entire operator list is also included at the bottom of this document.
rpn has pretty extensive built-in help, although the help files are not complete. However, all operators have at least a brief description, and most are obvious enough to use easily.
Start with rpn help for an overview. To dive right in, see rpn help examples. In interactive mode, typing help will launch help mode. Then, topics will print out a list of help topics and exit will return to rpn.
The data files are stored in the same location as rpn.py in a subdirectory called rpndata/.
If you really want to generate prime numbers, see my ""primes"" project: https://github.com/ConceptJunkie/primes I've calculated the first 15 billion prime numbers and will someday update the rpn lookup tables.
The project https://github.com/ConceptJunkie/rpnChiladaData provides the compiled prime number data files.  If you installed rpnChilada with pip, then this data will be automatically installed.
rpn also provides a simple interface for accessing The On-Line Encyclopedia of Integer Sequences (http://oeis.org), see rpn help special and rpn help oeis.
rpnChilada used to provide a Windows installer, but I haven't been able to do that since version 6.4.0.  I hope to bring that back some day.
Feedback, Comments, Bug Reports:
Any feedback is welcome at rickg@his.com.  This was originally an exercise to learn Python, but slowly blossomed into something really useful and fun, so I wanted to share it. rpn also exposes just a few of the features of the amazing mpmath library (by Fredrik Johansson, http://mpmath.org/) which is where almost all the hard math stuff is actually done.
Rick Gutleber
rickg@his.com
p.s. rpn is licensed under the GNU GPL version 3.0. See (see (http://www.gnu.org/licenses/gpl.html) for more information).
Release Notes
8.0.0
The unit conversion code has been heavily refactored and works much better now.
Added the 'base_units' and 'dimensions' operators, mostly for testing purposes.
Added '_dump_conversions' and '_dump_cache', also for testing purposes.
rpnChilada is now smart enough to recognize when an OEIS request has failed,
and to ignore the cached result stored as a result.  If it detects that the
cached value is empty, it will perform the request again and recache the
result.
Help now supports units and constant operators after way too long.  Filling in
the help info for the units and constant operators, along with all the existing
help info that's missing, will take a while, and is continuing.
rpnChilada has officially dropped Python 2 support.  I rarely tested it anyway.
Added 'wind_chill' and 'heat_index' operators.
The unit tests now confirm that aliases do not collide with other reserved
words.  The alias creation for generated types has also been cleaned up.
The astronomy functionality has been refactored to support migrating to the
skyfield library from pyephem.
Removed the 'break_on' operator because it no longer works.  It will be
re-implemented in the future.
Added 'to_ethiopian', 'to_ethiopian_name' and 'from_ethiopian' operators for
converting to and from the Ethiopian calendar.
7.2.5
I fat-fingered an addition to the requirements.txt file.  :-/
7.2.4
Just a bunch of fixes.  makeUnits has been improved a bit, and I've validated that all conversions exist, and are consistent.
7.2.3
I messed up the upload for 7.2.2.  No code changes, just fixed packaging.
7.2.2
A big change that doesn't affect functionality is that the prime number data now resides in a separate package called rpnChiladaData.  This data rarely changes so there's no reason to download it.
A major bug was uncovered after almost a year.  rpnChilada thought there were 51920.97 seconds in a day because of a typo.  This has been fixed, and I figured out how to detect other similar problems if they exist.  This change will be implemented in the next few days.
7.2.1
Unit conversion is now a lot smarter because the automatically-generated area and volume units are generated more intelligently.  This means expressions using the ""square"" and ""cubic"" units will convert automatically and you won't end up with something like ""foot^2/square_mile"".
...and yes, a few bug fixes.
7.2.0
Added 'random_element' operator.
The gmpy2 digits( ) function is a much faster way to convert numbers to bases 2 through 62.
Added support for using yafu for factoring.
Added 'aliquot_limit' operator.
Added support for user configuration:  'set_config', 'get_config', 'delete_config' and 'dump_config'.
Added the 'mothers_day', 'fathers_day' and 'advent' operators.
Added the 'molar_gas_constant', 'aliquot_limit' and 'distance' operators (the old 'distance' operator is now called 'geo_distance').
Added unit tests for converting units, and made a few fixes accordingly.
Verbose mode for factoring gets turned on with -D.
Oops, there were two operators named 'distance'.  'distance' now refers to the physics operator and the geography operator is now named 'geo_distance'.
The 'acceleration' operator has been implemented.
The derived Planck units are now calculated, instead of hard-coded.
Block Hole operators:  'black_hole_entropy', 'black_hole_lifetime', 'black_hole_luminosity', 'black_hole_mass', 'black_hole_radius' (was 'schwarzchild_radius'), 'black_hole_surface_area', 'black_hole_surface_gravity', 'black_hole_temperature'
...and the usual bug fixes.
7.0.0
Version 7 represents over 2-1/2 years of work and I neglected to keep track of the changes.
There are probably around 200 more operators since 6.4 was released, and I replaced the factoring code with a much faster verison.
rpn now supports user-defined variables and functions, including persistent variables and functions.
6.4.0 - ""Factoring Fun""
Revamped factorization to be much, much faster, using the Brent-Pollard
algorithm instead of just brute-force dividing.   More to come...
Added the 'magnetic_constant', 'electric_constant', 'rydberg_constant',
'newtons_constant' and 'fine_structure' operators.
Added 'eulerphi' operator.
Added caching for factorizations.  I often factor the same numbers over and over (like when I'm playing with the Fibonaccis) so it made sense to cache the results for non-trivial factoring.
Added the 'sigma, 'aliquot', 'polypower', 'mobius' and 'mertens' operators.  The old 'mertens' operator was renamed to 'mertens_constant'.  The 'aliquot' operator is another use-case for caching factorizations... try it with 276.
rpn can can now factor the first 450 or so in a reasonably short time.
Added the 'frobenius', 'slice', 'sublist', 'left' and 'right' operators.
Added 'crt' operator.
...and the usual slew of bug fixes.
6.3.0
Added the 'geomean' operator.
Added the 'argument' and 'conjugate' operators.
Fixed 'trianglearea'.  It's been wrong for a long time.  Sorry.
Added the 'fibonorial' operator.
Added the 'eulerbrick' operator.
Added the 'unlist' operator.
Added the 'makepyth3' and 'makepyth4' operators.
Added the 'equal', 'greater', 'less', 'not_equal', 'not_greater', and
'not_less' operators.
Added the 'reduce' operator.
Added the 'lcm' operator.
The 'pascal' operator was renamed to 'pascaltri' to avoid a collision with the 'pascal' unit.
Fixed several minor bugs.
6.2.0
Experimental support for mpath plotting functionality using the new
operators, 'plot', 'plot2', 'plotc'.  These operators are not supported
in the Windows installer.
'quit' is now an alias for 'exit' in interactive mode and help mode.
Improvements in function definition.  'y' and 'z' are now operators, allowing for defining functions on 2 or 3 variables.
Operators 'eval2' and 'eval3' allow for evaluation of 2 and 3 variable
operators.
rpn now throws an error if a user-defined function is invalidly specified, instead of going into an infinite loop.
'filter' allows filtering a list based on a user-defined function.
If the units in a measurement cancel out, then the measurement is converted back to a numerical value.
Added 'rand_' and 'randint_' operators.
Added the 'debruijn' operator.
Fixed several minor bugs.
6.1.0
New operators:  'maxdouble', 'maxfloat', 'mindouble', 'minfloat'
Base conversion for output is no longer limited to 1000 digits.  There's no reason to do that.
'rpn 0 cf' now throws an error rather than dividing by 0.
6.0.1
Added code to prevent scientific notation from messing up base conversions for the integral part of the number (up to 1000 digits).
6.0.0
Introduced interactive mode, including variable declaration and referencing previous results by number.  (see 'rpn help interactive_mode')
Added caching for OEIS operators.  However, it turns out some OEIS text is non-ASCII, so I'll have to deal with that.
Operator help now includes examples by default.
The 'time' operator type conflicted with the 'time' unit type, so I changed the operator type to 'date'... because they were all about dates!
Fixed a long-standing precision problem with unit conversion.
Lots more bug fixes.
5.28.5
More bug fixes and code cleanup.  Added the 'unfloat' and 'undouble' operators.
5.28.4
Added the 'diffs2' operator.
More bug fixes thanks to the test script!
5.28.3
The operators 'doublebal', doublebal_', 'triplebal', and 'triplebal_' now work
correctly.  The data files have been significantly expanded as well.
More prime number updates will come in the next few weeks.  My target is to
expand every table up to the first 10 billion primes.
5.28.2
Several bug fixes relating to 'estimate' and unit conversion.   Some unit types
were folded together because they had the same basic units (e.g., frequency and
radioactivity were both time ^ -1, which confused the conversion logic).
5.28.1
Added separate installers for the plain-vanilla rpn (with only the ""small
primes"" data file, i.e., the first million primes), and the installer with all
of the prime data files.
The 'primes' operator has been fixed so it works correctly for small values.
I'm currently testing the prime functions, which I haven't touched in a long
time, so more fixes will definitely be coming.  The balanced prime functions
are currently broken and will be fixed shortly, including updated data files.
5.28.0
Added 'x', 'eval', 'nsum', 'nprod', 'limit', 'limitn', 'infinity', and
'negative_infinity', and 'value' operators.
5.27.2
Help for unit types now prints out all aliases for the unit operators.
5.27.1
Added an error message if the 'name' operand is out of range, and added support
for negative numbers.
5.27.0
Added the 'name' operator.
5.26.0
Added dynamic_visocity and frequency unit types and a few bug fixes.
Added units for the days and years of the other 8 planets in the Solar System.
Added several constant units for quaint or archaic number terms like 'score'
and 'gross'.
Added mass units for common particle masses.
Updated some natural values (electron mass, etc.).
Fixed some problems with generating and interpreting compound units.
Added the 'prevost' operator.
5.25.0
Added Julian date operators, ISO date operators, calendar operators and the
'ash_wednesday' operator.  Added support for the density unit type and several
small bug fixes.
5.24.0
A few more bug fixes, plus new calendar-related operators:  easter.
election_day, labor_day, memorial_day, nthday, presidents_day, thanksgiving
5.23.1
The help improvements actually work now.  So much for testing.
There are now some examples of absolute time handling.
5.23.0
Help will now search topics for partial matches if a complete match isn't found.
5.22.0
Added a bunch of new constants for powers of 10.
5.21.2
Added -l to format help output for different line lengths.  However, it still
doesn't format the blockquoted help text.
5.21.1
Added percent operator, weekday now throws a proper error is the operand isn't
a time value.
5.21.0
The long-awaited absolute time feature:  rpn can now handle absolute time
values.  For input, just use ISO 8601 format, or a reasonable subset thereof.
There is also the 'maketime' operator, which takes a list similar to the old
'tounixtime' operator.
5.20.7
Added help for unit types.   Help for individual units will come eventually,
but they are pretty self-explanatory.
5.20.6
The prime? operator wasn't working correctly for small values.
5.20.5
rpn now throws an error when attempting to get the 0th or less prime number.
5.20.4
rpn now correctly reports the argument in question on any error.
5.20.3
Made a fix to improve rpn's reporting of the argument in question when there is
an error.  It's probably not 100% correct yet.
5.20.2
Fixed the list operator parsing so polyprod and polysum work correctly.
5.20.1
Several calls to polyval( ) had hard-coded fractions in them instead of calls
to fdiv( ), resulting in rounding errors.
5.20.0
rpn finally comes with an installer for Windows, in 32-bit and 64-bit flavors.
5.19.3
The test script has been rewritten in Python.  It's still very basic and only
does a sanity test to show every operator works without crashing.  It doesn't
test for correct answers yet.
5.19.2
rpn now outputs an empty list correctly.  The 'append' operator (to append
lists) has been fixed.
5.19.1
Fixed several problems with 'tounixtime' and 'fromunixtime'.
The first version of a test script is available as a batch file.
5.19.0
Added 'randint' operator.
5.18.7
compoundUnits was still being referred to without the ""g."" global specifier.
5.18.6
rpn now prints out an error message if you try to get help for an unknown
topic.
5.18.5
Fixed a bug concerning adding dissimilar units.
5.18.4
rpn now correctly parses ""-0"" as a value again.
5.18.3
Added 'split' as an alias for 'unpack' because I couldn't remember what it was
called.
Made some minor fixes made based on running pyflakes, pylint pep8, and the
test script.
5.18.2
Made a bunch of bug fixes that showed up as a result of reorganizing the code.
5.18.1
It's clear I haven't done any unit conversions in a while because there were
still issues with declarations of variables.  Now, I've started eliminating the
use of ""global"" in favor of a global module.
Operators supported by rpn:
( ) aa_battery abs abundance abundance_ratio acceleration accuracy acos acosh
acot acoth acsc acsch add add_digits add_polynomials advent agm aliquot
aliquot_limit alpha_particle_mass alternate_signs alternate_signs_2
alternating_factorial alternating_sum alternating_sum_2 and and_all
angular_separation angular_size antiprism_area antiprism_volume
antitransit_time apery_constant append april argument arrangements ascension
asec asech ash_wednesday asin asinh astronomical_dawn astronomical_dusk atan
atanh atomic_number atomic_symbol atomic_weight august autumnal_equinox
avogadro_number balanced_prime balanced_prime_ barnesg base base_units
bell_polynomial beta binomial bitwise_and bitwise_nand bitwise_nor bitwise_not
bitwise_or bitwise_xor black_hole_entropy black_hole_lifetime
black_hole_luminosity black_hole_mass black_hole_radius black_hole_surface_area
black_hole_surface_gravity black_hole_temperature bohr_radius
boltzmann_constant build_numbers build_step_numbers calendar calkin_wilf
catalan_constant ceiling centered_cube centered_decagonal centered_dodecahedral
centered_heptagonal centered_hexagonal centered_icosahedral centered_nonagonal
centered_octagonal centered_octahedral centered_pentagonal centered_polygonal
centered_square centered_tetrahedral centered_triangular cf
champernowne_constant char christmas classical_electron_radius collate collatz
columbus_day combinations combine_digits comma comma_mode compare_lists
compositions cone_area cone_volume conjugate convert copeland_erdos_constant
cos cosh cot coth coulomb_constant count count_bits count_different_digits
count_digits count_divisors cousin_prime cousin_prime_ crt csc csch cube
cube_root cumulative_diffs cumulative_ratios cyclic_permutations cyclotomic
dawn day_time debruijn decagonal decagonal_centered_square decagonal_heptagonal
decagonal_hexagonal decagonal_nonagonal decagonal_octagonal
decagonal_pentagonal decagonal_triangular december decimal_grouping decrement
default delete_config denomination_combinations density_of_water describe
deuteron_mass dhms difference diffs digamma digital_root digits dimensions
discriminant distance distance_from_earth divide divisors dms dodecahedral
dodecahedron_area dodecahedron_volume double double_balanced double_balanced_
double_factorial dst_end dst_start dump_config duplicate_digits
duplicate_number duplicate_operator duplicate_term dusk e earth_density
earth_gravity earth_mass earth_radius earth_volume easter echo eclipse_totality
eddington_number egypt election_day electric_constant electron_charge
electron_mass element element_block element_boiling_point element_density
element_description element_group element_melting_point element_name
element_occurrence element_period element_state energy_equivalence enumerate
enumerate_dice enumerate_dice_ epiphany equals_one_of erdos_persistence ernal
operators: escape_velocity estimate eta euler_brick euler_mascheroni_constant
euler_phi eval eval0 eval2 eval3 eval_list eval_list2 eval_list3
eval_polynomial exp exp10 exponential_range expphi factor factorial false
faraday_constant fathers_day february fibonacci fibonorial filter
filter_by_index filter_lists find find_palindrome find_polynomial
find_sum_of_cubes find_sum_of_squares fine_structure_constant flatten float
floor for_each for_each_list fraction friday frobenius from_bahai
from_ethiopian from_hebrew from_indian_civil from_islamic from_julian
from_mayan from_persian from_unix_time function gallon_of_ethanol
gallon_of_gasoline gamma gcd gcd2 generalized_pentagonal
generate_polydivisibles geometric_mean geometric_range geometric_recurrence
geo_distance get_base_k_digits get_combinations get_config get_day get_digits
get_hour get_left_digits get_left_truncations get_minute get_month
get_nonzero_base_k_digits get_nonzero_digits get_partitions get_permutations
get_repeat_combinations get_repeat_permutations get_right_digits
get_right_truncations get_second get_timezone get_variable get_year
glaisher_constant good_friday group_elements harmonic harmonic_mean
has_any_digits has_digits has_only_digits heat_index helion_mass help
heptagonal heptagonal_hexagonal heptagonal_pentagonal heptagonal_square
heptagonal_triangular heptanacci hexagonal hexagonal_pentagonal
hexagonal_square hexanacci hex_mode hms horizon_distance hurwitz_zeta hyper4_2
hyperfactorial hyperfine_transition_frequency_of_cesium hypotenuse i
icosahedral icosahedron_area icosahedron_volume identify identify_mode if
imaginary increment independence_day infinity input_radix integer
integer_grouping interleave intersection interval_range invert_units
isolated_prime iso_date iso_day is_abundant is_achilles is_automorphic
is_base_k_pandigital is_base_k_smith_number is_bouncy is_carmichael
is_composite is_decreasing is_deficient is_digital_permutation is_divisible
is_equal is_even is_friendly is_generalized_dudeney is_greater is_harshad
is_increasing is_integer is_kaprekar is_kth_power is_k_hyperperfect
is_k_morphic is_k_narcissistic is_k_semiprime is_k_sphenic is_less
is_narcissistic is_not_equal is_not_greater is_not_less is_not_zero is_odd
is_order_k_smith_number is_palindrome is_palindrome_list is_pandigital is_pddi
is_pdi is_perfect is_polydivisible is_powerful is_power_of_k is_prime is_pronic
is_rough is_ruth_aaron is_semiprime is_smith_number is_smooth is_sphenic
is_square is_squarefree is_step_number is_strong_pseudoprime is_sum_product
is_trimorphic is_unusual is_zero itoi january july june jupiter jupiter_mass
jupiter_radius jupiter_revolution jupiter_volume khinchin_constant
kinetic_energy k_fibonacci k_persistence k_sphere_area k_sphere_radius
k_sphere_volume labor_day lah lambda lambertw larger latlong_to_nac lat_long
lcm lcm2 leading_zero leading_zero_mode left leyland li limit limitn
linear_recurrence linear_recurrence_with_modulo list_from_file location
location_info log log10 log2 logxy log_gamma long longlong lucas
magnetic_constant magnetic_flux_quantum make_cf make_datetime make_iso_time
make_julian_time make_pyth_3 make_pyth_4 mantissa march mars mars_mass
mars_radius mars_revolution mars_volume martin_luther_king_day mass_equivalence
maximum max_char max_double max_float max_index max_long max_longlong
max_quadlong max_short max_uchar max_ulong max_ulonglong max_uquadlong
max_ushort may mean memorial_day mercury mercury_mass mercury_radius
mercury_revolution mercury_volume merten merten_constant mills_constant minimum
min_char min_double min_float min_index min_long min_longlong min_quadlong
min_short min_uchar min_ulong min_ulonglong min_uquadlong min_ushort mobius
modulo molar_gas_constant molar_mass monday moon moonrise moonset
moon_antitransit moon_gravity moon_mass moon_phase moon_radius moon_revolution
moon_transit moon_volume mothers_day multifactorial multinomial multiply
multiply_digits multiply_digit_powers multiply_nonzero_digits
multiply_nonzero_digit_powers multiply_polynomials muon_mass name nand nand_all
narayana nautical_dawn nautical_dusk nearest_int negative negative_infinity
neptune neptune_mass neptune_radius neptune_revolution neptune_volume
neutron_mass newton_constant new_years_day next_antitransit
next_first_quarter_moon next_full_moon next_last_quarter_moon next_new_moon
next_prime next_primes next_quadruplet_prime next_quintuplet_prime next_rising
next_setting next_transit night_time nonagonal nonagonal_heptagonal
nonagonal_hexagonal nonagonal_octagonal nonagonal_pentagonal nonagonal_square
nonagonal_triangular nonzero nor nor_all not november now nprod nsum nth_apery
nth_bell nth_bernoulli nth_carol nth_catalan nth_centered_decagonal
nth_centered_heptagonal nth_centered_hexagonal nth_centered_nonagonal
nth_centered_octagonal nth_centered_pentagonal nth_centered_polygonal
nth_centered_square nth_centered_triangular nth_decagonal nth_delannoy
nth_heptagonal nth_hexagonal nth_jacobsthal nth_kynea nth_leonardo
nth_linear_recurrence nth_linear_recurrence_with_modulo nth_menage
nth_mersenne_exponent nth_mersenne_prime nth_motzkin nth_nonagonal
nth_octagonal nth_padovan nth_pell nth_pentagonal nth_perfect_number
nth_polygonal nth_prime nth_quadruplet_prime nth_quintuplet_prime nth_schroeder
nth_schroeder_hipparchus nth_square nth_stern nth_sylvester nth_thue_morse
nth_triangular nth_weekday nth_weekday_of_year nuclear_magneton occurrences
occurrence_cumulative occurrence_ratios octagonal octagonal_heptagonal
octagonal_hexagonal octagonal_pentagonal octagonal_square octagonal_triangular
octahedral octahedron_area octahedron_volume octal_mode octanacci october oeis
oeis_comment oeis_ex oeis_name oeis_offset omega_constant or orbital_mass
orbital_period orbital_radius orbital_velocity ordinal_name or_all output_radix
pack parity partitions pascal_triangle pentagonal pentagonal_square
pentagonal_triangular pentanacci pentatope pentecost permutations permute_dice
permute_digits permute_lists persistence phi pi planck_acceleration
planck_angular_frequency planck_area planck_charge planck_constant
planck_current planck_density planck_electrical_inductance planck_energy
planck_energy_density planck_force planck_impedance planck_intensity
planck_length planck_magnetic_inductance planck_mass planck_momentum
planck_power planck_pressure planck_temperature planck_time planck_viscosity
planck_voltage planck_volume planck_volumetric_flow_rate plastic_constant plot
plot2 plotc pluto pluto_mass pluto_radius pluto_revolution pluto_volume polyexp
polygamma polygonal polygon_area polylog polynomial_power polynomial_product
polynomial_sum polyprime polytope power powerset power_tower power_tower2
powmod precision presidents_day previous previous_antitransit
previous_first_quarter_moon previous_full_moon previous_last_quarter_moon
previous_new_moon previous_prime previous_primes previous_rising
previous_setting previous_transit prevost_constant prime primes prime_pi
prime_range primorial prism_area prism_volume product proton_mass pyramid
quadlong quadruplet_prime quadruplet_prime_ quintuplet_prime quintuplet_prime_
radiation_constant radical random random_ random_element random_integer
random_integer_ range ratios real reciprocal recurrence reduce
reduced_planck_constant repeat replace_digits repunit result reversal_addition
reverse reverse_digits rhombic_dodecahedral riesel right robbins_constant
roll_dice roll_dice_ roll_simple_dice root rotate_digits_left
rotate_digits_right round round_by_digits round_by_value rydberg_constant
safe_prime saturday saturn saturn_mass saturn_radius saturn_revolution
saturn_volume sec sech september set_config set_variable sextuplet_prime
sextuplet_prime_ sexy_prime sexy_prime_ sexy_quadruplet sexy_quadruplet_
sexy_triplet sexy_triplet_ shift_left shift_right short show_erdos_persistence
show_k_persistence show_persistence shuffle sidereal_year sigma sigma_k sign
silver_ratio sin sinh sized_range sky_location slice smaller solar_constant
solar_noon solve solve_cubic solve_quadratic solve_quartic sophie_prime sort
sort_descending speed_of_light sphere_area sphere_radius sphere_volume square
square_digit_chain square_root square_triangular star stddev
stefan_boltzmann_constant stella_octangula subfactorial sublist subtract sum
summer_solstice sums_of_k_nonzero_powers sums_of_k_powers sum_digits sun sunday
sunrise sunset sun_antitransit sun_luminosity sun_mass sun_radius sun_volume
superfactorial superprime surface_gravity tan tanh tau_mass tetrahedral
tetrahedron_area tetrahedron_volume tetranacci tetrate thabit thanksgiving
thue_morse_constant thursday timer timer_mode time_dilation today tomorrow
topic torus_area torus_volume to_bahai to_bahai_name to_ethiopian
to_ethiopian_name to_hebrew to_hebrew_name to_indian_civil to_indian_civil_name
to_islamic to_islamic_name to_iso to_iso_name to_julian to_julian_day
to_lilian_day to_mayan to_ordinal_date to_persian to_persian_name to_unix_time
transit_time triangle_area triangular tribonacci trigamma triplet_prime
triplet_prime_ triple_balanced triple_balanced_ triple_point_of_water
triton_mass tropical_year true truncated_octahedral truncated_tetrahedral
tuesday twin_prime twin_prime_ uchar uinteger ulong ulonglong undouble unfilter
unfilter_by_index unfloat union unique unit_roots unlist unpack uquadlong
uranus uranus_mass uranus_radius uranus_revolution uranus_volume ushort uuid
uuid_random vacuum_impedance value velocity venus venus_mass venus_radius
venus_revolution venus_volume vernal_equinox veterans_day von_klitzing_constant
wednesday weekday weekday_name wind_chill winter_solstice x xnor xor y ydhms
year_calendar yesterday z zero zeta zeta_zero [ ] _dump_aliases _dump_cache
_dump_constants _dump_conversions _dump_operators _dump_units _stats
",13
wmjordan/Codist,C#,"Codist
Codist is a Visual Studio extension which strives to provide better coding experience and productivity for C# programmers.
Features

Advanced Syntax Highlight with Comment Tagger
Super Quick Info with Click and Go to source code
Smart Bar with symbol reference analyzers
Scrollbar Marker
Symbol Marker
Navigation Bar (new in version 4.0)
Display Enhancements
Comprehensive Configurations
License, Bugs and Sugguestions


Advanced C# Syntax Highlight
The advanced syntax highlight function highlights every aspect of C# language elements with diverse styles, including using various font families and text styles, enlarging or shrinking font sizes, changing foreground or background colors and transparency.
The following screenshots of the TestPage.cs file in the source code project demonstrates possible syntax highlight effects in the Light theme.


The font size of type and member declarations can be enlarged, so it is much easier to spot them.
Syntax highlight can be applied to braces and parentheses.
Various syntax identifiers have different styles, temporary elements such as method parameters and local variables are italic, static symbols are underlined.
Comment content can be tagged (e.g. note).
Unnecessary code is marked strike-through.
Keywords are categorized and highlighted with various styles (e.g. abstract and sealed, return and throw, etc.).
Overriding members (such as ToString) can be painted with gradient background color, so at a glance we know that the marked implementations have overrided their base classes.
Imported symbols (from external assemblies, e.g. NotImplementedException, ToString) can be marked with a different style (bold here) from symbols defined in your code.
All the above styles are customizable.

Default Syntax Highlight Themes
To quickly get started with advanced syntax highlight, open a C# project, then open the Options dialog, navigate to the Syntax Highlight section, click the Light theme or Dark theme button in the dialog and see changes in effect. Don't forget to click the OK button to confirm the changes.

With the Save and Load buttons, you can backup and share your own syntax highlight settings.
If you mess up your syntax highlight styles, you can press the Reset button to reset all settings to default, or press the Light theme or Dark theme button to reapply predefined themes.
Note: There is a known issue in Codist that if you change the theme of Visual Studio, you may have to restart it to make syntax highlight settings to work properly.
From version 4.5 on, it is possible to load only part of the syntax preset or backup theme by unchecking check boxes under Load following parts when importing themes.
Customization of Syntax Highlight Styles
To customize and tweak the syntax highlight styles, click the sub sections inside the Syntax Highlight section to change individual styles, accordingly.

From version 4.6 on, it is possible to configure color and opacity individually. If we change the opacity value only, the default syntax color for a syntax definition is used.
Syntax definitions under the All languages section apply to all languages; those under Comment section apply to comment taggers (see below), others apply to corresponding languages accordingly.
TIP: Open a document window before you change the syntax theme or tweak the syntax highlight settings. While you change theme, you can see how the styles change in the code document window simultaneously.
My Symbols and External Symbols
Codist can also identify symbols which are defined in your source code and which are imported from external assemblies. This feature is so unique that you may not find it elsewhere.
You can customize it in the Symbol Marker tab of in the C# section of Syntax Highlight. Style My Type and Member is used for symbols from your code, and Referenced Type and Member is used for symbols imported from external assemblies.

Note: the predefined Light theme and Dark theme have defined external symbols with bold style, as the above screenshot shows.
Comment Tagger and Styles


The comment tagger highlights comments to your specific styles, according to the first token inside the comment.
Here are default effects of the some tagged comments.

To configure the comment tags, click the Tags tab, in the Comment sub-section of the Syntax Highlight section, where you can add, remove or modify comment tags.

To disable comment tagger, uncheck the check box of Comment Tagger on the Syntax Highlight option page.


The syntax style of comments or C# XML Documentations could be changed too. You can make them semitrasparent to stand behind usual code lines by changing the Opacity or the Font size value of the corresponding syntax parts.

Note: the predefined Light theme and Dark theme have defined XML Doc with a smaller font size (-1), as the above screenshot shows.


Super Quick Info
The quick info (the tooltip shown when you hover your mouse pointer on your C# source code) can be enhanced by Codist.
General Quick Info
To customize the Super Quick Info, adjust the settings in the options page.

Options in the General page apply to all code editor windows.


Hide Quick Info until Shift key is pressed
By default, Quick Info appears when you hover your mouse over a symbol or syntax token in code editor. Some programmers think this behavior interferes their workflow. Checking this option will suppress the Quick Info until Shift key is pressed.


Show info about selection length
This option will show how many characters and lines in your selection (if your selection spans over multiple lines). So you don't have to count characters one by one.



Show info about color
This option enables you preview color values. It works for hex color values (such as #00FF00Â£Â¬#FF993300), named colors (such as Black, White, etc.).

In C# code editor, it analysis system colors (such as SystemColors.WindowColor, SystemColors.Control, etc.), Color.FromArgb or Color.FromRgb expression with constant values as well.

The color info not only works in code windows, but also in debugger Watch window.



C# Quick Info
Super Quick Info especially enhances programming experience for C# programmers. There are plenty of options available in the options page.



Click and go to source code of symbol definition
If a symbol is defined in your source code, you can click and go to its definition on the Quick Info window. There's no need to hit F12 on your keyboard any more. Even more, Codist also tells you where the symbol is defined if you hover your mouse over it.



Override XML Documentation
The overridden XML Documentation makes the following changes to the documentation.

More syntax colors (adopting syntax highlight colors) for symbols.
Icons for documetation parts.
Selectable content of the documentation.
Symbols inside the documentation work with Click and Go feature too.
Concise form of members (without leading namespace or containing type names, hover your mouse over a symbol to view its full definition).
Extra tags, such as <b> (for bold), <i> (for italic) and <u> (for underline) are supported.
Extra information from documentations (see below).
Copyable quick info content (First select text with your mouse, and press Ctrl + C shortcut key).


When Override XML Documentation checkbox is checked in the options page, it is also possible to activate options under it.


Inherit from base type or interfaces option will show documentation description from base classes or implemeted interfaces if the XML Doc description of the current symbol is absent.



Inherit from <inheritdoc cref=""MemberName""/> target option will borrow description from the referenced MemberName.



Show <returns> XML Doc and Show <remarks> XML Doc will add content of those tags.


Override <exception> XML Doc option adds back documentations for exceptions to the Quick Info.





Quick Info Item Size
Quite often the Quick Info can take up a lot of space, covering almost half of the screen. It is possible to limit its size with Super Quick Info by assigning values to Max width and Max height in the options page.



Additional Quick Info Items
A dozen of additional quick info items could be displayed in the Additional Quick Info Items options page.



Attributes option shows attributes of a symbol.


Base types and interfaces options shows inheritance and implementation info of a type. It is recommended to check All ancestor types and Inherited interfaces to display the complete info of the hierarchy of a type.

Note: the IDisposable interface has special importance in .NET programming, thus it is assigned a special icon and pinned to the top of the interface list.


Declaration modifier option shows modifiers to a symbol when it is not a public instance one.



Interface implementation option shows if a member implements any interface.



Method overload options shows possible overloads of a method (including applicable extension methods).

This option also helps you find out correct overloads when any argument passed to a method is incorrect.



Parameter of method options shows whether a token or an expression is the parameter of a method in the argument list. What is more, the documentation of the parameter is also displayed.



Type parameter option shows information and documentation about type parameters.


Symbol location shows where a symbol is defined.


Numeric forms shows decimal, hexadecimal and binary forms for constant integer and Enum values.

The binary form is useful when working with bit flags.



String length and Hash codes for string constants.
(Hint: We can use Hash codes to quickly compare whether two strings that look alike are identical)


Smart Bar
The Smart Bar is a context-aware tool bar that appears automatically when you select some text, or double tap the Shift key on your keyboard.
There are two toolbars on Smart Bar. The top bar contains general editing commands for all file types. Buttons on the bottom bar changes according to file types.
Buttons on the Smart Bar changes according to your selection, typical buttons are editing operations (e.g. Cut, Copy, Paste,  Delete, Duplicate, Formatting, Find, etc.), code analysis operations (e.g. Go to defintion, Find references), refactoring operations (e.g. Rename, Extract method, etc.)

Each button on Smart Bar usually has multiple functions. Left clicking, right clicking, Ctrl+clicking and Shift+clicking trigger different commands. For details, see the tooltip for the buttons. Right clicking a button usually expands the effective range of a command to the whole line, or brings out a pop-up menu for more commands.

C# Specific Commands
When you select a symbol, you may probably see a Smart Bar like below.

The C# commands are on the second row.
The first one is Go to Definition, that behaves the same as the keyboard F12 command. With this, you no longer need hitting the F12 key to go to definition.
The second one is the Analyze symbol... button, a menu will pop up showing possible symbol analysis commands for the symbol. Since some commands require considerable amount of calculation, items ending with ""..."" will require a mouse click to expand. For instance, clicking the Find Callers command in the following screen shot will search the source code and list at what places are calling the selected method in a sub-menu. After the sub-menu is popped up, you can click items on the sub-menu and jump to the corresponding location.

Symbol Marker
Symbol marker draws markers for C# symbols.
Typically, you can double click a symbol in the C# source code, select the Mark Symbol command on the Smart Bar and choose the desired highlight marker on the drop-down menu.

After applying the command, all occurrences of the marked symbol will be marked with a different style.

To remove symbol marker, click the Remove symbol mark command in the drop-down menu of the Mark symbol command.
Symbol markers will be cleared when the solution is unloaded.
Note: The style of symbol markers can be customized in options page of the Syntax highlight feature. The default colors are listed below. You also need to turn on the Syntax Highlight feature in order to make this feature work.

Behavior of Smart Bar
By default, Smart Bar appears after selection changes, you can alter the behavior in the options page by unchecking the Show Smart Bar when selection is changed checkbox.

Smart Bar automatically disappears when you move your mouse cursor away from it, or execute a certain commands on the Smart Bar, or click somewhere else in the code editor window, emptying the selection.
To make the Smart Bar reappear, you can tap the Shift key on your keyboard twice within a second. This behavior can also be suppressed by unchecking the Show/hide Smart Bar with Shift key checkbox.
Smart Bar in Other Windows
Smart Bar also works on Output, C# Interactive, Immediate (Debug), Find Results and some other text selectable window panes. If you select a path within those windows, extra commands will pop up allowing you to open it directly or locate it in Windows Explorer.

From version 4.4 on, some extra buttons will show up on Smart Bar in C/C++ code windows.
Scrollbar Marker
Scollbar Marker draws extra glyphs and shapes on the vertical scrollbar for the following syntax elements:


C# class/struct/interface/enum declarations (marked with a square and their names)


C# symbol match marker (matches symbol under the caret, marked with an aqua square)


C# instructions (#if, #else, #region, #pragma) (marked with a gray spot)


Line numbers (marked with gray dashed lines and numbers)


Special comments tagged by comment tagger (marked with small squares)
Please see the first screenshot of this article.


Navigation Bar
Navigation bar locates at the top of the code editor window. It overrides the original navigation bar. When the Navigation Bar is loadeded, it hides two drop-down lists on the original Navigation Bar, but preserves the project drop-down list.
Basically, the Navigation Bar serves the same purpose of the original one, displaying symbol information where the caret is placed.

Note: currently Navigation Bar only works with C# code documents.
Typically you can see three or four items on the bar.

Namespace node: the innermost namespace which contains the caret. On the above screen shot, it is the ""TestProject"" node.
Type node: the type which contains the caret. On the above screen shot, it is the ""MyStruct"" node.
Region node: when the caret is between #region and #endregion, this node appears. On the above screen shot, it is the ""Private fields"" node.
Member node: the member where the caret is in. This node is drawn highlighted. On the above screen shot, it is the ""Constant"" node.

Nodes on the Navigation Bar are clickable.


Clicking on a Namespace node will popup a menu, displaying namespaces and types defined in the active document. You can click on those items and jump to the beginning of corresponding definitions.

On top of the menu there is a Search Declaration box, within which you can type and search declarations.
Besides the Search Declaration box, there are three buttons. The first one is pressed by default, which restricts the search scope to active document. If the second one is pressed, it pops up the first button and expands the search scope to current project (see screen shot below). The third button clears the search box and reverts the items back to unfiltered namespaces and types.



Clicking on a Type node will popup a menu, displaying members and regions defined within the type. You can click on those items and jump to the definition of the corresponding member.

The current symbol where the caret is on is highlighted.
Field values and auto-property expressions are also displayed on this menu. So, you can instantly know the initial value of fields.
There is also a search box in this menu, which filters content of the menu. There are six buttons beside the search box. The first five of them narrow down the displayed items of the menu and the last one clears the filter.
To navigate to the beginning of the type, click the first item on the menu.


Clicking on a Member node will select the whole member. If you have the Smart Bar feature on and let it appear when selection is changed, Smart Bar will be displayed and let you perform actions onto the member.



Customization
The Navigation Bar can be configure via the options page.



If Show syntax detail option is set, the Navigation Bar not only shows available types and declarations in the code window like the original navigation bar, but also syntax nodes such as statements and expressions containing the caret.



If Show symbol info tip option is set, you can read information about a symbol when you hover your mouse onto a node.



If Highlight node range in editor option is set, when you hover the mouse over the node on the bar, corresponding span of the node will be highlighted in the editor.



If Show #region name option is set, #region names will be displayed on the Navigation Bar. If you pad region names with some non-alphabetic characters like ""#region [====== private methods ======]"", you can check the Trim non-letter characters checkbox so only alphabetic part like ""private methods"" will be displayed on the Navigation Bar.


To customize drop-down menus of the Navigation Bar, change options in the Drop-down Menu tab.

Display Enhancements
In the Display tab of the General options page, several display enhancement options are offered.

Within the Extra line margins group box, you can adjust margins between lines to make code lines more readable.
Programmers who do not like ClearType rendering, which made text blurry and colorful, may want to try Force Grayscale Text Rendering options.
Feature Control
Open the Codist section in the Tools->Options dialog. In the General section you can toggle features of Codist.



Feature controllers contains check boxes which can be used to enable/disable features of Codist.
When you are running on a laptop with battery. Disabling Codist may help it sustain a little bit longer.
Someone who does not like the syntax highlight or use another syntax highlighter can also turn off the Syntax Highlight feature individually here.
These options will take effect on new document windows. Existing document windows won't be affected.


To share or backup your settings of Codist, you can use the Save and Load buttons.


Acknowledgements
I have learned a lot from the following extension projects (sorted by the dates when I learned from them).

CommentsPlus: https://github.com/mhoumann/CommentsPlus
Better comments: https://github.com/omsharp/BetterComments
Remarker: https://github.com/jgyo/remarker
Font Sizer: https://github.com/Oceanware/FontSizer
Visual Studio Productivity Power Tools: https://github.com/Microsoft/VS-PPT
Inheritance Margin: https://github.com/tunnelvisionlabs/InheritanceMargin
CoCo: https://github.com/GeorgeAlexandria/CoCo
CodeBlockEndTag: https://github.com/KhaosCoders/VSCodeBlockEndTag
UntabifyReplacement: https://github.com/cpmcgrath/UntabifyReplacement
Extensiblity Tools: https://github.com/madskristensen/ExtensibilityTools
CodeMaid: https://github.com/codecadwallader/codemaid
Select Next Occurence: https://github.com/2mas/SelectNextOccurrence

License
Codist comes from the open source community and it goes back to the community.
Codist is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.
This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
You should have received a copy of the GNU General Public License along with this program. If not, see ""https://www.gnu.org/licenses"".
Bugs and Suggestions
Please post New Issue in the GitHub project if you find any bug or have any suggestion.
Your vote and feedback on the Visual Studio Extension Marketplace are also welcomed.
Support Codist by Donation
If you like Codist and want to support the future development of it, you can donate to the author.
You can donate any amount of money as you like. The recommended amount of donation is $19.99.
",30
devsnek/slither,Rust,"slither
A modern scripting runtime
// modules keep your code organized
// and your global clean
import { print } from standard:debug;

function fib(n, a = 0, b = 1) { // argument initializers
  if n == 0 { // no parenthesis around if or try
    return a;
  }

  if n == 1 {
    return // unambiguous grammar means
      b;   // that this returns b, not null
  }

  // tail recursion
  return fib(n - 1, b, a + b);
}

print(fib(10) == 55);
Goals in no particular order

staged JIT for good performance
fast and easy networking
good ffi interface

",28
nytimes/video-transcoding-api,Go,"
Video Transcoding API



The Video Transcoding API provides an agnostic API to transcode media assets
across different cloud services. Currently, it supports the following
providers:

Amazon Elastic Transcoder
Bitmovin
Elemental Conductor
Encoding.com
Hybrik
Zencoder

Setting Up
With latest Go installed, make sure to export the follow
environment variables:
Providers configuration
For Amazon Elastic Transcoder
export AWS_ACCESS_KEY_ID=your.access.key.id
export AWS_SECRET_ACCESS_KEY=your.secret.access.key
export AWS_REGION=""us-east-1""
export ELASTICTRANSCODER_PIPELINE_ID=""yourpipeline-id""

Please notice that for Elastic Transcoder you don't specify the destination
bucket, as it is defined in the Elastic Transcoder
Pipeline.
For Bitmovin
export BITMOVIN_API_KEY=your.api.key
export BITMOVIN_AWS_ACCESS_KEY_ID=your.access.key.id
export BITMOVIN_AWS_SECRET_ACCESS_KEY=your.secret.access.key
export BITMOVIN_AWS_STORAGE_REGION=your.s3.region.such.as.US_EAST_1.or.EU_WEST_1
export BITMOVIN_DESTINATION=s3://your-s3-bucket
export BITMOVIN_ENCODING_REGION=your.provider.region.such.as.AWS_US_EAST_1.or.GOOGLE_EUROPE_WEST_1
export BITMOVIN_ENCODING_VERSION=STABLE.or.BETA

For Elemental Conductor
export ELEMENTALCONDUCTOR_HOST=https://conductor-address.cloud.elementaltechnologies.com/
export ELEMENTALCONDUCTOR_USER_LOGIN=your.login
export ELEMENTALCONDUCTOR_API_KEY=your.api.key
export ELEMENTALCONDUCTOR_AUTH_EXPIRES=30
export ELEMENTALCONDUCTOR_AWS_ACCESS_KEY_ID=your.access.key.id
export ELEMENTALCONDUCTOR_AWS_SECRET_ACCESS_KEY=your.secret.access.key
export ELEMENTALCONDUCTOR_DESTINATION=s3://your-s3-bucket/

For Encoding.com
export ENCODINGCOM_USER_ID=your.user.id
export ENCODINGCOM_USER_KEY=your.user.key
export ENCODINGCOM_DESTINATION=http://access.key.id:secret.access.key@your-s3-bucket.s3.amazonaws.com/
export ENCODINGCOM_REGION=""us-east-1""

For Hybrik
export HYBRIK_URL=your.hybrik.api.endpoint.such.as.https://api_demo.hybrik.com/v1
export HYBRIK_COMPLIANCE_DATE=20170601
export HYBRIK_OAPI_KEY=your.hybrik.oapi.key
export HYBRIK_OAPI_SECRET=your.hybrik.oapi.secret
export HYBRIK_AUTH_KEY=your.hybrik.auth.key
export HYBRIK_AUTH_SECRET=your.hybrik.auth.secret
export HYBRIK_DESTINATION=s3://your-s3-bucket
export HYBRIK_PRESET_PATH=video-transcoding-api-presets

HYBRIK_PRESET_PATH is optional and defines the folder presets will be
stored in. If not specified, it will default to
'video-transcoding-api-presets'.
For Zencoder
export ZENCODER_API_KEY=your.api.key
export ZENCODER_DESTINATION=http://access.key.id:secret.access.key@your-s3-bucket.s3.amazonaws.com/

Database configuration
In order to store preset maps and job statuses we need a Redis instance
running. Learn how to setup and run a Redis
here. With the Redis instance running, set
its configuration variables:
export REDIS_ADDR=192.0.2.31
export REDIS_PASSWORD=p4ssw0rd.here

If you are running Redis in the same host of the API and on the default port
(6379) the API will automatically find the instance and connect to it.
With all environment variables set and redis up and running, clone this
repository and run:
$ git clone https://github.com/NYTimes/video-transcoding-api.git
$ make run

Running tests
$ make test

Using the API
Check out on our Wiki how
to
use this API.
Contributing

Fork it
Create your feature branch: git checkout -b my-awesome-new-feature
Commit your changes: git commit -m 'Add some awesome feature'
Push to the branch: git push origin my-awesome-new-feature
Submit a pull request

License

This code is under Apache 2.0
license.
The video-transcoding-api logo is a variation on the Go gopher that was
designed by Renee French and copyrighted under the Creative Commons
Attribution 3.0 license.

",443
saucepleez/taskt,C#,"
taskt (formerly sharpRPA) is the first truly free, easy to use, and open-source process automation client built on the .NET Framework in C#.  taskt allows you to build and design process automation without needing to write application code.


taskt allows you to automate the boring stuff and create efficienies by giving you the power to craft a digital workforce that executes and performs rule-based automation.  No API? No Problem!  Included is a ""what you see is what you get"" bot designer with dozens of automation commands. An element recorder and screen recorder is also included that can record and replay scripted automation.


taskt works by allowing a bot developer to design a bot configuration known as a script.  The bot configuration is then intepreted by a script engine at run-time and executes against the bot developer's selected parameter inputs.  Each command contains the definitions for the required inputs as well as the required logic at run-time.  Please check out the Wiki for basic documenation surrounding the application and the available commands


taskt can perform automation on both web and desktop applications, simulating the actions a person would do.  From swivel-chair data entry to report generation, taskt can handle your automation needs.  Prefer to write and implement code?  taskt can use youe existing .NET DLLs and services additionally with the ability to compile code on the fly using the Custom Code command! taskt can start and stop processes, launch VB and PowerShell scripts, work directly with Excel workbooks, and perform OCR (OneNote installation required) among many other functions.  You can review all the automation commands by clicking here.

CURRENTLY IN ALPHA Manage and orchestrate your digital workforce with taskt's optional server component that allows you to publish and execute tasks remotely as well as monitor the overall health of your bots and discover metrics around your robot workers.


Find and download the latest signed release by clicking HERE. Extract to any folder and double-click 'taskt.exe'.  taskt will ask if you want to create a scripts folder to store your scripts as well as copy and deploy sample files.  You can also build directly from source -- take the latest from the master branch!

taskt is free for both personal and commercial use. taskt is licensed under the Apache 2.0 License -- see LICENSE.md for further details. As a community-driven project, the goal of taskt is to give everyone, big or small, the ability to build and deploy process automation.

Feel free to open up a feature request or report a bug/issue.
Click here to open a new issue!
Need support? Want to say Hi? Come chat with us on Gitter!
",78
eugenekolo/github-scripts,Shell,"Awesome Stars 

A curated list of my GitHub stars!  Generated by starred

Contents

Java
Scala
JavaScript
Makefile
Perl
[Jupyter Notebook](#jupyter notebook)
Matlab
Shell
Assembly
Python
HTML
QML
Others
Ruby
C
LLVM
C++
[Vim script](#vim script)
CSS
Swift
OCaml
C#
Go
PHP

Java

CTF-Android-Writeup - å¾ä¹ä»¥ååå CTFæ¯èµååºæ¥çé¨åAndroidéåé¢ç®wpï¼çåï¼èªç¨è®°å½ï¼
santa-tracker-android - Ho Ho Ho
kololib - Library of tools, testng things, and bring up material I use.
Apktool - A tool for reverse engineering Android apk files
binnavi - BinNavi is a binary analysis IDE that allows to inspect, navigate, edit and annotate control flow graphs and call graphs of disassembled code.
Silence - A fork of Signal with only SMS/MMS encryption.
clipcaster - A LastPass clipboard password sniffer

Scala

bfg-repo-cleaner - Removes large or troublesome blobs like git-filter-branch does, but faster. And written in Scala

JavaScript

puppeteer-recorder - Puppeteer recorder is a Chrome extension that records your browser interactions and generates a  Puppeteer script.
appmon - Documentation:
house - A runtime mobile application analysis toolkit with a Web GUI, powered by Frida, written in Python.
pwnjs - A Javascript library for browser exploitation
juice-shop - OWASP Juice Shop: Probably the most modern and sophisticated insecure web application
frida-ios-dump - pull decrypted ipa from jailbreak device
dual-captions - ð Subtitles in two languages for YouTube & Netflix
racer - One-click utility to test race conditions
insomnia - Cross-platform HTTP and GraphQL Client
pibakery - The blocks based, easy to use setup tool for Raspberry Pi
You-Dont-Need-jQuery - Examples of how to do query, style, dom, ajax, event etc like jQuery with plain javascript.
You-Dont-Need-Lodash-Underscore - List of JavaScript methods which you can use natively + ESLint Plugin
aggle - Course project for EC500 Agile Software Development for ECE Applications.
Ghost - ð» The most popular headless Node.js CMS for professional publishing
atom-pair - An Atom package that allows for epic pair programming
UnuglifyJS - A simpler open-source version of JavaScript deobfuscator JSNice
javascript - JavaScript Style Guide
FuckAdBlock - Detects ad blockers (AdBlock, ...)
rodeo - A data science IDE for Python
WhoAmI - A mind-reading website.
shapdar - shape radar w/ html5 + js

Makefile

frida - Clone this repo to build Frida
srclib-c -
memeshop - exploit challenge from csaw ctf qualifier 2015

Perl

diff-so-fancy - Good-lookin' diffs. Actuallyâ¦ nahâ¦ The best-lookin' diffs. ð
RegRipper2.8 - RegRipper version 2.8
Academic-Writing-Check - check for passive words, weasel words, duplicate words, typographical errors and words strunk & white don't like
perl5 - The Perl 5 language interpreter (MIRROR ONLY)
watson-perl -

Jupyter Notebook

pytudes - Python programs to practice or demonstrate skills.

Matlab

hbridge - Wireless MSP430 microcontroller hooked up to a small RC car with a MATLAB UI for control

Shell

Zines - Mirror of my favourite hacking Zines for the lulz, nostalgy, and reference
security-tools - Collection of small security tools created mostly in Python. CTFs, pentests and so on
makeself - A self-extracting archiving tool for Unix systems, in 100% shell script.
vbox - Easier to use wrapper around vboxmanage
github-scripts - Some GitHub scripts
ctf-tools - Some setup scripts for security research tools.

Assembly

PwnAdventureZ - NES zombie survival game made to be hacked
REpsych - Psychological warfare in reverse engineering

Python

amazon-dash - Hack your Amazon Dash to run what you want.
collisions - Hash collisions
bfac - BFAC (Backup File Artifacts Checker): An automated tool that checks for backup artifacts that may disclose the web-application's source code.
on-pwning - My solutions to some CTF challenges and a list of interesting resources about pwning stuff
awesome-python-applications - ð¿ Free software that works great, and also happens to be open-source Python.
pigaios - A tool for matching and diffing source codes directly against binaries.
internalblue - Bluetooth experimentation framework based on Reverse Engineering of Broadcom Bluetooth Controllers.
T-Fuzz -
GitCTF - Git-based CTF
diaphora - Diaphora, the most advanced Free and Open Source program diffing tool.
AndBug - Android Debugging Library
XSStrike - Most advanced XSS scanner.
IDA-Function-Tagger - This IDAPython script tags subroutines according to their use of imported functions
FRAPL - FRAPL Framework
ida_ea - A set of exploitation/reversing aids for IDA
prefix - Function Prefixing for IDA Pro
gdbida - gdbida - a visual bridge between a GDB session and IDA Pro's disassembler
iOS-AppStore-Malware-Automatic-Hunting-System - Blackhat USA 2018 Arsenal
SublimeTodoReview - A SublimeText plugin for reviewing todo (and other) comments within your code.
HexRaysPyTools -
pyxel - A retro game engine for Python
xsssniper - An automatic XSS discovery tool
uEmu - Tiny cute emulator plugin for IDA based on unicorn.
firmware-analysis-toolkit - Toolkit to emulate firmware and analyse it for security vulnerabilities
pwn_repo - To store some CTF_pwn_bins and exps
gef - GEF - GDB Enhanced Features for exploit devs & reversers
zeropress - A dumb script for finding dumb coding errors in WordPress plugins
Zeratool - Automatic Exploit Generation (AEG) and remote flag capture for exploitable CTF problems
theftfuzzer - TheftFuzzer is a tool that fuzzes Cross-Origin Resource Sharing implementations for common misconfigurations.
WPSeku - WPSeku - Wordpress Security Scanner
PinCTF - Using Intel's PIN tool to solve CTF problems
Pwngdb - gdb for pwn
PayloadsAllTheThings - A list of useful payloads and bypass for Web Application Security and Pentest/CTF
focuson - A tool to surface security issues in python code
pre-commit-python-sorter - A pre-commit hook to sort your Python imports.
hqtrivia-automation - Automate finding better answers in HQ Trivia. This is for educational purposes only!
hqtrivia - hack HQ trivia with OCR and google search
Sublist3r - Fast subdomains enumeration tool for penetration testers
ida -
ctf-crypto-writeups -
dash - Analytical Web Apps for Python. No JavaScript Required.
ctfs - ctf exploit codes or writeups
LazyIDA - Make your IDA Lazy!
domato - DOM fuzzer
truffleHog - Searches through git repositories for high entropy strings and secrets, digging deep into commit history
interactive-coding-challenges - 120+ interactive Python coding interview challenges (algorithms and data structures).  Includes Anki flashcards.
Mailpile - A free & open modern, fast email client with user-friendly encryption and privacy features
peda-heap - Some new commands debug heap for peda
stuffz - Basically a script thrift shop
persepolis - Persepolis Download Manager is a GUI for aria2.
QTodoTxt - Cross Platform todo.txt GUI
Openroast - An open source, cross-platform application for home coffee roasting
PPlayer - Music Player code by Python 2.7 and PyQt. MP3 and WMA format are supported.
simple-markpad - a markdown editor made with pyqt
qhangups - Alternative client for Google Hangouts written in PyQt
manticore - Symbolic execution tool
RSAExploits -
ctf-writeups - Selected CTF writeups
imgkit - ð Wkhtmltoimage python wrapper to convert html to image
python-patterns - A collection of design patterns/idioms in Python
pyshell - PyShell makes interacting with web-based command injection less painful, emulating the feel of an interactive shell as much as possible.
metame - metame is a metamorphic code engine for arbitrary executables
PS4-3.55-Code-Execution-PoC -
flare-floss - FireEye Labs Obfuscated String Solver - Automatically extract obfuscated strings from malware.
chosen-plaintext - A small python library for exploiting simple chosen-plaintext attacks.
linux-insides - A little bit about a linux kernel
ec700-charlie-3 -
CANToolz - CANToolz - framework for black-box CAN network analysis
osxcollector - A forensic evidence collection & analysis toolkit for OS X
flask-user-api -
workshops -
crypto-tools - Some crypto tools I've written
maybe - ð ð ð© See what a program does before deciding whether you really want it to happen (NO LONGER MAINTAINED)
linux-ransomware-decrypter - Bitdefender's Linux.Encoder.1 Decrypter
ida-patcher - IDA Patcher is a plugin for Hex-Ray's IDA Pro disassembler designed to enhance IDA's ability to patch binary files and memory.
ete - Python package for building, comparing, annotating, manipulating and visualising trees. It provides a comprehensive API and a collection of command line tools, including utilities to work with the NCBI taxonomy tree.
project-euler - Project Euler solutions in diferent languages
viper - Binary analysis and management framework
libc-binary-collection - A collection of more than 1000 binary libc files
grequests - Requests + Gevent = <3
pwntools-write-ups - A colleciton of CTF write-ups all using pwntools
xortool - A tool to analyze multi-byte xor cipher
pwntools - CTF framework and exploit development library
SimplyEmail - Email recon made fast and easy, with a framework to build on
schedule - Python job scheduling for humans.
num2words - Modules to convert numbers to words. 42 --> forty-two
ARDT - Akamai Reflective DDoS Tool - Attack the origin host behind the Akamai Edge hosts and DDoS protection offered by Akamai services.
pupy - Pupy is an opensource, cross-platform (Windows, Linux, OSX, Android) remote administration and post-exploitation tool mainly written in python
saws - A supercharged AWS command line interface (CLI).
robobrowser -
gdb-dashboard - Modular visual interface for GDB in Python
Pylsy - Pylsy is a simple python library draw tables in the Terminal.Just two lines of code .
big-list-of-naughty-strings - The Big List of Naughty Strings is a list of strings which have a high probability of causing issues when used as user-input data.
python-magic - A python wrapper for libmagic
pwndbg - Exploit Development and Reverse Engineering with GDB Made Easy
net-creds - Sniffs sensitive data from interface or pcap

HTML

MyArticles - è¸ç±³çæç« ï¼iOSå°ä¸ç«ä¹æ­ç³»åï¼ä¸æ­¥ä¸æ­¥å­¦ROPç³»åï¼å®åå¨æè°è¯ä¸ç§æ­¦å¨ç³»åç­ï¼
ctf-challenges -
research - A repo for various research
Droid-Application-Fuzz-Framework - Android application fuzzing framework with fuzzers and crash monitor.
owasp-mstg - The Mobile Security Testing Guide (MSTG) is a comprehensive manual for mobile app security testing and reverse engineering.
en.javascript.info - Modern JavaScript Tutorial
CTF-Writeups -
sec-tools - A set of security related tools
highlighter.js - Easily navigate the DOM and highlight the elements - http://720kb.github.io/highlighter.js/
vector-exploit - Exploit repository
kitsu-tools - ð¨ The tools we use to build Kitsu, the coolest platform for anime and manga

QML

eugenekolo-ctf-challenges - CTF challenges I've made in the past

Others

fuzzing_paper - puzzing related paper
browser-pwn - An updated collection of resources targeting browser-exploitation.
ios-resources - Useful resources for iOS hacking
awesome-interview-questions -  A curated awesome list of lists of interview questions. Feel free to contribute! ð
slides - won't maintain
awesome-browser-exploit - awesome list of browser exploitation tutorials
ToolsOfTheTrade - Tools of The Trade, from Hacker News.
survivingtheappstore - My book on getting to the #1 Spot in the App Store. Buy my games to support me.
Android-Malwares -
Exploit-Writeups - A collection where my current and future writeups for exploits/CTF will go
secbook - ä¿¡æ¯å®å¨ä»ä¸èä¹¦åæ¨è
secure-ios-app-dev - Collection of the most common vulnerabilities found in iOS applications
Code-Execution - Executables that execute other stuff
awesome-mobile-CTF - This is a curated list of mobile based CTFs, write-ups and vulnerable apps. Most of them are android based due to the popularity of the platform.
android-crackme - You have 8 flags to retrieve.  Crack it already!
iOS - Most usable tools for iOS penetration testing
CTF-pwn-tips - Here record some tips about pwn. Something is obsoleted and won't be updated. Sorry about that.
wifi-cracking - Crack WPA/WPA2 Wi-Fi Routers with Airodump-ng and Aircrack-ng/Hashcat
mms - Modern Memory Safety in C/C++
emptyrepo - an empty repository
2015-ctf-game - Repo containing links to all CTF Challenges used in the 2015 MITRE CTF.
2014-ctf-game - Repo containing links to all CTF Challenges used in the 2014 MITRE CTF.
2013-ctf-game - Repo containing links to all CTF Challenges used in the 2013 MITRE CTF.
MobileApp-Pentest-Cheatsheet - The Mobile App Pentest cheat sheet was created to provide concise collection of high value information on specific mobile application penetration testing topics.
Malware - Course materials for Malware Analysis by RPISEC
awesome-malware-analysis - A curated list of awesome malware analysis tools and resources.
awesome-pentest - A collection of awesome penetration testing resources, tools and other shiny things

Ruby

seccomp-tools - Provide powerful tools for seccomp analysis
blue_hydra - Blue Hydra
brakeman - A static analysis security vulnerability scanner for Ruby on Rails applications
watson-ruby -

C

ctf-writeups - Collection of scripts and writeups
rbndr - Simple DNS Rebinding Service
android_vuln_poc-exp - This project contains pocs and exploits for vulneribilities I found (mostly)
HITCON-Training - For Linux binary Exploitation
Rhme-2016 - Rhme2 challenge (2016)
cb-multios - DARPA Challenges Sets for Linux, Windows, and macOS
armadito-av - Armadito antivirus main repository
ctf-training - Repository with the material of the Tower of Hanoi introductory briefings on binary exploitation
chw00t - chw00t - Unices chroot breaking tool
how2heap - A repository for learning various heap exploitation techniques.
libctf - Library for creating CTF services.
shellforge4 - Enhanced version of secdev's shellforge G3. More platforms and architectures supported.
peinjector - peinjector - MITM PE file infector
minhook - The Minimalistic x86/x64 API Hooking Library for Windows
cdefs - Describe C function prototypes in JSON.
preeny - Some helpful preload libraries for pwning stuff.
SwiftFilesZip - A repo for saving, loading, deleting and unzipping in iOS
MBE - Course materials for Modern Binary Exploitation by RPISEC
GOAT-Plugs - GCC Obfuscation Augmentation Tools
Deviare2 - Deviare API Hook
pcompress - A Parallelized Data Deduplication and Compression utility

LLVM

Tigress_protection - Playing with the Tigress binary protection. Break some of its protections and solve some of its challenges. Automatic deobfuscation using symbolic execution, taint analysis and LLVM.

C++

calculator - Windows Calculator: A simple yet powerful calculator that ships with Windows
exploit_me - Very vulnerable ARM application (CTF style exploitation tutorial)
functionsimsearch - Some C++ example code to demonstrate how to perform code similarity searches using SimHashing.
HexType - HexType: Efficient Detection of Type Confusion Errors for C++
node-memwatch - A NodeJS library to keep an eye on your memory usage, and discover and isolate leaks.
Ponce - IDA 2016 plugin contest winner! Symbolic Execution just one-click away!
devilution - Diablo devolved - magic behind the 1996 computer game
QBDI - A Dynamic Binary Instrumentation framework based on LLVM.
SimplifyGraph - IDA Pro plugin to assist with complex graphs
dxxd-decrypter - DXXD Ransomware Decrypter
al-khaser - Public malware techniques used in the wild: Virtual Machine, Emulation, Debuggers, Sandbox detection.
MazeWalker - Toolkit for enriching and speeding up static malware analysis
paybreak -
sqlitebrowser - Official home of the DB Browser for SQLite (DB4S) project. Previously known as ""SQLite Database Browser"" and ""Database Browser for SQLite"". Website at:
iaito - This project has been moved to:
hexrays_tools -
Process-Dump - Windows tool for dumping malware PE files from memory back to disk for analysis.
coho - Base libraries for C++ development
CrowdDetox -
PackerAttacker - C++ application that uses memory and code hooks to detect packers
keygenme - keygenme challenge from csaw ctf 2013
ghostwriter - ghostwriter is a cross-platform, aesthetic, distraction-free Markdown editor.
Blackbone - Windows memory hacking library
pn - Programmer's Notepad
vld - Visual Leak Detector for Visual C++ 2008-2015
cbang - C! (cbang) is a library of cross-platform C++ utilities.
packJPG - A compression program for further compressing JPEG image files

Vim script

dotfiles - home of the award winning tmux configuration file

CSS

CTF-challenges-by-me - Pwnable|Web Security|Cryptography CTF-style challenges
0xbu.github.io - 0xBU.com website source code
csp-testing - For testing browser support for Content Security Policy
cozy-youth-theme - A cozy, friendly, and readable theme for Ghost blog.
kolotheme - Dark Ghost blog theme for a developer

Swift

androidtool-mac - One-click screenshots, video recordings, app installation for iOS and Android

OCaml

infer - A static analyzer for Java, C, C++, and Objective-C

C#

NBug - Automated bug reporting library for .NET

Go

aquatone - A Tool for Domain Flyovers
grv - GRV is a terminal interface for viewing git repositories
gitrob - Reconnaissance tool for GitHub organizations
GoSublime - A Golang plugin collection for SublimeText 3, providing code completion and other IDE-like features.
pyre - tinder cli built at stupid hackathon san francisco 2015

PHP

phpggc - PHPGGC is a library of PHP unserialize() payloads along with a tool to generate them, from command line or programmatically.
vuejs-serverside-template-xss - Demo of a Vue.js app that mixes both clientside templates and serverside templates leading to an XSS vulnerability
iOS-Mail.app-inject-kit - iOS 8.3 Mail.app inject kit

License

To the extent possible under law, eugenekolo has waived all copyright and related or neighboring rights to this work.
",2
animalsheltr/animalsheltr,PHP,"








In development

AnimalSheltr
Animal Shelter Manager.
Contact
Email: jaimesares@gmail.com | Twitter: @animalsheltr
| Facebook: @animalsheltr
",9
CloudPipelines/scripts,Shell,"Cloud Pipelines Scripts

This project tries to solve the following problems:




Creation of a common deployment pipeline


Propagation of good testing & deployment practices


Speed up the time required to deploy a feature to production




A common way of running, configuring and deploying applications lowers support costs
and time needed by new developers to blend in when they change projects.


You can check out the docs folder for the documentation. The deployed docs are available here
",16
shunwuyu/lesson_md,CSS,"lesson_md
ç¾æ»´ç­
",6
openwrt/packages,Makefile,"OpenWrt packages feed
Description
This is the OpenWrt ""packages""-feed containing community-maintained build scripts, options and patches for applications, modules and libraries used within OpenWrt.
Installation of pre-built packages is handled directly by the opkg utility within your running OpenWrt system or by using the OpenWrt SDK on a build system.
Usage
This repository is intended to be layered on-top of an OpenWrt buildroot. If you do not have an OpenWrt buildroot installed, see the documentation at: OpenWrt Buildroot â Installation on the OpenWrt support site.
This feed is enabled by default. To install all its package definitions, run:
./scripts/feeds update packages
./scripts/feeds install -a -p packages

License
See LICENSE file.
Package Guidelines
See CONTRIBUTING.md file.
",1814
malramsay64/statdyn-analysis,Python,"Statdyn Analysis




This is a set of scripts that use
Hoomd to perform the Molecular
dynamics simulations of a glass forming molecular liquid. There is a particular
focus on understanding the dynamic properties of these molecules.
Note that this is still very early alpha software and there are likely to be
large breaking changes that occur.
Installation
The simplest method of installation is using conda. To install
conda install -c malramsay statdyn-analysis

It is also possible to set the repository up as a development environment,
in which case cloning the repository and installing is possible by running
git clone https://github.com/malramsay64/statdyn-analysis.git
cd statdyn-analysis
conda env create
source activate sdanalysis-dev
python setup.py develop

Once the environment is setup the tests can be run with
pytest

Running Analysis
Dynamics of a trajectory can be computed using the command
sdanalysis comp-dynamics trajectory-Trimer-13.50-1.20.gsd

which will generate an hdf5 file of the same name containing a single table,
dynamics which has all the dynamic quantities tabulated. This also includes
a start index, over which statistics can be computed.
Finally the command
sdanalysis figure

will open up a bokeh server which will allow for the interactive visualisation
of all dump-*.gsd files in the current directory.
",4
naderghanbari/clrs-scala,Scala,"Introduction to Algorithms in Scala
You will nee Java 8 or later and sbt in
order to compile and run tests.
This project is an attempt to implement algorithms in
Introduction to algorithms, 3rd edition, CLRS, MIT Press in Scala.
In most cases the implementations are identical to the original
algorithms in the book. In some cases a functional counterpart is also
implemented. Check the docs of classes and functions for more
info per case.
Indices
The book has the convention of 1-based indices for arrays, i.e. first
element is located at index 1, except for very rare cases
where 0-based indices are used.
We follow the 0-based convention here though, as in Scala like many
other programming language, arrays are 0-based.
Test
Tests are written using ScalaTest.
Run them with the following command:
> sbt test

",2
hanickadot/compile-time-regular-expressions,C++,"Compile time regular expressions v2

Fast compile-time regular expression with support for matching/searching/capturing in compile-time or runtime.
You can use single header version from directory single-header. This header can be regenerated with make single-header.
More info at compile-time.re
What this library can do?
ctre::match<""REGEX"">(subject); // C++20
""REGEX""_ctre.match(subject); // C++17 + N3599 extension

Matching
Searching
Capturing content (named captures are supported too)

The library is implementing most of the PCRE syntax with a few exceptions:

atomic groups
boundaries other than ^$
callouts
character properties
comments
conditional patterns
control characters (\cX)
horizontal / vertical character classes (\h\H\v\V)
match point reset (\K)
named characters
octal numbers
options / modes
subroutines
unicode grapheme cluster (\X)

More documentation on pcre.org.
What can be subject (input)?

std::string-like object (std::string_view or your own string if it's providing begin/end functions with forward iterators)
pair of forward iterators

Supported compilers

clang 6.0+ (template UDL, C++17 syntax)
xcode clang 10.0+ (template UDL, C++17 syntax)
gcc 7.4+ (template UDL, C++17 syntax)
gcc 9.0+ (C++17 & C++20 cNTTP syntax)
MSVC 15.8.8+ (C++17 syntax only)

Template UDL syntax
Compiler must support N3599 extension, as GNU extension in gcc (not in GCC 9.1+) and clang.
constexpr auto match(std::string_view sv) noexcept {
	using namespace ctre::literals;
	return ""h.*""_ctre.match(sv);
}
If you need N3599 extension in GCC 9.1+ you can't use -pedantic mode and define macro CTRE_ENABLE_LITERALS.
C++17 syntax
You can provide pattern as a constexpr ctll::fixed_string variable.
static constexpr auto pattern = ctll::fixed_string{ ""h.*"" };

constexpr auto match(std::string_view sv) noexcept {
	return ctre::match<pattern>(sv);
}
(this is tested in MSVC 15.8.8)
C++20 syntax
Currently only compiler which supports cNTTP syntax ctre::match<PATTERN>(subject) is GCC 9+.
constexpr auto match(std::string_view sv) noexcept {
	return ctre::match<""h.*"">(sv);
}
Examples
Extracting number from input
std::optional<std::string_view> extract_number(std::string_view s) noexcept {
	if (auto m = ctre::match<""[a-z]+([0-9]+)"">(s)) {
        return m.get<1>().to_view();
    } else {
        return std::nullopt;
    }
}
link to compiler explorer
Extracting values from date
struct date { std::string_view year; std::string_view month; std::string_view day; };

std::optional<date> extract_date(std::string_view s) noexcept {
    using namespace ctre::literals;
    if (auto [whole, year, month, day] = ctre::match<""(\\d{4})/(\\d{1,2})/(\\d{1,2})"">(s); whole) {
        return date{year, month, day};
    } else {
        return std::nullopt;
    }
}

//static_assert(extract_date(""2018/08/27""sv).has_value());
//static_assert((*extract_date(""2018/08/27""sv)).year == ""2018""sv);
//static_assert((*extract_date(""2018/08/27""sv)).month == ""08""sv);
//static_assert((*extract_date(""2018/08/27""sv)).day == ""27""sv);
link to compiler explorer
Lexer
enum class type {
    unknown, identifier, number
};

struct lex_item {
    type t;
    std::string_view c;
};

std::optional<lex_item> lexer(std::string_view v) noexcept {
    if (auto [m,id,num] = ctre::match<""([a-z]+)|([0-9]+)"">(v); m) {
        if (id) {
            return lex_item{type::identifier, id};
        } else if (num) {
            return lex_item{type::number, num};
        }
    }
    return std::nullopt;
}
link to compiler explorer
Range over input
This support is preliminary and probably the API will be changed.
auto input = ""123,456,768""sv;

for (auto match: ctre::range<""([0-9]+),?"">(input)) {
	std::cout << std::string_view{match.get<0>()} << ""\n"";
}
",725
gosuri/uitable,Go,"uitable  
uitable is a go library for representing data as tables for terminal applications. It provides primitives for sizing and wrapping columns to improve readability.
Example Usage
Full source code for the example is available at example/main.go
table := uitable.New()
table.MaxColWidth = 50

table.AddRow(""NAME"", ""BIRTHDAY"", ""BIO"")
for _, hacker := range hackers {
  table.AddRow(hacker.Name, hacker.Birthday, hacker.Bio)
}
fmt.Println(table)
Will render the data as:
NAME          BIRTHDAY          BIO
Ada Lovelace  December 10, 1815 Ada was a British mathematician and writer, chi...
Alan Turing   June 23, 1912     Alan was a British pioneering computer scientis...
For wrapping in two columns:
table = uitable.New()
table.MaxColWidth = 80
table.Wrap = true // wrap columns

for _, hacker := range hackers {
  table.AddRow(""Name:"", hacker.Name)
  table.AddRow(""Birthday:"", hacker.Birthday)
  table.AddRow(""Bio:"", hacker.Bio)
  table.AddRow("""") // blank
}
fmt.Println(table)
Will render the data as:
Name:     Ada Lovelace
Birthday: December 10, 1815
Bio:      Ada was a British mathematician and writer, chiefly known for her work on
          Charles Babbage's early mechanical general-purpose computer, the Analytical
          Engine

Name:     Alan Turing
Birthday: June 23, 1912
Bio:      Alan was a British pioneering computer scientist, mathematician, logician,
          cryptanalyst and theoretical biologist

Installation
$ go get -v github.com/gosuri/uitable


",475
HussainiLab/BatchTINTV3,Python,"BatchTINTV3
BatchTINT is A GUI created by the Taub Institute in order to create an end-user friendly batch processing solution to complement Axona's new command line modification of TINT.
This GUI will allow the user to define a directory. Within this directory it will be continuously (unless closed) searching for new files to analyze via Tint. The user simply drags a folder containing the appropriate '.set', '.eegx', '.pos', and '.x' tetrode files and the GUI will automatically detect these files and take care of the rest.
Requirements
Operating System: Windows
This GUI was created with the Windows operating system in mind. Therefore, it is untested on Mac OSX, as well as Linux. It is possible
(though unlikely) that it would work on other operating systems.
Suggested: Use of Python 3.4.4, PyQt4 is most compatible with this version of Python, however there are Python 3.5 versions that may work
Python 3.4.4 can be downloaded here as well: https://www.python.org/downloads/release/python-344/
Installation


For those that do not have GitHub installed on their desktop, they will need to install the GitHub Desktop Application:
https://desktop.github.com/


The next step would be to open the Command Prompt


In the Command Prompt navigate to the folder where you want to clone the repository (type in: cd folder_path).


If you want it on your Desktop type in the following: cd ""C:\Users\ [user name]\Desktop\""

Then your next step will be to clone the repository by typing in the following to your Command Prompt:

git clone https://github.com/ephyslab/BatchTINTV3.git

Note: This may take a few minutes. If there is an error produced by the Command Prompt saying the following:
'git' is not recognized as an internal or external command, operable program or batch file.
ensure that you have added the appropriate git locations to the path system variable. Follow these steps in order to add system variables
a) First. you are going to need to find the location of git-core and copy the path, it will be similar to the following:
C:\Users\ [Your Username]\AppData\Local\GitHub\ [Something Similar to PortableGit_25d850739bc178b2eb13c3e2a9faafea2f9143c0]\mingw32\libexec\git-core
b) Second, you will need to find the path of the 'bin' folder within the 'mingw32' folder which will look similar to the following:
C:\Users\ [your name]\AppData\Local\GitHub\ [Something Similar to PortableGit_25d850739bc178b2eb13c3e2a9faafea2f9143c0]\mingw32\bin
c) Go to the following window: Control Panel -> System and Security -> System -> Advanced Systems Settings
-> Advanced Tab (if not already on it) and -> Environmental Variables
d) Under 'System variables' edit the 'Path' variable
e) If the variable is a single line of paths then append the two paths to the end of the variable,
you will need to add a semicolon to separate each path (existing path;git-core path;bin path).
If the window you are looking at has a list of the different paths then you will simply add the two paths separately.
f) Click apply/okay to confirm the addition of these paths, close the existing Command Prompt, open a new Command Prompt and the commands will now be available

If you are using Python 3.4.4 I have included two wheel (.whl) files in the GitHub repository for PyQt4 that will need
to be installed via the Command Prompt.

If you have not added the Python 3.4.4 path to the system variable (as done for the GitHub path) then you will have to do the same.
Add the following paths to the 'path' system variable:
C:\Python34\Scripts
C:\Python34
You should also upgrade the 'pip' python script which allows for the downloading of python libraries. To upgrade pip, type the
following into the Command Prompt (remember to close and re-open the Command Prompt after adding the system variable):
python -m pip install --upgrade pip
Now you can type the following into the command prompt to install PyQt4:
python -m pip install [wheel file path] 
If you have spaces in your wheel file path make sure to surround the path by quotes
example:
python -m pip install ""C:\Users\My Name\Desktop\GitHub\file.whl""
The wheel files are the following:
64-bit PC: use the PyQt4-4.11.4-cp34-none-win_amd64.whl files
32-bit PC: use the PyQt4-4.11.4-cp34-none-win32.whl file
Note: if you are using Python 3.5 you can find those .whl files here: http://www.lfd.uci.edu/~gohlke/pythonlibs/#pyqt4

Install the python library responsible for some of the images on the GUI

Type in the following into the Command Prompt:
python -m pip install pillow

You will also have to add Tint to the system variable as we did before with GitHub and Python

Add the following path for 64-bit systems: C:\Program Files (x86)\Axona\Tint
32-bit systems should be the following: C:\Program Files\Axona\Tint
Running GUI
Now in your Command Prompt you can type the following in order to run the GUI:
The easiest way to run it is to create a '.bat' file on the desktop that contains the following information:
cd ""[pathway to your BatchTINT folder]""
python BatchSort.py
exit

When you click this .bat file it will run the program.
Now you can see a main window of the GUI that states the current directory (if it's your first time opening the program, it will say
there is no directory chosen), as a few checkboxes, and a few buttons at the bottom. You are going to want to click the 'choose directory' button and navigate to a directory that this program will analyze.
If you do not click the 'apply' button on the Choose Directory window, the directory will not be applied, so make sure you click 'apply' and not 'back'
Choose the directory based off of the following modes:

Batch: This you need to choose a directory that contains sub-directories with the sessions you want to analyze.

Chosen Directory
    âââ Session 1
    |      âââ session_file.set
    |      âââ session_file.pos
    |      âââ ...
    âââ Session 2
    |      âââ session_file2.set
    |      âââ session_file2.pos
    |      âââ ...
    |    
    âââ session_file3.set
    âââ session_file3.pos
    âââ ...
    
In the above example, it will convert the sub-directories 'Session 1' and 'Session 2', but not the session files directly within the chosen directory (session_file3)


Non Batch: You will choose the directory that directly contains the session files that you want to convert. Thus using the same example above, it will skip the files within sub-directories 'Session 1' and 'Session 2', and only look for those files directly within the Chosen Directory, thus session_file3 will be chosen. Note: if you want this mode, click the Non-Batch checkbox

Once a directory is chosen, you will see the Queue populate a list of sessions that are able to be converted (if it has already been converted, it won't be on this list). You can re-order this list if you want certain files to be converted first using the Move Up/Down buttons.
You should now look at the Klusta Settings (by clicking the Klusta Settings button) and look through the basic/advanced settings options. The format should look familiar as it is a replica (almost) of that which you've seen while using Tint.
It is important to change the Number of Tetrodes option in the 'basic' tab. This will help the GUI look for the tetrode data. Our lab uses both 4 and 8 tetrode drives therefore the default for this GUI was set to 8. This number does not need to be exact, but it needs to be greater than or equal to the number of tetrodes you used in the files you are analyzing. If you have 8 tetrodes but the field has the number 4 filled in, it will only analyze the first four tetrodes (if they exist in the folder). It will skip any non-existing tetrodes.
Once these settings have been applied, the values will be saved for the next time you open up the GUI.
There is also the option if you want Tint to run in ""silent"" mode or be ""visible"". There is a Run Silently checkbox on main window of the GUI that you will be able to check. If it is checked everything will run in the background.
You can press Run if all the settings are correct. A Processed folder will be created within the directory you chose which will have your newly created .CUT files.
Authors

Geoff Barrett - Geoffâs GitHub

License
This project is licensed under the GNU  General  Public  License - see the LICENSE.md file for details
",3
ArduPilot/ardupilot,C++,"ArduPilot Project

  


The ArduPilot project is made up of:


ArduCopter (or APM:Copter) : code, wiki


ArduPlane (or APM:Plane) : code, wiki


ArduRover (or APMrover2) : code, wiki


ArduSub (or APM:Sub) : code, wiki


Antenna Tracker : code, wiki


User Support & Discussion Forums


Support Forum: http://discuss.ardupilot.org/


Community Site: http://ardupilot.org


Developer Information


Github repository: https://github.com/ArduPilot/ardupilot


Main developer wiki: http://dev.ardupilot.org


Developer discussion: http://discuss.ardupilot.org


Developer chat: https://gitter.im/ArduPilot/ardupilot


Top Contributors

Flight code contributors
Wiki contributors
Most active support forum users
Partners who contribute financially

How To Get Involved


The ArduPilot project is open source and we encourage participation and code contributions: guidelines for contributors to the ardupilot codebase


We have an active group of Beta Testers especially for ArduCopter to help us find bugs: release procedures


Desired Enhancements and Bugs can be posted to the issues list.


Help other users with log analysis in the support forums


Improve the wiki and chat with other wiki editors on Gitter


Contact the developers on one of the communication channels


License
The ArduPilot project is licensed under the GNU General Public
License, version 3.


Overview of license


Full Text


Maintainers
Ardupilot is comprised of several parts, vehicles and boards. The list below
contains the people that regularly contribute to the project and are responsible
for reviewing patches on their specific area.  See also the list of developers with merge rights.

Andrew Tridgell:

Vehicle: Plane, AntennaTracker
Board: APM1, APM2, Pixhawk, Pixhawk2, PixRacer


Francisco Ferreira:

Bug Master


Grant Morphett:

Vehicle: Rover


Jacob Walser:

Vehicle: Sub


Lucas De Marchi:

Subsystem: Linux


Michael du Breuil:

Subsystem: Batteries
Subsystem: GPS
Subsystem: Scripting


Peter Barker:

Subsystem: DataFlash, Tools


Randy Mackay:

Vehicle: Copter, Rover, AntennaTracker


Tom Pittenger:

Vehicle: Plane


Bill Geyer:

Vehicle: TradHeli


Chris Olson:

Vehicle: TradHeli


Emile Castelnuovo:

Board: VRBrain


Eugene Shamaev:

Subsystem: CAN bus
Subsystem: UAVCAN


Georgii Staroselskii:

Board: NavIO


Gustavo JosÃ© de Sousa:

Subsystem: Build system


Julien Beraud:

Board: Bebop & Bebop 2


Leonard Hall:

Subsystem: Copter attitude control and navigation


Matt Lawrence:

Vehicle: 3DR Solo & Solo based vehicles


Matthias Badaire:

Subsystem: FRSky


Mirko Denecke:

Board: BBBmini, BeagleBone Blue, PocketPilot


Paul Riseborough:

Subsystem: AP_NavEKF2
Subsystem: AP_NavEKF3


Pierre Kancir:

Subsystem: Copter SITL, Rover SITL


VÃ­ctor Mayoral Vilches:

Board: PXF, Erle-Brain 2, PXFmini


Amilcar Lucas:

Subsystem: Marvelmind



",3978
php/php-src,C,"




The PHP Interpreter
PHP is a popular general-purpose scripting language that is especially suited to
web development. Fast, flexible and pragmatic, PHP powers everything from your
blog to the most popular websites in the world. PHP is distributed under the PHP
License v3.01.


Documentation
The PHP manual is available at php.net/docs.
Installation
Prebuilt packages and binaries
Prebuilt packages and binaries can be used to get up and running fast with PHP.
For Windows, the PHP binaries can be obtained from
windows.php.net. After extracting the archive the
*.exe files are ready to use.
For other systems, see the installation chapter.
Building PHP source code
For Windows, see Build your own PHP on Windows.
PHP uses autotools on Unix systems to configure the build:
./buildconf
./configure [options]

See ./configure -h for configuration options.
make [options]

See make -h for make options.
The -j option shall set the maximum number of jobs make can use for the
build:
make -j4

Shall run make with a maximum of 4 concurrent jobs: Generally the maximum
number of jobs should not exceed the number of cores available.
Testing PHP source code
PHP ships with an extensive test suite, the command make test is used after
successful compilation of the sources to run this test suite.
It is possible to run tests using multiple cores by setting -jN in
TEST_PHP_ARGS:
make TEST_PHP_ARGS=-j4 test

Shall run make test with a maximum of 4 concurrent jobs: Generally the maximum
number of jobs should not exceed the number of cores available.
The qa.php.net site provides more detailed info about
testing and quality assurance.
Installing PHP built from source
After a successful build (and test), PHP may be installed with:
make install

Depending on your permissions and prefix, make install may need super user
permissions.
PHP extensions
Extensions provide additional functionality on top of PHP. PHP consists of many
essential bundled extensions. Additional extensions can be found in the PHP
Extension Community Library - PECL.
Contributing
The PHP source code is located in the Git repository at
git.php.net. Contributions are most welcome by forking
the GitHub mirror repository and sending a
pull request.
Discussions are done on GitHub, but depending on the topic can also be relayed
to the official PHP developer mailing list internals@lists.php.net.
New features require an RFC and must be accepted by the developers. See
Request for comments - RFC and
Voting on PHP features for more information
on the process.
Bug fixes do not require an RFC but require a bug tracker ticket. Open a
ticket at bugs.php.net and reference the bug id using
#NNNNNN.
Fix #55371: get_magic_quotes_gpc() throws deprecation warning

After removing magic quotes, the get_magic_quotes_gpc function caused a
deprecated warning. get_magic_quotes_gpc can be used to detect the
magic_quotes behavior and therefore should not raise a warning at any time.
The patch removes this warning.

Pull requests are not merged directly on GitHub. All PRs will be pulled and
pushed through git.php.net. See
Git workflow for more details.
Guidelines for contributors
See further documents in the repository for more information on how to
contribute:

Contributing to PHP
PHP coding standards
Mailinglist rules
PHP release process

Credits
For the list of people who've put work into PHP, please see the
PHP credits page.
",23158
codefellows/seattle-dotnet-401d7,C#,"401 .NET Core Curriculum Overview
Resources:

Readme:
Git Ignore:

Week 1 - Basics

Exception Handling

LAB: Numbers Game


Unit Testing

LAB: ATM


System.IO

LAB: Word Guess Game


Classes, Stack/Heap, Garbage Collector

LAB: Tic-Tac-Toe


Linked Lists

LAB: Linked List Implementation
Class with JavaScript



Data Structures:
- How to Approach a DS
- String & Array manipulation
Quiz 1
Week 2 - Advanced

OOP Principles

LAB: Dealership Part 1


Interfaces

LAB: Dealership Part 2


Collections (Generic) & Enums

LAB: Lending Library


LINQ & Lambda Expressions

LAB: LINQ in Manhattan


Stacks & Queues // Recursion

LAB: Stacks and Queues Implementation



Data Structure: Linked Lists
Quiz 2
Week 3 - MVC & Entity Framework Core

MVC Intro

Fullstack MVC App


Relational Databases & schemas

Lab: System Design//Design a ERD // Schema


CRUD Intro to Entity Framework

Lab: AsyncInn Hotel Project Part 1
Create Models from DB schema
Identify Primary Keys/Foreign Keys/Composite Keys


Entity Framework part 2

LAB: EFCore Seeding/View Models/Tag Helpers


Career Coaching

Data Structure: Stacks/Queues
Quiz 3
Week 4 - Repository Design Pattern & APIs

Dependency Injection & Repository Design Pattern

Incorporate the Repository Design Pattern into lab
Introduce Singleton Design Pattern


Azure Deployment & Unit Tests

Deploy app to Azure and write basic tests


API Introduction

TODO List Part 1


API - API part 2

LAB: Making a call out to an API


Midterm Project Kickoff

Data Structures: Trees (Binary, BST, K-ary)
Quiz 4
Week 5
Midterm Project week

Build a Full CRUD web app
Build a custom API
Make the Web app call out to the API

Week 6 - Identity

Intro to E-Com project and PM Tool ""Azure DevOps""

Beginning of Sprint 1: Create a basic MVC app with database


Intro to Identity: Setup & Registration

Implement Identity API and create use registration


Login and Claims

Add Login page to E-Com and capture specific claims


Custom Policies

Create policies to customize access across the site with previous claims
END OF SPRINT 1


Career Coaching

Data Structure: Hash Tables
Quiz 5
Azure Dev Ops

Sprint Backlog
Create User stories with tasks and Acceptance tests
Task Branching
Time estimation
PRs within Azure Dev Ops
Peer Reviews
Weekly Goals and Retrospectives

Week 7

View Components

SPRINT 2 START
Add a ""Basket"" component to E-Com site
System Design exercise - Integrate basket capabilities into the site with DB tables


OAUTH

Add 2 3rd party providers as login to project


AUTH.NET (How to read 3rd party Docs)

Incorporate ""fake"" payment processing into project


Razor Pages

Add in user profile & admin dashboard page as Razor Page
END OF SPRINT 2


Career Coaching

Data Structure: Graphs
Quiz 6
Week 8 - Azure

Sass//SCSS

SPRINT 3 START


Email Services

LAB: Incorporate SendGrid into project


Azure Blob Storage

LAB: Save all product images in Azure Blob Storage


Web Security

OWASP security Requirements
HTTP and SSL
GDPR
LAB: Vulnerability Report
END OF SPRINT 3


Review Day

Data Structure: Sorting Algorithms
Quiz 7
Week 9 - MISC.

.NET 4.7 MVC & Web Forms
Design Patterns

Different Types
Implement Factory


Ethics in Technology
Open Source Contribution

Learn, Investigate, and Contribute to an open source project


Career Coaching 3

Data Structures: Mock Interviews
Quiz 8
Week 10
Final Project Week

Build a full-stack app with ASP.NET Core
Collaborate as a team with git and VSTS
Present on completed project: test coverage, performance, security, and privacy

",4
php/php-src,C,"




The PHP Interpreter
PHP is a popular general-purpose scripting language that is especially suited to
web development. Fast, flexible and pragmatic, PHP powers everything from your
blog to the most popular websites in the world. PHP is distributed under the PHP
License v3.01.


Documentation
The PHP manual is available at php.net/docs.
Installation
Prebuilt packages and binaries
Prebuilt packages and binaries can be used to get up and running fast with PHP.
For Windows, the PHP binaries can be obtained from
windows.php.net. After extracting the archive the
*.exe files are ready to use.
For other systems, see the installation chapter.
Building PHP source code
For Windows, see Build your own PHP on Windows.
PHP uses autotools on Unix systems to configure the build:
./buildconf
./configure [options]

See ./configure -h for configuration options.
make [options]

See make -h for make options.
The -j option shall set the maximum number of jobs make can use for the
build:
make -j4

Shall run make with a maximum of 4 concurrent jobs: Generally the maximum
number of jobs should not exceed the number of cores available.
Testing PHP source code
PHP ships with an extensive test suite, the command make test is used after
successful compilation of the sources to run this test suite.
It is possible to run tests using multiple cores by setting -jN in
TEST_PHP_ARGS:
make TEST_PHP_ARGS=-j4 test

Shall run make test with a maximum of 4 concurrent jobs: Generally the maximum
number of jobs should not exceed the number of cores available.
The qa.php.net site provides more detailed info about
testing and quality assurance.
Installing PHP built from source
After a successful build (and test), PHP may be installed with:
make install

Depending on your permissions and prefix, make install may need super user
permissions.
PHP extensions
Extensions provide additional functionality on top of PHP. PHP consists of many
essential bundled extensions. Additional extensions can be found in the PHP
Extension Community Library - PECL.
Contributing
The PHP source code is located in the Git repository at
git.php.net. Contributions are most welcome by forking
the GitHub mirror repository and sending a
pull request.
Discussions are done on GitHub, but depending on the topic can also be relayed
to the official PHP developer mailing list internals@lists.php.net.
New features require an RFC and must be accepted by the developers. See
Request for comments - RFC and
Voting on PHP features for more information
on the process.
Bug fixes do not require an RFC but require a bug tracker ticket. Open a
ticket at bugs.php.net and reference the bug id using
#NNNNNN.
Fix #55371: get_magic_quotes_gpc() throws deprecation warning

After removing magic quotes, the get_magic_quotes_gpc function caused a
deprecated warning. get_magic_quotes_gpc can be used to detect the
magic_quotes behavior and therefore should not raise a warning at any time.
The patch removes this warning.

Pull requests are not merged directly on GitHub. All PRs will be pulled and
pushed through git.php.net. See
Git workflow for more details.
Guidelines for contributors
See further documents in the repository for more information on how to
contribute:

Contributing to PHP
PHP coding standards
Mailinglist rules
PHP release process

Credits
For the list of people who've put work into PHP, please see the
PHP credits page.
",23158
codefellows/seattle-dotnet-401d7,C#,"401 .NET Core Curriculum Overview
Resources:

Readme:
Git Ignore:

Week 1 - Basics

Exception Handling

LAB: Numbers Game


Unit Testing

LAB: ATM


System.IO

LAB: Word Guess Game


Classes, Stack/Heap, Garbage Collector

LAB: Tic-Tac-Toe


Linked Lists

LAB: Linked List Implementation
Class with JavaScript



Data Structures:
- How to Approach a DS
- String & Array manipulation
Quiz 1
Week 2 - Advanced

OOP Principles

LAB: Dealership Part 1


Interfaces

LAB: Dealership Part 2


Collections (Generic) & Enums

LAB: Lending Library


LINQ & Lambda Expressions

LAB: LINQ in Manhattan


Stacks & Queues // Recursion

LAB: Stacks and Queues Implementation



Data Structure: Linked Lists
Quiz 2
Week 3 - MVC & Entity Framework Core

MVC Intro

Fullstack MVC App


Relational Databases & schemas

Lab: System Design//Design a ERD // Schema


CRUD Intro to Entity Framework

Lab: AsyncInn Hotel Project Part 1
Create Models from DB schema
Identify Primary Keys/Foreign Keys/Composite Keys


Entity Framework part 2

LAB: EFCore Seeding/View Models/Tag Helpers


Career Coaching

Data Structure: Stacks/Queues
Quiz 3
Week 4 - Repository Design Pattern & APIs

Dependency Injection & Repository Design Pattern

Incorporate the Repository Design Pattern into lab
Introduce Singleton Design Pattern


Azure Deployment & Unit Tests

Deploy app to Azure and write basic tests


API Introduction

TODO List Part 1


API - API part 2

LAB: Making a call out to an API


Midterm Project Kickoff

Data Structures: Trees (Binary, BST, K-ary)
Quiz 4
Week 5
Midterm Project week

Build a Full CRUD web app
Build a custom API
Make the Web app call out to the API

Week 6 - Identity

Intro to E-Com project and PM Tool ""Azure DevOps""

Beginning of Sprint 1: Create a basic MVC app with database


Intro to Identity: Setup & Registration

Implement Identity API and create use registration


Login and Claims

Add Login page to E-Com and capture specific claims


Custom Policies

Create policies to customize access across the site with previous claims
END OF SPRINT 1


Career Coaching

Data Structure: Hash Tables
Quiz 5
Azure Dev Ops

Sprint Backlog
Create User stories with tasks and Acceptance tests
Task Branching
Time estimation
PRs within Azure Dev Ops
Peer Reviews
Weekly Goals and Retrospectives

Week 7

View Components

SPRINT 2 START
Add a ""Basket"" component to E-Com site
System Design exercise - Integrate basket capabilities into the site with DB tables


OAUTH

Add 2 3rd party providers as login to project


AUTH.NET (How to read 3rd party Docs)

Incorporate ""fake"" payment processing into project


Razor Pages

Add in user profile & admin dashboard page as Razor Page
END OF SPRINT 2


Career Coaching

Data Structure: Graphs
Quiz 6
Week 8 - Azure

Sass//SCSS

SPRINT 3 START


Email Services

LAB: Incorporate SendGrid into project


Azure Blob Storage

LAB: Save all product images in Azure Blob Storage


Web Security

OWASP security Requirements
HTTP and SSL
GDPR
LAB: Vulnerability Report
END OF SPRINT 3


Review Day

Data Structure: Sorting Algorithms
Quiz 7
Week 9 - MISC.

.NET 4.7 MVC & Web Forms
Design Patterns

Different Types
Implement Factory


Ethics in Technology
Open Source Contribution

Learn, Investigate, and Contribute to an open source project


Career Coaching 3

Data Structures: Mock Interviews
Quiz 8
Week 10
Final Project Week

Build a full-stack app with ASP.NET Core
Collaborate as a team with git and VSTS
Present on completed project: test coverage, performance, security, and privacy

",4
cityofsandiego/seaboard,CSS,"DataSD is the official portal for City of San Diego Open Data. Here, you'll find data about City operations, including public safety, street repairs, public facilities, code enforcement, business licensing, etc. If you canât find what youâre looking for, we might still be working on publishing it, or it might come from another agency.
",17
TensShinet/toy_os,None,"toy_os
ç¨ c è¯­è¨å®ç°ä¸ä¸ª toy_os
",11
Mach131/CMS611-S19Final,C#,"CMS611-S19Final
CMS.611 Spring 2019 Final Project
",2
maohhgg/leetcode,TypeScript,"LST (Leetcode Solutions with TypeScript)
æç LeetCode è¡¥å¨è®¡åï¼æ¨å¨ç¨ TypeScript å·å®ææç LeetCode Problems ð
è§£é¢
é®é¢åç±»

ææè§£ (All)
æ°ç» (Array)
å­ç¬¦ä¸² (String)
æ°å­¦ (Math)
æåº (Sort)
é¾è¡¨ (Linked List)
éå½ (Recursion)
æ  (Stack)
å  (Heap)
æ  (Tree)
åæé(Two Pointers)
ä½è¿ç® (Bit Manipulation))
åå¸è¡¨ (Hash Table)
å¨æè§å (Dynamic Programming)
æ·±åº¦ä¼åæç´¢ (Depth-first Search)
å¹¿åº¦ä¼åæç´¢ (Breadth-first Search)
äºåæ¥æ¾ (Binary Search)
åæ²»ç®æ³ (Divide and Conquer)

æ¨¡å
å¨ææé®é¢ä¸­ï¼ä¼ç»å¸¸åºç°éè¦é¢å¤çä»£ç å
// Definition for singly-linked list.
function ListNode(val) {
    this.val = val;
    this.next = null;
}
// Definition for a binary tree node.
function TreeNode(val) {
    this.val = val;
    this.left = this.right = null;
}
å¨æ¬é¡¹ç®ä¸­ä¼å®ç°ä¸äºæ¨¡åï¼æ¹ä¾¿æä»¬è°è¯æ¯å¦ é¾è¡¨ å æ  ä¹ç±»çé¢ç®ãå·ä½ä½¿ç¨æ¹å¼è¯·ç¹å»ä¸é¢é¾æ¥ï¼

æ°ç» IntervalUnit
é¾è¡¨ LinkList
æ  Tree

ä½¿ç¨è¯´æ
ä¾èµ
TypeScript éè¦ typescript@>=2.0 çæ¯æï¼å¦æéè¦ç´æ¥è¿è¡ TypeScript èæ¬ï¼è¿éè¦ ts-node çæ¯æ
# æ¨èå¨å±å®è£
npm install -g ts-node
npm install -g typescript
è¿è¡
è¿è¡ä»£ç åè°è¯ä»£ç ï¼éè¦æå¨è¿è¡æå®æä»¶ï¼
problems $ ts-node ./src/problems/1.two-sum/index.ts    # è¿è¡ TypeScript èæ¬
problems $ tsc ./src/problems/1.two-sum/index.ts        # è½¬è¯æ JavaScript èæ¬

# è½¬è¯æ JavaScript èæ¬åï¼å¯ä»¥ä½¿ç¨ nodejs è¿è¡èæ¬
problems $ node ./src/problems/1.two-sum/index.js
å¶ä»
å½è§£ç­å®å¶ä»é¢ç®ï¼éè¦æ´æ°å±ç¤ºå·²ç»è§£ç­ç markdown ææ¡£æ¶ï¼åªéæ§è¡ï¼
cd build
python3 update.py
å³å¯æ´æ° doc ç®å½ä¸ææåç±»ä¿å­ä¿¡æ¯ç markdownææ¡£ï¼å½åé»è®¤åä¸ºåç±»ï¼è¯·æ¥éä¸è¾¹çé®é¢åç±»äºè§£å·ä½çåç±»ãå¦ææ³æ·»å æ°çåç±»ï¼åªéè¦å¨ update.py æä»¶ç mianå½æ°ä¸­è¿½å æ³è¦çåç±»åï¼
if __name__ == ""__main__"":
    p = Problems()
    p.update('All')
    p.update('Array')
    p.update('Binary Search')
    ...
    p.update('Breadth-first Search')
éè¦æ³¨æåç§°å¿é¡»å LeetCode ç tagåç§°ä¸è´ã
TODO

 æçä¹å¹´å®æææé¢ç® ð

",2
vseryakov/backendjs,JavaScript,"Backend library for Node.js
General purpose backend library. The primary goal is to have a scalable platform for running and managing Node.js
servers for Web services implementation.
This project only covers the lower portion of the Web services ecosystem:
Node.js processes, HTTP servers, basic API functionality, database access, caching, messaging between processes,
metrics and monitoring, a library of tools for developing Node.js servers.
For the UI and presentation layer there are no restrictions what to use as long as it can run on top of the Express server.
Features:

Exposes a set of Web service APIs over HTTP(S) using Express framework.
Database API supports SQLite, PostgreSQL, MySQL, DynamoDB, Cassandra, MongoDB, Redis with all basic operations behaving the
same way allowing you to switch databases without changing the code.
Database drivers for LevelDB, LMDB, CouchDB, Riak, ElasticSearch support only a subset of all database operations
Database operations (Get, Put, Del, Update, Select) for all supported databases using the same DB API.
DynamoDB Streams processing in background worker processes
Easily extensible to support any kind of database, provides a database driver on top of Redis with all supported methods as an example.
Provides accounts, connections, locations, messaging and icons APIs with basic functionality for a quick start.
Supports crontab and queue job processing by separate worker processes.
Authentication is based on signed requests using API key and secret, similar to Amazon AWS signing requests.
Runs web server as separate processes to utilize multiple CPU cores.
Supports WebSockets connections and process them with the same Express routes as HTTP requests
Supports several cache modes(Redis, Memcache, Hazelcast, LRU) for the database operations, multiple hosts support
in the clients for failover.
Supports several PUB/SUB modes of operations using Redis, RabbitMQ, Hazelcast.
Supports async jobs processing using several work queue implementations on top of SQS, Redis, DB, RabbitMQ, Hazelcast.
ImageMagick as a separate C++ module for in-process image scaling, see bkjs-wand on NPM.
REPL (command line) interface for debugging and looking into server internals.
Supports push notifications for mobile devices, APN and GCM/FCM.
Supports HTTP(S) reverse proxy mode where multiple Web workers are load-balanced by the proxy
server running in the master process instead of relying on the OS scheduling between processes listening on the same port.
Can be used with any MVC, MVVC or other types of frameworks that work on top of, or with, the Express server.
AWS support is very well integrated including EC2, S3, DynamoDB, SQS and more.
Includes simple log watcher to monitor the log files including system errors.
Supports i18n hooks for request/response objects, easily overriden with any real i18n implementation.
Integrated very light unit testing facility which can be used to test modules and API requests
Support runtime metrics about the timing on database, requests, cache, memory and request rate limit control
Hosted on github, BSD licensed.

Check out the Documentation for more details.
Installation
To install the module with all optional dependencies if they are available in the system
npm install backendjs

This may take some time because of downloading and compiling required dependencies like ImageMagick. They are not required in all
applications but still part of the core of the system to be available once needed.
To install from the git
 npm install git+https://github.com/vseryakov/backendjs.git

or simply
 npm install vseryakov/backendjs

Quick start


Simplest way of using the backendjs, it will start the server listening on port 8000
  $ node
  > const bkjs = require('backendjs')
  > bkjs.server.start()



Access is allowed only with valid signature except urls that are explicitly allowed without it (see api-allow config parameter below)


Same but using the helper tool, by default it will use embedded SQLite database and listen on port 8000.
  bkjs web



To start the server and connect to the DynamoDB (command line parameters can be saved in the etc/config file, see below about config files)
  bkjs web -db-pool dynamodb -db-dynamodb-pool default -aws-key XXXX -aws-secret XXXX



If running on EC2 instance with IAM profile then no need to specify AWS credentials:
  bkjs web -db-pool dynamodb -db-dynamodb-pool default



or to the PostgreSQL server, database backend
  bkjs web -db-pool pgsql -db-pgsql-pool postgresql://postgres@127.0.0.1/backend



All commands above will behave exactly the same


Tables are not created by default, in order to initialize the database, run the server or the shell with -db-create-tables flag,
it is called only inside a master process, a worker never creates tables on start


prepare the tables in the shell
bksh -db-pool pgsql -db-pgsql-pool postgresql://postgres@127.0.0.1/backend -db-create-tables



run the server and create tables on start
bkjs web -db-pool pgsql -db-pgsql-pool postgresql://postgres@127.0.0.1/backend -db-create-tables





While the local backendjs is runnning, the documentation is always available at http://localhost:8000/doc.html (or whatever port is the server using)


To add users from the command line
  bksh -account-add login test secret test name TestUser email test@test.com -scramble 1



By default no external modules are loaded so it needs the accounts module with a
parameter -allow-modules PATTERN, this will load all modules that match the pattern, default modules start with bk_:
  bkjs web -allow-modules bk_



To start Node.js shell with backendjs loaded and initialized, all command line parameters apply to the shell as well
  bkjs shell



To access the database while in the shell
  > db.select(""bk_account"", {}, function(err, rows, info) { console.log(err, rows, info) });
  > db.select(""bk_account"", {}, lib.log);
  > db.add(""bk_account"", { login: 'test2', secret: 'test2', name' Test 2 name', gender: 'f' }, lib.log);
  > db.select(""bk_account"", { gender: 'm' }, lib.log);
  > db.select(""bk_account"", { gender: ['m','f'] }, { ops: { gender: ""in"" } }, lib.log);



To run an example


Go to examples/api directory:


Run the application, it will start the Web server on port 8000:
  ./app.sh



Now log in with the new account,


Go to http://localhost:8000/api.html and click on Login at the top-right corner, then enter 'test' as login and 'test' as secret in the login popup dialog.


To see your account details run the command in the console /account/get


To see current metrics run the command in the console /system/stats/get


To see charts about accumulated metrics go to http://localhost:8000/metrics.html


When the web server is started with -watch parameters any change in the source files will make the server restart automatically
letting you focus on the source code and not server management, this mode is only enabled by default in development mode,
check app.sh for parameters before running it in production.


Configuration
Almost everything in the backend is configurable using config files, a config database or DNS.
The whole principle behind it is that once deployed in production, even quick restarts are impossible to do so
there should be a way to push config changes to the processes without restarting.
Every module defines a set of config parameters that defines the behavior of the code, due to the single threaded
nature of the Node.js. It is simple to update any config parameter to a new value so the code can operate differently.
To achieve this the code must be written in a special way, like driven by configuration which can be changed at
any time.
All configuration goes through the configuration process that checks all inputs and produces valid output which
is applied to the module variables. Config file or database table with configuration can be loaded on demand or
periodically, for example all local config files are watched for modification and reloaded automatically, the
config database is loaded periodically which is defined by another config parameter.
Backend runtime
When the backendjs server starts it spawns several processes that perform different tasks.
There are 2 major tasks of the backend that can be run at the same time or in any combination:

a Web server (server) with Web workers (web)
a job scheduler (master)

These features can be run standalone or under the guard of the monitor which tracks all running processes and restarted any failed ones.
This is the typical output from the ps command on Linux server:
ec2-user    891  0.0  0.6 1071632 49504 ?  Ssl  14:33   0:01 bkjs: monitor
ec2-user    899  0.0  0.6 1073844 52892 ?  Sl   14:33   0:01 bkjs: master
ec2-user    908  0.0  0.8 1081020 68780 ?  Sl   14:33   0:02 bkjs: server
ec2-user    917  0.0  0.7 1072820 59008 ?  Sl   14:33   0:01 bkjs: web
ec2-user    919  0.0  0.7 1072820 60792 ?  Sl   14:33   0:02 bkjs: web
ec2-user    921  0.0  0.7 1072120 40721 ?  Sl   14:33   0:02 bkjs: worker

To enable any task a command line parameter must be provided, it cannot be specified in the config file. The bkjs utility supports several
commands that simplify running the backend in different modes.

bkjs start - this command is supposed to be run at the server startup as a service, it runs in the background and the monitors all tasks,
the env variable BKJS_SERVER can be set in the profile to one of the master or monitor to define which run mode to use, default mode is monitor
bkjs monitor - this command is supposed to be run at the server startup, it runs in the background and the monitors all processes,
the command line parameters are: -daemon -monitor -master -syslog
bkjs master - this command is supposed to be run at the server startup, it runs in the background and the monitors all processes,
the command line parameters are: -daemon -monitor -master -syslog
bkjs watch - runs the master and Web server in wather mode checking all source files for changes, this is the common command to be used
in development, it passes the command line switches: -watch -master
bkjs web - this command runs just web server process.
bkjs run - this command runs without other parameters, all additional parameters can be added in the command line, this command
is a barebone helper to be used with any other custom settings.
bkjs shell or bksh - start backendjs shell, no API or Web server is initialized, only the database pools

Application structure
The main purpose of the backendjs is to provide API to access the data, the data can be stored in the database or some other way
but the access to that data will be over HTTP and returned back as JSON. This is default functionality but any custom application
may return data in whatever format is required.
Basically the backendjs is a Web server with ability to perform data processing using local or remote jobs which can be scheduled similar to Unix cron.
The principle behind the system is that nowadays the API services just return data which Web apps or mobiles apps can render to
the user without the backend involved. It does not mean this is simple gateway between the database, in many cases it is but if special
processing of the data is needed before sending it to the user, it is possible to do and backendjs provides many convenient helpers and tools for it.
When the API layer is initialized, the api module contains app object which is an Express server.
Special module/namespace app is designated to be used for application development/extension. This module is available in the same way as api and core
which makes it easy to refer and extend with additional methods and structures.
The typical structure of a backendjs application is the following:
    const bkjs = require('backendjs');
    const api = bkjs.api;
    const app = bkjs.app;
    const db = bkjs.db;

    app.listArg = [];

    // Define the module config parameters
    core.describeArgs('app', [
        { name: ""list-arg"", array: 1, type: ""list"", descr: ""List of words"" },
        { name: ""int-arg"", type: ""int"", descr: ""An integer parameter"" },
     ]);

    // Describe the tables or data models, all DB pools will use it, the master or shell
    // process only creates new tables, workers just use the existing tables
    db.describeTables({
         ...
    });

     // Optionally customize the Express environment, setup MVC routes or else, `api.app` is the Express server
    app.configureMiddleware = function(options, callback)
    {
       ...
       callback()
    }

    // Register API endpoints, i.e. url callbacks
    app.configureWeb = function(options, callback)
    {
        api.app.get('/some/api/endpoint', function(req, res) {
          // to return an error, the message will be translated with internal i18n module if locales
          // are loaded and the request requires it
          api.sendReply(res, err);
          // or with custom status and message, explicitely translated
          api.sendReply(res, 404, res.__({ phrase: ""not found"", locale: ""fr"" }));

          // with config check
          if (app.intArg > 5) ...
          if (app.listArg.indexOf(req.query.name) > -1) ...

          // to send data back with optional postprocessing hooks
          api.sendJSON(req, err, data);
          // or simply
          res.json(data);
        });
        ...
        callback();
    }

    // Optionally register post processing of the returned data from the default calls
    api.registerPostProcess('', /^\/account\/([a-z\/]+)$/, function(req, res, rows) { ... });
     ...

    // Optionally register access permissions callbacks
    api.registerAccessCheck('', /^\/test\/list$/, function(req, status, callback) { ...  });
    api.registerPreProcess('', /^\/test\/list$/, function(req, status, callback) { ...  });
     ...
    bkjs.server.start();
Except the app.configureWeb and server.start() all other functions are optional, they are here for the sake of completeness of the example. Also
because running the backend involves more than just running web server many things can be setup using the configuration options like common access permissions,
configuration of the cron jobs so the amount of code to be written to have fully functioning production API server is not that much, basically only
request endpoint callbacks must be provided in the application.
As with any Node.js application, node modules are the way to build and extend the functionality, backendjs does not restrict how
the application is structured.
Modules
Another way to add functionality to the backend is via external modules specific to the backend, these modules are loaded on startup from the backend
home subdirectory modules/ and from the backendjs package directory for core modules. The format is the same as for regular Node.js modules and
only top level .js files are loaded on the backend startup.
By default no modules are loaded except bk_accounts|bk_icons, it must be configured by the -allow-modules config parameter.
The modules are managed per process role, by default server and master processes do not load any modules at all to keep them
small and because they monitor workers the less code they have the better.
The shell process loads all modules, it is configured with .+.
To enable any module to be loaded in any process it can be configured by using a role in the config parameter:
  // Global modules except server and master
  -allow-modules '.+'

  // Master modules
  -allow-modules-master 'bk_accounts|bk_debug'

Once loaded they have the same access to the backend as the rest of the code, the only difference is that they reside in the backend home and
can be shipped regardless of the npm, node modules and other env setup. These modules are exposed in the core.modules the same way as all other core submodules
methods.
Let's assume the modules/ contains file facebook.js which implements custom FB logic:
    const bkjs = require(""backendjs"");
    const fb = {
        args: [
            { name: ""token"", descr: ""API token"" },
        ]
    }
    module.exports = fb;

    fb.configureWeb = function(options, callback) {
       ...
    }

    fb.makeRequest = function(options, callback) {
         bkjs.core.sendRequest({ url: options.path, query: { access_token: fb.token } }, callback);
    }
This is the main app code:
    const bkjs = require(""backendjs"");
    const core = bkjs.core;

    // Using facebook module in the main app
    api.app.get(""some url"", function(req, res) {

       core.modules.facebook.makeRequest({ path: ""/me"" }, function(err, data) {
          bkjs.api.sendJSON(req, err, data);
       });
    });

    bkj.server.start();
NPM packages as modules
In case different modules is better keep separately for maintenance or development purposes they can be split into
separate NPM packages, the structure is the same, modules must be in the modules/ folder and the package must be loadable
via require as usual. In most cases just empty index.js is enough. Such modules will not be loaded via require though but
by the backendjs core.loadModule machinery, the NPM packages are just keep different module directories separate from each other.
The config parameter allow-packages can be used to specify NPM package names to be loaded separated by comma, as with the default
application structure all subfolders inside each NPM package will be added to the core:

modules will be loaded from the modules/ older
locales from the locales/ folder
files in the web/ folder will be added to the static search path
all templates from views/ folder will be used for rendering

If there is a config file present as etc/config it will be loaded as well, this way each package can maintain its default config parameters if necessary
without touching other or global configuration. Although such config files will not be reloaded on changes, when NPM installs or updates packages it
moves files around so watching the old config is no point because the updated config file will be different.
Database schema definition
The backend support multiple databases and provides the same db layer for access. Common operations are supported and all other specific usage can be achieved by
using SQL directly or other query language supported by any particular database.
The database operations supported in the unified way provide simple actions like db.get, db.put, db.update, db.del, db.select. The db.query method provides generic
access to the database driver and executes given query directly by the db driver, it can be SQL or other driver specific query request.
Before the tables can be queried the schema must be defined and created, the backend db layer provides simple functions to do it:

first the table needs to be described, this is achieved by creating a JavaScript object with properties describing each column, multiple tables can be described
at the same time, for example lets define album table and make sure it exists when we run our application:

        db.describeTables({
           album: {
               id: { primary: 1 },                         // Primary key for an album
               name: { pub: 1 },                           // Album name, public column
               mtime: { type: ""now"" },                     // Modification timestamp
           },
           photo: {
               album_id: { primary: 1 },                   // Combined primary key
               id: { primary: 1 },                         // consisting of album and photo id
               name: { pub: 1, index: 1 },                 // Photo name or description, public column with the index for faster search
               mtime: { type: ""now"" }
           }
        });

the system will automatically create the album and photos tables, this definition must remain in the app source code
and be called on every app startup. This allows 1) to see the db schema while working with the app and 2) easily maintain it by adding new columns if
necessary, all new columns will be detected and the database tables updated accordingly. And it is all JavaScript, no need to learn one more language or syntax
to maintain database tables.

Each database may restrict how the schema is defined and used, the db layer does not provide an artificial layer hiding all specifics, it just provides the same
API and syntax, for example, DynamoDB tables must have only hash primary key or combined hash and range key, so when creating table to be used with DynamoDB, only
one or two columns can be marked with primary property while for SQL databases the composite primary key can consist of more than 2 columns.
The backendjs always creates several tables in the configured database pools by default, these tables are required to support default API functionality and some
are required for backend operations. Refer below for the JavaScript modules documentation that described which tables are created by default. In the custom applications
the db.describeTables method can modify columns in the default table and add more columns if needed.
For example, to make age and some other columns in the accounts table public and visible by other users with additional columns the following can be
done in the api.initApplication method. It will extend the bk_account table and the application can use new columns the same way as the already existing columns.
Using the birthday column we make 'age' property automatically calculated and visible in the result, this is done by the internal method api.processAccountRow which
is registered as post process callback for the bk_account table. The computed property age will be returned because it is not present in the table definition
and all properties not defined and configured are passed as is.
The cleanup of the public columns is done by the api.sendJSON which is used by all API routes when ready to send data back to the client. If any post-process
hooks are registered and return data itself then it is the hook responsibility to cleanup non-public columns.
    db.describeTables({
        bk_account: {
            gender: { pub: 1 },
            birthday: {},
            ssn: {},
            salary: { type: ""int"" },
            occupation: {},
            home_phone: {},
            work_phone: {},
        });

    app.configureWeb = function(options, callback)
    {
       db.setProcessRow(""post"", ""bk_account"", this.processAccountRow);
       ...
       callback();
    }
    app.processAccountRow = function(req, row, options)
    {
       if (row.birthday) row.age = Math.floor((Date.now() - core.toDate(row.birthday))/(86400000*365));
    }
To define tables inside a module just provide a tables property in the module object, it will be picked up by database initialization automatically.
const mod = {
    name: ""billing"",
    tables: {
       invoices: {
          id: { type: ""int"", primary: 1 },
          name: {},
          price: { type: ""real"" },
          mtime: { type: ""now"" }
       }
    }
}
module.exports = mod;

// Run db setup once all the DB pools are configured, for example produce dynamic icon property
// for each record retrieved
mod.configureModule = function(options, callback)
{
    db.setProcessRows(""post"", ""invoices"", function(req, row, opts) {
       if (row.id) row.icon = ""/images/"" + row.id + "".png"";
    });
    callback();
}
API requests handling
All methods will put input parameters in the req.query, GET or POST.
One way to verify input values is to use lib.toParams, only specified parameters will be returned and converted according to
the type or ignored.
Example:
   var params = {
      test1: { id: { type: ""text"" },
               count: { type: ""int"" },
               email: { regexp: /^[^@]+@[^@]+$/ }
      }
   };

   api.app.all(""/endpoint/test1"", function(req, res) {
      var query = lib.toParams(req.query, params.test1);
      ...
   });
Example of TODO application
Here is an example how to create simple TODO application using any database supported by the backend. It supports basic
operations like add/update/delete a record, show all records.
Create a file named app.js with the code below.
    const bkjs = require('backendjs');
    const api = bkjs.api;
    const lib = bkjs.lib;
    const app = bkjs.app;
    const db = bkjs.db;

    // Describe the table to store todo records
    db.describeTables({
       todo: {
           id: { type: ""uuid"", primary: 1 },  // Store unique task id
           due: {},                           // Due date
           name: {},                          // Short task name
           descr: {},                         // Full description
           mtime: { type: ""now"" }             // Last update time in ms
       }
    });

    // API routes
    app.configureWeb = function(options, callback)
    {
        api.app.get(/^\/todo\/([a-z]+)$/, function(req, res) {
           var options = api.getOptions(req);
           switch (req.params[0]) {
             case ""get"":
                if (!req.query.id) return api.sendReply(res, 400, ""id is required"");
                db.get(""todo"", { id: req.query.id }, options, function(err, rows) { api.sendJSON(req, err, rows); });
                break;
             case ""select"":
                options.noscan = 0; // Allow empty scan of the whole table if no query is given, disabled by default
                db.select(""todo"", req.query, options, function(err, rows) { api.sendJSON(req, err, rows); });
                break;
            case ""add"":
                if (!req.query.name) return api.sendReply(res, 400, ""name is required"");
                // By default due date is tomorrow
                if (req.query.due) req.query.due = lib.toDate(req.query.due, Date.now() + 86400000).toISOString();
                db.add(""todo"", req.query, options, function(err, rows) { api.sendJSON(req, err, rows); });
                break;
            case ""update"":
                if (!req.query.id) return api.sendReply(res, 400, ""id is required"");
                db.update(""todo"", req.query, options, function(err, rows) { api.sendJSON(req, err, rows); });
                break;
            case ""del"":
                if (!req.query.id) return api.sendReply(res, 400, ""id is required"");
                db.del(""todo"", { id: req.query.id }, options, function(err, rows) { api.sendJSON(req, err, rows); });
                break;
            }
        });
        callback();
     }
     bkjs.server.start();
Now run it with an option to allow API access without an account:
node app.js -log debug -web -api-allow-path /todo -db-create-tables

To use a different database, for example PostgresSQL(running localy) or DynamoDB(assuming EC2 instance),
all config parametetrs can be stored in the etc/config as well
node app.js -log debug -web -api-allow-path /todo -db-pool dynamodb -db-dynamodb-pool default -db-create-tables
node app.js -log debug -web -api-allow-path /todo -db-pool pgsql -db-pgsql-pool default -db-create-tables

API commands can be executed in the browser or using curl:
curl 'http://localhost:8000/todo?name=TestTask1&descr=Descr1&due=2015-01-01`
curl 'http://localhost:8000/todo/select'

Backend directory structure
When the backend server starts and no -home argument passed in the command line the backend makes its home environment in the ~/.bkjs directory.
It is also possible to set the default home using BKJS_HOME environment variable.
The backend directory structure is the following:


etc - configuration directory, all config files are there


etc/profile - shell script loaded by the bkjs utility to customize env variables


etc/config - config parameters, same as specified in the command line but without leading -, each config parameter per line:
Example:
  debug=1
  db-pool=dynamodb
  db-dynamodb-pool=http://localhost:9000
  db-pgsql-pool=postgresql://postgres@127.0.0.1/backend

  To specify other config file: bkjs shell -config-file file



etc/config.local - same as the config but for the cases when local environment is different than the production or for dev specific parameters


some config parameters can be configured in DNS as TXT records, the backend on startup will try to resolve such records and use the value if not empty.
All params that  marked with DNS TXT can be configured in the DNS server for the domain where the backend is running, the config parameter name is
concatenated with the domain and queried for the TXT record, for example: cache-host parameter will be queried for cache-host.domain.name for TXT record type.


etc/crontab - jobs to be run with intervals, JSON file with a list of cron jobs objects:
Example:


Create file in ~/.backend/etc/crontab with the following contents:
 [ { ""cron"": ""0 1 1 * * 1,3"", ""job"": { ""app.cleanSessions"": { ""interval"": 3600000 } } } ]



Define the function that the cron will call with the options specified, callback must be called at the end, create this app.js file
 var bkjs = require(""backendjs"");
 bkjs.app.cleanSessions = function(options, callback) {
      bkjs.db.delAll(""session"", { mtime: options.interval + Date.now() }, { ops: ""le"" }, callback);
 }
 bkjs.server.start()



Start the jobs queue and the web server at once
 bkjs master -jobs-workers 1 -jobs-cron





etc/crontab.local - additional local crontab that is read after the main one, for local or dev environment




modules - loadable modules with specific functionality


images - all images to be served by the API server, every subfolder represent naming space with lots of subfolders for images


var - database files created by the server


tmp - temporary files


web - Web pages served by the static Express middleware


Cache configurations
Database layer support caching of the responses using db.getCached call, it retrieves exactly one record from the configured cache, if no record exists it
will pull it from the database and on success will store it in the cache before returning to the client. When dealing with cached records, there is a special option
that must be passed to all put/update/del database methods in order to clear local cache, so next time the record will be retrieved with new changes from the database
and refresh the cache, that is { cached: true } can be passed in the options parameter for the db methods that may modify records with cached contents. In any case
it is required to clear cache manually there is db.clearCache method for that.
Also there is a configuration option -db-caching to make any table automatically cached for all requests.
Local
If no cache is configured the local driver is used, it keeps the cache on the master process in the LRU pool and any worker or Web process
communicate with it via internal messaging provided by the cluster module. This works only for a single server.
memcached
Set ipc-cache=memcache://HOST[:PORT] that points to the host running memcached. To support multiple servers add the option
ipc-cache-options-servers=10.1.1.1,10.2.2.1:5000.
Redis
Set ipc-cache=redis://HOST[:PORT] that points to the server running Redis server.
To support more than one master Redis server in the client add additional servers in the servers parameter,
ipc-cache-options-servers=10.1.1.1,10.2.2.1:5000, the client will reconnect automatically on every
disconnect. To support quick failover it needs a parameter for the node-redis module (which is used by the driver) max_attempts to be a
number how many attempts to reconnect before switching to another server like ipc-cache-options-max_attempts=3. If there is only one
server then it will keep reconnecting until total reconnect time exceeds the connect_timeout ms.
Any other node-redis module parameter can be passed as well.
Cache configurations also can be passed in the url, the system supports special parameters that start with bk-, it will extract them into options automatically.
For example:
ipc-cache=redis://host1?bk-servers=host2,host3&bk-max_attempts=3
ipc-cache-backup=redis://host2
ipc-cache-backup-options-max_attempts=3

Redis Sentinel
To enable Redis Sentinel pass in the option -sentinel-servers: ipc-cache=redis://host1?bk-sentinel-servers=host1,host2.
The system will connect to the sentinel, get the master cache server and connect the cache driver to it, also it will listen constantly on
sentinel events and failover to a new master autimatically. Sentinel use the regular redis module and supports all the same
parameters, to pass options to the sentinel driver prefix them with sentinel-:
ipc-cache=redis://host1?bk-servers=host2,host3&bk-max_attempts=3&bk-sentinel-servers=host1,host2,host3
ipc-cache-backup=redis://host2
ipc-cache-backup-options-sentinel-servers=host1,host2
ipc-cache-backup-options-sentinel-max_attempts=5

PUB/SUB or Queue configurations
Publish/subscribe functionality allows clients to receive notifications without constantly polling for new events. A client can be anything but
the backend provides some partially implemented subscription notifications for Web clients using the Long Poll.
The Account API call /account/subscribe can use any pub/sub mode.
The flow of the pub/sub operations is the following:

a HTTP client makes /account/subscribe API request, the connection is made and is kept open indefinitely or as long as configured using api-subscribe-timeout.
the API backend receives this request, and runs the api.subscribe method with the key being the account id, this will subscribe to the events for the current
account and registers a callback to be called if any events occurred. The HTTP connection is kept open.
some other client makes an API call that triggers an event like makes a connection or sends a message, on such event the backend API handler
always runs ipc.publish after the DB operation succeeds. If the messaging is configured, it publishes the message for the account, the
message being a JSON object with the request API path and mtime, other properties depend on the call made.
the connection that initiated /account/subscribe receives an event

Redis
To configure the backend to use Redis for PUB/SUB messaging set ipc-queue=redis://HOST where HOST is IP address or hostname of the single Redis server.
This will use native PUB/SUB Redis feature.
Redis Queue
To configure the backend to use Redis for job processing set ipc-queue=redisq://HOST where HOST is IP address or hostname of the single Redis server.
This driver implements reliable Redis queue, with visibilityTimeout config option works similar to AWS SQS.
Once configured, then all calls to jobs.submitJob will push jobs to be executed to the Redis queue, starting somewhere a backend master
process with -jobs-workers 2 will launch 2 worker processes which will start pulling jobs from the queue and execute.
An example of how to perform jobs in the API routes:
   app.processAccounts = function(options, callback) {
       db.select(""bk_account"", { type: options.type || ""user"" }, function(err, rows) {
          ...
          callback();
       });
   }

   api.all(""/process/accounts"", function(req, res) {
       jobs.submitJob({ job: { ""app.processAccounts"": { type: req.query.type } } }, function(err) {
          api.sendReply(res, err);
       });
   });

RabbitMQ
To configure the backend to use RabbitMQ for messaging set ipc-queue=amqp://HOST and optionally amqp-options=JSON with options to the amqp module.
Additional objects from the config JSON are used for specific AMQP functions: { queueParams: {}, subscribeParams: {}, publishParams: {} }. These
will be passed to the corresponding AMQP methods: amqp.queue, amqp.queue.sibcribe, amqp.publish. See AMQP Node.js module for more info.
DB
This is a simple queue implementation using the atomic UPDATE, it polls for new jobs in the table and updates the status, only who succeeds
with the update takes the job and executes it. It is not effective but can be used for simple and not busy systems for more or less long jobs.
The advantage is that it uses the same database and does not require additional servers.
SQS
To use AWS SQS for job processing set ipc-queue=https://sqs.amazonaws.com...., this queue system will poll SQS for new messages on a worker
and after successful execution will delete the message. For long running jobs it will automatically extend visibility timeout if it is configured.
Local
The local queue is implemented on the master process as a list, communication is done via local sockets between the master and workers.
This is intended for a single server development purposes only.
Security configurations
API only
This is default setup of the backend when all API requests except must provide valid signature and all HTML, JavaScript, CSS and image files
are available to everyone. This mode assumes that Web development will be based on 'single-page' design when only data is requested from the Web server and all
rendering is done using JavaScript. This is how the examples/api/api.html developers console is implemented, using JQuery-UI and Knockout.js.
To see current default config parameters run any of the following commands:
    bkjs bkhelp | grep api-allow

    node -e 'require(""backendjs"").core.showHelp()'

To enable open registration in this mode just add config parameter api-allow-path=^/account/add$.
Secure Web site, client verification
This is a mode when the whole Web site is secure by default, even access to the HTML files must be authenticated. In this mode the pages must defined 'Backend.session = true'
during the initialization on every html page, it will enable Web sessions for the site and then no need to sign every API request.
The typical client JavaScript verification for the html page may look like this, it will redirect to login page if needed,
this assumes the default path '/public' still allowed without the signature:
   <script src=""/js/jquery.js""></script>
   <link href=""/css/bootstrap.css"" rel=""stylesheet"">
   <script src=""/js/bootstrap.js""></script>
   <script src=""/js/knockout.js"" type=""text/javascript""></script>
   <script src=""/js/crypto.js"" type=""text/javascript""></script>
   <script src=""/js/bkjs.js"" type=""text/javascript""></script>
   <script src=""/js/bkjs-bootstrap.js"" type=""text/javascript""></script>
   <script src=""/js/bkjs-ko.js"" type=""text/javascript""></script>
   <script>
    $(function () {
       Bkjs.session = true;
       $(Bkjs).on(""bkjs.nologin"", function() { window.location='/public/index.html'; });
       Bkjs.koInit();
   });
   </script>
Secure Web site, backend verification
On the backend side in your application app.js it needs more secure settings defined i.e. no html except /public will be accessible and
in case of error will be redirected to the login page by the server. Note, in the login page Bkjs.session must be set to true for all
html pages to work after login without singing every API request.

We disable all allowed paths to the html and registration:

   app.configureMiddleware = function(options, callback) {
      this.allow.splice(this.allow.indexOf('^/$'), 1);
      this.allow.splice(this.allow.indexOf('\\.html$'), 1);
      callback();
   }

We define an auth callback in the app and redirect to login if the request has no valid signature, we check all html pages, all allowed html pages from the /public
will never end up in this callback because it is called after the signature check but allowed pages are served before that:

   api.registerPreProcess('', /^\/$|\.html$/, function(req, status, callback) {
      if (status.status != 200) {
          status.status = 302;
          status.url = '/public/index.html';
      }
      callback(status);
   });
WebSockets connections
The simplest way is to configure ws-port to the same value as the HTTP port. This will run WebSockets server along the regular Web server.
All requests must be properly signed with all parameters encoded as for GET requests.
Example:
    wscat --connect ws://localhost:8000
    connected (press CTRL+C to quit)
    > /account/get
    < {
        ""status"": 400,
        ""message"": ""Invalid request: no host provided""
      }
    >

Versioning
There is no ready to use support for different versions of API at the same because there is no just one solution that satisfies all applications. But there are
tools ready to use that will allow to implement such versioning system in the backend. Some examples are provided below:


Fixed versions
This is similar to AWS version system when versions are fixed and changed not very often. For such cases the backend exposes core.bkVersion which is
supposed to be a core backend version. This version is returned with every backend response in the Server: header. A client also can specify the core version
using bk-version header. When a request is parsed and the version is provided it will be set in the request options object as apiVersion.
All API routes are defined using Express middleware and one of the possible ways of dealing with different versions can look like this, by
appending version to the command it is very simple to call only changed API code.


          api.all(/\/domain\/(get|put|del)/, function(req, res) {
              var options = api.getOptions(req);
              var cmd = req.params[0];
              if (options.apiVersion) cmd += ""/"" + options.apiVersion;
              switch (cmd) {
              case ""get"":
                  break;

              case ""get/2015-01-01"":
                  break;

              case ""put"":
                  break;

              case ""put/2015-02-01"":
                  break;

              case ""del""
                  break;
              }
          });


Application semver support
For cases when applications support Semver kind of versioning and it may be too many releases the method above still can be used while the number of versions is
small, once too many different versions with different minor/patch numbers, it is easier to support greater/less comparisons.
The application version bk-app can be supplied in the query or as a header or in the user-agent HTTP header which is the easiest case for mobile apps.
In the middlware, the code can look like this:


        var options = api.getOptions(req);
        var version = lib.toVersion(options.appVersion);
        switch (req.params[0]) {
        case ""get"":
            if (version < lib.toVersion(""1.2.5"")) {
                res.json({ id: 1, name: ""name"", description: ""descr"" });
                break;
            }
            if (version < lib.toVersion(""1.1"")) {
                res.json([id, name]);
                break;
            }
            res.json({ id: 1, name: ""name"", descr: ""descr"" });
            break;
        }
The actual implementation can be modularized, split into functions, controllers.... there are no restrictions how to build the working backend code,
the backend just provides all necessary information for the middleware modules.
The backend provisioning utility: bkjs
The purpose of the bkjs shell script is to act as a helper tool in configuring and managing the backend environment
and as well to be used in operations on production systems. It is not required for the backend operations and provided as a convenience tool
which is used in the backend development and can be useful for others running or testing the backend.
Running without arguments will bring help screen with description of all available commands.
The tool is multi-command utility where the first argument is the command to be executed with optional additional arguments if needed.
On Linux, when started the bkjs tries to load and source the following config files:
    /etc/sysconfig/bkjs
    $BKJS_HOME/etc/profile

Any of the following config files can redefine any environment variable thus pointing to the correct backend environment directory or
customize the running environment, these should be regular shell scripts using bash syntax.
Most common used commands are:


bkjs watch - run the backend or the app for development purposes, uses local app.js if exists otherwise runs generic server


bkjs shell - start REPL shell with the backend module loaded and available for use, all submodules are available in the shell as well like core, db, api


bkjs sync [-path path] [-host host] [-user user] - sync sources of the app with the remote site, this is for development version of the backend only


bkjs init-server [-home path] [-user user] [-host name] [-domain name] - initialize Linux instance(Amazon,CentOS) for backend use, optional -home can be specified where the backend
home will be instead of ~/.bkjs, optional -user tells to use existing user instead of the current user and not root.
This command will create /etc/sysconfig/bkjs file with BKJS_HOME set to the home of the
backendjs app which was passed in the command line. This makes the bkjs or bksh run globally regardless of the current directory.


Web development notes
The server supports simple web bundling using uglify-js utility. To enable it just add to the local config a list of directories to be
watched for changes. For example adding these lines to the local config will enable the watcher and bundle support
 watch-web=web/js,web/css,$HOME/src/js,$HOME/src/css
 watch-ignore=.bundle.(js|css)$
 build-web=bkjs web-bundle -dev

Now instead of incding a bunch of .js or css files in the html pages it only needs /js/bkjs.bundle.js and /css/bkjs.bundle.css. The configuration is in the
package.json file.
The simple script below allows to build the bundle and refresh Chrome tab automatically, saves several clicks:
 #!/bin/bash
 bkjs web-bundle -dev -file $2
 [ ""$?"" != ""0"" ] && exit
 osascript -e ""tell application \""Google Chrome\"" to reload (tabs of window 1 whose URL contains \""$1\"")""
 #osascript -e 'tell application ""Google Chrome"" to tell the active tab of its first window to reload'

To use it call this script instead in the config.local:
 build-web=web-bundle.sh /website

Deployment use cases
AWS instance setup with node and backendjs
Here is the example how to setup new custom AWS server, it is not required and completely optional but bkjs provides some helpful commands that may simplify
new image configuration.


start new AWS instance via AWS console, use Amazon Linux


login as ec2-user


install commands
  yum-config-manager --enable epel
  sudo yum install npm
  npm install backendjs
  sudo bkjs init-service
  bkjs restart



try to access the instance via HTTP port 8000 for the API console or documentation


after reboot the server will be started automatically


AWS instance as an appliance
To make an API appliance by using the backendjs on the AWS instance as user ec2-user with the backend in the user home


start new AWS instance via AWS console, use Amazon Linux or CentOS 6


login as ec2-user


install commands
  git clone https://github.com/vseryakov/backendjs.git
  sudo backendjs/bkjs install-ec2 -tools $(pwd)/backendjs/tools
  bkjs restart



run ps agx, it should show several backend processes running


try to access the instance via HTTP port for the API console or documentation


NOTE: if running behind a Load balancer and actual IP address is needed set Express option in the command line -api-express-options {""trust%20proxy"":1}. In the config file
replacing spaces with %20 is not required.
AWS Beanstalk deployment
As with any Node.js module, the backendjs app can be packaged into zip file according to AWS docs and deployed the same way as any other Node.js app.
Inside the app package etc/config file can be setup for any external connections.
AWS Provisioning examples
Note: on OS X laptop the -aws-sdk-profile uc when AWS credentials are in the ~/.aws/credentials.
Make an AMI
On the running machine which will be used for an image:
bksh -aws-create-image -no-reboot

Use an instance by tag for an image:
bksh -aws-create-image -no-reboot -instance-id `bkjs ec2-show -tag api -fmt id | head -1`

Launch instances when not using AutoScaling Groups
When launching from an EC2 instance no need to specify any AWS credentials.


admin (EC2)
bksh -aws-sdk-profile uc -aws-launch-instances -aws-instance-type t2.small -subnet-name api -name admin -elb-name Admin -alarm-name alarms -public-ip 1 -dry-run


api (EC2)
bksh -aws-sdk-profile uc -aws-launch-instances -aws-instance-type m3.large -subnet-name api -name api -elb-name api -alarm-name alarms -public-ip 1 -dry-run


jobs (EC2)
bksh -aws-sdk-profile uc -aws-launch-instances -aws-instance-type t2.small -subnet-name internal -name sync -alarm-name alarms -dry-run
bksh -aws-sdk-profile uc -aws-launch-instances -aws-instance-type t2.small -subnet-name internal -name sync -zone 1c -alarm-name alarms -dry-run


Elasticsearch
bksh -aws-sdk-profile uc -aws-launch-instances -aws-instance-type m3.large -subnet-name internal -name elasticsearch -bkjs-cmd stop-service -bkjs-cmd ""init-elasticsearch-service -memsize 50"" -alarm-name alarms -public-ip 1 -dry-run


Redis
bksh -aws-sdk-profile uc -aws-launch-instances -aws-instance-type m3.large -subnet-name internal -name redis -bkjs-cmd stop-service -bkjs-cmd ""init-redis-service -memsize 70"" -alarm-name alarms -public-ip 1 -dry-run


Launch Configurations
bksh -aws-create-launch-config -config-name elasticsearch -aws-sdk-profile uc -instance-type m3.large -update-groups -bkjs-cmd stop-service -bkjs-cmd init-logwatcher -bkjs-cmd ""init-elasticsearch-service -memsize 50"" -device /dev/xvda:gp2:16 -dry-run

Copy Autoscaling launch configs after new AMI is created
bksh -aws-create-launch-config -config-name jobs -aws-sdk-profile uc -update-groups -dry-run
bksh -aws-create-launch-config -config-name api -aws-sdk-profile uc -update-groups -dry-run

Update Route53 with all IPs from running instances
bksh -aws-set-route53 -name elasticsearch.ec-internal -filter elasticsearch

Proxy mode
By default the Web proceses spawned by the server are load balanced using default cluster module which relies on the OS to do scheduling. On Linux with node 0.10
this is proven not to work properly due to the kernel keeping the context switches to a minimum thus resulting in one process to be very busy while the others
idle. Node versions 4 and above perform round-robin by default.
For such case the Backendjs implements the proxy mode by setting proxy-port config parameter to any number above 1000, this will be the initial
port for the web processes to listen for incoming requests, for example if use -proxy-port 3000 and launch 2 web processes they will listen on ports
3000 and 3001. The main server process will start internal HTTP proxy and will perform round-robin load balancing the incoming requests between the web processes by forwarding
them to the web processes over TCP and then returning the responses back to the clients.
Configure HTTP port
The first thing when deploying the backend into production is to change API HTTP port, by default is is 8000, but we would want port 80 so regardless
how the environment is setup it is ultimately 2 ways to specify the port for HTTP server to use:


config file
The config file is always located in the etc/ folder in the backend home directory, how the home is specified depends on the system but basically it can be
defined via command line arguments as -home or via environment variables when using bkjs. See bkjs documentation but on AWS instances created with bkjs
init-server command, for non-standard home use /etc/sysconfig/bkjs profile, specify BKJS_HOME=/home/backend there and the rest will be taken care of


command line arguments
When running node scripts which use the backend, just specify -home command line argument with the directory where your backend should be and the backend will use it
Example:
  node app.js -home $HOME -port 80



config database
If -db-config is specified in the command line or db-config= in the local config file, this will trigger loading additional
config parameters from the specified database pool, it will load all records from the bk_config table on that db pool. Using the database to store
configuration make it easier to maintain dynamic environment for example in case of auto scaling or launching on demand, this way
a new instance will query current config from the database and this eliminates supporting text files and distributing them to all instances.
The config database is refreshed from time to time acording to the db-config-interval parameter, also all records with ttl property in the bk_config
will be pulled every ttl interval and updated in place.


DNS records
Some config options may be kept in the DNS TXT records and every time a instance is started it will query the local DNS for such parameters. Only a small subset of
all config parameters support DNS store. To see which parameters can be stored in the DNS run bkjs show-help and look for 'DNS TXT configurable'.


Backend library development (Mac OS X, developers)


for DB drivers and ImageMagick to work propely it needs some dependencies to be installed:
  port install libpng jpeg tiff lcms2 mysql56 postgresql93



make sure there is no openjpeg15 installed, it will conflict with ImageMagick jp2 codec


git clone https://github.com/vseryakov/backendjs.git or git clone git@github.com:vseryakov/backendjs.git


cd backendjs


if Node.js is already installed skip to the next section


to install binary release run the command, it will install it into /opt/local on Darwin
   bkjs install-node

   # To install into different path
   bkjs install-node -prefix /usr/local/node



Important: Add NODE_PATH=$BKJS_PREFIX/lib/node_modules to your environment in .profile or .bash_profile so
node can find global modules, replace $BKJS_PREFIX with the actual path unless this variable is also set in the .profile




to install all dependencies and make backendjs module and bkjs globally available:
      npm link backendjs



to run local server on port 8000 run command:
      bkjs web



to start the backend in command line mode, the backend environment is prepared and initialized including all database pools.
This command line access allows you to test and run all functions from all modules of the backend without running full server
similar to Node.js REPL functionality. All modules are accessible from the command line.
      $ ./bkjs shell
      > core.version
      '0.70.0'
      > logger.setLevel('info')



Design considerations
While creating Backendjs there were many questions and issues to be considered, some I was able to implement, some still not. Below are the thoughts that
might be useful when designing, developing or choosing the API platform:

purpose of the API:

to expose some parts of the existing system to external apps, users...
to make it the only way to access services
to complement another system


scalability considerations:

unlimited/uncontrolled access like mobile, web, more users the better
enterprise level, controlled growth
not to be horizontally scalable, just vertically


security:

support authentication, users, accounts, profiles...
just for robots, limited by api key only
signed requests only
support all access, web, mobile, desktop
user access controls, how to distinguish users, grant access to only parts of the API
ability to run custom/specific filters during processing API requests, independently and ability to extend the app without rewriting/rebuilding the whole system
third party authentication, OAUTH, user mapping


platform/framework:

one for all, same language/SDK/framework to cover all aspects
multiple languages/frameworks for different tasks, then how to integrate, how to communicate, share code
availability of the third party modules, libraries
support, forums, docs, how easy to learn for new developers
modularity, ability to develop by multiple developers, teams
flexibility in extending, how simple/easy to add custom stuff
maintenance, support,how easy to scale, change, replace parts


database layer:

one central database for everything
multiple database for different parts of the system according to scalability/other requirements
switch databases behind the scene in order to scale, adding to features, easier to maintain
caching, needs to be independent from other parts and easily enabled/disabled for different components preferably via config
to have or not ORM


process management, easy to deploy, monitor
logging, metrics, profiling
agnostic to the frontends or to be included with some kind of MVC/server based tools
ability to support simple Web development for simple web pages without installing/supporting general purpose tools like Apache/PHP/nginx

API endpoints provided by the backend
All API endpoints are optional and can be disabled or replaced easily. By default the naming convention is:
 /namespace/command[/subname[/subcommand]]

Any HTTP methods can be used because its the command in the URL that defines the operation. The payload can be url-encoded query
parameters or JSON or any other format supported by any particular endpoint. This makes the backend universal and usable with any
environment, not just a Web browser. Request signature can be passed in the query so it does not require HTTP headers at all.
Authentication and sessions
Signature
All requests to the API server must be signed with account login/secret pair.

The algorithm how to sign HTTP requests (Version 1, 2):

Split url to path and query parameters with ""?""
Split query parameters with ""&""
'''ignore parameters with empty names'''
'''Sort''' list of parameters alphabetically
Join sorted list of parameters with ""&""

Make sure all + are encoded as %2B


Form canonical string to be signed as the following:

Line1: The signature version
Line2: The application tag or other opaque data
Line3: The login name
Line4: The HTTP method(GET), followed by a newline.
Line5: The host name, lowercase, followed by a newline.
Line6: The request URI (/), followed by a newline.
Line7: The sorted and joined query parameters as one string, followed by a newline.
Line8: The expiration value in milliseconds, required, followed by a newline
Line9: The Content-Type HTTP header, lowercase, optional, followed by a newline
Line10: The SHA1 checksum of the body content, optional, for JSON and other forms of requests not supported by query parameters


Computed HMAC-SHA1 digest from the canonical string and encode it as BASE64 string, preserve trailing = if any
Form the signature HTTP header as the following:

The header string consist of multiple fields separated by pipe |

Field1: Signature version:

version 1, obsolete, do not use first 3 lines in the canonical string
version 2,3 to be used in session cookies only
version 4


Field2: Application tag or other app specific data
Field3: account login or whatever it might be in the login column
Field4: HMAC-SHA digest from the canonical string, version 1 uses SHA1, other SHA256
Field5: expiration value in milliseconds, same as in the canonical string
Field6: SHA1 checksum of the body content, optional, for JSON and other forms of requests not supported by query parameters
Field7: empty, reserved for future use







The resulting signature is sent as HTTP header bk-signature or in the header specified by the api-signature-name config parameter.
For JSON content type, the method must be POST and no query parameters specified, instead everything should be inside the JSON object
which is placed in the body of the request. For additional safety, SHA1 checksum of the JSON payload can be calculated and passed in the signature,
this is the only way to ensure the body is not modified when not using query parameters.
See web/js/bkjs.js function Bkjs.createSignature or
api.js function api.createSignature for the JavaScript implementations.
There is also native iOS implementation Bkjs.m.
Authentication API


/auth
This API request returns the current user record from the bk_auth table if the request is verified and the signature provided
is valid. If no signature or it is invalid the result will be an error with the corresponding error code and message.
By default this endpoint is secured, i.e. requires a valid signature.
Parameters:


_session=1 - if the call is authenticated a cookie with the session signature is returned, from now on
all requests with such cookie will be authenticated, the primary use for this is Web apps


_accesstoken=1 - returns new access token to be used for subsequent requests without a signature for the current account,
the token is short lived with expiration date returned as well. This access token can be used instead of a signature and
is passed in the query as bk-access-token=TOKEN.
Example:
     /auth?_accesstoken=1
     > { id: ""XXXX..."", name: ""Test User"", ""bk-access-token"": ""XXXXX...."", ""bk-access-token-age"": 604800000 }

     /account/get?bk-access-token=XXXXXX...
     > { id: ""XXXX..."", name: ""Test User"", ... }





/login
Same as the /auth but it uses secret for user authentication, this request does not need a signature, just simple
login and secret query parameters to be sent to the backend. This must be sent over SSL.
The intended usage is for Web sessions which use sessions cookies when sent with _session=1 or to be used with access tokens when
sent with _accesstoken=1.
Parameters:

login - account login
zecret - account secret
_session=1 - same as in /auth request
_accesstoken=1 - same as in /auth reuest

On successful login, the result contains full account record including the secret, this is the only time when the secret is returned back
Example:
        $.ajax({ url: ""/login?login=test123&secret=test123&_session=1"",
                 success: function(json, status, xhr) { console.log(json) }
        });

        > { id: ""XXXX..."", name: ""Test User"", login: ""test123"", ...}



/logout
Logout the current user, clear session cookies if exist. For pure API access with the signature this will not do anything on the backend side.


Accounts
The accounts API manages accounts and authentication, it provides basic user account features with common fields like email, name, address.
This is implemented by the accounts module from the core. To enable accounts functionality specify -allow-modules=bk_accounts.


/account/get
Returns information about current account or other accounts, all account columns are returned for the current account and only public columns
returned for other accounts. This ensures that no private fields ever be exposed to other API clients. This call also can used to login into the service or
verifying if the given login and secret are valid, there is no special login API call because each call must be signed and all calls are stateless and independent.
Parameters:

no id is given, return only one current account record as JSON
id=id,id,... - return information about given account(s), the id parameter can be a single account id or list of ids separated by comma
_session=1 - after successful login setup a session with cookies so the Web app can perform requests without signing every request anymore
_accesstoken=1 - after successful login, return new access token that ca be used to make requests without signing every request, it can be
passed in the query or headers with the name bk-access-token

Note: When retrieving current account, all properties will be present including the location, for other accounts only the properties marked as pub in the
bk_account table will be returned.
Response:
    { ""id"": ""57d07a4e28fc4f33bdca9f6c8e04d6c3"",
      ""name"": ""Test User"",
      ""name"": ""Real Name"",
      ""mtime"": 1391824028,
      ""latitude"": 34,
      ""longitude"": -118,
      ""geohash"": ""9qh1"",
      ""login"": ""testuser"",
    }



/account/add
Add new account, all parameters are the columns from the bk_account table, required columns are: name, secret, login.
To enable open registration add api-allow-path=^/account/add$ to the config file or specify in the command line.
More complex ways to perform registration will require adding pre and.or post callbacks to handle account registration
for example with invitation codes....
In the table bk_auth, the column type is used to distinguish between account roles, by default only account with type admin can
add other accounts with this type specified, this column can also be used in account permissions implementations. Because it is in the bk_auth table,
all columns of this table are available as req.account object after the successful authentication where req is an Express request object used in the middleware
parameters.
Secret and login can be anything, the backend does not require any specific formats and does not process the contents of the login/secret fields.
There are several ways to create authenticated account:

API only access with signed signature, supply a login and secret which will be stored in the database as is, when making requests use the same login and secret to produce the signature.
In the Web client web/js/bkjs.js, if Bkjs.scramble is set to 1 then the secret is replaced by the BASE64_HMAC_SHA256(secret, login) automatically,
no actual secret is ever saved or sent, only used in the login form. This is intended for Web apps not to store the actual secret anywhere in the memory or localStorage,
for the backend this is still just a secret.

Example:
      /account/add?name=test&login=test@test.com&secret=fc4f33bd07a4e6c8e&gender=f&phone=1234567

How to make an account as admin
      # Run backend shell
      bkjs shell

      # Update record by login
      > db.update(""bk_auth"", { login: 'login@name', type: 'admin' });



/account/select
Return list of accounts by the given condition, calls db.select for bk_account table. Parameters are the column values to be matched and
all parameters starting with underscore are control parameters that goes into options of the db.select call with underscore removed. This will work for SQL
databases only because DynamoDB or Cassandra will not search by non primary keys. In the DynamoDB case this will run ScanTable action which will be very expensive for
large tables. Supports special query parameters _select,_ops, see docs about db.select for more info.
Example:
      /account/search?email=test&_ops=email,begins_with
      /account/search?name=test

Response:
      {  ""data"": [{
                    ""id"": ""57d07a4e28fc4f33bdca9f6c8e04d6c3"",
                    ""name"": ""Test User1"",
                    ""mtime"": 1391824028,
                    ""login"": ""test1"",
                  },
                  {
                    ""id"": ""57d07a4e2824fc43bd669f6c8e04d6c3"",
                    ""name"": ""Test User2"",
                    ""mtime"": 1391824028,
                    ""login"": ""test2"",
                  }],
          ""next_token"": """"
      }



/account/del
Delete current account, after this call no more requests will be authenticated with the current credentials


/account/update
Update current account with new values, the parameters are columns of the table bk_account, only columns with non empty values will be updated.
Example:
      /account/update?name=New%2BName&gender=m



/account/put/secret
Change account secret for the current account, no columns except the secret will be updated and expected.
Parameters:

secret - new secret for the account
token_secret - set to 1 to reset access token secret to a new value thus revoking access from all existing access tokens

Example:
      /account/put/secret?secret=blahblahblah



/account/subcribe
Subscribe to account events delivered via HTTP Long Poll, a client makes the connection and waits for events to come, whenever
somebody updates the account's counter or send a message or creates a connection to this account the event about it will be sent to this HTTP
connection and delivered as JSON object. This is not a persistent queue so if not listening, all events will just be ignored, only events published
since the connect will be delivered. To specify what kind of events needs to be delivered, match query parameter can be specified which is a
RegExp of the whole event body string.
Note: On the server side there is a config parameter api-subscribe-interval which defines how often to deliver notifications, by default it is 5 seconds which means
only every 5 seconds new events will be delivered to the Web client, if more than one event happened, they all accumulate and will be sent as a JSON list.
Example:
  /account/subscribe
  /account/subscribe?match=connection/add.*type:*like

  // To run in the browser:
  (function poll() {
      Bkjs.send({ url: ""/account/subscribe"", complete: poll }, function(data) {
          console.log(""received event:"", data);
       });
   })();

Response:
  [ { ""path"": ""/message/add"", ""mtime:"" 1234566566, ""type"": ""1"" },
    { ""path"": ""/counter/incr"", ""mtime:"" 1234566566, ""type"": ""like,invite"" } },
    { ""path"": ""/connection/add"", ""mtime"": 1223345545, ""type"": ""like"" } ]



/account/select/icon
Return a list of available account icons, icons that have been uploaded previously with /account/put/icon calls. The url property is an URL to retrieve this particular icon.
Parameters:

id - if specified then icons for the given account will be returned

Example:
  /account/select/icon?id=12345

Response:
  [ { id: '12345', type: '1', url: '/account/get/icon?id=12345&type=1' },
    { id: '12345', type: '2', url: '/account/get/icon?id=12345&type=2' } ]



/account/get/icon
Return an account icon, the icon is returned in the body as binary BLOB, if no icon with specified type exists, i.e. never been uploaded then 404 is returned.
Parameters:

type - a number from 0 to 9 or any single letter a..z which defines which icon to return, if not specified 0 is used

Example:
  /account/get/icon?type=2



/account/put/icon
Upload an account icon, once uploaded, the next /account/get call will return properties in the format iconN where N is any of the
type query parameters specified here, for example if we uploaded an icon with type 5, then /account/get will return property icon5 with the URL
to retrieve this icon.
By default all icons uploaded only accessible for the account which uploaded them.
Parameters:

type - icon type, a number between 0 and 9 or any single letter a..z, if not specified 0 is used
icon - can be passed as base64 encoded image in the query,

can be passed as base64 encoded string in the body as JSON, like: { type: 0, icon: 'iVBORw0KGgoA...' },
for JSON the Content-Type HTTP headers must be set to application/json and data should be sent with POST request
can be uploaded from the browser using regular multi-part form


acl_allow - icon access permissions:

"""" (empty) - only own account can access
all - public, everybody can see this icon
auth - only authenticated users can see this icon
id,id.. - list of account ids that can see this account


_width - desired width of the stored icon, if negative this means do not upscale, if the image width is less than given keep it as is
_height - height of the icon, same rules apply as for the width above
_ext - image file format, default is jpg, supports: gif, png, jpg, jp2

Example:
  /account/put/icon?type=1&icon=iVBORw0KGgoAAAANSUhEUgAAAAcAAAAJCAYAAAD+WDajAAAABGdBTUEAALGPC/xhBQAAAAlwSFlzAAAOwgAADs....



/account/del/icon
Delete account icon
Parameters:

type - what icon to delete, if not specified 0 is used

Example:
  /account/icon/del?type=1



Health enquiry
When running with AWS load balancer there should be a url that a load balancer polls all the time and this must be very quick and lightweight request. For this
purpose there is an API endpoint /ping that just responds with status 200. It is not open by default, the allow-path or other way to allow non-authenticated access
needs to be configured. This is to be able to control how pinging can be perform in the apps in case it is not simple open access.
Public Images endpoint
This endpoint can server any icon uploaded to the server for any account, it is supposed to be a non-secure method, i.e. no authentication will be performed and no signature
will be needed once it is configured which prefix can be public using api-allow or api-allow-path config parameters.
The format of the endpoint is:


/image/prefix/id/type[.png|.jpg]
Example:
  # Configure accounts icons to be public in the etc/config
  api-allow-path=/image/account/

  # Or pass in the command line
  ./app.sh -api-allow-path /image/account/

  # Make requests
  /image/account/12345/0
  /image/account/12345/1
  /image/account/12345/1.jpg

  #Return icons for account 12345 for types 0 and 1



Icons
The icons API provides ability for an account to store icons of different types. Each account keeps its own icons separate form other
accounts, within the account icons can be separated by prefix which is just a namespace assigned to the icons set, for example to keep messages
icons separate from albums, or use prefix for each separate album. Within the prefix icons can be assigned with unique type which can be any string.
Prefix and type can consist from alphabetical characters and numbers, dots, underscores and dashes: [a-z0-9._-]. This means, they are identifiers, not real titles or names,
a special mapping between prefix/type and album titles for example needs to be created separately.
The supposed usage for type is to concatenate common identifiers first with more specific to form unique icon type which later can be queried
by prefix or exactly by icon type. For example album id can be prefixed first, then sequential con number like album1:icon1, album1:icon2....
then retrieving all icons for an album would be only query with album1: prefix.
The is implemented by the icons module from the core. To enable this functionality specify -allow-modules=bk_icons.


/icon/get
Return icon for the current account in the given prefix, icons are kept on the local disk in the directory
configured by -api-images-dir parameter(default is images/ in the backend directory). Current account id is used to keep icons
separate from other accounts. Icon presence is checked in the bk_icon table before returning it and if any permissions are set in
the acl_allow column it will be checked if this icon can be returned.
The following parameters can be used:

prefix - must be specified, this defines the icons namespace
type is used to specify unique icon created with such type which can be any string.
_ext - image extension, like png or jpg if it was saved with it previously



/icon/put
Upload new icon for the given account in the folder prefix, if type is specified it creates an icon for this type to separate
multiple icons for the same prefix. type can be any string consisting from alpha and digits characters. It creates a record in the bk_icon
table with all the parameters passed.
The following parameters can be used:

prefix - prefix for the icons, required
descr - optional description of the icon
latitude, longitude - optional coordinates for the icon
acl_allow - allow access permissions, see /account/put/icon for the format and usage
_width - desired width of the stored icon, if negative this means do not upscale, if the image width is less than given then keep it as is
_height - height of the icon, same rules apply as for the width above
_ext - image file format, default is jpg, supports: gif, png, jpg



/icon/upload
Upload a new image and store on the server, no record is created in bk_icon table, just simple image upload,
but all the same query parameters as for /icon/put are accepted. Returns an JSON object with url property being the full path
to the uploaded image.


/icon/del
Delete the default icon for the current account in the folder prefix or by type


/icon/select
Return list of available icons for the given prefix and type, all icons starting with prefix/type will be returned,
the url property will provide full URL to retrieve the icon contents
Example:
  /icon/select?prefix=album&type=me
  /icon/select?prefix=album&type=12345

Responses:
  [ { id: 'b3dcfd1e63394e769658973f0deaa81a', type: 'me-1', icon: '/icon/get?prefix=album&type=me1' },
    { id: 'b3dcfd1e63394e769658973f0deaa81a', type: 'me-2', icon: '/icon/get?prefix=album&type=me2' } ]

  [ { id: 'b3dcfd1e63394e769658973f0deaa81a', type: '12345-f0deaa81a', icon: '/icon/get?prefix=album&type=12345-f0deaa81a' } ]



File API
The file API provides ability to store and retrieve files. The operations are similar to the Icon API.
This is implemented by the files module from the core. To enable this functionality specify -allow-modules=bk_files.


/file/get
Return a file with given prefix and name, the contents are returned in the response body.
The following parameters can be used:

prefix - must be provided, defines the namespace where the file is stored
name - name of the file, required



/file/put
Store a file on the backend, the file can be sent using form multipart upload or as JSON
The following parameters can be used:

prefix - must be provided, defines the namespace where the file is stored
name - name of the file, required
_name - name of the property that contains the file contents, for use with JSON or defines the name of the file attribute for multipart upload
_tm - append the current timestamp to the file name
_ext - extension to be assign to the file, otherwise the actual extension from the file name is used



/file/del
Delete file, prefix and name must be given


Connections
The connections API maintains two tables bk_connection and bk_reference for links between accounts of any type. bk_connection table maintains my
links, i.e. when i make explicit connection to other account, and bk_reference table is automatically updated with reference for that other account that I made
a connection with it. No direct operations on bk_reference is allowed.
This is implemented by the connections module from the core. To enable this functionality specify -allow-modules=bk_connections.


/connection/add


/connection/put
Create or replace a connection between two accounts, required parameters are:

peer - id of account to connect to
type - type of connection, like,dislike,....
_connected - the reply will contain a connection record if the other side of our connection is connected to us as well

This call automatically creates a record in the bk_reference table which is reversed connection for easy access to information like
''who is connected to me''.
Example:
  /connection/add?peer=12345&type=invite&state=sent



/connection/update


/connection/incr
Update other properties of the existing connection, for connections that may take more than i step or if a connection has other data associated with it beside
the type of the connection.
Example:
  /connection/update?peer=12345&type=invite&state=accepted



/connection/del
Delete existing connection(s), id and/or type may be be specified, if not all existing connections will be deleted.
Example:
  /connection/del?type=invite&peer=12345



/connection/get
Return a single connection for given id
Parameters:

peer - account id of the connection, required
type - connection type, required

Example:
  /connection/get?peer=12345&type=like

Response:
  { ""id"": ""1111"",
    ""type: ""like"",
    ""peer"": ""12345"",
    ""mtime"": ""2434343543543"" }



/reference/get
Return a single reference record for given account id, works the same way as /connection/get


/connection/select
Receive all my connections of the given type, i.e. connection(s) i made, if id is given only one record for the specified connection will be returned. Supports special
query parameters _select,_ops,_desc, see docs about db.select for more info.
Example:
  # Return all accounts who i invited
  /connection/select?type=invite
  # Return connection for specific type and account id
  /connection/select?type=invite&peer=12345
  # Return accounts who i invited me after specified mtime
  /connection/select?type=invite&_ops=mtime,gt&mtime=12334312543
  # Return accounts who i invited before specified mtime
  /connection/select?type=invite&_ops=mtime,le&_desc=1&mtime=12334312543

Response:
  { ""data"": [ { ""id"": ""111"",
                ""type"": ""invite"",
                ""peer"": ""12345"",
                ""status"": """",
                ""mtime"": ""12334312543""
            }],
    ""next_token"": """"
  }



/reference/select
Receive all references that connected with my account, i.e. connections made by somebody else with me, works the same way as for connection query call
Example:
  # Return all accounts who invited me
  /reference/select?type=invite
  # Return accounts who invited me after specified mtime
  /reference/select?type=invite&_ops=mtime,gt&mtime=12334312543

Response:
  { ""data"": [ { ""id"": ""111"",
                ""type"": ""invite"",
                ""peer"": ""12345"",
                ""status"": """",
                ""mtime"": ""12334312543""
            }],
    ""next_token"": """"
  }



Locations
The location API maintains a table bk_location with geolocation coordinates for accounts and allows searching it by distance. The configuration parameter
min-distance defines the radius for the smallest bounding box in km containing single location, radius searches will combine neighboring boxes of
this size to cover the whole area with the given distance request, also this affects the length of geohash keys stored in the bk_location table. By default min-distance is 5 km
which means all geohashes in bk_location table will have geohash of size 4. Once min-distance is set it cannot be changed without rebuilding the bk_location table with new geohash size.
The location search is implemented by using geohash as a primary key in the bk_location table with the account id as the second part of the primary key, for DynamoDB this is the range key.
When request comes for all matches for the location for example 37.7, -122.4, the search that is executed looks like this:

geohash for latitude 37.7 and longitude -122.4 and radius 10 km will be 9q8y
all neighboring areas around this point within 10 km radius will be '9q8z', '9q8v', '9q8w', '9q8x', '9q8t', '9q9n', '9q9p', '9q9j'
we start the search on the bk_location table by the primary key geohash with the value 9q8y
filter out all records beyond our radius by calculating the difference between our point and the candidate record
if total number of results expected is still less than required, continue to the next neighbor area
continue until we visit all neighbors or received required number of matched records
on return the next_token opaque value will be provided if we want to continue the search for more matched for the same location

This is implemented by the locations module from the core. To enable this functionality specify allow-modules=bk_locations.


/location/put
Store currenct location for current account, latitude and longitude parameters must be given, this call will update the bk_account table as well with
these coordinates
Example:
  /location/put?latitude=-188.23232&longitude=23.4545454



/location/get
Return matched accounts within the distance(radius) specified by distance= parameter in kilometers and current position specified by latitude/longitude parameters. This
call returns results in chunks and requires navigation through all pages to receive all matched records. Records returned will start with the closest to the current
point. If there are more matched records than specified by the _count, the next_token property is set with the token to be used in the subsequent call,
it must be passed as is as _token= parameter with all original query parameters.
Note: The current account will not be present in the results  even if it is within the range, to know my own location use /account/get call.
Example:
      /location/get?distance=10&latitude=-118.23434&longitude=23.45665656&_count=25
      /location/get?distance=10&latitude=-118.23434&longitude=23.45665656&_count=25&_token=FGTHTRHRTHRTHTTR.....

Response:
     { ""data"": [ { ""id"": ""12345"",
                   ""distance"": 5,
                   ""latitude"": -118.123,
                   ""longitude"": 23.45
                   ""mtime"": ""12334312543""
                 },
                 { ""id"": ""45678"",
                   ""distance"": 5,
                   ""latitude"": -118.133,
                   ""longitude"": 23.5
                   ""mtime"": ""12334312543""
                 }],
       ""next_token"": """"
     }



Messages
The messaging API allows sending and receiving messages between accounts, it supports text and images. All new messages arrive into the bk_messsage table, the inbox. The client
may keep messages there as new, delete or archive them. Archiving means transferring messages into the bk_archive table. All sent messages are kept in the bk_sent table.
This is implemented by the messages module from the core. To enable this functionality specify -allow-modules=bk_messages.


/message/get/unread
Return how many unread messages in the inbox, this is just a flag to signal about new messages, the actual number may not be up to date,
it is cleared on messages read.
Example:
 /message/get/unread

Response:
{ count: 1 }



/message/get
Read all messages from the inbox.
Parameters:

_archive - if set to 1, all returned messages will be archived automatically, so no individual /message/read call needed
_trash - if set to 1, all returned messages will be deleted, not archived
_total - if set to 1 then return how many messages in the inbox
the unread flag with the actual number of unread messages.

Example:
  # Get all new messages
  /message/get

  # Get all new messages and archive them
  /message/get?_archive=1

  # Get all new messages from the specific sender
  /message/get?sender=12345

  # How many new messages
  /message/get?_total=1



/message/get/archive
Receive archived messages. The images are not returned, only link to the image in icon property of reach record,
the actual image data must be retrieved separately.
Parameters:

mtime - if specified then only messages received since that time will be returned, it must be in milliseconds since midnight GMT on January 1, 1970, this is what
Date.now() return in JavaScript.
sender - if specified then all messages from the given sender will be returned.

NOTE: The mtime is when the backend server received the message, if client and the server clocks are off this may return wrong data or not return anything at all,
also because the arrival order of the messages cannot be guaranteed, sending fast multiple messages may be received in different order by the backend and this will
result in mtimes that do not correspond to actual times when the message has been sent.
Example:
  # Get all messages
  /message/get/archive

  # Get all messages received after given mtime
  /message/get/archive?mtime=123475658690

  # Get all messages received before given mtime
  /message/get/archive?mtime=123475658690&_ops=mtime,lt

  # Get all messages with custom filter: if msg text contains Hi
  /message/get/archive?_ops=msg,iregexp&msg=Hi

  # Get all messages from the specific sender
  /message/get/archive?sender=12345

Response:
  { ""data"": [ { ""sender"": ""12345"",
                ""msg"": ""Hi, how r u?"",
                ""mtime"": ""12334312543""
              },
              { ""sender"": ""45678"",
                ""msg"": ""check this out!"",
                ""icon"": ""/message/image?sender=45678&mtime=12334312543"",
                ""mtime"": ""12334312543""
              }],
       ""next_token"": """"
     }



/message/get/sent
Return all messages i sent out. All the same query rules apply as for the archived messages API call.
Parameters:

recipient - id of the recipient where i have sent messages
mtime - time before or after messages sent, defined by _ops parametrs

Example:
  /message/get/sent?recipient=123
  /message/get/sent?recipient=123&mtime=123475658690&_ops=mtime,le



/message/add
Send a message to an account, the following parameters must be specified:

id - recipient account id
msg - text of the message, can be empty if icon property exists
icon - icon of the message, it can be base64 encoded image in the query or JSON string if the whole message is posted as JSON or
can be a multipart file upload if submitted via browser, can be omitted if msg/connection/get?type=invite&id=12345 property exists.
_nosent - do not save this message in my sent messages

Example:
  /message/add?id=12345&msg=Hello
  /message/add?id=12345&msg=this%2Bis%2Bthe%2Bpic&icon=KHFHTDDKH7676758JFGHFDRDEDET....TGJNK%2D



/message/read
Mark a message as read
Example:
  /message/read?sender=12345&mtime=124345656567676



/message/archive
Move a new message to the archive. The required query parameters are sender and mtime.
Example:
  /message/read?sender=12345&mtime=12366676434



/message/update
Update a message, can be used to keep track of read/unread status, etc...
Example:
  /message/update?sender=12345&mtime=124345656567676&read=1



/message/update/archive
Update a message in the archive.


/message/del
Delete new message(s) by sender and/or mtime which must be passed as query parameters. If no mtime is given, all messages from the given sender will be deleted.
Example:
  /message/del?sender=12345&mtime=124345656567676



/message/del/archive
Delete archived message(s) by sender and/or mtime which must be passed as query parameters. If no mtime is given, all messages from the given sender will be deleted.
Example:
  /message/del/archive?sender=12345&mtime=124345656567676



/message/del/sent
Delete the message(s) by recipient and/or mtime which must be passed as query parameters. If no mtime is given, all messages to the given recipient will be deleted.
Example:
  /message/del/sent?recipient=12345&mtime=124345656567676



/message/image
Return the image data for the given message, the required parameters are:

sender - id of the sender returned in the by /message/get reply results for every message
mtime - exact timestamp of the message



Counters
The counters API maintains realtime counters for every account records, the counters record may contain many different counter columns for different purposes and
is always cached with whatever cache service is used, by default it is cached by the Web server process on every machine. Web worker processes ask the master Web server
process for the cached records thus only one copy of the cache per machine even in the case of multiple CPU cores.
This is implemented by the counters module from the core. To enable this functionality specify -allow-modules=bk_counters|bk_accounts.


/counter/get
Return counter record for current account with all available columns of if id is given return public columns for given account, it works with bk_counter table
which by default defines some common columns:

ping - a counter for general use, can be used to send a notification event to any account by increasing this counter for an account
like0 - how many i liked, how many time i liked someone, i.e. made a new record in bk_connection table with type 'like'
like1 - how many liked me, reverse counter, who connected to me with type 'like'
More columns can be added to the bk_counter table.

NOTE: The columns with suffixes 0 and 1 are special columns that support the Connections API, every time a new connection is created, the type of new connection
is checked against any columns in the bk_counter table, if a property type0 exists and marked in the table description as autoincr then the corresponding
counter property is increased, this is how every time new connection like/dislike/invite/follow is added, the counters in the bk_counter table are increased.


/counter/put
Replace my counters record, all values if not specified will be set to 0


/counter/incr
Increase one or more counter fields, each column can provide a numeric value and it will be added to the existing value, negative values will be substracted.
if id parameter is specified, only public columns will be increased for other account.
Example:
  /counter/incr?msg_read=5&
  /counter/incr?id=12345&ping=1



Data
The data API is a generic way to access any table in the database with common operations, as oppose to the any specific APIs above this API only deals with
one table and one record without maintaining any other features like auto counters, cache...
Because it exposes the whole database to anybody who has a login it is a good idea to disable this endpoint in the production or provide access callback that verifies
who can access it.


To disable this endpoint completely in the config: deny-modules=data


To allow admins to access it only in the config: api-allow-admin=^/data


To allow admins to access it only:
api.registerPreProcess('GET', '/data', function(req, status, cb) { if (req.account.type != ""admin"") return cb({ status: 401, message: 'access denied' }; cb(status)); });



This is implemented by the data module from the core.


/data/columns


/data/columns/TABLE
Return columns for all tables or the specific TABLE


/data/keys/TABLE
Return primary keys for the given TABLE


/data/(select|search|list|get|add|put|update|del|incr|replace)/TABLE
Perform database operation on the given TABLE, all options for the db functiobns are passed as query parametrrs prepended with underscore,
regular parameters are the table columns.
By default the API does not allow table scans without a condition to avoid expensive and long queries, to enable a scan pass _noscan=0.
For this to work the Data API must be configured as unsecure in the config file using the parameter api-unsecure=data.
Some tables like messages and connections perform data convertion before returning the results, mostly splitting combined columns like type into
separate fields. To return raw data pass the parameter _noprocessrows=1.
Example:
  /data/get/bk_account?id=12345
  /data/put/bk_counter?id=12345&like0=1
  /data/select/bk_account?name=john&_ops=name,gt&_select=name,email
  /data/select/bk_connection?_noscan=0&_noprocessrows=1



Pages
The pages API provides a simple Wiki like system with Markdown formatting. It keeps all pages in the database table bk_pages and
exposes an API to manage and render pages.
The pages support public mode, all pages with pub set to true will be returning without an account, this must be enabled with api-allow-path=^/pages/(get|select|show)
to work.
All .md files will be rendered into html automatically if there is not _raw=1 query parameter and pages view exists (api-pages-view=pages.html by default).
This is implemented by the pages module from the core. To enable this functionality specify -allow-modules=bk_accounts.


/pages/get/ID
Return a page with given id or the main page if id is empty. If the query parameter _render=1 is given, the content will be rendered into html from markdown, otherwise
returns all data as is.


/pages/select
Return all pages or only ones which match the query criteria. This potentially scans the whole table to return all pages and
is used to show pages index.


/pages/put
Replace or add a new page.


/pages/del
Delete a page from the database


/pages/show/ID
Render a page with given id, markdown is converted into html using marked. A view must be configured in order to render to work, by default pages.html view
is provided to simply wrap the markdown in the page layout.


System API
The system API returns information about the backend statistics, allows provisioning and configuration commands and other internal maintenance functions. By
default is is open for access to all users but same security considerations apply here as for the Data API.
This is implemented by the system module from the core. To enable this functionality specify -allow-modules=accounts.


/system/restart
Perform restart of the Web processes, this will be done gracefully, only one Web worker process will be restarting while the other processes will keep
serving requests. The intention is to allow code updates on live systems without service interruption.


/system/cache/(init|stats|keys|get|set|put|incr|del|clear)
Access to the caching functions


/system/config/(init)
Access to the config functions


/system/msg/(init|send)
Access to the messaging functions


/system/jobs/(send)
Access to the jobs functions


/system/queue/(init|publish)
Access to the queue functions


/system/params/get
Return all config parameters applied from the config file(s) or remote database.


/system/stats/get
Database pool statistics and other diagnostics

latency - how long a pending request waits in queue at this moment
busy - how many busy error responses have been returned so far
pool - database metrics

response - stats about how long it takes between issuing the db request and till the final moment all records are ready to be sent to the client
queue - stats about db requests at any given moment queued for the execution
cache - db cache response time and metrics


api - Web requests metrics, same structure as for the db pool metrics
url - metrics per url endpoints

Individual sub-objects:

meter - Things that are measured as events / interval.

rmean: The average rate since the meter was started.
rcnt: The total of all values added to the meter.
rate: The rate of the meter since the last toJSON() call.
r1m: The rate of the meter biased towards the last 1 minute.
r5m: The rate of the meter biased towards the last 5 minutes.
r15m: The rate of the meter biased towards the last 15 minutes.


queue or histogram - Keeps a reservoir of statistically relevant values biased towards the last 5 minutes to explore their distribution

hmin: The lowest observed value.
mmax: The highest observed value.
hsum: The sum of all observed values.
hvar: The variance of all observed values.
hmean: The average of all observed values.
hdev: The standard deviation of all observed values.
hcnt: The number of observed values.
hmed: median, 50% of all values in the reservoir are at or below this value.
hp75: See median, 75% percentile.
hp95: See median, 95% percentile.
hp99: See median, 99% percentile.
hp999: See median, 99.9% percentile.



Response:
       {
            ""id"": ""172.31.31.85-25170"",
            ""ip"": ""172.31.31.85"",
            ""mtime"": 1417500027321,
            ""ctime"": 1416941754760,
            ""type"": """",
            ""host"": """",
            ""pid"": 25170,
            ""instance"": ""i-d4c89eff"",
            ""worker"": 27,
            ""latency"": 0,
            ""cpus"": 4,
            ""mem"": 15774367744,
            ""rss_hmin"": 66879488,
            ""rss_hmax"": 151891968,
            ""rss_hsum"": 2451506479104,
            ""rss_hvar"": 254812067010902.66,
            ""rss_hmean"": 118895507.98312236,
            ""rss_hdev"": 15962833.92793719,
            ""rss_hcnt"": 20619,
            ""rss_hmed"": 147644416,
            ""rss_h75p"": 149262336,
            ""rss_h95p"": 150834585.6,
            ""rss_h99p"": 151550033.92000002,
            ""rss_h999p"": 151886266.368,
            ""heap_hmin"": 25790920,
            ""heap_hmax"": 72316184,
            ""heap_hsum"": 1029889929504,
            ""heap_hvar"": 54374337037311.65,
            ""heap_hmean"": 49948587.68630874,
            ""heap_hdev"": 7373895.648658967,
            ""heap_hcnt"": 20619,
            ""heap_hmed"": 57480704,
            ""heap_h75p"": 61934254,
            ""heap_h95p"": 67752391.2,
            ""heap_h99p"": 70544797.92,
            ""heap_h999p"": 72315029.104,
            ""avg_hmin"": 0.04541015625,
            ""avg_hmax"": 0.06005859375,
            ""avg_hsum"": 938.234375,
            ""avg_hvar"": 4.491222722966496e-7,
            ""avg_hmean"": 0.04550338886463941,
            ""avg_hdev"": 0.0006701658543201448,
            ""avg_hcnt"": 20619,
            ""avg_hmed"": 0.04541015625,
            ""avg_h75p"": 0.04541015625,
            ""avg_h95p"": 0.04541015625,
            ""avg_h99p"": 0.05078125,
            ""avg_h999p"": 0.05997363281250001,
            ""free_hmin"": 12879872000,
            ""free_hmax"": 13228994560,
            ""free_hsum"": 268429937405952,
            ""free_hvar"": 5839592954606286,
            ""free_hmean"": 13018572064.889277,
            ""free_hdev"": 76417229.43555522,
            ""free_hcnt"": 20619,
            ""free_hmed"": 12908707840,
            ""free_h75p"": 12915716096,
            ""free_h95p"": 12919331430.4,
            ""free_h99p"": 12922073088,
            ""free_h999p"": 12922164563.968,
            ""util_hmin"": 0.05905642141342145,
            ""util_hmax"": 0.0607655708794173,
            ""util_hsum"": 1230.6298386264643,
            ""util_hvar"": 2.1530671850148948e-7,
            ""util_hmean"": 0.059684263961708346,
            ""util_hdev"": 0.0004640115499656118,
            ""util_hcnt"": 20619,
            ""util_hmed"": 0.05920415878947068,
            ""util_h75p"": 0.059217278415661254,
            ""util_h95p"": 0.05934395790869296,
            ""util_h99p"": 0.059361851867105964,
            ""util_h999p"": 0.0593659827984017,
            ""pool_name"": ""dynamodb"",
            ""pool_que_rate"": 0,
            ""pool_que_rcnt"": 1989,
            ""pool_que_rmean"": 0.0035627883554577716,
            ""pool_que_r1m"": 0,
            ""pool_que_r5m"": 0,
            ""pool_que_r15m"": 0,
            ""pool_que_hmin"": 0,
            ""pool_que_hmax"": 230,
            ""pool_que_hsum"": 45843,
            ""pool_que_hvar"": 366.86587852909315,
            ""pool_que_hmean"": 23.048265460030166,
            ""pool_que_hdev"": 19.15374319889178,
            ""pool_que_hcnt"": 1989,
            ""pool_que_hmed"": 21,
            ""pool_que_h75p"": 23,
            ""pool_que_h95p"": 33,
            ""pool_que_h99p"": 126.42000000000007,
            ""pool_que_h999p"": 225.971,
            ""pool_req_hmin"": 1,
            ""pool_req_hmax"": 2,
            ""pool_req_hsum"": 1991,
            ""pool_req_hvar"": 0.001005024617286425,
            ""pool_req_hmean"": 1.0010055304172951,
            ""pool_req_hdev"": 0.03170212322994195,
            ""pool_req_hcnt"": 1989,
            ""pool_req_hmed"": 1,
            ""pool_req_h75p"": 1,
            ""pool_req_h95p"": 1,
            ""pool_req_h99p"": 1,
            ""pool_req_h999p"": 1.9710000000000036,
            ""pool_count"": 0,
            ""pool_req_0"": 2,
            ""pool_cache_rate"": 0.1303780964797914,
            ""pool_cache_rcnt"": 284,
            ""pool_cache_rmean"": 0.0005087436344326025,
            ""pool_cache_r1m"": 0,
            ""pool_cache_r5m"": 0,
            ""pool_cache_r15m"": 0,
            ""pool_cache_hmin"": 0,
            ""pool_cache_hmax"": 2,
            ""pool_cache_hsum"": 70,
            ""pool_cache_hvar"": 0.19345045538247163,
            ""pool_cache_hmean"": 0.24647887323943662,
            ""pool_cache_hdev"": 0.4398300301053483,
            ""pool_cache_hcnt"": 284,
            ""pool_cache_hmed"": 0,
            ""pool_cache_h75p"": 0,
            ""pool_cache_h95p"": 1,
            ""pool_cache_h99p"": 1,
            ""pool_cache_h999p"": 2,
            ""pool_hits"": 239,
            ""pool_misses"": 45,
            ""cache_inserted"": 484,
            ""cache_deleted"": 310,
            ""cache_cleanups"": 0,
            ""cache_hits"": 7642,
            ""cache_misses"": 1411,
            ""cache_max"": 1000000,
            ""cache_size"": 61586,
            ""cache_count"": 174,
            ""api_que_hmin"": 1,
            ""api_que_hmax"": 6,
            ""api_que_hsum"": 13237,
            ""api_que_hvar"": 0.005674280465987009,
            ""api_que_hmean"": 1.0024992426537414,
            ""api_que_hdev"": 0.07532782000022972,
            ""api_que_hcnt"": 13204,
            ""api_que_hmed"": 1,
            ""api_que_h75p"": 1,
            ""api_que_h95p"": 1,
            ""api_que_h99p"": 1,
            ""api_que_h999p"": 2,
            ""api_nreq"": 1,
            ""api_req_rate"": 0,
            ""api_req_rcnt"": 13203,
            ""api_req_rmean"": 0.02365120609256502,
            ""api_req_r1m"": 0,
            ""api_req_r5m"": 0,
            ""api_req_r15m"": 0,
            ""api_req_hmin"": 0,
            ""api_req_hmax"": 536,
            ""api_req_hsum"": 20115,
            ""api_req_hvar"": 89.12554520926801,
            ""api_req_hmean"": 1.5235173824130879,
            ""api_req_hdev"": 9.440632669968046,
            ""api_req_hcnt"": 13203,
            ""api_req_hmed"": 1,
            ""api_req_h75p"": 1,
            ""api_req_h95p"": 1,
            ""api_req_h99p"": 33.13000000000011,
            ""api_req_h999p"": 99.36200000000008,
            ""url_message_get_rate"": 0,
            ""url_message_get_rcnt"": 24,
            ""url_message_get_rmean"": 0.00004299242196761214,
            ""url_message_get_r1m"": 0,
            ""url_message_get_r5m"": 0,
            ""url_message_get_r15m"": 0,
            ""url_message_get_hmin"": 16,
            ""url_message_get_hmax"": 71,
            ""url_message_get_hsum"": 792,
            ""url_message_get_hvar"": 208.34782608695653,
            ""url_message_get_hmean"": 33,
            ""url_message_get_hdev"": 14.434258764722092,
            ""url_message_get_hcnt"": 24,
            ""url_message_get_hmed"": 30.5,
            ""url_message_get_h75p"": 40.75,
            ""url_message_get_h95p"": 68,
            ""url_message_get_h99p"": 71,
            ""url_message_get_h999p"": 71,
            ""url_message_get_0"": 0,
            ""api_req_0"": 20,
            ""url_ping_rate"": 0,
            ""url_ping_rcnt"": 12407,
            ""url_ping_rmean"": 0.022226981327796796,
            ""url_ping_r1m"": 0,
            ""url_ping_r5m"": 0,
            ""url_ping_r15m"": 0,
            ""url_ping_hmin"": 0,
            ""url_ping_hmax"": 4,
            ""url_ping_hsum"": 6915,
            ""url_ping_hvar"": 0.25785489698686204,
            ""url_ping_hmean"": 0.5573466591440316,
            ""url_ping_hdev"": 0.5077941482400737,
            ""url_ping_hcnt"": 12407,
            ""url_ping_hmed"": 1,
            ""url_ping_h75p"": 1,
            ""url_ping_h95p"": 1,
            ""url_ping_h99p"": 1,
            ""url_ping_h999p"": 2,
            ""url_ping_0"": 5,
            ""url_image_account_rate"": 0,
            ""url_image_account_rcnt"": 95,
            ""url_image_account_rmean"": 0.00017084907295404685,
            ""url_image_account_r1m"": 0,
            ""url_image_account_r5m"": 0,
            ""url_image_account_r15m"": 0,
            ""url_image_account_hmin"": 17,
            ""url_image_account_hmax"": 121,
            ""url_image_account_hsum"": 4295,
            ""url_image_account_hvar"": 372.42329227323637,
            ""url_image_account_hmean"": 45.21052631578947,
            ""url_image_account_hdev"": 19.29827174317007,
            ""url_image_account_hcnt"": 95,
            ""url_image_account_hmed"": 42,
            ""url_image_account_h75p"": 51,
            ""url_image_account_h95p"": 89.59999999999991,
            ""url_image_account_h99p"": 121,
            ""url_image_account_h999p"": 121,
            ""url_image_account_0"": 0,
            ""incr_follow_0"": 0,
            ""api_bad_0"": 3,
            ""url_account_update_rate"": 0,
            ""url_account_update_rcnt"": 6,
            ""url_account_update_rmean"": 0.000010813705805470248,
            ""url_account_update_r1m"": 0,
            ""url_account_update_r5m"": 0,
            ""url_account_update_r15m"": 0,
            ""url_account_update_hmin"": 53,
            ""url_account_update_hmax"": 182,
            ""url_account_update_hsum"": 573,
            ""url_account_update_hvar"": 2041.5,
            ""url_account_update_hmean"": 95.5,
            ""url_account_update_hdev"": 45.18296139032943,
            ""url_account_update_hcnt"": 6,
            ""url_account_update_hmed"": 82,
            ""url_account_update_h75p"": 120.5,
            ""url_account_update_h95p"": 182,
            ""url_account_update_h99p"": 182,
            ""url_account_update_h999p"": 182,
            ""url_account_update_0"": 0,
            ""auth_add_0"": 0,
            ""url_account_get_rate"": 0,
            ""url_account_get_rcnt"": 9,
            ""url_account_get_rmean"": 0.0001993511695335063,
            ""url_account_get_r1m"": 0,
            ""url_account_get_r5m"": 0,
            ""url_account_get_r15m"": 0,
            ""url_account_get_hmin"": 2,
            ""url_account_get_hmax"": 100,
            ""url_account_get_hsum"": 435,
            ""url_account_get_hvar"": 844.0000000000001,
            ""url_account_get_hmean"": 48.333333333333336,
            ""url_account_get_hdev"": 29.051678092667903,
            ""url_account_get_hcnt"": 9,
            ""url_account_get_hmed"": 46,
            ""url_account_get_h75p"": 67,
            ""url_account_get_h95p"": 100,
            ""url_account_get_h99p"": 100,
            ""url_account_get_h999p"": 100,
            ""url_account_get_0"": 1,
            ""url_system_stats_rate"": 0,
            ""url_system_stats_rcnt"": 1,
            ""url_system_stats_rmean"": 0.04501665616278023,
            ""url_system_stats_r1m"": 0,
            ""url_system_stats_r5m"": 0,
            ""url_system_stats_r15m"": 0,
            ""url_system_stats_hmin"": 3,
            ""url_system_stats_hmax"": 3,
            ""url_system_stats_hsum"": 3,
            ""url_system_stats_hmean"": 3,
            ""url_system_stats_hdev"": 0,
            ""url_system_stats_hcnt"": 1,
            ""url_system_stats_hmed"": 3,
            ""url_system_stats_h75p"": 3,
            ""url_system_stats_h95p"": 3,
            ""url_system_stats_h99p"": 3,
            ""url_system_stats_h999p"": 3,
            ""url_system_stats_0"": 2
        }



Author
Vlad Seryakov
Check out the Documentation for more details.
",39
r3eckon/Unity-SimpleGrid-Shader,ShaderLab,"Unity-SimpleGrid-Shader
Simple procedural grid shader with GUI customizable parameters
Usage
Drag and drop both Shader and Material files in your project. The Material can then be edited and also dropped on a gameobject mesh inside Unity.
To edit the grid material, the following GUI options are available.

Line Color, Cell Color and Selected Color all represent their respective grid components. Colors use Alpha Cutoff for full transparency by setting the alpha channel to 0.
Grid Size is the amount of cells in the grid. You must make a simple edit to the shader itself to go above 100.
Line Size is the size of lines making up the grid.
Select Cell enables or disables the cell ""Selected"" by the parameters Selected Cell X and Y. It only colors a certain cell using a different color, but the base code to ""Select"" cells in the grid can be used in more complex ways.
The parameters shown above create the following grid.

More information
There is no aspect ratio based scaling by default, to keep cells squared keep the plane mesh square ( or implement your own aspect ratio scaling )
The selected cell can also be chosen by editing the material using the SetFloat value, to potentially make the material interactive. ( See official unity docs to learn more )
The shader, when applied to new materials, can be found under ""PDTShaders/TestGrid"".
",6
jeaye/safepaste,Clojure,"safepaste
safepaste is a security-conscious paste service for sharing private, encrypted data. All encryption is done client-side and it's impossible for the server, admin, or anyone without your 256 bit key to view the paste. All pastes are encrypted using AES-256.
Find it online here.
Features

AES-256 with random 256 bit secret keys
Always over HTTPS
Optional ""burn after reading""
Always free and open source

Learn more about the service
here.
Command-line tool
There is a command line tool for uploading and downloading pastes, written in
bash, included in the repo. It supports all of the same options as the web page
and performs the client-side encryption using openssl. To install it, use:
$ wget https://raw.githubusercontent.com/jeaye/safepaste/master/tool/safepaste
$ chmod +x ./safepaste

# To paste file (assuming safepaste script is within PATH):
$ safepaste < my-file

# To paste command output:
$ some-command | safepaste

# To download and decrypt a paste:
$ safepaste https://safepaste.org/f1a8f535#31bcdb56b77528a3c1b540bc460ed07d5b74fcf65eb91733bc4d10884e764caf

# To see more options:
$ safepaste -h
License
safepaste is under a strict copyleft license; see the
LICENSE file.
",21
jeaye/safepaste,Clojure,"safepaste
safepaste is a security-conscious paste service for sharing private, encrypted data. All encryption is done client-side and it's impossible for the server, admin, or anyone without your 256 bit key to view the paste. All pastes are encrypted using AES-256.
Find it online here.
Features

AES-256 with random 256 bit secret keys
Always over HTTPS
Optional ""burn after reading""
Always free and open source

Learn more about the service
here.
Command-line tool
There is a command line tool for uploading and downloading pastes, written in
bash, included in the repo. It supports all of the same options as the web page
and performs the client-side encryption using openssl. To install it, use:
$ wget https://raw.githubusercontent.com/jeaye/safepaste/master/tool/safepaste
$ chmod +x ./safepaste

# To paste file (assuming safepaste script is within PATH):
$ safepaste < my-file

# To paste command output:
$ some-command | safepaste

# To download and decrypt a paste:
$ safepaste https://safepaste.org/f1a8f535#31bcdb56b77528a3c1b540bc460ed07d5b74fcf65eb91733bc4d10884e764caf

# To see more options:
$ safepaste -h
License
safepaste is under a strict copyleft license; see the
LICENSE file.
",21
narigacdo/automation-all,Shell,"automation-all
Scripts para diversos tipo de funÃ§Ã£o
",2
jaymcole/DungeonCrawler2,Java,"Dungeon Crawler 2
2D Java Rogue-like rpg dungeon crawler game.
(Screenshots below)
Features

Procedurally generated levels
2D fragment based lighting
Simple Game AI

Pathfinding
Targeting/Attacking/Etc.


100% custom GUI/Interface

Custom windows and window management
Custom widgets
Custom event handling


Experience/Leveling system

Gain attribute points to improve your character by defeating dungeon monsters.


Inventory management system
Fast-paced gameplay
Loot!

Items/Loot can be found throughout the dungeon or by defeating dungeon monsters.


Record keeping system

Keeps track of various in-game stats (time played/attribute points spent/damage dealt/damage taken and many more)
Allows for developers to quickly and easily add new stats to record with just two short lines of code.


Custom asset/resource manager

Ensures duplicate resources aren't loaded into memory.
Ensures resources are disposed of correctly.


Custom Animations system

Getting Started
These instructions will get you a copy of the project up and running on your local machine for development and testing purposes. See deployment for notes on how to deploy the project on a live system.

Clone DungeonCrawler2 repo
Import DungeonCrawler2 into Eclipse as a Gradle project

Note: There are currently incompatibility issues with Gradle and Java 10.


Set DungeonCrawler2 to use the assets folder

Right-click ""DungeonCrawler2-desktop"" (in Eclipse project explorer)
Run As
Run Configurations
Arguments (tab)
Under ""Working directory:""
Change from ""Default"" to ""Other""
""Workspace..."" (button)
Select ""DungeonCrawler2 > core > assets""
""OK"" (button)


Starting the game

Launch DungeonCrawler2-desktop > src > ecu.se.desktop > DesktopLauncher.java as Java Application



Built With

LibGdx - The graphical framework

Authors

Jason Cole

License
This project is licensed under the MIT License - see the LICENSE.md file for details
Screenshots



",2
ppy/osu-wiki,None,"osu! wiki

Home of the osu! wiki.
Contributing
Please see the ""contributing"" file if you are interested in helping out with the project!
File caching
Wiki articles
Articles are cached for up to five hours.
Images
Images are cached for up to two hours.
News posts
News posts are cached for up to sixty days. If there are any issues after merging a news post, merge a pull request to fix it then tell Ephemeral (ephemeralis#0001) or Shiro (Shiro#1584) on the osu!dev Discord (#osu-wiki channel) to force a refresh for the fixed news post.
Licence
The majority of content in this repository is licensed under CC-BY-NC 4.0. Please see the licence file for more information. tl;dr you can use it in a non-commercial manner.
As this is a wiki, there may be content with third party licences. These licences will be cited local to the content, and override the global licence file.
Please note that this does not cover the usage of the ""osu!"" or ""ppy"" branding in any software, resources, advertising or promotion, as this is protected by trademark law. If you require clearance for the use of these terms, please contact us.
",137
greenriver/hmis-warehouse,Ruby,"Boston HMIS Warehouse 
Introduction
The HMIS Warehouse project was initiated by the City of Boston's Department of Neighborhood Development to gather data from across various HMIS installations, produce aggregated reports, and supply de-duplicated client information to the Boston CAS system for Coordinated Access to housing.
The Warehouse is capable if ingesting standard HUD HMIS CSV files as well as data via the Social Solutions ETO API.
Copyright Â© 2017 Green River Data Analysis, LLC

This program is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

A copy of the license is available in LICENSE.md
Vision
The City of Boston made a conscientious choice to release this project into the open source under a GPL. Our goal is to promote this opportunity, allowing Boston's investment to assist other municipalities and organizations, and realize the vision of a tool under continuous, collaborative improvement helping communities nationwide.
Looking ahead, we see the Warehouse codebase serving as a foundation for all communities that report to the department of Housing and Urban Development, or have a need to aggregate and de-duplicate homeless client data from across various systems.  To our knowledge, this is the only open source, freely available implementation of many HUD reports.
Application Design
The application is designed around the HUD Data Standards and the data structure is based on the HMIS Logical Model
The application is written primarily in Ruby on Rails and we use RVM to select a ruby version. Other ruby version managers should work fine, as would manually installing the ruby version mentioned in the .ruby-version
The application uses postgres for application data storage and Microsoft SQL Server or postgres for the warehouse data.
We've developed locally on OSX using homebrew and deployed to Ubuntu 16.04 using apt for dependencies.
Developer Prequisites
If you are unfamilar with contributing to open source projects on github you may first want to read some of the guides at:  https://guides.github.com/
There is a simple script to setup a development environment in bin/setup. To make it run smoothly you should have:

A running Ruby 2.3+ environment with bundler 1.11+ installed.
A local install of postgresql 9.4+ allowing your user to create new databases.
A local install of redis for caching. redis-server should be running on the default port
libmagic

Once these are in place, bin/setup should:

Install all ruby dependencies.
Create initial copies of configuration files.
Create an initial database and seed it with reference data and a randomly generated admin user.

If all goes well you should then be able to run bin/rails server and open the Warehouse in your system at http://localhost:3000 using the email/password created during bin/setup. If not, read bin/setup to figure out what went wrong and fix it.
Hack on your version as you see fit and if you have questions or want to contibute open an issue on github.
Developer Notes
We use the following common rails gems and conventions:

haml for view templating
bootstrap for base styles and layout
sass for custom-css
simple_form for forms
kaminari for pagination
brakeman for basic security scanning.
rack-mini-profiler to make sure pages are fast. Ideally <200ms
helpers need to be explictly loaded in controllers. i.e. we have config.action_controller.include_all_helpers = false set
bin/rake generate controller ...  doesn't make fixures and they are disabled in test_helper. We don't use them and instead seed data in test or let test create their own data however they need to.
it also doesn't make helper or asset stubs, make them by hand if you need one. See config/application.rb for details.

Multiple databases
The project reads/writes from several different databases. We keep track of these different environments by setting up parallel db configs and structures for each database. Health care data is configured in config/database_health.yml and database resources are in db/health. Warehouse data is configured in config/database_warehouse.yml and resources are in db/warehouse. When running migrations, use the custom generators.
App migrations can be created with:
rails generate migration foo

and run with
rake db:migrate

Warehouse migrations can be created with:
rails generate warehouse_migration foo

and run with
rake warehouse:db:migrate

Health migrations can be created with
rails generate health_migration foo

and run with
rake health:db:migrate

",8
kuazhu/w1802,JavaScript,"ä»åºè¯´æ
æ¬ä»åºä¸ºæ¼ç¤ºä»£ç åº,ä»ä¾åèç¨


éå¥å­¦ä¹ è§é¢:å­¦ä¹ è§é¢
éå¥å­¦ä¹ èµæ:å­¦ä¹ èµæ


",4
edvb/tisp,C,"tisp - tiny lisp

tisp is a tiny lisp library designed to to be lightweight and easy to embedded
in other programs. Simply drop the tisp.c and tisp.h files into your
project and include the header file in order to use the necessary functions for
your program. An example command line interpreter is provided in main.c.
Options
-h
Print help and exit
-v
Print version info and exit
Usage
Run the program from the command line to launch the REPL, type a command and
press enter to see the result.
$ tisp
> (+ (+ 1 2) 3)
6
> (+ 1 2 3)
6

Alternatively you can pass a file name which will be opened and run, outputting
the result before exiting.
$ echo '((lambda (x) (+ x 1)) 10)' > inc.lisp
$ tisp inc.lisp
11

Commands can also be piped directing into tisp through the command line.
$ echo '(= ""foo"" ""foo"")' | tisp
t

Language
tisp is mainly based off of scheme, with minor features borrowed from other
lisps.
General
Comments
Single line comments with a semicolon, eg (cons 1 2) ; ingnored by tisp until new line.
Types
Nil
Nil, null, empty, or false, represented as an empty list, eg ().
Integers
Whole real numbers, positive or negative with optional + or - prefixes
repressively. Also supports scientific notation with a capital or lowercase
e. The exponent also needs to be integer which can be positive or negative.
eg 1, -48, +837e4, 3E-2.
Floating Pointing
Floating point numbers, as know as decimals, are integers followed by a period
and an optional integer with leading integers. Like integers can be positive or
negative with scientific notation, but still need an integer as an exponent. eg
1., +3.14, -43.00, 800.001e-3.
Rationals
Fraction type, a ratio of two integers. Similar rules apply for numerator and
dominator as integers (real positive or negative), expect for scientific
notation. Will try to simplify fraction where possible, and will through error
on division by zero. eg 1/2, 4/3 -1/2, 01/-30, -6/-3.
Strings
String of characters contained inside two double quotes. eg ""foo"", ""foo bar"".
Symbols
Case sensitive symbols which can be used as variable names. Supports lower and
upper case letters, numbers, as well as the characters _+-*/=<>?. First
character can not be a number, if the first character is a + or - then the
second digit cannot be a number either. Unlike all the previously listed types,
symbols are not self evaluating, but instead return the value they are defined
to. Throws an error if a symbol is evaluated without it being previously
assigned a value. eg foo, foo-bar, cat9, +, >=, nil?.
Lists
Lists composed of one or more element of any other types, including lists them
selves. Expressed with surrounding parentheses and each element is separated by
white space. When evaluated runs the first element as function with the rest of
the elements as arguments. Technically list is not a type, but simply a
nil-terminating chain of nested pairs. A pair is a group of two and only two
elements, normally represented as (a . b), with a being the first element
(car) and b being the second element (cdr). for example (a b c) is actually
(a . (b . (c . ()))). But it is often easier just to think of them as lists.
Functions
Lambda functions created within tisp itself. Called using list syntax where the
first element is the function name and any proceeding elements are the
arguments. For example (cadr '(1 2 3)) is a list of elements cadr and '(1 2 3). It calls the function cadr which returns the 2nd element of the first
argument given, here a list of size 3. In this case it return a 2.
Primitives
Functions built in to the language written in C. Called like regular functions,
see primitives section for more details.
Primitives
Built in primitives included by default.
car
Returns first element of given list
cdr
Return rest of the given list, either just the second element if it is of size
2 or a pair, or a new list with the first element removed.
cons
Creates a new pair with the two given arguments, first one as the car, second
as the cdr.
quote
Returns the given argument unevaluated.
void
Returns nothing. Used to insert a void type in a list or force a function not
to return anything.
begin
Executes all of its arguments and returns the value of the last expression.
eval
Evaluates the expression given.
=
Tests if multiple values equal. Returns nil if any are not, and t otherwise.
cond
Evaluates each expression if the given condition corresponding to it is true.
Runs through any arguments, each is a list with the first element as the
condition which needs to be t after evaluated, and the second element is the
expression to be run if and only if the condition is met.
type
Returns a string stating the given argument's type.
lambda
Creates function, first argument is a list of elements representing the symbol
name for any arguments for the new function. Next argument is code to be run
with the supplied arguments.
define
Create variable with the name of the first argument, with the value of the
second.
load
Loads the library, given as a string.
Differences From Other Lisps
In tisp there are no boolean types, much like common lisp, true is represented
by the self evaluating symbol t and false is nil, represented as (), an
empty list.
tisp also only has one equality primitive, =, which tests integers, symbols,
strings, and objects which occupy the same space in memory, such as primitives.
It also accepts any number of arguments to compare.
Symbols are also case sensitive following the Unix way, unlike many other lisps.
Author
Ed van Bruggen edvb@uw.edu
See Also
See project page at https://edryd.org/projects/tisp.html
View source code at https://git.edryd.org/tisp
LICENSE
zlib License
",5
KalilDev/textos,Dart,"textos
Aplicativo para visualizar os textos do kalil e cria-los
Getting Started
This project is a starting point for a Flutter application.
A few resources to get you started if this is your first Flutter project:

Lab: Write your first Flutter app
Cookbook: Useful Flutter samples

For help getting started with Flutter, view our
online documentation, which offers tutorials,
samples, guidance on mobile development, and a full API reference.
",2
PacktPublishing/Python-Image-Processing-Cookbook,Jupyter Notebook,"Python-Image-Processing-Cookbook
",3
leon-ai/leon,JavaScript,"



Leon
Your open-source personal assistant.






Website ::
  Documentation ::
  Roadmap ::
  Contributing ::
  Story


Introduction
Leon is an open-source personal assistant who can live on your server.
He does stuff when you ask him for.
You can talk to him and he can talk to you.
You can also text him and he can also text you.
If you want to, Leon can communicate with you by being offline to protect your privacy.
Why?


If you are a developer (or not), you may want to build many things that could help in your daily life.
Instead of building a dedicated project for each of those ideas, Leon can help you with his
packages/modules (skills) structure.
With this generic structure, everyone can create their own modules and share them with others.
Therefore there is only one core (to rule them all).
Leon uses AI concepts, which is cool.
Privacy matters, you can configure Leon to talk with him offline. You can already text with him without any third party services.
Open source is great.


What is this repository for?

This repository contains the following nodes of Leon:

The server
The packages/modules
The web app
The hotword node


What is Leon able to do?

Today, the most interesting part is about his core and the way he can scale up. He is pretty young but can easily scale to have new features (packages/modules).
You can find what he is able to do by browsing the packages list.

Sounds good for you? Then let's get started!
Getting Started
Prerequisites

Node.js 10 or 11
npm >= 5
Python 3.6.x
Pipenv
Supported OSes: Linux, macOS and Windows

To install these prerequisites, you can follow the How To section of the documentation.
Installation
# Clone the repository (stable branch)
git clone -b master https://github.com/leon-ai/leon.git leon
# OR download the latest release at: https://github.com/leon-ai/leon/releases/latest

# Go to the project root
cd leon

# Install
npm install
Usage
# Check the setup went well
npm run check

# Build
npm run build

# Run
npm start

# Go to http://localhost:1337
# Hooray! Leon is running
Docker Installation
# Build
npm run docker:build

# Run on Linux or macOS
npm run docker:run

# Run on Windows (you can replace ""UTC"" by your time zone)
docker run -e TZ=UTC -p 1337:1337 -it leonai/leon

# Go to http://localhost:1337
# Hooray! Leon is running
Documentation
For full documentation, visit docs.getleon.ai.
Roadmap
To know what is going on, follow roadmap.getleon.ai.
Contributing
If you have an idea for improving Leon, do not hesitate.
Leon needs open source to live, the more modules he has, the more skillful he becomes.
The Story Behind Leon
You'll find a write-up on this blog post.
Stay Tuned

Newsletter
Blog
GitHub issues
Twitter
#LeonAI

Author
Louis Grenard (@louistiti_fr)
Donate
You can also contribute by buying me a fruit juice.
License
MIT License
Copyright (c) 2019-present, Louis Grenard louis.grenard@gmail.com
Cheers!

",5307
NilsTheBest/NilsTheBot,Python,"NilsTheBot
A discord bot created by @NilsTheBest.
The bot is still being programmed and still can be improved. Here you can report bugs if you find any, or improve the code by making a pull request - any help is appreciated!
List of commands
 ntb!info - tells you a bit more about the bot and how to use him.
 ntb!help - displays a list of commands.
 ntb!mod (off by default)
 ---> {on/off} - toggles moderation mode
 ---> {0-2} - changes moderation mode (0 is off)
 ===============================
 !C-to-F and !F-to-C - converts Celsius to Fahrenheit, and vice-versa.
 !huge - displays huge text.
",2
eccentricdevotion/GameModeInventories,Java,"GameModeInventories
A CraftBukkit plugin for Minecraft Server.
Allow players to have separate inventories for each game mode (Creative, Survival and Adventure).
This plugin (and the GMIDatabaseConverter plugin) are available for download as a single ZIP file from the GameModeInventories page on BukkitDev.
Warning
This version of GameModeInventories uses a different storage format when saving inventories. Before installing this version, you should first run the GMIDatabaseConverter plugin on your CraftBukkit 1.6.4 server to update your GameModeInventories database.
How do I update my GMI database?
Before upgrading your server to CraftBukkit 1.7.x and installing GameModeInventories version 2.x, you should run GMIDatabaseConverter on your 1.6.4 server.

Install GMIDatabaseConverter.jar to the server's plugins folder
Start the server

The plugin will attempt to find and backup your old GameModeInventories database file
It will then read the existing inventory data
The existing data will be converted to the new format
The new data will be written back to the database


Once conversion is complete, you can update your GameModeInventories plugin to version 2.x and restart the server
If you are satisfied that GameModeInventories version 2.x is functioning correctly, you can safely remove GMIDatabaseConverter

Why did you change the storage format?
The format change is a result of code changes removing the reliance on using net.minecraft.server and org.craftbukkit code directly within the plugin (instead of using only the Bukkit API). This led to the plugin breaking with every Minecraft/CraftBukkit update. These code changes mean the plugin should no longer break between versions.
",3
r3eckon/Recursive-Tile-Map-Growth,Java,"Recursive Tile Map Growth
A simple recursive algorithm used to generate corridors and rooms inside of a grid based tile map.
The core of the algorithm has been uploaded alongside a built version for demonstration purposes.

To use the built jar, make sure you have the lastest verson of Java installed.
The title of the window will show you the current generation parameters as well as more useful information.
Original Build is the original version of the algorithm, to compare progress.
Model Build is the newest version of the algorithm with animated showoff.
Model Build - Realtime Generation is the newest version of the algorithm without animated showoff.
Controls
G to generate a new map
Arrow Keys to move the camera around
- and = to zoom
Numpad to select an alternate floor
General Explanation
The algorithm begins by checking that it is still within the bounds of the map, then checks neighboring tiles to make sure no tile types that should be avoided are nearby ( such as Rooms for Corridor tiles )
After checks are complete, the Corridor tile type is added to the current position. Tile Types are stored as an Enum in another class and only represent an arbitrary type. Many more types can be used.
The algorithm then proceeds to RNG rolls, which implies generating multiple float type numbers from 0 to 1 and checking if they are lower than the Branch, Turn, End, Room, Stairs, Model, and CSAvoid to induce their respective effects to the current process. Since we are checking if the generated number is lower, a parameter of 1 will ensure the effect happens every time.


Branch causes the corridor to branch into a perpendicular corridor, the direction of which is determined by a boolean random roll.


Turn converts a currently branching corridor into a single ""turn"" by calling return once the first branch has completed.


End suspends the current corridor by immediately calling return.


Room adds an entrance and calls the room generation algorithm to grow a room, the style and type of which depending on the orientation of the entrance.


Stairs adds stairwells towards the top or bottom of the dungeon, also creating new corridors to grow a new floor.


Model adds a pre made model by chosing randomly from the input list of models.


CSAvoid or Corridor Self Avoid allows or disallow the corridor to connect to existing corridors.


More of those random parameters can be added to generate more desirable results.
Models
Models have been recently added and combine the manual level design capabilities of a human to the growth of the level by randomly chosing from a set of premade tile type arrays. Those models, which can be of any size and span multiple floors, are then rotated and placed by the algorithm.
This system has recently been updated to allow Unique models or models that are limited in how often they can appear on generated maps.
Code samples for model placement, rotation and creation are included in the Source folder.
Deadend Removal
Deadends can now be found and removed using a couple algorithms, which have been added to the Source folder.
Essentially, any Corridor type tile that has less than 2 non empty immediate neighbors can be considered to be deadends. They are found and removed after the map is generated to give them a cleaner layout, as seen below.
Example 1 - Before

Example 1 - After

Example 2 - Before

Example 2 - After

Of course, it is also possible to to single passes of the find+remove algorithms to simply shorten the deadends rather than completely removing them.
Deadend removal code has been recently updated to also remove a new type of ""Planar"" style staircases and useless room entrances.
Post Generation Triggers
Post Generation Triggers have recently been added as a way to invoke generation algorithms after the main layout has been generated.
For example, a room may include an alternate exit or entrance which is not initlally connected to the rest of the layout.
PGTriggers allows the storage of which position on your map require post generation actions, which action to execute and in what orientation.
For the case of our alternate room entrance, simply adding a PGTrigger at the position of this entrance with the ""Grow Corridor"" behavior will start a new corridor from this point and hopefully connect that alternate entrance to another part of your layout.
PGTriggers can also be used to generate extra rooms, stairs and models.
The system has recently been updated to allow artifical inflation of the Current Count and Max Length values used to control the length of corridors, as well as placing the Ending type tile. By using an offset on those values on a corridor being generated from a trigger, the generator can be forced to place the Ending tile after a particular room.
Parameter Scaling
A simple way to make more diverse layouts is to apply a scaling factor to each random roll value. The strength of this scaling factor is calculated using the distance the current floor is relative to the spawn floor.
This means that scaling factors can be used to make floors that are further away from the spawn point get increasingly chaotic and messy by scaling up the Branch parameter.
Selective Layout Generation
To create levels that make a bit more sense in the context of a game, some layout requirements must be put in place. Selective Layout Generation makes sure that only levels that meet those requirements are kept by the generator.
The non animated updated build shows this feature in action. In this instance, only maps that feature one Boss Room ( big yellow area ) are kept.
Since many maps must be discarded, this feature should not be abused since too complex requirement paired with a setup that produces bad maps could result in very long gen time. The maximum amount of tries should be capped for this reason.
",29
georgewfraser/java-language-server,Java,"Language Server for Java using the Java compiler API
A Java language server based on v3.0 of the protocol and implemented using the Java compiler API.

Installation (VS Code)
Install from the VS Code marketplace
Installation (other editors)
Vim (with vim-lsc)

Checkout this repository
Run ./scripts/link_mac.sh
Add the vim plugin natebosch/vim-lsc to your vimrc
Add vim-lsc configuration:
let g:lsc_server_commands = {'java': '<path-to-java-language-server>/java-language-server/dist/mac/bin/launcher --quiet'}


See the vim-lsc README for other configuration options.

Note: This tool is not compatible with vim-lsp as it only supports LSPv2.0.
Issues
Features
Javadoc

Signature help

Autocomplete symbols (with auto-import)


Autocomplete members

Go-to-definition


Find symbols


Lint

Type information on hover

Find references


Usage
The language server will provide autocomplete and other features using:

.java files anywhere in your workspace
Java platform classes
External dependencies specified using pom.xml, Bazel, or settings

Settings
If the language server doesn't detect your external dependencies automatically, you can specify them using .vscode/settings.json
{
    ""java.externalDependencies"": [
        ""junit:junit:jar:4.12:test"", // Maven format
        ""junit:junit:4.12"" // Gradle-style format is also allowed
    ]
}
If all else fails, you can specify the java class path manually:
{
    ""java.classPath"": [
        ""lib/some-dependency.jar""
    ]
}
You can generate a list of external dependencies using your build tool:

Maven: mvn dependency:list
Gradle: gradle dependencies

The Java language server will look for the dependencies you specify in java.externalDependencies in your Maven and Gradle caches ~/.m2 and ~/.gradle. You should use your build tool to download the library and source jars of all your dependencies so that the Java language server can find them:

Maven

mvn dependency:resolve for compilation and autocomplete
mvn dependency:resolve -Dclassifier=sources for inline Javadoc help


Gradle

gradle dependencies for compilation and autocomplete
Include classifier: sources in your build.gradle for inline Javadoc help, for example:
dependencies {
    testCompile group: 'junit', name: 'junit', version: '4.+'
    testCompile group: 'junit', name: 'junit', version: '4.+', classifier: 'sources'
}





Design
The Java language server uses the Java compiler API to implement language features like linting, autocomplete, and smart navigation, and the language server protocol to communicate with text editors like VSCode.
Incremental updates
The Java compiler API provides incremental compilation at the level of files: you can create a long-lived instance of the Java compiler, and as the user edits, you only need to recompile files that have changed. The Java language server optimizes this further by focusing compilation on the region of interest by erasing irrelevant code. For example, suppose we want to provide autocomplete after print in the below code:
class Printer {
    void printFoo() {
        System.out.println(""foo"");
    }
    void printBar() {
        System.out.println(""bar"");
    }
    void main() {
        print // Autocomplete here
    }
}
None of the code inside printFoo() and printBar() is relevant to autocompleting print. Before servicing the autocomplete request, the Java language server erases the contents of these methods:
class Printer {
    void printFoo() {
        
    }
    void printBar() {
        
    }
    void main() {
        print // Autocomplete here
    }
}
For most requests, the vast majority of code can be erased, dramatically speeding up compilation.
Logs
The java service process will output a log file to stderr, which is visible in VSCode using View / Output, under ""Java"".
Contributing
If you have npm and maven installed, you should be able to install locally using
npm install -g vsce
npm install
./scripts/build.sh

At the time of this writing, the build only works on Mac, because of the way it uses JLink. However, it would be straightforward to fix this by changing scripts/link_mac.sh to be more like scripts/link_windows.sh.
",196
ChoGGi/SurvivingMars_CheatMods,Lua,"You should buy a copy: GOG, Steam, or Paradox
For packaged versions of these mods see Steam or Nexus Mods.
Install help (Nexus/GoG)
Place mod folder(s) in %AppData%\Surviving Mars\Mods (Create ""Mods"" folder if it doesn't exist)

https://pcgamingwiki.com/wiki/Surviving_Mars#Save_game_data_location (other OS locations)

Ã¯Â»Â¿Enable with in-game mod manager

If you don't have a mod manager button see here or Nexus.
",19
georgewfraser/java-language-server,Java,"Language Server for Java using the Java compiler API
A Java language server based on v3.0 of the protocol and implemented using the Java compiler API.

Installation (VS Code)
Install from the VS Code marketplace
Installation (other editors)
Vim (with vim-lsc)

Checkout this repository
Run ./scripts/link_mac.sh
Add the vim plugin natebosch/vim-lsc to your vimrc
Add vim-lsc configuration:
let g:lsc_server_commands = {'java': '<path-to-java-language-server>/java-language-server/dist/mac/bin/launcher --quiet'}


See the vim-lsc README for other configuration options.

Note: This tool is not compatible with vim-lsp as it only supports LSPv2.0.
Issues
Features
Javadoc

Signature help

Autocomplete symbols (with auto-import)


Autocomplete members

Go-to-definition


Find symbols


Lint

Type information on hover

Find references


Usage
The language server will provide autocomplete and other features using:

.java files anywhere in your workspace
Java platform classes
External dependencies specified using pom.xml, Bazel, or settings

Settings
If the language server doesn't detect your external dependencies automatically, you can specify them using .vscode/settings.json
{
    ""java.externalDependencies"": [
        ""junit:junit:jar:4.12:test"", // Maven format
        ""junit:junit:4.12"" // Gradle-style format is also allowed
    ]
}
If all else fails, you can specify the java class path manually:
{
    ""java.classPath"": [
        ""lib/some-dependency.jar""
    ]
}
You can generate a list of external dependencies using your build tool:

Maven: mvn dependency:list
Gradle: gradle dependencies

The Java language server will look for the dependencies you specify in java.externalDependencies in your Maven and Gradle caches ~/.m2 and ~/.gradle. You should use your build tool to download the library and source jars of all your dependencies so that the Java language server can find them:

Maven

mvn dependency:resolve for compilation and autocomplete
mvn dependency:resolve -Dclassifier=sources for inline Javadoc help


Gradle

gradle dependencies for compilation and autocomplete
Include classifier: sources in your build.gradle for inline Javadoc help, for example:
dependencies {
    testCompile group: 'junit', name: 'junit', version: '4.+'
    testCompile group: 'junit', name: 'junit', version: '4.+', classifier: 'sources'
}





Design
The Java language server uses the Java compiler API to implement language features like linting, autocomplete, and smart navigation, and the language server protocol to communicate with text editors like VSCode.
Incremental updates
The Java compiler API provides incremental compilation at the level of files: you can create a long-lived instance of the Java compiler, and as the user edits, you only need to recompile files that have changed. The Java language server optimizes this further by focusing compilation on the region of interest by erasing irrelevant code. For example, suppose we want to provide autocomplete after print in the below code:
class Printer {
    void printFoo() {
        System.out.println(""foo"");
    }
    void printBar() {
        System.out.println(""bar"");
    }
    void main() {
        print // Autocomplete here
    }
}
None of the code inside printFoo() and printBar() is relevant to autocompleting print. Before servicing the autocomplete request, the Java language server erases the contents of these methods:
class Printer {
    void printFoo() {
        
    }
    void printBar() {
        
    }
    void main() {
        print // Autocomplete here
    }
}
For most requests, the vast majority of code can be erased, dramatically speeding up compilation.
Logs
The java service process will output a log file to stderr, which is visible in VSCode using View / Output, under ""Java"".
Contributing
If you have npm and maven installed, you should be able to install locally using
npm install -g vsce
npm install
./scripts/build.sh

At the time of this writing, the build only works on Mac, because of the way it uses JLink. However, it would be straightforward to fix this by changing scripts/link_mac.sh to be more like scripts/link_windows.sh.
",196
ChoGGi/SurvivingMars_CheatMods,Lua,"You should buy a copy: GOG, Steam, or Paradox
For packaged versions of these mods see Steam or Nexus Mods.
Install help (Nexus/GoG)
Place mod folder(s) in %AppData%\Surviving Mars\Mods (Create ""Mods"" folder if it doesn't exist)

https://pcgamingwiki.com/wiki/Surviving_Mars#Save_game_data_location (other OS locations)

Ã¯Â»Â¿Enable with in-game mod manager

If you don't have a mod manager button see here or Nexus.
",19
xiaohao890809/xiaohao890809.github.io,HTML,"æçä¸ªäººåå®¢

å°åï¼http://xiaohao890809.github.io
åºäºjekyllçblog
ä½¿ç¨äºbootstrapæ¡æ¶
ä½¿ç¨font-awesomeè¿è¡ä¿®é¥°
åä½èæ¯ï¼https://github.com/enml/blog/tree/jekyll-blog ï¼ç¹æ­¤è¡¨ç¤ºæè°¢ï¼

",2
triton/triton,Nix,"Triton
Triton is a collection of packages for the Nix package
manager.
Triton linux distribution source code is located inside the
nixos/ folder.
Discussion Channels

Matrix Community: +triton:matrix.org

Documentation
Legacy Documentation

NixOS installation instructions
Documentation (Nix Expression Language chapter)
Manual (How to write packages for Nix)
Manual (NixOS)
Nix Wiki

Supported Platforms (not all platforms implemented)

ARM requires: NEON, VFPv3+ (aka. armv7+)

armv7l-linux WIP
armv8l-linux WIP
aarch64-linux WIP


x86 requires: MMX,SSE,SSE2,SSE3,SSSE3,SSE4,SSE4.1,SSE4.2,AES
(aka. at least Intel Westmere, AMD 15h, or VIA Eden x4)

i686-linux (libs only)
x86_64-linux


POWER requires: POWER8+

powerpc64le-linux Incomplete



",45
lcp0578/cheat-sheets,PHP,"ð cheat sheets ð

symfony

Basic åºç¡åå¸¸ç¨

Basic åºç¡ç¥è¯ç¹
Symfony Twig Extensions symfonyå¯¹Twigçæ©å±
Shortcuts Methods æ§å¶å¨ä¸­çå¿«æ·æ¹æ³
FileControllerHelper æä»¶å¤ççhelper
Json Response Jsonååºååæ°è®¾ç½®
Streamed Response æµååº


Twig Twigç¸å³

Twig Twigåºç¡
Twig Extension Twigæ©å±ç¤ºä¾
Twig Form Reference Twig Fromç¸å³çå½æ°ä¸åé
Twig functions Twigå½æ°ç¨æ³ç¤ºä¾
Whitespace Control ç©ºæ ¼æ§å¶
Twig tags Twig Tagsç¨æ³ç¤ºä¾
Twig macro macroå®çç¤ºä¾


Doctrine Doctrineç¸å³

Doctrine Doctrineåºç¡ç¥è¯
Doctrine Types Doctrineå­æ®µç±»å
An Entity Demo ä¸ä¸ªç¥å¤æçEntityçç¤ºä¾
Validation Constraints éªè¯çº¦æè®¾ç½®
Custom Constraint.mdèªå®ä¹éªè¯çº¦æ
Doctrine Cache éç½®Doctrineç¼å­éç½®
Doctrine Annotations Reference
Doctrine Schema Manager Doctrine æ¨¡å¼ç®¡çå¨
Doctrine SQL Filter SQLè¿æ»¤å¨ç¤ºä¾
Doctrine Query Functions DQLä½¿ç¨SQLå½æ°ï¼ä¾å¦ï¼DATE_FORMAT
Custom DQL Funtions èªå®ä¹DQLå½æ°
DQL(Doctrine Query Language) DQLç¸å³
QueryBuilder examples æ¥è¯¢æé å¨ç¤ºä¾
RawSQLQuery examples åçSQLæ¥è¯¢
associations è¡¨ä¹é´å³è
Table to Entity (reverse engineering) æ°æ®è¡¨è½¬Entityï¼éåå·¥ç¨ï¼
MultipleDatabase å¤æ°æ®åºéç½®ä¸ä½¿ç¨
ColumnDefaultValue è®¾ç½®å­æ®µé»è®¤å¼çé£äºå
Schema Manager Schemaç®¡çå¨çä½¿ç¨
batch processing æ¹éå¤ç
truncate table æªæ­è¡¨
SQL log å¼åæ¨¡å¼ä¸éç½®SQL log


Router è·¯ç±ç¸å³

routing.yml ymlè·¯ç±éç½®ç¤ºä¾


Form è¡¨åç¸å³

FormBuilder examples è¡¨åæé å¨ç¤ºä¾
Validation Note è¡¨åéªè¯ç¸å³
Validation Groups éªè¯ç»
argument value resolver
create custom field type
create form type extension
Custom Form Theme
DataTransformers
Pass Custom Options Form
dynamic form modificationå©ç¨äºä»¶çå¬å¨æä¿®æ¹è¡¨åæ°æ®


Service æå¡ç¸å³

Service
service id æå¡ID
autowiring æå¡çèªå¨è£é
alias private service
Custom Service Tags
service decoration
Service Container


Dependency Injection ä¾èµæ³¨å¥ç¸å³

Dependency Injection Tags
Compiler Pass


Security å®å¨ç¸å³

security authentication  å®å¨ç¸å³ä»ç»
Authenticator demo è®¤è¯å¨çdemo
Login and Register ç»å½åæ³¨åç¸å³
Logout Handler éåºç»å½ï¼åå«å¤±è´¥ï¼å¤ç
Logout Success Handler æåéåºç»å½å¤ç
multi field login æ¯æå¤å­æ®µç»å½ç³»ç»
SetLoginToken æå¨ç¨æ·ç»å½ï¼è®¾ç½®token


EventListener äºä»¶çå¬ç¸å³

EventListener äºä»¶çå¬
Login Event Listener ç»å½äºä»¶çå¬
Guzzle Http Event Listener GuzzleHttpäºä»¶çå¬
Enable SQL Filter Event Listener SQL Filter äºä»¶çå¬
Api Version APIçæ¬æ§å¶
kernel view æ¨¡æ¿å±çå¬
Api Exception Listener APIå¼å¸¸çå¬
Doctrine Event Listeners SubscribersDoctrineçäºä»¶çå¬


Command

Console Command å¸¸ç¨çconsoleå½ä»¤
Command call Command commandä¹é´è°ç¨
command in controller å¨æ§å¶å¨è°ç¨command
Custom Command èªå®ä¹command
Command LifecycleCommandçå½å¨æå½æ°


ReusableBundle åå»ºå¯éå¤ä½¿ç¨bundleç¸å³

BundleStruct å¯å¤ç¨bundleç»æ
Bundle Configuration Bundleéç½®ç¤ºä¾


Components ç»ä»¶ç¸å³

Process å¨å­è¿ç¨ä¸æ§è¡å½ä»¤
Asset ç®¡çéæèµæºã
Serializer åºåååååºåå
Event Dispatcher äºä»¶è°åº¦ï¼äºä»¶æ´¾é£ï¼
Workflow å·¥ä½æµ
Stopwatch æ§è½è°è¯ï¼æ¶é´ååå­ï¼å¯åç»ï¼
Finder æä»¶åç®å½æ¥æ¾
Filesystem å¯¹æä»¶ç³»ç»åäºé¢åå¯¹è±¡çå°è£
Dotenv è®¾ç½®ç¯å¢åé
Ldap LDAP serverè¿æ¥ç¸å³
Config éç½®æä»¶ç»ä»¶ï¼æ¯æYAML, XML, INIæ ¼å¼ææ°æ®åºã
Debug æ¹ä¾¿è°è¯çç»ä»¶
VarDumper è°è¯æ¶æå°ä¿¡æ¯çç»ä»¶


Bundles Note ç¬¬ä¸æ¹bundleä½¿ç¨ç¬è®°

DoctrineFixturesBundle	åå§åæ°æ®Bundleç¬è®°


symfony coding standard Symfonyç¼ç è§è

code conventions ä»£ç çº¦å®
code standards ä»£ç æ å


Others å¶ä»æé¡¹

Version Symfonyçæ¬æ¥ç
Upload File æä»¶ä¸ä¼ ç¤ºä¾
Cookie cookieç¸å³
Session sessionç¸å³
parameters.yml.dist éç½®parameters.ymlä¸æ´æ°
Clear Cache In Controller
Symfony Performance
symfony tips and tricks
Loggeréç½®éè¯¯æ¥å¿
Customize Error Pages èªå®ä¹éè¯¯é¡µé¢
symfony 3.3 features
symfony 3.4 features
web server configuration


Webpack Encore Webpack Encoreç¸å³

Webpack Encore Webpack Encoreä»ç»
Webpack Encore Example Webpack Encoreä½¿ç¨ç¤ºä¾


Symfony4 sf4ç¸å³

flex
maker-bundle
recipes-contrib
recipes


Symfony 1.x

symfony1.4 symfony1.4ç¬è®°


Varnish symfonyä½¿ç¨Varnishå éç½ç«
Deployment

proxies è®¾ç½®ä»£ç
symfony deploy symfonyé¡¹ç®é¨ç½²ææ¡£




chrome extensions
MySQL

MySQL join
MySQL functions
MySQL explain
MySQL table design
MySQL table index
my confguire å¸¸ç¨çéç½®é¡¹
MySQL Optimize
MySQL where
mysqldump
Innodb
master slave ä¸»ä»éç½®
grant
sql_mode SQL MODEè®¾ç½®ä¸ä»ç»
update root password
windows mysql windowsä¸å®è£mysql
DROP INDEX
Atlas Atlas (MySQL proxy) ä½¿ç¨
MySQL 8 windows install MySQL8å¨windowsä¸çå®è£
MySQL8 authentication pluginMySQL8å¯ç éªè¯æä»¶æ´æ¢åï¼é®é¢è§£å³åæ³
show processlist æ¥çæ­£å¨è¿è¡ççº¿ç¨


composer

composer basic composeråºç¡ä½¿ç¨
composer config composeréç½®ç¸å³
composer versions composeråçæ¬çº¦å®
recover composer.json æ¢å¤composer.json


zend studio
guzzle http
silex
linux

basic
network configure
nohup
sudo
crontab
package management
rsync
CentOS Local yum repo
log view
netstat
telnet
iptables
tar
df & du
scp
rz & sz
iconv
Aliyunæå¡å¨éç½®IPV6
chinese support ä¸­ææ¯æ
fdisk Linuxä¸ç£çæè½½


Go

gofmt vs go fmt
Compiler Directives
for select
string å­ç¬¦ä¸²æä½ç¸å³
string number æ°å­ä¸å­ç¬¦ä¸²ä¹é´çè½¬æ¢
number base conversionè¿å¶è½¬æ¢
vgo çæ¬æ§å¶
Byte Order å­èåº
Standard library æ ååºç¬è®°

strconv
binary
hex 16è¿å¶æä½å


Others Library å¶ä»ç±»åºç¬è®°
windowsä¸å¼å

call cmd.exe è°ç¨cmd.exeå¹¶éèçªå£


Package Management åç®¡çç¸å³

go modules
athens


Fatal Error å¸¸è§çfatal error

fatal error: concurrent map read and map writeå¹¶åè¯»åmapéè¯¯




redis

basic redisåºç¡
redis windowsrediså¨windowsä¸çä½¿ç¨
redis install Redisæºç ç¼è¯å®è£
master slave rediséç½®ä¸»ä»
redis.conf rediséç½®æä»¶ä»ç»
Predis VS phpredis Predisä¸phprediså¯¹æ¯


gitç¸å³

git branch gitåæ¯ç¸å³
git tag gitæ ç­¾ç¸å³
rm commit log
git ssh git sshéç½®
fork sync forkä»åºä¸åä»åæ­¥
Github Github cloneæ¢éç½®
git update gitåçº§
rm git index ç§»é¤æä»¶æç®å½çgitç´¢å¼
git recover gitè¿åæä¸ªæäº¤ID
Gogs Gogsä»£ç å¹³å°
Gitea Gitea(Gogsçä¸ä¸ªåé)


javascript

json convert
flexible
Mobile Image Upload
console
knockoutjs
vuejs
ActiveX Objectå¤æ­å¯¹è±¡æ¯å¦å­å¨çæ¹æ³
requirejs requrejså¼å¥jsãcssãfontsç­
art template art-templateæ¨¡æ¿å¼æ


framework7
markdown
yii2
select2
discuz
destoon
CodeIgniter
cakephp
yaf
yar
PHP

PHP Extension Install PHPæ©å±ç¼è¯å®è£
Memcached PHP Memcachedæ©å±å®è£
oci8PHP Oracleè¿æ¥æ©å±
Socket
control structures alternative syntax æµç¨æ§å¶çæ¿ä»£è¯­æ³
SOAP è°ç¨SOAPæå¡
preg_match VS preg_match_all æ­£åå¹éå¯¹æ¯
PHP Functions PHPå¸¸ç¨å½æ°
PHP Extensions PHPå¸¸ç¨æ©å±


PHP code
Shell

deploy.sh é¨ç½²é¡¹ç®shellèæ¬
network configure
exit codeéåºç 
backup.sh å¤ä»½é¡¹ç®shellèæ¬


Nginx

nginx basic nginxåºç¡
nginx conf nginx.confæ³¨éç
vhost conf vhostéç½®ç¤ºä¾
proxy_pass ä»£çè½¬å
ssl SSLéç½®ç¤ºä¾
syntax éç½®è¯­æ³
nginx errors å¸¸è§éè¯¯åä¿®å¤åæ³


Code::Blocks

Code::Blocks shortcut


Ubuntu

å¼å¯sshdæå¡
é²ç«å¢


svg
wechat
FFmpeg

FFmpeg install  ç¼è¯å®è£FFmpeg
PHP-FFmpeg PHP-FFmpegç±»åº


OAuth 2.0

rfc 6749
Go

github.com/golang/oauth2
github.com/dexidp/dex
github.com/ory/fosite


PHP


Modbus

SSCOMä¸²å£è°è¯è½¯ä»¶


CSS3

rem


webpack
vuejs
HAProxy
phpStudy  phpStudyåçº§php&MySQL
windows

taskkill æè¿ç¨


assemblyæ±ç¼è¯­è¨
CEF
VisualStudio

InstallShield


java

eclipseeclipseç¸å³
jar jaråç¼è¯
jdk jdkå®è£
tomcatTomcatå®è£


xunsearch
mac macç¸å³

keyboardç³»ç»å¿«æ·é®
chrome Chromeå¿«æ·é®


MSSQL

install php sqlsrv extension å®è£sqlsrvæ©å±


Oracle Oracleæ°æ®åºç¸å³

mac docker oracle macä¸éè¿dockerå®è£Oracle
SQL errors SQLéè¯¯ç¬è®°


DB æ°åæ°æ®ç¸å³

TiDBå¼æºåå¸å¼ NewSQL å³ç³»åæ°æ®åº
RadonDB äºåççMySQLæ°æ®åº,å¯ä»¥æ éæ©å±
influxdb å¼æºæ¶åºåæ°æ®åº
vitess æ°æ®åºä¸­é´ä»¶ï¼ç¨äºé¨ç½²ãæ©å±åç®¡çå¤§åMySQLå®ä¾éç¾¤ã


hadoop hadoopåå¸å¼è®¡ç®å¹³å°
TCP/IP TCP/IPåè®®ç¸å³

MQTT æ¶æ¯éåé¥æµä¼ è¾åè®®


Docker Dockerç¸å³
OA

file2pdf æä»¶è½¬PDF
install fontså®è£ä¸­æå­ä½


JavaBridge
ios

xcode


Securityä»£ç å®å¨

APPæ¥å£å®å¨è®¾è®¡è¦ç¹
æºä»£ç å®å¨å®¡è®¡

cobra




æºä»£ç å®å¨å®¡è®¡

cobra


ç¨æ·è®¤è¯ä¸ææ

åç¹ç»å½SSO
CAS
OAuth2


æ¶æ¯éå

nsq
RabbitMQ
Kafka
ZeroMQ
ActiveMQ
RocketMQ


ZooKeeper

åºæ¬æ¦å¿µ
å¸ååºç¨åºæ¯


Erlang
Scala
Kotlin
flutter
Go & PHP

goridge
roadrunner
Spiral Framework
github.com/VKCOM/noverify  Pretty fast linter (code static analysis utility) for PHP


crawler ç¬è«ç¸å³

selenium

github.com/SeleniumHQ/selenium


PHP

github.com/FriendsOfPHP/Goutte Goutte, a simple PHP Web Scraper
github.com/symfony/dom-crawler The DomCrawler component eases DOM navigation for HTML and XML documents.
github.com/symfony/browser-kit The BrowserKit component simulates the behavior of a web browser, allowing you to make requests, click on links and submit forms programmatically.
github.com/symfony/css-selector The CssSelector component converts CSS selectors to XPath expressions.
github.com/owner888/phpspider


Go

github.com/gocolly/colly Elegant Scraper and Crawler Framework for Golang
github.com/henrylee2cn/pholcus Pholcus is a distributed, high concurrency and powerful web crawler software.
github.com/PuerkitoBio/gocrawl Polite, slim and concurrent web crawler.
github.com/MontFerret/ferret Declarative web scraping





",28
VagnerBomJesus/MyFinances,Java,"My Finances
Meu Projeto Android
My Finaces->Ã© uma aplicaÃ§Ã£o mÃ³vel desenvolvida para os dispositivos Android ""atÃ© 4.0.3 versÃ£o Android"" que permite gerenciar as finanÃ§as pessoais ""despesas e receitas"".
My Objectivo do app
Â  Â  Â  Â  Â  Â  Â  Â Â  Â  Â  Â  Â  Â  Â  Â ->gerenciar as despesas e receitas por meio de banco de dados SQLite.
Â  Â  Â  Â  Â  Â  Â  Â Â  Â  Â  Â  Â  Â  Â  Â -> interface amigÃ¡vel. 
Â  Â  Â  Â  Â  Â  Â  Â Â  Â  Â  Â  Â  Â  Â  Â -> Adicionar registros (despesa ou receita) extremamente rÃ¡pido. 
Â  Â  Â  Â  Â  Â  Â  Â Â  Â  Â  Â  Â  Â  Â  Â -> Categorizar o tipo de despesa e receita. 
Â  Â  Â  Â  Â  Â  Â  Â Â  Â  Â  Â  Â  Â  Â  Â -> Adicionar novas categorias. 
Â  Â  Â  Â  Â  Â  Â  Â Â  Â  Â  Â  Â  Â  Â  Â -> Visualizar um relatÃ³rio de despesas e receitas diÃ¡rias, mensais e anuais. 
",3
b3log/symphony,Java,"


ä¸ä¸ä»£çç¤¾åºç³»ç»ï¼ä¸ºæªæ¥èæå»º
















Â Â 
Â Â 
Â Â 


ç®ä»
Symphonyï¼[ËsÉªmfÉni]ï¼n.äº¤åä¹ï¼æ¯ä¸ä¸ªç°ä»£åçç¤¾åºå¹³å°ï¼å ä¸ºå®ï¼

å®ç°äºé¢ååå®¹è®¨è®ºçè®ºå
å®ç°äºé¢åç¥è¯é®ç­çç¤¾åº
åå«äºé¢åç¨æ·åäº«ãäº¤åãæ¸¸æçç¤¾äº¤ç½ç»
100% å¼æº

æ¬¢è¿å° Sym å®æ¹è®¨è®ºåºäºè§£æ´å¤ã
å¨æº
å¾å¤ç¤¾åºè®ºåç³»ç»ï¼

çé¢é£æ ¼èå¼ï¼æ²¡æè·ä¸æ¶ä»£åå±çæ­¥ä¼
ç¼ºå°åæ°ãå¥½ç©çç¹æ§ï¼ç¼ºå°ç°ä»£åçäº¤äºåç´ åç¨æ·ä½éª
ç¼ºä¹èèå®éè¿è¥éæ±ï¼ç®¡çåè½è¿äºåä¸
ç»èä¸å¤ç²¾è´ãç¼ºä¹é¿æç»´æ¤

å®¢æ·æ¡ä¾
ç¤¾åºçï¼

å®½å®¢ç½
AIQ-æºå¨å­¦ä¹ 
è®¸æITå
å¤å°å¯
çªç©æ´¾ | åæ¬¢æ¸¸ç©  ç­ç±çæ´»  ä¹äºåäº«ï¼
ä¿©ç´ç½
å¬é¨è½©
èºèµæ RPAï¼åç¨ææï¼
åæç¤¾åºï¼åç¨ææï¼
ç¥å·é¦é¦ï¼åç¨ææï¼
......

åä¸çï¼

é»å®¢æ´¾
ITéå²
æ±æ¡ç½
ä¹¾å­¦é¢
GeeCallæå®¢ç¤¾åº
éè¶ç²¾æäºç¤¾åº
......

åè½

Sym ç®ä»å¹»ç¯ç
Sym åè½ç¹èå¾

çé¢
ä»¥ä¸æªå¾æ¥èª Sym åä¸çã
é¦é¡µ

åè¡¨

å¸å­

åå¸

ç¨æ· - PC ç«¯

ç¨æ· - ç§»å¨ç«¯



å®è£
åå¨ MySQL ä¸­æå¨å»ºåºï¼åºå symphonyï¼å­ç¬¦éä½¿ç¨ utf8mb4ï¼æåºè§å utf8mb4_general_ciï¼ï¼ç¶åæç§å¦ä¸æ¹å¼ä¹ä¸å¯å¨æå¡ã
war åå¯å¨
ä¸è½½ææ°ç Sym åè§£åï¼è¿å¥è§£åç®å½æ§è¡ï¼

Windows: java -cp ""WEB-INF/lib/*;WEB-INF/classes"" org.b3log.symphony.Starter
Unix-like: java -cp ""WEB-INF/lib/*:WEB-INF/classes"" org.b3log.symphony.Starter

å¦æè¦å° war åé¨ç½²å° Servlet å®¹å¨ä¸­å¯å¨è¯·åèå®è£æåã
Docker é¨ç½²
è·åææ°éåï¼
docker pull b3log/symphony
å¯å¨å®¹å¨ï¼
docker run --detach --name sym --network=host \
    --env RUNTIME_DB=""MYSQL"" \
    --env JDBC_USERNAME=""root"" \
    --env JDBC_PASSWORD=""123456"" \
    --env JDBC_DRIVER=""com.mysql.cj.jdbc.Driver"" \
    --env JDBC_URL=""jdbc:mysql://127.0.0.1:3306/symphony?useUnicode=yes&characterEncoding=UTF-8&useSSL=false&serverTimezone=UTC"" \
    b3log/symphony --listen_port=8080 --server_scheme=http --server_host=localhost 
ä¸ºäºç®åï¼ä½¿ç¨äºä¸»æºç½ç»æ¨¡å¼æ¥è¿æ¥ä¸»æºä¸ç MySQLã
å¯å¨åæ°è¯´æï¼

--listen_portï¼è¿ç¨çå¬ç«¯å£
--server_schemeï¼æç»è®¿é®åè®®ï¼å¦æåä»£æå¡å¯ç¨äº HTTPS è¿éä¹éè¦æ¹ä¸º https
--server_hostï¼æç»è®¿é®ååæå¬ç½ IPï¼ä¸è¦å¸¦ç«¯å£å·

å®æ´å¯å¨åæ°çè¯´æå¯ä»¥ä½¿ç¨ -h æ¥æ¥çã
ææ¡£

ãæé®çæºæ§ãç²¾è¯»æ³¨è§£ç
Sym å®è£æå
Sym éç½®é¡¹è¯´æ
Sym è´¡ç®æå

ææ

ç¤¾åºçï¼ä½¿ç¨ AGPLv3 å¼æºï¼å¦æä½ éæ©ä½¿ç¨ç¤¾åºçï¼åå¿é¡»å®å¨éµå® AGPLv3 çç¸å³æ¡æ¬¾
åä¸çï¼æä¾å®æ´æºç ä»¥ä¾¿äºå¼ï¼æ¥ä»· Â¥20000
äºæå¡ï¼æä¾å¼ç®±å³ç¨çäºç«¯æå¡ï¼æ¯å¹´ Â¥5000

å³äºåä¸çåç¤¾åºççå¯¹æ¯è¯·çè¿éï¼ä¼ä¸ç½ç«ãç»è¥æ§ç½ç«ãä»¥è¥å©ä¸ºç®çæå®ç°çå©çç½ç«è¯·è´­ä¹°åä¸çã
æ¬¢è¿èç³» QQ 845765 æé®ç®± d@b3log.org è¿è¡ç»èå¨è¯¢ã
ç¤¾åº

è®¨è®ºåº
æ¥åé®é¢

é¸£è°¢

jQueryï¼åç«¯ JavaScript å·¥å·åº
Vditorï¼ æµè§å¨ç«¯ç Markdown ç¼è¾å¨
Highlight.jsï¼åç«¯ä»£ç é«äº®åº
pjaxï¼pushState + ajax = pjax
MathJaxï¼åç«¯æ°å­¦å¬å¼æ¸²æå¼æ
Sassï¼åç«¯ CSS å¤çå·¥å·
jsoupï¼Java HTML è§£æå¨
flexmarkï¼Java Markdown å¤çåº
Apache Commonsï¼Java å·¥å·åºé
Joddï¼Java å·¥å·åºé
Latkeï¼ä»¥ JSON ä¸ºä¸»ç Java Web æ¡æ¶

å®å¨æ¹é¢ç¹å«æè°¢ï¼

ç±³æ¯ç¹å®å¨å¢é
@gh0stkey
@SeagullGR
é¿äº­ç§æ


å¼æºé¡¹ç®æ¨è

å¦æä½ éè¦æ­å»ºä¸ä¸ªä¸ªäººåå®¢ç³»ç»ï¼å¯ä»¥èèä½¿ç¨ Solo
å¦æä½ éè¦æ­å»ºä¸ä¸ªå¤ç¨æ·åå®¢å¹³å°ï¼å¯ä»¥èèä½¿ç¨ Pipe
æ¬¢è¿å å¥æä»¬çå°ä¼å¼æºç¤¾åºï¼è¯¦æè¯·çè¿é

",11470
